{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some concrete examples of Network Machine Learning tasks, along with the techniques that can tackle them which we'll explore in this book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding working groups in your company\n",
    "Community detection is a major focus in network science, and many techniques have been proposed to accomplish this. We'll primarily use Adjacency Spectral Embedding or Laplacian Spectral Embedding (6.3, Spectral Embedding Methods, and throughout the book) combined with K-Means Clustering or a Gaussian Mixture Model to reconstruct labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from graspologic.simulations import sbm\n",
    "from graspologic.embed import AdjacencySpectralEmbed as ASE\n",
    "import numpy as np\n",
    "from graspologic.plot import pairplot_with_gmm\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from graphbook_code import cmaps\n",
    "\n",
    "# Make network and embed\n",
    "B = np.array([[0.8, 0.1, .1], \n",
    "              [0.1, 0.8, .1],\n",
    "              [0.1, 0.1, .8]])\n",
    "n = [25, 25, 25]\n",
    "A, labels = sbm(n, p=B, return_labels=True)\n",
    "X = ASE(n_components=3).fit_transform(A)\n",
    "\n",
    "# plot\n",
    "gmm = GaussianMixture(n_components=3, covariance_type='full').fit(X)\n",
    "graph = pairplot_with_gmm(X, gmm, cluster_palette=cmaps[\"qualitative\"],  label_palette=cmaps[\"qualitative\"], title=\"Working groups in a company, found from a network (simulated)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the hemisphere a new neuron you haven't seen before belongs to\n",
    "This is called out-of-sample embedding, and is typically done by using the results from a previous embedding along with a trick involving the moore-penrose pseudoinverse (8.5, Out-of-Sample Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from graspologic.utils import remove_vertices\n",
    "from graspologic.plot import pairplot\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate parameters\n",
    "nodes_per_community = 100\n",
    "P = np.array([[0.8, 0.2],\n",
    "              [0.2, 0.8]])\n",
    "\n",
    "# Generate an undirected Stochastic Block Model (SBM)\n",
    "undirected, labels_ = sbm(2*[nodes_per_community], P, return_labels=True)\n",
    "labels = list(labels_)\n",
    "\n",
    "# Grab out-of-sample vertices\n",
    "oos_idx = 0\n",
    "oos_labels = labels.pop(oos_idx)\n",
    "A, a = remove_vertices(undirected, indices=oos_idx, return_removed=True)\n",
    "\n",
    "# Generate an embedding with ASE\n",
    "ase = ASE(n_components=2)\n",
    "X_hat_ase = ase.fit_transform(A)\n",
    "\n",
    "# predicted latent positions\n",
    "w_ase = ase.transform(a)\n",
    "\n",
    "def plot_oos(X_hat, oos_vertices, labels, oos_labels, title):\n",
    "    # Plot the in-sample latent positions\n",
    "    plot = pairplot(X_hat, labels=labels, title=title)\n",
    "\n",
    "    # generate an out-of-sample dataframe\n",
    "    oos_vertices = np.atleast_2d(oos_vertices)\n",
    "    data = {'Type': oos_labels,\n",
    "          'Dimension 1': oos_vertices[:, 0],\n",
    "          'Dimension 2': oos_vertices[:, 1]}\n",
    "    oos_df = pd.DataFrame(data=data)\n",
    "\n",
    "    # update plot with out-of-sample latent positions,\n",
    "    # plotting out-of-sample latent positions as stars\n",
    "    plot.data = oos_df\n",
    "    plot.hue_vals = oos_df[\"Type\"]\n",
    "    plot.map_offdiag(sns.scatterplot, s=500,\n",
    "                     marker=\"*\", edgecolor=\"black\")\n",
    "    plot.tight_layout()\n",
    "    return plot\n",
    "\n",
    "# Plot all latent positions\n",
    "title = \"Star represents previously-unseen neuron (simulated data)\"\n",
    "plot_oos(X_hat_ase, w_ase, labels=labels, oos_labels=[0], title=title);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a subset of connecting flights to find the rest of them\n",
    "This a problem called vertex nomination, where you have a network along with a few nodes that are interesting to you, and want to find the rest of the interesting nodes (8.4, Single-Network Vertex Nomination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from graspologic.nominate import SpectralVertexNomination\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# construct network\n",
    "n = 100\n",
    "B = np.array([[0.5, 0.35, 0.2],\n",
    "              [0.35, 0.6, 0.3],\n",
    "              [0.2, 0.3, 0.65]])\n",
    "\n",
    "# Create a network from and SBM, then embed\n",
    "A, labels = sbm([n, n, n], p=B, return_labels=True)\n",
    "ase = ASE()\n",
    "X = ase.fit_transform(A)\n",
    "\n",
    "# Let's say we know that the first five nodes belong to the first community.\n",
    "# We'll say that those are our seed nodes.\n",
    "seeds = np.ones(5)\n",
    "\n",
    "# grab a set of seed nodes\n",
    "memberships = labels.copy() + 1\n",
    "mask = np.zeros(memberships.shape)\n",
    "seed_idx = np.arange(len(seeds))\n",
    "mask[seed_idx] = 1\n",
    "memberships[~mask.astype(bool)] = 0\n",
    "\n",
    "# find the latent positions for the seed nodes\n",
    "seed_latents = X[memberships.astype(bool)]\n",
    "\n",
    "# Choose the number of nominations we want for each seed node\n",
    "svn = SpectralVertexNomination(n_neighbors=5)\n",
    "svn.fit(A)\n",
    "\n",
    "# get nominations and distances for each seed index\n",
    "nominations, distances = svn.predict(seed_idx)\n",
    "\n",
    "color = ['red', 'lightgreen', 'gold', 'cyan', 'pink']\n",
    "seed_color = ['firebrick', 'green', 'tan', 'darkblue', 'purple']\n",
    "\n",
    "\n",
    "fix, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "for i, seed_group in enumerate(nominations.T):\n",
    "    neighbors = X[seed_group]\n",
    "    x, y = neighbors[:, 0], neighbors[:, 1]\n",
    "    ax.scatter(x, y, c=seed_color[i], s=10)\n",
    "    \n",
    "ax.scatter(x=seed_latents[:, 0], y=seed_latents[:, 1], marker='*', s=200, c=color, alpha=1)\n",
    "    \n",
    "ax.set_title(\"Original flights (stars) and similar flights\", loc=\"left\", fontsize=24);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding a small subset of people in your social network that are representative of the whole network\n",
    "This is a problem called signal subgraph estimation, which we renamed to signal subnetwork estimation. The general idea is that you have two different networks, and you want to find the subset of nodes which carry all the information about the differences between your networks. We talk about this in 5.6, Network Models with Covariates, and then again in 10.2, Testing for Significant Edges, and 10.3, Testing for Significant Nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO: thing for 8.2, testing for differences between groups of edges  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using extra data like house size and price to find more precise groups of houses in a house buying/selling network\n",
    "This is called joint representation learning, and is talked about extensively in 6.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "from graspologic.embed import CovariateAssistedEmbed as CASC\n",
    "from graspologic.embed import LaplacianSpectralEmbed as LSE\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from graphbook_code import plot_latents\n",
    "\n",
    "# Start with some simple parameters\n",
    "N = 1500  # Total number of nodes\n",
    "n = N // 3  # Nodes per community\n",
    "p, q = .3, .15\n",
    "B = np.array([[.3, .3, .15],\n",
    "              [.3, .3, .15],\n",
    "              [.15, .15, .3]])  # Our block probability matrix\n",
    "\n",
    "# Make our Stochastic Block Model\n",
    "A, labels = sbm([n, n, n], B, return_labels = True)\n",
    "\n",
    "def make_community(a, b, n=500):\n",
    "    return beta.rvs(a, b, size=(n, 30))\n",
    "\n",
    "def gen_covariates():\n",
    "    c1 = make_community(2, 5)\n",
    "    c2 = make_community(2, 2)\n",
    "    c3 = make_community(2, 2)\n",
    "\n",
    "    covariates = np.vstack((c1, c2, c3))\n",
    "    return covariates\n",
    "    \n",
    "\n",
    "def embed(matrix, *, dimension):\n",
    "    latents, _, _ = randomized_svd(matrix, n_components=dimension)\n",
    "    return latents\n",
    "\n",
    "# Generate a covariate matrix\n",
    "Y = gen_covariates()\n",
    "casc = CASC(n_components=2)\n",
    "X = casc.fit_transform(A, Y)\n",
    "X_A = LSE(n_components=2).fit_transform(A)\n",
    "X_Y = embed(Y, dimension=2)\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15,5))\n",
    "plot_latents(X_A, title=\"House groups when we only use the network\", \n",
    "             labels=labels, ax=axs[0])\n",
    "plot_latents(X_Y, title=\"House groups when we only use extra data\", \n",
    "             labels=labels, ax=axs[1]);\n",
    "plot_latents(X, title=\"House groups when we use both\", \n",
    "             labels=labels, ax=axs[2])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing sets of mouse brain networks as a single point in space to compare their overall similarities and differences\n",
    "To do this, you'd jointly embed all of your brain networks at once using an Omnibus Embedding, then you'd create a pairwise difference matrix for each embedding. You'd then embed the pairwise distance matrix using Classic Multidimensional Scaling. This isn't discussed at length in this book, but is mentioned in 4.2.4, Bag of Networks. You can look up Multiscale Comparative Connectomics by Gopalakrishnan et al., 2021 to see how to do this in more depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from graspologic.embed import OmnibusEmbed as OMNI\n",
    "from graspologic.embed import ClassicalMDS\n",
    "from graphbook_code import draw_cartesian\n",
    "\n",
    "def make_network(*probs, n=100, return_labels=False):\n",
    "    pa, pb, pc, pd = probs\n",
    "    P = np.array([[pa, pb], \n",
    "                  [pc, pd]])\n",
    "    \n",
    "    return sbm([n, n], P, return_labels=return_labels)\n",
    "\n",
    "n = 100\n",
    "p1, p2, p3 = .12, .06, .03\n",
    "\n",
    "first_group = []\n",
    "for _ in range(6):\n",
    "    network = make_network(p1, p3, p3, p1)\n",
    "    first_group.append(network)\n",
    "    \n",
    "second_group = []\n",
    "for _ in range(12):\n",
    "    network = make_network(p2, p3, p3, p2)\n",
    "    second_group.append(network)\n",
    "\n",
    "# Find a euclidean location for the nodes of all of our networks\n",
    "omni = OMNI(n_components=2)\n",
    "omni_embedding = omni.fit_transform(first_group + second_group)\n",
    "\n",
    "# embed each network representation into a 2-dimensional space\n",
    "cmds = ClassicalMDS(2)\n",
    "cmds_embedding = cmds.fit_transform(omni_embedding)\n",
    "\n",
    "# Find and normalize the dissimilarity matrix\n",
    "distance_matrix = cmds.dissimilarity_matrix_ / np.max(cmds.dissimilarity_matrix_)\n",
    "\n",
    "labels = [0]*6 + [1]*12\n",
    "ax = draw_cartesian(xrange=(-1, 1), yrange=(-1, 1))\n",
    "plot = plot_latents(cmds_embedding, ax=ax, labels=labels)\n",
    "plot.set_title(\"Simulated sets of mouse brain networks as single points in space\", y=1.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figuring out which users match between the facebook social network and the twitter social network, without knowing their names\n",
    "This problem has been studied extensively, and is called graph matching. You can find an in-depth discussion of it in 9.3, Graph Matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from graspologic.simulations import er_np\n",
    "from graspologic.match import GraphMatch\n",
    "import networkx as nx\n",
    "from graphbook_code import cmaps\n",
    "\n",
    "def rm_ticks(ax, x=False, y=False, **kwargs):\n",
    "    if x is not None:\n",
    "        ax.axes.xaxis.set_visible(x)\n",
    "    if y is not None:\n",
    "        ax.axes.yaxis.set_visible(y)\n",
    "    sns.despine(ax=ax, **kwargs)\n",
    "\n",
    "n = 5\n",
    "p = 0.5\n",
    "\n",
    "# draw a network, then shuffle\n",
    "A = er_np(n=n, p=p)\n",
    "node_shuffle_input = np.random.permutation(n)\n",
    "B = A[node_shuffle_input][:, node_shuffle_input]\n",
    "\n",
    "gmp = GraphMatch()\n",
    "gmp = gmp.fit(A,B)\n",
    "B_ = B[gmp.perm_inds_][:, gmp.perm_inds_]\n",
    "\n",
    "A_nx = nx.from_numpy_matrix(A)\n",
    "B_nx = nx.from_numpy_matrix(B)\n",
    "\n",
    "# explicitly set positions\n",
    "pos = {0: (0, 0), 1: (-1, 0.3), 2: (2, 0.17), 3: (4, 0.255), 4: (5, 0.03)}\n",
    "\n",
    "options = {\n",
    "    \"font_size\": 36,\n",
    "    \"node_size\": 3000,\n",
    "    \"node_color\": \"white\",\n",
    "    \"edgecolors\": \"black\",\n",
    "    \"linewidths\": 5,\n",
    "    \"width\": 5,\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "nx.draw_networkx(A_nx, pos, ax=axs[0], **options)\n",
    "# Set margins for the axes so that nodes aren't clipped\n",
    "axs[0].margins(0.20)\n",
    "axs[0].set_title(\"Facebook Network\")\n",
    "axs[0].axis('off')\n",
    "\n",
    "pos_b = {node_shuffle_input[i]: loc for i, loc in pos.items()}\n",
    "# pos_b = {2: (0, 0), 1: (-1, 0.3), 4: (2, 0.17), 3: (4, 0.255), 0: (5, 0.03)}\n",
    "nx.draw_networkx(B_nx, pos_b, ax=axs[1], **options)\n",
    "axs[1].margins(0.20)\n",
    "axs[1].set_title(\"Twitter Network\")\n",
    "axs[1].axis('off')\n",
    "\n",
    "# add second arrow\n",
    "arrow_ax = fig.add_axes([1, .5, .3, .1])\n",
    "rm_ticks(arrow_ax, left=True, bottom=True)\n",
    "plt.arrow(x=0, y=0, dx=1, dy=0, width=.1, color=\"black\") \n",
    "\n",
    "# add second arrow\n",
    "match_ax = fig.add_axes([1.2, 0.1, .5, .8])\n",
    "rm_ticks(match_ax, left=True, bottom=True)\n",
    "\n",
    "match_ax = sns.heatmap(gmp.perm_inds_[:, None], cmap=cmaps[\"sequential\"], ax=match_ax, cbar=False, \n",
    "                 xticklabels=1, yticklabels=1, annot=True)\n",
    "match_ax.set_aspect(1.5)\n",
    "match_ax.set_title(\"Node correspondence between \\ntwitter and facebook network\", y=1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the day that the Federal Reserve tightened rates using a timeseries of stock market networks\n",
    "This is called timeseries anomaly detection, and is used when you have a timeseries of the same network, and you're trying to figure out when the probability distribution it was drawn from changed (10.1, Anomaly Detection for Timeseries of Networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from graphbook_code import heatmap, cmaps\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from graspologic.simulations import rdpg\n",
    "\n",
    "\n",
    "def gen_timepoint(X, perturbed=False, n_perturbed=20):\n",
    "    if perturbed:\n",
    "        X = np.squeeze(X)\n",
    "        baseline = np.array([1, -1, 0])\n",
    "        delta = np.repeat(baseline, (n_perturbed//2, \n",
    "                                     n_perturbed//2, \n",
    "                                     nodes-n_perturbed))\n",
    "        X += (delta * .15)\n",
    "    if X.ndim == 1:\n",
    "        X = X[:, np.newaxis]\n",
    "    A = rdpg(X)\n",
    "    return A\n",
    "    \n",
    "\n",
    "time_points = 4\n",
    "nodes = 100\n",
    "X = np.random.uniform(.2, .8, size=nodes)\n",
    "\n",
    "# normal time points\n",
    "networks = []\n",
    "for time in range(time_points - 1):\n",
    "    A = gen_timepoint(X)\n",
    "    networks.append(A)\n",
    "\n",
    "# perturbed time point\n",
    "A = gen_timepoint(X, perturbed=True)\n",
    "networks.insert(2, A)\n",
    "    \n",
    "networks = np.array(networks)\n",
    "\n",
    "fig = plt.figure();\n",
    "\n",
    "# adjacency matrices\n",
    "perturbed_point = 2\n",
    "for i in range(time_points):\n",
    "    if i != 2:\n",
    "        ax = fig.add_axes([.02*i, -.02*i, .8, .8])\n",
    "    else:\n",
    "        ax = fig.add_axes([.02*i+.8, -.02*i, .8, .8])\n",
    "    ax = heatmap(networks[i], ax=ax, cbar=False)\n",
    "    if i == 0:\n",
    "        ax.set_title(\"Three Normal Stock Days\", loc=\"left\", fontsize=16)\n",
    "    if i == 2:\n",
    "        ax.set_title(\"Anomaly Day\", loc=\"left\", fontsize=16)\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor(\"red\")\n",
    "    rm_ticks(ax, top=False, right=False)\n",
    "    \n",
    "plt.figtext(1, -.3, \"Figure 8.1\")\n",
    "fig.suptitle(\"Stock Network Timeseries Data (Simulated)\", fontsize=24, x=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figuring out if two estimated brain networks come from the same person\n",
    "This is hypothesis testing on networks, where you're trying to figure out if two networks were drawn from the same probability distribution (9.1, Two-Sample Hypothesis Testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from graspologic.inference import latent_distribution_test\n",
    "from graspologic.utils import symmetrize\n",
    "\n",
    "n_components = 4 # the number of embedding dimensions for ASE\n",
    "P = np.array([[0.9, 0.11, 0.13, 0.2],\n",
    "              [0, 0.7, 0.1, 0.1],\n",
    "              [0, 0, 0.8, 0.1],\n",
    "              [0, 0, 0, 0.85]])\n",
    "\n",
    "P = symmetrize(P)\n",
    "csize = [32] * 4\n",
    "A = sbm(csize, P)\n",
    "X = ASE(n_components=n_components).fit_transform(A)\n",
    "\n",
    "# generate networks from latent positions\n",
    "A1 = rdpg(X,\n",
    "          loops=False,\n",
    "          rescale=False,\n",
    "          directed=False)\n",
    "A2 = rdpg(X,\n",
    "          loops=False,\n",
    "          rescale=False,\n",
    "          directed=False)\n",
    "\n",
    "ldt_dcorr = latent_distribution_test(A1, A2, test=\"dcorr\", metric=\"euclidean\", n_bootstraps=1000)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(ldt_dcorr[2]['null_distribution'], 50)\n",
    "ax.axvline(ldt_dcorr[1], color='r')\n",
    "ax.set_title(\"Outlier p-value implying suggesting our two simulated \\nbrain networks came from the same person\".format(ldt_dcorr[0]), fontsize=16)\n",
    "ax.set_xlabel(\"test static\")\n",
    "ax.set_ylabel(\"frequency\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
