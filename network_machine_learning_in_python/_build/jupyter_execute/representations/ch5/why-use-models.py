#!/usr/bin/env python
# coding: utf-8

# # Why Use Statistical Models?
# 
# In network data science, we typically begin with a question of interest, and a network we use to answer that question. To answer this question, we will turn to statistical models. Consider the simplest possible statistical model which has been used for years: the coin flip model. Let's say we are playing a game with a gambler, and we bet one dollar. If the coin lands on heads, we get our dollar back, and an additional dollar. If the coin lands on tails, we lose our dollar. We get to watch ten coin flips before deciding whether or not to join the game. So, should we play?
# 
# A coin has a probability, which we will denote $p$, of landing on heads. Since the coin either lands on heads or tails, this means that the probability that the coin lands on tails is $1-p$. Reasonably, we might guess that the probability that this coin lands on heads is just $0.5$ (the coin has an equal chance of landing on heads and tails). Unfortunatetly, the universe is a nefarious place! We could easily construct coins which slightly favor heads (perhaps a coin with a chance of landing on heads of $0.51$) *or* a coin which slightly favors tails (perhaps a coin with a chance of landing on tails of $0.51$). 
# 
# To understand whether or not we should play this game, we turn to *statistical modelling*. A **statistical model** is a set of assumptions as to how a random system operates. The statistical model delineates what we think comes down to random chance in our system. In our coin flip example, this means that we describe the coin flip using the *Bernoulli model*, which means that the coin lands on heads with probability $p$ and tails with probability $1-p$. The statistical model is the set of all possible coins which could be used for the game.
# 
# A **random variable** is an object whose outcome comes down to random chance. In our coin flip example, the coin flip itself *is* the random variable. The coin possesses a probability $p$ of landing on heads and a probability $1-p$ of landing on tails. To learn about the coin, we conduct an *experiment*. The experiment here is watching the coin flip ten times, and observing the outcome of the flips. The outcome of the coin flip is called a *realization* of the random variable. We will never truly understand the coin flip perfectly (we can never say for sure whether the coin will definitely land on heads or tails unless it has two heads or two tails). If we observe enough realizations of coin flips, however, we might be able to describe the coin flip in a way which could work this game in our favor.
# 
# The coin flip example is obviously very trivial, but it extends directly to statistical network models which we will use for simple networks. Consider a network of $100$ students, in which each of the students attends one of two schools. We are interested in understanding whether students are more likely to be friends on a social networking site with students in their school than with students from the other school. Unlike traditional machine learning, in network machine learning we do not observe $n$ outcomes (or realizations) with $d$ dimensions. Rather, we see an adjacency matrix $A$, whose nodes are the $100$ students, and whose edges are the entries $a_{ij}$ which take a value of one if the two students $i$ and $j$ are friends on the social networking site and a value of zero if the two students are not friends on the social networking site. 
# 
# Like the coin flip example, there is randomness and uncertainty to our social network. Perhaps a pair of students might be friends in real life, but they never got around to adding each other on the social media site. Maybe our students had a fight and are no longer friends, but never bothered to delete one another as friends on the site. Other factors might exist that we don't know about (sports, hobbies, special interests) that influence whether two people are friends. Our social network might not capture all of the students, and we might be missing a large portion of the community all together. In many additional ways, our social network is noisy, and in order to address our question of interest, we need procedures which account for this uncertainty.
# 
# In machine learning, we typically encounter situations in which we have $n$ observations in $d$ dimensions. Traditional statistical models include univariate statistical models (models for data with $1$ dimension) and multivariate statistical models (models for data with $d > 1$ dimensions), which can capture this traditional data representation. These models are well suited for discovering new insights about individual observations or collections of individual observations. Why do we need special statistical models for networks? Our realizations are not $n$ disparate observations in $d$-dimensions; a realization in network machine learning **is the full network itself**, consisting of nodes, edges, and potential network attributes. We seek to model a representation of the *entire* network so that we can convey insights about properties of the network. To address our question of interest above, we need to characterize how students relate to other students in the network, not describe individual stdents. To this end, we describe our random network using sets of statistical assumptions, referred to as the **statistical network model**. The coin flip model might haave felt really simple, but we will see how we can use collections of coins to describe pretty complicated random networks throughout this chapter. We break down the key aspects of the coin flip experiment because it is so crucial:
# 
# ```{admonition} The Coin Flip Experiment
# We had the following items we were concerned with in the coin flip example:
# 1. The outcomes: The outcomes are either heads or tails. These outcomes will be denoted by the letter $x$, which takes values which are H (Heads) or T (Tails). The value $x$ is called a **realization**.
# 2. The coin which was used: The specific coin being used in the coin flip experiment has a probability $p$ of landing on heads and a probability $1 - p$ of landing on tails. We will denote the specific coin being used by the letter $\mathbf x$. The bold-faced font means that the coin being used has a random outcome (it might be heads, it might be tails) to differentiate it from the coin flips which we saw and have known outcomes indicated by $x$ (which has a fixed value, since we flipped the coin and *realized* the outcome). We don't know anything about $p$ just yet, so we can't describe the coin's specific random behavior just yet. The value $\mathbf x$ is called the **random variable**.
# 3. Feasible coins: A possible coin that could have been used in the coin flipping experiment is one which has a probability $q$ (which might be different from $p$) of landing on heads, and $1 - q$ of landing on tails. A feasible coin will be denoted by $Bern(q)$, which just means that the coin lands on heads with probability $q$ and tails with probability $1 - q$. 
# 4. The Bernoulli model: The collection of all feasible coins which could have been used. This is described by the set $\left\{Bern(q) : q \text{ is a probability between $0$ and $1$}\right\}$. This set is infinitely large, since it contains a feasible coin for *any* specified probability. The commonality between the feasible coins is that they each have a unique probability of landing on heads and a unique probability of landing on tails. The statistical model is simply the collection of all possible feasible coin which feature this commonality. For instance, there is a coin $Bern(0.1)$ which has a probability $0.1$ of landing on heads in this set, and another coin $Bern(0.9)$ which has a probabiliy $0.9$ of landing on heads in this set. 
# The specific coin being used, the random variable $\mathbf x$ which lands on heads with probability $p$, behaves *exactly* like the coin $Bern(p)$ from the statistical model. For this reason, we will say that the coin $\mathbf x$ is a $Bern(p)$ coin. 
# ```
# 
# ## Models aren't Right. Why do we Care?
# 
# It is important to clarify that we must pay careful attention to the age old aphorism attributed to George Box, a pioneering British statistician of the 20$^{th}$ century. George Box stated, "all models are wrong, but some are useful." In this sense, it is important to remember that the statistical model we select is, in practice, *never* the correct model (this holds for any aspect of machine learning, not just network machine learning). In the context of network science, this means that even if we have a model we think describes our network very well, it is *not* the case that the model we select actually describes the network precisely and correctly. Despite this, it is often valuable to use statistical models for the simple reason that assuming that a stochastic process (that is, some *random* process) which governs our data is what allows us to convey *uncertainty*. To understand the importance of leveraging uncertainty, consider the following scenarios:
# 1. Lack of information: In practice, we would never have all of the information about the system that produced the network we observe, and uncertainty can be used in place of that information. For instance, in our social network example, we might only know which school that people are from, but there are many other attributes that would impact the friend circle of a given student. We might not know things like which classes people have taken nor which grade they're in, but we would expect these facts to impact whether a given pair of people might have a higher chance of being friends. We can use uncertainty in our model to capture the fact that we don't know the classes nor grades of the students.
# 2. We might think the network is deterministic, rather than stochastic: In the extreme case, we might think that if we had *all* of the information which governs the network, then we could determine exactly what realizations would look like with perfect accuracy. Even if we knew exactly what realizations of the network might look like, this description, too, isn't likely to be very valuable. If we were to develop a model on the basis of everything, our model would be extremely complex and require a large amount of data. For instance, in our social network example, to know whether two people were friends with perfect accuracy, we might need to have intimate knowledge of every single person's life (Did they just have a fight with somebody and de-connect with that person? Did they just go to a school dance and meet someone new?). 
# 3. We learn from uncertainty and simplicity: When we do statistical inference, it is rarely the case that we prioritize a complex, convoluted model that mirrors our data suspiciously closely. Instead, we are usually interested in knowing how faithfully a simpler, more generally applicable model might describe the network. This relates directly to the concept of the bias-variance tradeoff from machine learning, in which we prefer a model which isn't too specific (lower bias) but still describes the system effectively (lower variance).
# 
# Therefore, it is crucial to incorporate randomness and uncertainty to understand network data. In practice, we select a model which is appropriate from a family of candidate models on the basis of three primary factors:
# 1. Utility: The model of interest possesses the level of refinement or complexity that we need to answer our scientific question of interest. What this means is that the coin flip model will allow us to determine whether or not we should gamble.
# 2. Estimation: The data has the level of breadth to facilitate estimation of the parameters of the model of interest. This means that we can use the outcomes of coin flips to guess what the probability that the coin will land on heads is.
# 3. Appropriateness: The model is appropriate for the data we are given. This means that there are not major factors which are unaccounted for by the statistical model, such as if the coin thrower holds a magnet which will alter the outcome of the coin flip.
# 
# For the rest of this section, we will develop intuition for the first point. Later sections will cover estimation of parameters and model selection.

# In[ ]:




