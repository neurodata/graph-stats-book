{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Use Statistical Models?\n",
    "\n",
    "Consider a social network. A common question as a scientist that we might have is how, exactly, we could describe the network in the simplest way possible. For instance, if we know nothing about the people, or how they might be connected in the social network, we might want to just say that a pair of people have a fixed probability of being friends. On the other hand, if we know people within the social network are groups of students from different schools, we might say that people from the same school have a higher probability of being friends than people from different schools.\n",
    "\n",
    "The network we actually observe (for which we have nodes, edges, and perhaps network attributes) is *not* the true network; rather, we assume that the true network is a network for which we could *never* observe completely, as each time we look at the network, we will see it slightly differently. In our social network example above, for instance, a person's true friends may not necessarily be who they are friends with on the network. Stated another way, our observed network is merely a *realization* of an underlying **random network**. We describe our random network using sets of statistical assumptions, referred to as the **statistical network model**. In this book, we typically describe networks using an approach called *generative modeling*, which means that we use models which describe *how* the random network underlying our realization could have come about. Several models also use *discrimative modeling*, in which we have a target classification task, and wish to model the probability of a data being from a particular class given an observed network.\n",
    "\n",
    "```{admonition} Comparing a Univariate Statistical Model to a Random Network Model\n",
    "The traditional framework for univariate statistical models extends to random network models. For an example of a  univariate statistical model, let's imagine we are tossing a coin 100 times, and we want to determine what the probability of the coin landing on heads is. Every time we toss the coin, we will get an outcome that we can see (did the coin land on heads, or did it land on tails?). We call the outcome of this coin toss $x$. To determine the probability of the coin landing on heads, we will assume that the outcome of the coin is random, and that each time we toss the coin, we are *realizing* a random variable $\\pmb x$. It is important to emphasize (again!) that this $\\pmb x$ is random: it doesn't take any fixed value, whereas realizations of $\\pmb x$, $x$ here, take one of two possible values: heads or tails. If a coin toss was heads the first time, when we flip the coin again, we might not get a heads the second time. Instead, we describe $\\pmb x$ using a *univariate statistical model*. For instance, we might think that $\\pmb x$ is a Bernoulli-distributed random variable, which means that if we knew the Bernoulli probability $p$, we would know that $\\pmb x$ has a $p$ chance of landing on heads. In this case, the Bernoulli distribution is the model for $\\pmb x$.\n",
    "\n",
    "In much the same way, let's think about our social network example again. We have a simple network, $A$, where the nodes represent school students in a county, and the edges represent whether a given pair of students are friends or not. Like each of the coin toss outcomes above, we get to see $A$, and know exactly what values $A$ takes. In the same way as above, we will assume that the network $A$ is a realization of a random **network** $\\pmb A$. Like the coin flip, we can describe $\\pmb A$ using a statistical model, because it is a random quantity. The friends an individual has when we realize $\\pmb A$ are random, in the sense that they may be friends with some of their actual friends, not friends with some of their actual friends, or friends with arbitrary people they came into contact with in their lives. This level of uncertainty is captured in the randomness of $\\pmb A$. This time, we will describe $\\pmb A$ using a random network model, which we will learn more about in the next few sections.\n",
    "\n",
    "Let's summarize what we learned above in a table to familiarize ourselves with the vocabulary:\n",
    "| | Coin-Toss | Social Network |\n",
    "| --- | --- | --- |\n",
    "| Observed Data | Outcome of a coin toss $x$ | Simple network $A$ |\n",
    "| Random Variable | $\\pmb x$, where $x$ is supposed is said to be a *realization* of $\\pmb x$ | random-network $\\pmb A$, where $A$ is a realization of $\\pmb A$ |\n",
    "| Statistical Model | the Bernoulli distribution | a Random Network Model |\n",
    "```\n",
    "\n",
    "## Models aren't Right. Why do we Care?\n",
    "\n",
    "It is important to clarify that we must pay careful attention to the age old aphorism attributed to George Box, a pioneering British statistician of the 20$^{th}$ century. George Box stated, \"all models are wrong, but some are useful.\" In this sense, it is important to remember that the statistical model we select is, in practice, *never* the correct model (this holds for any aspect of statistics, not just network statistics). In the context of a network, this means that even if we have a model we think describes our network very well, it is *not* the case that the model we select actually describes the network precisely and correctly. Despite this, it is often valuable to use statistical models for the simple reason that assuming that a stochastic process (that is, some *random* process) underlies our data is what allows us to convey *uncertainty*. Stated another way, even if we believe that the process underlying the network isn't random at all, we can still extract value by using a statistical model. To understand the importance of leveraging uncertainty, consider the following scenarios:\n",
    "1. Lack of information: In practice, we would never have all of the information about the underlying system that produced the network we observe, and uncertainty can be used in place of the information we don't have. For instance, in our social network example, we might only know which school that people are from, even though there are many other attributes that would impact the friend circle of a given student. We might not know things like which classes people have taken nor which grade they're in, but we would expect these facts to impact whether a given pair of people might have a higher chance of being friends. We can use uncertainty in our model to capture the fact that we don't know the classes nor grades of the students.\n",
    "2. We might think the network is deterministic, rather than stochastic: In the extreme case, we might think that if we had *all* of the information which underlies the structure of a network, then we could determine exactly what realizations would look like with perfect accuracy. Even if we knew exactly what realizations of the network might look like, this description, too, isn't likely to be very valuable. If we were to develop a model on the basis of everything, our model would be extremely complex and require a large amount of data. For instance, in our social network example, to know whether two people were friends with perfect accuracy, we might need to have intimate knowledge of every single person's life (Did they just have a fight with somebody and de-connect with that person? Did they just go to a school dance and meet someone new?). \n",
    "3. We learn from uncertainty and simplicity: When we do statistical inference, it is rarely the case that we prioritize a complex, convoluted model that mirrors our data suspiciously closely. Instead, we are usually interested in knowing how faithfully a simpler, more generally applicable, model might describe the network. This relates directly to the concept of the bias-variance tradeoff from Machine Learning, in which we prefer a model which isn't too specific (lower bias) but still describes the system effectively (lower variance).\n",
    "\n",
    "Therefore, it is crucial to incorporate randomness and uncertainty to understand network data. In practice, we select a model which is appropriate from a family of candidate models on the basis of three primary factors:\n",
    "1. Utility: The model of interest possesses the level of refinement or complexity that we need to answer our scientific question of interest,\n",
    "2. Estimation: The data has the level of breadth to facilitate estimation of the parameters of the model of interest, and\n",
    "3. Model Selection: The model is appropriate for the data we are given.\n",
    "\n",
    "For the rest of this section, we will develop intuition for the first point. Later sections will cover estimation of parameters and model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
