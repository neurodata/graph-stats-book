{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Use Statistical Models?\n",
    "\n",
    "Consider a social network. A common question as a scientist that we might have is how, exactly, we could describe the network in the simplest way possible. For instance, if we know nothing about the people, or how they might be connected in the social network, we might want to just say that a pair of people have a fixed probability of being friends. On the other hand, if we know people within the social network are groups of students from different schools, we might want to say that people from the same school have a higher probability of being friends than people from different schools. The way we characterize the network is called the choice of an underlying statistical model.\n",
    "\n",
    "The network we actually observe (for which we have vertices, edges, and perhaps network attributes) is *not* the true network; rather, we assume that the true network is a network for which we could *never* observe completely, as each time we look at the network, we will see it slightly differently. In our social network example above, for instance, a person in our network might have a slightly different group of friends depending on when we look at their friend circle. Stated another way, our observed network is merely a *realization* of an underlying **random network**. We describe our random network using sets of statistical assumptions, referred to as the **statistical network model**. In this book, we describe networks using an approach called *generative modelling*, which means that we use models which describe *how* the random network underlying our realization could have come about. That is, the statistical network model indicates what, exactly, is random, and how we can characterize its behavior statistically. \n",
    "\n",
    "```{admonition} Comparing a Univariate Statistical Model to a Random Network Model\n",
    "Let's use a simple example to show how univariate statistical models compare to random network models. For a univariate statistical model, let's imagine we are tossing a coin 100 times, and we want to determine what the probability of the coin landing on heads is. Every time we toss the coin, we will get an outcome that we can see (did the coin land on heads, or did it land on tails?). Let's call the outcome of the coin toss (heads or tails) $x_i$, where $i$ just indicates the index (between $1$ and $100$) of the particular coin toss. To determine the probability of the coin landing on heads, we will assume that the outcome of the coin is random, and that each time we toss the coin, we are *realizing* a random variable $X$. It is important to emphasize (again!) that this $X$ is random: it doesn't take any fixed value. If a coin toss was heads the first time, when we flip the coin again, we might not get a heads the second time. Instead, we describe $X$ using a *univariate statistical model*. For instance, we might think that $X$ is a Bernoulli-distributed random variable, which means that if we knew the Bernoulli probability $p$, we would know that $X$ has a $p$ chance of landing on heads. In this case, the Bernoulli distribution is the model for $X$.\n",
    "\n",
    "In much the same way, let's think about our social network example again. We have the topology of a network, $\\pmb a$, where the vertices are school students in a county, and the edges are whether a pair of students are friends or not. Like each of the coin toss outcomes above, we get to see $\\pmb a$, and know exactly what values $\\pmb a$ takes. In the same way as above, we will assume that the network $\\pmb a$ is a realization of a random **network** $\\pmb A$. Like the coin flip, we can describe $\\pmb A$ using a statistical model, because it is a random quantity. If we looked at who students were friends with again, we might see that some people are friends who weren't before, and other people aren't friends who were friends before. This time, we will describe the random network $\\pmb A$ using a random network model, which we will learn more about in the next few sections.\n",
    "\n",
    "Let's summarize what we learned above in a table to familiarize ourselves with the vocabulary:\n",
    "| | Coin-Toss | Social Network |\n",
    "| --- | --- | --- |\n",
    "| Observed Data | Outcome of a coin toss $x_i$ | Topology of a network $\\pmb a$ |\n",
    "| Random Variable | $X$, where $x_i$ is supposed is said to be a *realization* of $X$ | random-network $\\pmb A$, where $\\pmb a$ is a realization of $\\pmb A$ |\n",
    "| Statistical Model | the Bernoulli distribution | a Random Network Model |\n",
    "```\n",
    "\n",
    "## Why the model is never right, and why we still care\n",
    "\n",
    "Before we get started, it is important to clarify that we must pay careful attention to the age old aphorism attributed to George Box, a pioneering British statistician of the 20$^{th}$ century. George Box stated, \"all models are wrong, but some are useful.\" In this sense, it is important to remember that the statistical model we select is, in practice, *never* the correct model (this holds for any aspect of statistics, not just network statistics). In the context of a network, this means that even if we have a model we think describes our network very well, it is *not* the case that the model we select actually describes the network precisely and correctly. Despite this, it is often valuable to use statistical models for the simple reason that assuming that a stochastic process (that is, some *random* process) underlies our data allows us to convey *uncertainty*. Stated another way, even if we believe that the process underlying the network is not random at all, we can still extract value by using a statistical model. To understand the importance of uncertainty, consider the following scenarios:\n",
    "1. Lack of information: In practice, we will never have all of the information about the underlying system that produced the network we observe, and we can use uncertainty to in place of the information we don't have. For instance, in our social network example, we might only know which school that people are from. We might not know things like which classes people have taken nor which grade they're in, even though we would expect these facts to impact whether a given pair of people might have a higher chance of being friends. We can use uncertainty in our model to capture the fact that we don't know the classes .\n",
    "2. We might think the network is deterministic, rather than stochastic: In the extreme case, we might think that if we had *all* of the information which underlies the structure of a network, we could determine exactly what realizations would look like with perfect accuracy (that is, the network is deterministic). Even if we knew exactly what realizations of the network might look like, this description, too, is not likely to be very valuable. If we were to develop a model on the basis of everything, our model would be extremely complex and require a large amount of data. For instance, in our social network example, to know whether two people were friends with perfect accuracy, we might need to have intimate knowledge of every single person's life (Did they just have a fight with somebody and de-connect with that person? Did they just go to a school dance and meet someone new?). \n",
    "3. We learn from uncertainty and simplicity: When we do statistical inference, it is rarely the case that we prioritize a complex, convoluted model that mirrors our data suspiciously closely. Instead, we are usually interested in knowing how faithfully a simpler, more generally applicable, model might describe the network. This relates directly to the concept of the bias-variance tradeoff from Machine Learning, in which we prefer a model which isn't too specific (lower bias) but still describes the system effectively (lower variance).\n",
    "\n",
    "Therefore, it is crucial to incorporate randomness and uncertainty to understand network data. In practice, we select a model which is appropriate from a family of candidate models on the basis of three primary factors:\n",
    "1. Utility: The model of interest possesses the level of refinement or complexity that we need to answer our scientific question of interest,\n",
    "2. Estimation: The data has the level of breadth to facilitate estimation of the parameters of the model of interest, and\n",
    "3. Model Selection: The model is appropriate for the data we are given.\n",
    "\n",
    "For the rest of this section, we will develop intuition for the first point. Later sections will cover estimation of parameters and model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
