{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abroad-cursor",
   "metadata": {},
   "source": [
    "# Erd&ouml;s-R&eacute;nyi (ER) Random Networks\n",
    "\n",
    "We will start our description with the simplest random network model. Consider a social network, with $50$ students. Our network will have $50$ nodes, where each node represents a single student in the network. Edges in the social network represent whether or not a pair of students are friends. What is the simplest way we could describe whether two people are friends?\n",
    "\n",
    "In this case, we have a yes or no question: are a pair of people friends, or are they not friends? In this case, the simplest possible thing to do would be to say, for any two students in our network, there is some probability (which we will call $p$) that describes how likely they are to be friends. In the below example, for the sake of argument, we will let $p=0.3$. What does a realization from this network look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-collectible",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from graphbook_code import draw_multiplot\n",
    "from graspologic.simulations import er_np\n",
    "\n",
    "n = 50  # network with 50 nodes\n",
    "p = 0.3  # probability of an edge existing is .3\n",
    "\n",
    "# sample a single simple adjacency matrix from ER(50, .3)\n",
    "A = er_np(n=n, p=p, directed=False, loops=False)\n",
    "\n",
    "draw_multiplot(A, title=\"ER(0.3) Simulation\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-marketing",
   "metadata": {},
   "source": [
    "Using this example, now let's get down to business. This simple random network model is called the Erd&ouml;s R&eacute;nyi (ER) model<sup>1</sup>. The way we can think of the $ER$ network is that the edges basically depend *only* on a probability, $p$. We can think of this example as though a coin flip is performed, where the coin has a probability $p$ of landing on heads, and $1-p$ of landing on tails. For each edge in the network, we basically flip the coin, and if it lands on heads, the edge exists, and if it lands on tails (with probability $1-p$) the edge does not exist. If $\\mathbf A$ is a random network which is ER with $n$ nodes and probability $p$, we will alternatively say that $\\mathbf A$ is an $ER_n(p)$ random network. \n",
    "\n",
    "```{admonition} Simulating a realization from an $ER_n(p)$ network\n",
    "1. Obtain a weighted coin which has a probability $p$ of landing on heads, and a probability $1 - p$ of landing on tails. Note that this probability $p$ might differ from the \"traditional\" coin with a probability of landing on heads of approximately $0.5$.\n",
    "2. Flip the once for each *possible* edge in the network. For a simple network, we will repeat the coin flip $\\binom n 2$ times. \n",
    "3. For each coin flip which landed on heads, define that the corresponding edge exists. For each coin flip which lands on tails, define that the corresponding edge does not exist.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-judge",
   "metadata": {},
   "source": [
    "## When do we use an $ER_n(p)$ Network?\n",
    "\n",
    "In practice, the ER model seems like it might be a little too simple to be useful. Why would it ever be useful to think that the best we can do to describe our network is to say that connections exist with some probability? Does this miss a *lot* of useful questions we might want to answer? Fortunately, there are a number of ways in which the simplicity of the ER model is useful. Given a probability and a number of nodes, we can easily describe the properties we would expect to see in a network if that network were ER. For instance, we know how many edges on average the nodes of an ER nework should have. We can reverse this idea, too: given a network we think might *not* be ER, we could check whether it's different in some way from a network which is ER. For instance, if we see that half the nodes have a ton of edges (meaning, they have a high degree), and half don't, we should probably use a more complicated model than an Erdos-Renyi. If this is the case, we might look for other models that could describe our network which are more complex. \n",
    "\n",
    "Another utility of the ER model is that we might often want to benchmark network algorithms on simulated networks with a given *sparsity*. **Network sparsity** is a feature of a network which describes the degree to which the network possesses fewer edges than the maximum number of possible edges. As an example, when we know ahead of time that the network is going to be sparse (the network has a *small* number of edges which exist relative the number of possible edges), we can use network machine learning techniques which anticipate this sparsity to make the algorithm faster. In a simple network, for instance, the maximum number of possible edges is $\\binom n 2$. In an ER network with probability $p$, we would expect the network to have on average about $p \\binom n 2$ edges; that is, $p$ describes the fraction of total possible edges that we would expect to exist. ER networks are extremely cheap to simulate computationally, because \"flipping weighted coins\" (if you are curious, this is called a *Bernoulli sample* with probability $p$) is usually able to be performed with extremely optimized code in most standard programming languages such as python. Being able to generate networks very easily with a given number of nodes $n$ and a given sparsity allows us to test just how efficient our network machine learning technique is.\n",
    "\n",
    "In the next code block, we are going to sample a single ER network with $50$ nodes and an edge probability $p$ of $0.3$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphbook_code import draw_multiplot\n",
    "from graspologic.simulations import er_np\n",
    "\n",
    "n = 10  # network with 50 nodes\n",
    "p = 0.3  # probability of an edge existing is .3\n",
    "\n",
    "# sample a single simple adjacency matrix from ER(50, .3)\n",
    "A = er_np(n=n, p=p, directed=False, loops=False)\n",
    "\n",
    "# and plot it\n",
    "draw_multiplot(A, title=\"$ER_{50}(0.3)$ Simulation\", xticklabels=10, yticklabels=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-harvest",
   "metadata": {},
   "source": [
    "Above, we visualize the network using a heatmap. The dark squares indicate that an edge exists between a pair of nodes, and white squares indicate that an edge does not exist between a pair of nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-notion",
   "metadata": {},
   "source": [
    "Next, let's see what happens when we use a higher edge probability, like $p=0.7$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.7  # network has an edge probability of 0.7\n",
    "\n",
    "# sample a single adjacency matrix from ER(50, 0.7)\n",
    "A = er_np(n=n, p=p, directed=False, loops=False)\n",
    "\n",
    "# and plot it\n",
    "draw_multiplot(A, title=\"$ER_{50}(0.7)$ Simulation\", xticklabels=10, yticklabels=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-tongue",
   "metadata": {},
   "source": [
    "As the edge probability increases, the sampled adjacency matrix tends to indicate that there are more connections in the network. This is because there is a higher chance of an edge existing when $p$ is larger."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-jewelry",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "former-student",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "attended-trader",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "objective-knock",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Erd&ouml;s P, R&eacute;nyi A. 1959. \"On random graphs, I.\" Publ. Math. Debrecen 6:290â€“297.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
