{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "powered-preview",
   "metadata": {},
   "source": [
    "# Erd&ouml;s-R&eacute;nyi (ER) Random Networks\n",
    "\n",
    "We will start our description with the simplest random network model. Consider a social network, with $50$ students. Our network will have $50$ nodes, where each node represents a single student in the network. Edges in the social network represent whether or not a pair of students are friends. What is the simplest way we could describe whether two people are friends?\n",
    "\n",
    "In this case, we have a yes or no question: are a pair of people friends, or are they not friends? In this case, the simplest possible thing to do would be to say, for any two students in our network, there is some probability (which we will call $p$) that describes how likely they are to be friends. In the below example, for the sake of argument, we will let $p=0.3$. What does a realization from this network look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-throw",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from graphbook_code import draw_multiplot\n",
    "from graspologic.simulations import er_np\n",
    "\n",
    "n = 50  # network with 50 nodes\n",
    "p = 0.3  # probability of an edge existing is .3\n",
    "\n",
    "# sample a single simple adjacency matrix from ER(50, .3)\n",
    "A = er_np(n=n, p=p, directed=False, loops=False)\n",
    "\n",
    "draw_multiplot(A, title=\"ER(0.3) Simulation\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-deadline",
   "metadata": {},
   "source": [
    "This random network model, where every pair of nodes has the same underlying probability of being connected, is called the Erd&ouml;s R&eacute;nyi (ER) model<sup>1</sup>. The way we can think of the $ER$ network is that the edges basically depend *only* on a probability, $p$. We can think of this example as though a coin flip is performed, where the coin has a probability $p$ of landing on heads, and $1-p$ of landing on tails. For each edge in the network, we basically flip the coin, and if it lands on heads, the edge exists, and if it lands on tails (with probability $1-p$) the edge does not exist. If $\\mathbf A$ is a random network which is ER with $n$ nodes and probability $p$, we will alternatively say that $\\mathbf A$ is an $ER_n(p)$ random network. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-contract",
   "metadata": {},
   "source": [
    "## Why do we care about ER networks?\n",
    "\n",
    "In practice, the ER model seems like it might be a little too simple to be useful. When atttempt to ask questions using statistical models, we *typically* want to use the parameters of the model to gain insight about our question. But the ER network, as we learned above, has only one parameter: the probability $p$! Why would it ever be useful to think that the best we can do to describe our network is to say that connections exist with some probability? Fortunately, there are a number of ways in which the simplicity of the ER model is useful. We can very easily deduce properties about an ER network, and can construct ranges in which those properties should fall with an arbitrarily high probability. Given a network we think might *not* be ER, we can use these simple properties to directly test and check whether an ER random network is a reasonable model to use. For instance, using the definition of an ER network, we can conclude that the expected degree of *every* vertex in the network is in fact $(n-1) \\times p$, or the number of nodes a given node could be connected to times the probability an edge exists between any pair of nodes (for a full derivation of this result, see the Theory section). If we see that half the nodes have a ton of edges (meaning, they have a high degree), and half don't, we should probably use a more complicated model than an Erdos-Renyi. If this is the case, we might look for other models that could describe our network which are more complex.\n",
    "\n",
    "In the next code block, we are going to sample a single ER network with $50$ nodes and an edge probability $p$ of $0.3$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphbook_code import draw_multiplot\n",
    "from graspologic.simulations import er_np\n",
    "\n",
    "n = 10  # network with 50 nodes\n",
    "p = 0.3  # probability of an edge existing is .3\n",
    "\n",
    "# sample a single simple adjacency matrix from ER(50, .3)\n",
    "A = er_np(n=n, p=p, directed=False, loops=False)\n",
    "\n",
    "# and plot it\n",
    "draw_multiplot(A, title=\"$ER_{50}(0.3)$ Simulation\", xticklabels=10, yticklabels=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-credit",
   "metadata": {},
   "source": [
    "Above, we visualize the network using a heatmap. The dark squares indicate that an edge exists between a pair of nodes, and white squares indicate that an edge does not exist between a pair of nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-sheffield",
   "metadata": {},
   "source": [
    "Next, let's see what happens when we use a higher edge probability, like $p=0.7$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-herald",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.7  # network has an edge probability of 0.7\n",
    "\n",
    "# sample a single adjacency matrix from ER(50, 0.7)\n",
    "A = er_np(n=n, p=p, directed=False, loops=False)\n",
    "\n",
    "# and plot it\n",
    "draw_multiplot(A, title=\"$ER_{50}(0.7)$ Simulation\", xticklabels=10, yticklabels=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-reporter",
   "metadata": {},
   "source": [
    "As the edge probability increases, the sampled adjacency matrix tends to indicate that there are more connections in the network. This is because there is a higher chance of an edge existing when $p$ is larger."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-winter",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "lyric-setup",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "appointed-cocktail",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "exotic-single",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Erd&ouml;s P, R&eacute;nyi A. 1959. \"On random graphs, I.\" Publ. Math. Debrecen 6:290â€“297.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
