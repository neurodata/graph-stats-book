{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multigraph Representation Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say you're a brain researcher, and you have a bunch of scans of people's brains - some are scans of normal people, and some are scans of people with Abnormal Disease. You have an algorithm that lets you create networks from these brains, so you turn all your brain scans into networks. You want to know if the scans from the abnormal group are more similar to each other than to the scans from normal people. What do you do? It seems like your abnormal networks should look different than normal networks, but how can you actually test this? How do you even deal with situations in which you have a lot of networks whose nodes all represent the same objects, but which might look quite different?\n",
    "\n",
    "Well, one thing that you could do is embed your networks and then try to learn from the embeddings. This would serve the dual purpose of having less stuff to deal with, as well as having some way to directly compare embeddings. Say you have nine networks of normal brains, and nine networks of abnormal brains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from graspologic.simulations import sbm\n",
    "\n",
    "# Generate networks from an SBM, given some parameters\n",
    "def make_network(*probs, n=100, return_labels=False):\n",
    "    p1, p2, p3, p4 = probs\n",
    "    P = np.array([[p1, p2], [p3, p4]])\n",
    "    return sbm([n, n], P, return_labels=return_labels)\n",
    "\n",
    "p1, p2, p3 = .12, .06, .03\n",
    "n = 100\n",
    "normals = [make_network(p1, p3, p3, p1, n=n) for i in range(9)]\n",
    "abnormals = [make_network(p3, p1, p1, p3, n=n) for i in range(9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from graspologic.plot import binary_heatmap, adjplot\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "fig = plt.figure(figsize=(14,7))\n",
    "\n",
    "grid1 = ImageGrid(fig, 121, (3, 3), axes_pad=.1, share_all=True)\n",
    "grid2 = ImageGrid(fig, 122, (3, 3), axes_pad=.1, share_all=True)\n",
    "\n",
    "for i, (axi, axj) in enumerate(zip(grid1, grid2)):\n",
    "    hmn = binary_heatmap(normals[i], ax=axi, cbar=False)\n",
    "    hma = binary_heatmap(abnormals[i], ax=axj, cbar=False)\n",
    "    for ax in [hmn, hma]:\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(True)    \n",
    "        ax.vlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "        ax.hlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "\n",
    "grid1.axes_all[1].set_title(\"Normal Brains\", fontsize=24, y=1.05)\n",
    "grid2.axes_all[1].set_title(\"Abnormal Brains\", fontsize=24, y=1.05)\n",
    "\n",
    "plt.tight_layout(w_pad=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most obvious way to embed these networks is by averaging them, and then embedding the result of that averaging. It turns out that this is actually not only the right thing to do, but the optimal thing to do if your networks are all drawn from the same distribution. In our case, averaging only the normal networks together, and averaging only the abnormal networks together, will produce two embeddings that are as good as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.embed import AdjacencySpectralEmbed as ASE\n",
    "\n",
    "# Compute the average adjacency matrix for \n",
    "# normal brains and alzheimer's brains\n",
    "normal_mean = np.array(normals).mean(axis=0)\n",
    "abnormal_mean = np.array(abnormals).mean(axis=0)\n",
    "\n",
    "# Embed both matrices\n",
    "ase = ASE(n_components=2)\n",
    "latents_normal = ase.fit_transform(normal_mean)\n",
    "latents_abnormal = ase.fit_transform(abnormal_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_latents(latent_positions, *, title, labels, ax=None, legend=False):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    plot = sns.scatterplot(latent_positions[:, 0], latent_positions[:, 1], hue=labels, \n",
    "                           s=10, ax=ax, palette=\"Set1\")\n",
    "    plot.set_title(title, wrap=True);\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    ax.axes.yaxis.set_visible(False)\n",
    "    if legend:\n",
    "        ax.legend(loc=\"upper right\", title=\"Community\")\n",
    "    else:\n",
    "        ax.get_legend().remove()\n",
    "    \n",
    "    return plot\n",
    "\n",
    "# plot\n",
    "labels = [0]*n + [1]*n\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "plot_latents(latents_normal, title=\"Embedding when we average the \\nnormal graphs\", \n",
    "             labels=labels, ax=axs[0])\n",
    "plot_latents(latents_abnormal, title=\"Embedding when we average the \\nalzheimer's graphs\", \n",
    "             labels=labels, ax=axs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these embeddings look great. But what if we wanted to embed *all* of the networks into the same space? Let's try it. We can take all of the networks, both normal and abnormal ones, and then average them together. This results in a single embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_mean = np.array(normals + abnormals).mean(axis=0)\n",
    "latents_everything = ase.fit_transform(total_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plot_latents(latents_everything, title=\"Embedding when we average everything together\", \n",
    "             labels=labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bummer. What we've just discovered is that, even though it's a great idea to simply average a bunch of networks if they were drawn from the same distribution, there are some situations in which averaging your networks simply results in meaningless noise. This is a case of averaging networks which are \"heterogeneous\". This means that not only are your networks slightly different, but they're *expected* to be different: they come from different distributions. So if you sampled a lot of networks, like we just did, then averaging them would produce poor results.\n",
    "\n",
    "We'd like to find a way to compare these heterogeneous networks directly, and to embed them all into the same space. Figuring out the best way to do this is a topic under active research, and the set of techniques and tools that have developed as a result are together called multigraph representation learning (here, \"graph\" just means \"network\").\n",
    "\n",
    "In this section, we'll explore the strengths and weaknesses of different types of multigraph representation learning. Multiple Adjacency Spectral Embedding (MASE) is a technique which embeds a bunch of networks separately (with normal Adjacency Spectral Embedding), and then re-embeds all the separate results into a single space. MASE is nice because you don't actually need each network to be generated from the same distribution - you only need the nodes of the different networks to be aligned and for them to belong to the same communities. Omnibus embedding combines the adjacency matrix of all of the matrices into a single super-matrix, and then embeds that super-matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Adjacency Spectral Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first algorithm we'll explore is called MASE, and is probably the easiest to understand if you know how Adjacency Spectral Embeddings work. Say you have some number of networks, and (like we said above) their nodes are aligned. The goal of MASE is to embed the networks into a single space, with each point in that space representing a single node - but, unlike simply averaging, your networks don't necessarily have to be drawn from the same distribution. MASE is based on the common subspace independent-edge (COSIE) model from the multi-network models section of chapter 5, so we're operating under the assumption that there *is* some low-dimensional space common to all of our networks that we can embed into in the first place.\n",
    "\n",
    "The figure below shows how MASE works under the hood. First, we embed the adjacency matrices of a bunch of networks separately. Then, we take all of those embeddings, concatenate them into a single matrix, and embed the entire concatenated matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../Images/mase1.jpeg\n",
    "---\n",
    "height: 400px\n",
    "name: mase-fig\n",
    "---\n",
    "The MASE algorithm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Collection of Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a set of networks generated from Stochastic Block Models with two communities in each network. The networks have aligned nodes -- meaning that the $i_{th}$ row of all of their adjacency matrices represent the same nodes. The nodes also all belong to the same communities. However, edge probabilities might change depending on the network - in the first network, you might have nodes in the same community having a high chance of connecting to each other, whereas in the second network, nodes are much more likely to be connected to other nodes in different communities. Your goal is to find a common space in which to represent all of these networks, that captures the common community structure in all of these.\n",
    "\n",
    "Below is Python code which generates four networks with Stochastic Block Models. The labels are the same across the networks (which means that nodes have a consistent community no matter which network you're looking at), but the block probability matrices are quite different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from graspologic.simulations import sbm\n",
    "\n",
    "n = 100\n",
    "p1, p2, p3 = .12, .06, .03\n",
    "A1, labels = make_network(p1, p3, p3, p1, \n",
    "                      return_labels=True)\n",
    "A2 = make_network(p1, p3, p3, p2)\n",
    "A3 = make_network(p3, p2, p2, p3)\n",
    "A4 = make_network(p1, p3, p3, p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from graspologic.plot import binary_heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(7,7))\n",
    "for ax, graph in zip(axs.flat, [A1, A2, A3, A4]):\n",
    "    hmap = binary_heatmap(graph, ax=ax, cbar=False)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "    hmap.vlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "    hmap.hlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "    \n",
    "plt.suptitle(\"Four different networks\", fontsize=26, y=.95)\n",
    "fig.subplots_adjust(hspace=.05, wspace=.05)\n",
    "\n",
    "cmap = ListedColormap([\"white\", \"black\"])\n",
    "cbar_ax = fig.add_axes([.95, 0.13, 0.07, 0.75])\n",
    "cbar = fig.colorbar(hmap.imshow(A1, cmap=cmap), cax=cbar_ax)\n",
    "cbar.set_ticks([0.25, 0.75])\n",
    "cbar.set_ticklabels([\"No Edge\", \"Edge\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to embed each of the four networks separately. Doing this lets us see what the individual embeddings of the networks each look like. We'll also need these embeddings to unify the networks all into a single space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.embed import AdjacencySpectralEmbed as ASE\n",
    "\n",
    "networks = [A1, A2, A3, A4]\n",
    "latents = []\n",
    "for network in networks:\n",
    "    ase = ASE(n_components=2)\n",
    "    latent = ase.fit_transform(network)\n",
    "    latents.append(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(7,7), sharex=True, sharey=True)\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    plot_latents(latents[i], title=None, labels=labels, ax=ax)\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "plt.suptitle(\"Embeddings of our four networks\", fontsize=20);\n",
    "\n",
    "# TODO: add legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to take these individual embeddings, concatenate them into a single matrix, and then embed the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.embed import selectSVD\n",
    "\n",
    "concatenated = np.hstack(latents)\n",
    "joint_embedding, *_ = selectSVD(concatenated, n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plot_latents(joint_embedding, title=\"Joint embedding of our four networks\",\n",
    "             labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Graspologic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.embed import MultipleASE as MASE\n",
    "\n",
    "mase = MASE(n_components=2)\n",
    "latents = mase.fit_transform(networks)\n",
    "\n",
    "plot_latents(latents, title=\"MASE embedding\", labels=labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
