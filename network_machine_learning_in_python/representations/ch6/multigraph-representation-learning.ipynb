{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multigraph Representation Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aliens and Humans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say you're a brain researcher, and you have a bunch of scans of brains - some are scans of normal people, and some are scans of aliens. You have some code that estimates networks from your scans, so you turn all your scans into networks. The nodes represent the brain regions which are common to both humans and aliens (isn't evolution amazing?), and the edges represent communication between these brain regions. You want to know if the human and alien networks share a common community structure. It seems like you should be able to find communities common to both races -- they're both brain networks, after all -- but what do you do? How do you even deal with situations in which you have a lot of networks whose nodes all represent the same objects, but whose edges might come from totally different distributions?\n",
    "\n",
    "Well, if your goal is to find the shared community structure between the human and alien networks, you could try embedding your networks and then seeing what those embeddings look like. This would serve the dual purpose of having less stuff to deal with and having some way to directly compare your networks in the same space. For example, say you have nine alien networks and nine human networks. Since alien brain networks aren't currently very accessible, we'll just simulate our human and alien networks with Stochastic Block Models. We'll say that the communities we're trying to find are the two hemispheres of the brain. We'll design the human brains to have strong connections within hemispheres, and we'll design the alien brains to have strong connections between hemispheres.\n",
    "\n",
    "we'll use a relatively small number of nodes and fairly small block probabilities. You can see the specific parameters in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from graspologic.simulations import sbm\n",
    "\n",
    "# Generate networks from an SBM, given some parameters\n",
    "def make_network(*probs, n=100, return_labels=False):\n",
    "    pa, pb, pc, pd = probs\n",
    "    P = np.array([[pa, pb], \n",
    "                  [pc, pd]])\n",
    "    \n",
    "    return sbm([n, n], P, return_labels=return_labels)\n",
    "\n",
    "# make nine human networks\n",
    "# and nine alien networks\n",
    "p1, p2, p3 = .12, .06, .03\n",
    "n = 100\n",
    "labels = [0]*n + [1]*n\n",
    "humans = [make_network(p1, p3, p3, p1, n=n) for i in range(9)]\n",
    "aliens = [make_network(p3, p1, p1, p3, n=n) for i in range(9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The edges of the human and alien networks come from very different distributions. As you can see from the Stochastic Block Model structure below, the regions in the human and the alien brains can both be separated into two communities. These communities represent the two hemispheres of the brain (who knew aliens also have bilateralized brains!). Although both humans and aliens have the same regions belonging to their respective hemispheres, as we planned, the alien networks have a strange property: their brain regions have more connections with regions in the opposite hemisphere than the same one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from graspologic.plot import binary_heatmap, adjplot\n",
    "\n",
    "fig = plt.figure(figsize=(14,7))\n",
    "\n",
    "grid1 = ImageGrid(fig, 121, (3, 3), axes_pad=.1, share_all=True)\n",
    "grid2 = ImageGrid(fig, 122, (3, 3), axes_pad=.1, share_all=True)\n",
    "\n",
    "for i, (axi, axj) in enumerate(zip(grid1, grid2)):\n",
    "    hmn = binary_heatmap(humans[i], ax=axi, cbar=False)\n",
    "    hma = binary_heatmap(aliens[i], ax=axj, cbar=False)\n",
    "    for ax in [hmn, hma]:\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(True)    \n",
    "        ax.vlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "        ax.hlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "\n",
    "grid1.axes_all[0].set_title(\"Human Brain Networks\", fontsize=24, y=1.05, loc=\"left\")\n",
    "grid2.axes_all[0].set_title(\"Alien Brain Networks\", fontsize=24, y=1.05, loc=\"left\")\n",
    "\n",
    "plt.tight_layout(w_pad=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping the Networks Separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, our goal is to find community structure common to both humans and aliens, and in our case that community structure is the brain hemispheres. We're going to try to to embed our brain networks into some lower-dimensional space - that way, we can use standard clustering methods from machine learning to figure out which regions are grouped. Try to think about how you might find a lower-dimensional embedding where the location of each node's latent positions uses information from all of the networks.\n",
    "\n",
    "The first idea you might come up with is to average your networks together, and then embed the result of that averaging with Spectral Embedding. It turns out that this is actually the right thing to do in the very special case where the edges of all the networks you have come from the same distribution. In our case, averaging only the human networks together, and averaging only the alien networks together, will produce two separate embeddings with nicely clustered nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.embed import AdjacencySpectralEmbed as ASE\n",
    "\n",
    "# Compute the average adjacency matrix for \n",
    "# human brains and alien brains\n",
    "human_mean_network = np.array(humans).mean(axis=0)\n",
    "alien_mean_network = np.array(aliens).mean(axis=0)\n",
    "\n",
    "# Embed both matrices\n",
    "ase = ASE(n_components=2)\n",
    "human_latents = ase.fit_transform(human_mean_network)\n",
    "alien_latents = ase.fit_transform(alien_mean_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you can see what happens when we embed the averaged human and alien networks separately. Like all of our embedding plots, each dot represents the latent positions for a particular node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_latents(latent_positions, *, title=None, labels=None, ax=None, legend=False,\n",
    "                 fontdict=None, **kwargs):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    plot = sns.scatterplot(latent_positions[:, 0], latent_positions[:, 1], hue=labels, \n",
    "                           s=10, ax=ax, palette=\"Set1\", color='k', **kwargs)\n",
    "    if title is not None:\n",
    "        plot.set_title(title, wrap=True, fontdict=fontdict, loc=\"left\");\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    ax.axes.yaxis.set_visible(False)\n",
    "    if legend:\n",
    "        ax.legend(loc=\"upper right\", title=\"Community\")\n",
    "    elif not legend and np.any(labels):\n",
    "        ax.get_legend().remove()\n",
    "    \n",
    "    return plot\n",
    "\n",
    "# plot\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "plot_latents(human_latents, title=\"Embedding when we average the human \\nnetworks\", ax=axs[0]);\n",
    "plot_latents(alien_latents, title=\"Embedding when we average the alien \\nnetworks\", ax=axs[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these embeddings have clear clustering: there are two communities of nodes in both the human and the alien networks. We can recover the labels for these communities fairly easily using our pick of unsupervised clustering method. We know that the latent positions in each community of an Adjacency Spectral Embedding are normally distributed under this simulation setting, and we have two communities. That means that the above embeddings are distributed according to a Gaussian Mixture. Here, \"Gaussian\" just means \"normal\", and a gaussian mixture just means that we have groups of normally distributed data clusters. As a result, it makes sense to cluster these data using scikit-learn's GaussianMixture implementation. We'll also use graspologic's `remap_labels` utility function to make sure that index of the nodes matches for both our predicted alien and human labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from graspologic.utils import remap_labels\n",
    "\n",
    "# Predict labels for the human and alien brains\n",
    "human_labels = GMM(n_components=2).fit_predict(human_latents)\n",
    "alien_labels = GMM(n_components=2).fit_predict(alien_latents)\n",
    "\n",
    "# Make corresponding communities have the same values\n",
    "alien_labels = remap_labels(human_labels, alien_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see a plot that predicts our community structure below. Success! When we embed the human and the alien networks separately, averaging them clearly lets us cluster the brain regions by hemisphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "plot_latents(human_latents, title=\"Clustering our averaged human network \\nembedding with a GMM\", \n",
    "             labels=human_labels, ax=axs[0])\n",
    "plot_latents(alien_latents, title=\"Clustering our averaged alien network \\nembedding with a GMM\", \n",
    "             labels=1 - alien_labels, ax=axs[1])\n",
    "\n",
    "plt.legend(loc=(1.15, .4), fontsize=\"x-large\", title=\"Community\",\n",
    "           title_fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping The Networks Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if you wanted to embed *all* of the networks into the same space, both the human and the alien networks, so that there's only one plot? Let's try it. We'll take all of the networks and then average them together, and then do an Adjacency Spectral Embedding. This will result in a single plot, with each point representing a single brain region. Do you think we'll still find this nice community separation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_mean_matrix = np.array(humans + aliens).mean(axis=0)\n",
    "all_latents = ase.fit_transform(total_mean_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plot_latents(all_latents, title=\"Embedding when we average everything together\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope, bummer. Our community separation into discrete hemispheres is gone - the human networks and the alien networks cancelled each other out. As far as anybody can tell, our latent positions have just become meaningless noise, so we can't cluster and find communities like we did before.\n",
    "\n",
    "What we've discovered is that, even though it's a great idea to simply average a bunch of networks if they were drawn from the same distribution, it's often a horrible idea to average your networks if they might come from different distributions. This is a case of averaging networks which are \"heterogeneous\": Not only are your networks slightly different, but they're *expected* to be different because they're drawn from different distributions. Sampling a lot of heterogenous networks and then averaging them, as you can see above, can result in losing the community signal you might have had.\n",
    "\n",
    "We'd like to find a way to compare these heterogeneous networks directly, so that we can embed all of our networks into the same space and still keep that community structure. Figuring out the best way to do this is a topic under active research, and the set of techniques and tools that have developed as a result are together called multigraph representation learning (here, \"graph\" just means \"network\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Types of Multigraph Representation Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a moment to explore some of the possible general approaches we could take in multigraph representation learning. At some point we need to combine the many individual representations of our networks into one, and there are at least three possible places where we could do this: combining the networks, combining the classifiers, and combining the embeddings. Each of these eventually results in a latent position representation for our networks. You can do whatever you want with these latent position representations; in our case, we'll illustrate that we can use them to classify our nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this approach, you'll start with a set of networks, and then you'll combine them all into a single network prior to do anything else. You can then embed and classify this network directly. What we did before, averaging the human and alien networks, was an example of combining our networks -- we just averaged all of our adjacency matrices, and then we embedded the result. Another technique that we'll learn about soon, Omnibus Embedding, is a more complex network combination algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from graspologic.embed import MultipleASE as MASE\n",
    "from graspologic.embed import OmnibusEmbed as OMNI\n",
    "from graspologic.embed.omni import _get_omni_matrix\n",
    "from graspologic.plot import heatmap\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "def rm_ticks(ax, **kwargs):\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    ax.axes.yaxis.set_visible(False)\n",
    "    sns.despine(ax=ax, **kwargs)\n",
    "    \n",
    "fig = plt.figure();\n",
    "\n",
    "# add stack of heatmaps\n",
    "for i in range(5):\n",
    "    ax = fig.add_axes([.02*i, -.02*i, .8, .8]) \n",
    "    ax = binary_heatmap(humans[i], ax=ax, cbar=False)\n",
    "    if i == 0:\n",
    "        ax.set_title(\"Adjacency Matrices\", loc=\"left\", fontsize=16)\n",
    "    rm_ticks(ax, top=False, right=False)\n",
    "    ax.vlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "    ax.hlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "\n",
    "\n",
    "# add arrow\n",
    "arrow_ax = fig.add_axes([.8, .3, .3, .1])\n",
    "rm_ticks(arrow_ax, left=True, bottom=True)\n",
    "plt.arrow(x=0, y=0, dx=1, dy=0, width=.1, color=\"black\") \n",
    "\n",
    "# add joint matrix\n",
    "omni_ax = fig.add_axes([1, -.02*3, .8, .8])\n",
    "A = _get_omni_matrix(humans+aliens)\n",
    "a_hm = heatmap(A, ax=omni_ax, cbar=False)\n",
    "a_hm.set_title(\"Joint Matrix\", loc=\"left\", fontsize=16)\n",
    "for _, spine in a_hm.spines.items():\n",
    "    spine.set_visible(True)\n",
    "    \n",
    "# add second arrow\n",
    "arrow_ax = fig.add_axes([1.75, .3, .3, .1])\n",
    "rm_ticks(arrow_ax, left=True, bottom=True)\n",
    "plt.arrow(x=0, y=0, dx=1, dy=0, width=.1, color=\"black\") \n",
    "\n",
    "# add omni embedding\n",
    "latents_omni = OMNI(n_components=2).fit_transform(humans+aliens).mean(axis=0)\n",
    "omni_embed_ax = fig.add_axes([2.1, -.02*3, .55, .8])\n",
    "plot_latents(latents_omni, ax=omni_embed_ax, title=\"Joint Embedding\", \n",
    "             fontdict={'fontsize': 16})\n",
    "rm_ticks(omni_embed_ax, top=False, right=False)\n",
    "\n",
    "# add third arrow\n",
    "arrow_ax = fig.add_axes([2.7, .3, .3, .1])\n",
    "rm_ticks(arrow_ax, left=True, bottom=True)\n",
    "plt.arrow(x=0, y=0, dx=1, dy=0, width=.1, color=\"black\") \n",
    "\n",
    "# classify\n",
    "labels_normal = GMM(n_components=2).fit_predict(human_latents)\n",
    "mase_ax = fig.add_axes([3.05, -.02*3, .55, .8])\n",
    "plot_latents(latents_omni, ax=mase_ax, title=\"Classification\", \n",
    "             fontdict={'fontsize': 16}, labels=human_labels)\n",
    "\n",
    "plt.suptitle(\"Combining the Networks\", x=2, y=1.1, fontsize=26);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can also start with a set of networks, and then train a classifier for each network. This classifier could be anything: maybe you train a separate Gaussian Mixture Model, or a k-means clustering model. You then have a set of classifiers, each one corresponding to one of the networks. You then figure out some reasonable way to combine these all into a single classifier. You use this single classifier to group your nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from graspologic.embed import MultipleASE as MASE\n",
    "from graspologic.embed import OmnibusEmbed as OMNI\n",
    "from graspologic.embed.omni import _get_omni_matrix\n",
    "from graspologic.plot import heatmap\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "def rm_ticks(ax, **kwargs):\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    ax.axes.yaxis.set_visible(False)\n",
    "    sns.despine(ax=ax, **kwargs)\n",
    "\n",
    "# add stack of heatmaps\n",
    "for i in range(5):\n",
    "    ax = fig.add_axes([.02*i, -.02*i, .8, .8]) \n",
    "    ax = binary_heatmap(humans[i], ax=ax, cbar=False)\n",
    "    if i == 0:\n",
    "        ax.set_title(\"Adjacency Matrices\", loc=\"right\", fontsize=20)\n",
    "    rm_ticks(ax, top=False, right=False)\n",
    "    ax.vlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "    ax.hlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "\n",
    "\n",
    "# add arrow\n",
    "arrow_ax = fig.add_axes([.8, .3, .3, .1])\n",
    "rm_ticks(arrow_ax, left=True, bottom=True)\n",
    "plt.arrow(x=0, y=0, dx=1, dy=0, width=.1, color=\"black\") \n",
    "\n",
    "# add stack of heatmaps\n",
    "for i in range(5):\n",
    "    left, bottom, width, height = [.02*i + 1.15, -.02*i, .55, .8]\n",
    "    ax = fig.add_axes([left, bottom, width, height]) \n",
    "    right = left + width\n",
    "    top = bottom + height\n",
    "    rm_ticks(ax, top=False, right=False)\n",
    "\n",
    "ax.text(.5, .5, 'Classifiers', transform=ax.transAxes, horizontalalignment='center', \n",
    "        verticalalignment='center', fontdict={'fontsize': 26})\n",
    "\n",
    "# add second arrow\n",
    "arrow_ax = fig.add_axes([1.85, .3, .3, .1])\n",
    "rm_ticks(arrow_ax, left=True, bottom=True)\n",
    "plt.arrow(x=0, y=0, dx=1, dy=0, width=.1, color=\"black\") \n",
    "\n",
    "# classify\n",
    "latents = MASE(n_components=2).fit_transform(humans+aliens)\n",
    "labels = GMM(n_components=2).fit_predict(latents)\n",
    "ax = fig.add_axes([2.2, -.02*3, .55, .8])\n",
    "plot_latents(latents, ax=ax, title=\"Classification \\n(with combined classifier)\", \n",
    "             fontdict={'fontsize': 20}, labels=labels)\n",
    "rm_ticks(ax, top=False, right=False)\n",
    "\n",
    "plt.suptitle(\"Combining the classifiers\", x=1.5, y=1.1, fontsize=26);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final approach to multigraph representation learning that we'll talk about is combining the embeddings themselves. With this approach, you're waiting until you've already embnedded all of your networks separately before you combine them, either with Adjacency Spectral Embedding or with some other single-network embedding method. Multiple Adjacency Spectral Embedding, another algorithm we'll be learning about later in this chapter, is an example of the Embedding Product approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "# add stack of heatmaps\n",
    "for i in range(5):\n",
    "    ax = fig.add_axes([.02*i, -.02*i, .5, .5]) \n",
    "    ax = binary_heatmap(humans[i], ax=ax, cbar=False)\n",
    "    if i == 0:\n",
    "        ax.set_title(\"Adjacency Matrices\", loc=\"right\")\n",
    "    rm_ticks(ax, top=False, right=False)\n",
    "    ax.vlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "    ax.hlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "\n",
    "# add arrow\n",
    "arrow_ax = fig.add_axes([.5, .2, .3, .1])\n",
    "rm_ticks(arrow_ax, left=True, bottom=True)\n",
    "plt.arrow(x=0, y=0, dx=1, dy=0, width=.1, color=\"black\") \n",
    "\n",
    "# add stack of latent plots\n",
    "for i in range(5):\n",
    "    ax = fig.add_axes([.8+.02*i, -.02*i, .35, .5])\n",
    "    if i == 0:\n",
    "        ax.set_title(\"Separate Embeddings\")\n",
    "    latents = ase.fit_transform(humans[i])\n",
    "    plot = sns.scatterplot(latents[:, 0], latents[:, 1], \n",
    "                       s=10, ax=ax, color=\"black\")\n",
    "    rm_ticks(ax, top=False, right=False)\n",
    "    \n",
    "# add second arrow\n",
    "arrow_ax = fig.add_axes([1.25, .2, .3, .1])\n",
    "rm_ticks(arrow_ax, left=True, bottom=True)\n",
    "plt.arrow(x=0, y=0, dx=1, dy=0, width=.1, color=\"black\") \n",
    "\n",
    "# add group embeddings\n",
    "mase = MASE(n_components=2)\n",
    "latents_mase = mase.fit_transform(humans + aliens)\n",
    "mase_ax = fig.add_axes([1.57, -.03, .35, .5])\n",
    "plot_latents(latents_mase, ax=mase_ax, title=\"Joint Embedding\")\n",
    "rm_ticks(mase_ax, top=False, right=False)\n",
    "\n",
    "# add third arrow\n",
    "arrow_ax = fig.add_axes([1.95, .2, .3, .1])\n",
    "rm_ticks(arrow_ax, left=True, bottom=True)\n",
    "plt.arrow(x=0, y=0, dx=1, dy=0, width=.1, color=\"black\") \n",
    "\n",
    "# classify\n",
    "labels_normal = GMM(n_components=2).fit_predict(human_latents)\n",
    "mase_ax = fig.add_axes([2.27, -.03, .35, .5])\n",
    "plot_latents(latents_mase, ax=mase_ax, title=\"Classification\", \n",
    "             labels=labels_normal)\n",
    "\n",
    "plt.suptitle(\"Combining the Embeddings\", x=1.4, y=.7, fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of this section, we'll explore the strengths and weaknesses of different particular algorithms that use these approaches. Multiple Adjacency Spectral Embedding (MASE) is a technique combines embeddings by concatennating and re-embedding the separate latent positions into a single space. MASE is nice because you don't actually need each network to be generated from the same distribution - you only need the nodes of the different networks to be aligned and for them to belong to the same communities. Omnibus embedding combines the adjacency matrix of all of the matrices into a single super-matrix, and then embeds that super-matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Adjacency Spectral Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MASE is probably the easiest to understand if you know how Adjacency Spectral Embeddings work. Say you have some number of networks, and (like we said above) their nodes are aligned. The goal of MASE is to embed the networks into a single space, with each point in that space representing a single node - but, unlike simply averaging, MASE lets you combine networks which aren't necessarily drawn from the same distribution. MASE is based on the common subspace independent-edge (COSIE) model from the multi-network models section of chapter 5, so we're operating under the assumption that there *is* some low-dimensional space common to all of our networks that we can embed into in the first place.\n",
    "\n",
    "Let's go back to our group of human and alien brains and try using MASE to embed them rather than averaging. Then, we'll dive deeper into what's going on under the hood. First, we'll instantiate a MASE classifier and embed down to two dimensions. Then we'll create a combined list of the human and alien brains, and use MASE to find the latent positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.embed import MultipleASE as MASE\n",
    "\n",
    "# Use MASE to embed everything\n",
    "mase = MASE(n_components=2)\n",
    "latents_mase = mase.fit_transform(humans + aliens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plot_latents(latents_mase, title=\"Embedding when we use MASE on the group \\nof all human and alien networks\", labels=labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the disastrous results from simply averaging all of our networks together, MASE manages to keep the community structure that we found when we averaged our networks separately. Let's see what's under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's Going On Under The Hood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you can see how MASE works. We start with networks, drawn as nodes in space connected to each other. We turn them into adjacency matrices, and then we embed the adjacency matrices of a bunch of networks separately, using our standard Adjacency Spectral Embedding algorithm. Then, we take all of those embeddings, concatenate horizontally into a single matrix, and embed the entire concatenated matrix. The colors are the true communities each node belongs to: there's a red and an orange community. We're cheating a bit here because we know in advance which nodes belong to which community."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../Images/mase1.jpeg\n",
    "---\n",
    "height: 400px\n",
    "name: mase-fig\n",
    "---\n",
    "The MASE algorithm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Collection of Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a set of networks generated from Stochastic Block Models with two communities in each network. The networks have aligned nodes -- meaning that the $i_{th}$ row of all of their adjacency matrices represent the same nodes. The nodes also all belong to the same communities. However, edge probabilities might change depending on the network. In the first network, you might have nodes in the same community having a high chance of connecting to each other, whereas in the second network, nodes are much more likely to be connected to other nodes in different communities. You want to end up with a classification that distinctly groups the nodes into their respective communities, using the information from all of the networks. Because MASE takes the Embedding Product approach, we start by embedding each network separately with an Adjacency Spectral Embedding.\n",
    "\n",
    "Below is Python code which generates four networks with Stochastic Block Models. Each of the networks is drawn from a different distribution (the block probability matrices are different), but the labels are the same across the networks (which means that nodes have a consistent community no matter which network you're looking at)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from graspologic.simulations import sbm\n",
    "\n",
    "n = 100\n",
    "p1, p2, p3 = .12, .06, .03\n",
    "A1, labels = make_network(p1, p3, p3, p1, \n",
    "                      return_labels=True)\n",
    "A2 = make_network(p1, p3, p3, p2)\n",
    "A3 = make_network(p3, p2, p2, p3)\n",
    "A4 = make_network(p1, p3, p3, p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from graspologic.plot import binary_heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(7,7))\n",
    "for ax, graph in zip(axs.flat, [A1, A2, A3, A4]):\n",
    "    hmap = binary_heatmap(graph, ax=ax, cbar=False)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "    hmap.vlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "    hmap.hlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "    \n",
    "plt.suptitle(\"Four different networks\", fontsize=26, y=.95)\n",
    "fig.subplots_adjust(hspace=.05, wspace=.05)\n",
    "\n",
    "cmap = ListedColormap([\"white\", \"black\"])\n",
    "cbar_ax = fig.add_axes([.95, 0.13, 0.07, 0.75])\n",
    "cbar = fig.colorbar(hmap.imshow(A1, cmap=cmap), cax=cbar_ax)\n",
    "cbar.set_ticks([0.25, 0.75])\n",
    "cbar.set_ticklabels([\"No Edge\", \"Edge\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll embed each of the four networks separately using Adjacency Spectral Embedding. We'll need these embeddings to unify the networks all into a single space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.embed import AdjacencySpectralEmbed as ASE\n",
    "\n",
    "networks = [A1, A2, A3, A4]\n",
    "latents = []\n",
    "for network in networks:\n",
    "    ase = ASE(n_components=2)\n",
    "    latent = ase.fit_transform(network)\n",
    "    latents.append(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(7,7), sharex=True, sharey=True)\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    plot_latents(latents[i], title=None, labels=labels, ax=ax)\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "plt.suptitle(\"Embeddings of our four networks\", fontsize=20);\n",
    "\n",
    "# TODO: add legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to take these individual embeddings, concatenate them into a single matrix, and then embed the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.embed import selectSVD\n",
    "\n",
    "concatenated = np.hstack(latents)\n",
    "joint_embedding, *_ = selectSVD(concatenated, n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plot_latents(joint_embedding, title=\"Joint embedding of our four networks\",\n",
    "             labels=labels);\n",
    "\n",
    "# TODO: add legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Graspologic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, you don't actually have to implement any of this stuff yourself. Graspologic's MultipleASE class implements it all for you under the hood. You can see the embedding - you give MultipleASE a list of networks, and it spits out a set of joint latent positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.embed import MultipleASE as MASE\n",
    "\n",
    "mase = MASE(n_components=2)\n",
    "latents = mase.fit_transform(networks)\n",
    "\n",
    "plot_latents(latents, title=\"MASE embedding\", labels=labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *The Mathematics of MASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With MASE, each network has a corresponding score matrix. Just like the set of joint latent positions describes how the networks are similar, the score matrices describe how each network is different.\n",
    "\n",
    "Suppose we have a set of networks with adjacency matrices $A^{(1)}, ..., A^{(m)}$, with each network being unweighted. Suppose our joint latent positions are called $V$. Then each adjacency matrix, $A^{(i)}$, can be decomposed into $VR^{(i)} V^\\top$, where $R^{(i)}$ is the score matrix corresponding to the $i_{th}$ network:\n",
    "\n",
    "\\begin{align*}\n",
    "    A^{(i)} = VR^{(i)} V^\\top\n",
    "\\end{align*}\n",
    "\n",
    "Any particular score matrix, $R^{(i)}$, is square and $d \\times d$. The dimension, $d$, corresponds to the number of embedding dimensions -- so if we wanted to embed down to two dimensions, each $R^{(i)}$ would be a $2 \\times 2$ matrix. \n",
    "\n",
    "Now, here's the interesting part: how do we find our score matrices? Well, there's a theorem in linear algebra about matrices which are *orthogonal*, meaning that they're all perpendicular to each other. This theorem says that the inverse of an orthogonal matrix is its transpose. So, for an orthogonal matrix $O$,\n",
    "\n",
    "\\begin{align*}\n",
    "    O^\\top = O^{-1}\n",
    "\\end{align*}\n",
    "\n",
    "Interestingly, the column-vectors of our joint embedding matrix (let's call it $V$) are all orthogonal. Since definitionally, what it means for two vectors to be orthogonal is that they have a dot product of 0, we can check this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = joint_embedding.copy()\n",
    "\n",
    "# Take the dot product of the columns of our joint latent position matrix\n",
    "np.round(V[:, 0] @ V[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this all means is that the inverse of our joint embedding matrix $V$ is its transpose. You can see below that $V^\\top V$ is just the identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(V.T@V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and so, finally, we can use the above two facts to find a score matrix. We just take matrix inverses, and then use the fact that the matrices we're inverting are orthogonal to turn them into transposes.\n",
    "\n",
    "\\begin{align*}\n",
    "    A^{(i)} &= VR^{(i)} V^\\top \\\\\n",
    "    V^{-1} A^{(i)} (V^\\top)^{-1} &= R^{(i)} \\\\\n",
    "    V^\\top A^{(i)} V &= R^{(i)} \n",
    "\\end{align*}\n",
    "\n",
    "Below, we turn our list of networks into a 3-D numpy array, and then do the above multiplication to get a new 3D numpy array of scores matrices. Because we embedded into two dimensions, each score matrix is $2 \\times 2$, and the four score matrices are \"slices\" along the 0th axis of the numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks_array = np.asarray(networks)\n",
    "scores = V.T @ networks_array @ V\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's recreate the first network using only its score matrix and the joint latent positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_0 = V @ scores[0] @ V.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1, p2, p3 = .12, .06, .03\n",
    "A1, labels = make_network(p1, p3, p3, p1, \n",
    "                      return_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below and to the left, you can see the original adjacency matrix for the first matrix. In the center, you can see the heatmap for the first network's score matrix. Next to it, you can see the recreation of the first network. Remember that we only used the score matrix to recreate it. The first network has a block probability matrix of\n",
    "\n",
    "\\begin{align}\n",
    "\\begin{bmatrix}\n",
    ".12 & .03 \\\\\n",
    ".03 & .06 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "and so we should expect the edges in the top-left block of our adjacency matrix to be more connected, the edges in the two off-diagonal blocks to not be very connected, and the edges in the bottom-right block to be kind of connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "\n",
    "binary_heatmap(networks[0], title=\"The original adjacency matrix \\nfor the first network\", ax=axs[0])\n",
    "heatmap(scores[0], title=\"Score matrix for the first network\", ax=axs[1])\n",
    "heatmap(A_0, title=\"The first network, recreated\", ax=axs[2])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Omnibus Embedding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
