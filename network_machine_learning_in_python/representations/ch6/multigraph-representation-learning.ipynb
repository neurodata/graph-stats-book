{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multigraph Representation Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say you're a brain researcher, and you have a bunch of scans of people's brains - some are scans of normal people, and some are scans of people with Abnormal Disease. You have an algorithm that lets you create networks from these brains, so you turn all your brain scans into networks. You want to know if these two different types of networks share a common community structure. It seems like you should be able to find communities in both networks -- they're both brain networks, after all -- but what do you do? How do you even deal with situations in which you have a lot of networks whose nodes all represent the same objects, but which might come from quite different distributions?\n",
    "\n",
    "Well, if your goal is to find the shared community structure between the normal and abnormal networks, you could try embedding your networks and then seeing those embeddings look like. This would serve the dual purpose of having less stuff to deal with and having some way to directly compare your networks in the same space. For example, say you have nine networks of normal brains and nine networks of abnormal brains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from graspologic.simulations import sbm\n",
    "\n",
    "# Generate networks from an SBM, given some parameters\n",
    "def make_network(*probs, n=100, return_labels=False):\n",
    "    p1, p2, p3, p4 = probs\n",
    "    P = np.array([[p1, p2], \n",
    "                  [p3, p4]])\n",
    "    \n",
    "    return sbm([n, n], P, return_labels=return_labels)\n",
    "\n",
    "# make nine normal networks\n",
    "# and nine abnormal networks\n",
    "p1, p2, p3 = .12, .06, .03\n",
    "n = 100\n",
    "labels = [0]*n + [1]*n\n",
    "normals = [make_network(p1, p3, p3, p1, n=n) for i in range(9)]\n",
    "abnormals = [make_network(p3, p1, p1, p3, n=n) for i in range(9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normal brains are all drawn from the same distribution, and the abnormal brains are also all drawn from the same distribution. We're using Stochastic Block models to model both types of brain networks. However, if you look at the code, you'll see that the normal brains were set up to have strong connections within communities, whereas the abnormal brains were set up to have strong connections between communities. Below is a plot of the adjacency networks for every normal and every abnormal brain we've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from graspologic.plot import binary_heatmap, adjplot\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "fig = plt.figure(figsize=(14,7))\n",
    "\n",
    "grid1 = ImageGrid(fig, 121, (3, 3), axes_pad=.1, share_all=True)\n",
    "grid2 = ImageGrid(fig, 122, (3, 3), axes_pad=.1, share_all=True)\n",
    "\n",
    "for i, (axi, axj) in enumerate(zip(grid1, grid2)):\n",
    "    hmn = binary_heatmap(normals[i], ax=axi, cbar=False)\n",
    "    hma = binary_heatmap(abnormals[i], ax=axj, cbar=False)\n",
    "    for ax in [hmn, hma]:\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(True)    \n",
    "        ax.vlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "        ax.hlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "\n",
    "grid1.axes_all[1].set_title(\"Normal Brains\", fontsize=24, y=1.05)\n",
    "grid2.axes_all[1].set_title(\"Abnormal Brains\", fontsize=24, y=1.05)\n",
    "\n",
    "plt.tight_layout(w_pad=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, our goal is to find the community structure in these brains. We'd like to embed our brain networks into some lower-dimensional space to see if we can see this more clearly. Then, we'll see whether we can find some clustering in that space. Try to think about how you might find a lower-dimensional embedding where the location of each node's latent positions uses information from all of the networks.\n",
    "\n",
    "The first thing you might come up with is to average your networks together, and then embed the result of that averaging. It turns out that this is actually the right thing to do in the special case where every network you average comes from the same distribution. In our case, averaging only the normal networks together, and averaging only the abnormal networks together, will produce two separate embeddings with nicely clustered nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.embed import AdjacencySpectralEmbed as ASE\n",
    "\n",
    "# Compute the average adjacency matrix for \n",
    "# normal brains and alzheimer's brains\n",
    "normal_mean = np.array(normals).mean(axis=0)\n",
    "abnormal_mean = np.array(abnormals).mean(axis=0)\n",
    "\n",
    "# Embed both matrices\n",
    "ase = ASE(n_components=2)\n",
    "latents_normal = ase.fit_transform(normal_mean)\n",
    "latents_abnormal = ase.fit_transform(abnormal_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below plot shows what happens when we embed the averaged normal and abnormal networks separately. Like all of our embedding plots, each dot represents the latent positions for a particular node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_latents(latent_positions, *, title=None, labels=None, ax=None, legend=False,\n",
    "                 fontdict=None, **kwargs):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    plot = sns.scatterplot(latent_positions[:, 0], latent_positions[:, 1], hue=labels, \n",
    "                           s=10, ax=ax, palette=\"Set1\", color='k', **kwargs)\n",
    "    if title is not None:\n",
    "        plot.set_title(title, wrap=True, fontdict=fontdict);\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    ax.axes.yaxis.set_visible(False)\n",
    "    if legend:\n",
    "        ax.legend(loc=\"upper right\", title=\"Community\")\n",
    "    elif not legend and np.any(labels):\n",
    "        ax.get_legend().remove()\n",
    "    \n",
    "    return plot\n",
    "\n",
    "# plot\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "plot_latents(latents_normal, title=\"Embedding when we average the \\nnormal networks\", ax=axs[0]);\n",
    "plot_latents(latents_abnormal, title=\"Embedding when we average the \\nabnormal networks\", ax=axs[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these embeddings have clear clustering: there are two communities of nodes in both the normal and the abnormal graphs. We can recover the labels for these communities fairly easily using our pick of unsupervised clustering algorithm. Because we know that the latent positions in an Adjacency Spectral Embedding are normally distributed, we know that the above embeddings are distributed according to a Gaussian Mixture. \"Gaussian\" just means \"normal\", and a gaussian mixture model just means that we have groups of normally distributed data clusters. As a result, it makes sense to cluster these data using scikit-learn's GaussianMixture implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from graspologic.utils import remap_labels\n",
    "\n",
    "# Predict labels for the normal and abnormal brains\n",
    "labels_normal = GMM(n_components=2).fit_predict(latents_normal)\n",
    "labels_abnormal = GMM(n_components=2).fit_predict(latents_normal)\n",
    "\n",
    "# Make corresponding communities have the same values\n",
    "labels_abnormal = remap_labels(labels_normal, labels_abnormal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a plot showing which community we predict each community belongs to, according to our Gaussian Mixture Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "normal_plot_gmm = plot_latents(latents_normal, title=\"Clustering our normal network \\nembedding with a GMM\", \n",
    "             labels=labels_normal, ax=axs[0])\n",
    "abnormal_plot_gmm = plot_latents(latents_abnormal, title=\"Clustering our abnormal network \\nembedding with a GMM\", \n",
    "                   labels=labels_abnormal, ax=axs[1])\n",
    "\n",
    "plt.legend(loc=(1.15, .4), fontsize=\"x-large\", title=\"Community\",\n",
    "           title_fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we wanted to embed *all* of the networks into the same space, both the alzheimer's and normal networks, so that there's only one plot? Let's try it. We'll take all of the networks, both normal and abnormal ones, and then average them together, and then do an Adjacency Spectral Embedding. This will result in a single plot, with each point representing a single node. Do you think we'll still find this nice community separation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_mean = np.array(normals + abnormals).mean(axis=0)\n",
    "all_latents = ase.fit_transform(total_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plot_latents(all_latents, title=\"Embedding when we average everything together\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope, bummer. Our community separation is gone. As far as anybody can tell, our latent positions have just become meaningless noise, so we can't cluster and find communities like we did before.\n",
    "\n",
    "What we've discovered is that, even though it's a great idea to simply average a bunch of networks if they were drawn from the same distribution, it's a horrible idea to average your networks if they might come from different distributions. This is a case of averaging networks which are \"heterogeneous\": Not only are your networks slightly different, but they're *expected* to be different because they're distributed differently. Sampling a lot of heterogenous networks and then averaging them, as you can see above, can result in losing the community signal you might have had.\n",
    "\n",
    "We'd like to find a way to compare these heterogeneous networks directly, so that we can embed all of our networks into the same space and still keep that community structure. Figuring out the best way to do this is a topic under active research, and the set of techniques and tools that have developed as a result are together called multigraph representation learning (here, \"graph\" just means \"network\").\n",
    "\n",
    "There are a few ways of going about multigraph representation learning. The first is called the Embedding Product. The idea "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from graspologic.embed import MultipleASE as MASE\n",
    "from graspologic.embed import OmnibusEmbed as OMNI\n",
    "from graspologic.embed.omni import _get_omni_matrix\n",
    "from graspologic.plot import heatmap\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "def rm_ticks(ax, **kwargs):\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    ax.axes.yaxis.set_visible(False)\n",
    "    sns.despine(ax=ax, **kwargs)\n",
    "\n",
    "# add stack of heatmaps\n",
    "for i in range(5):\n",
    "    ax = fig.add_axes([.02*i, -.02*i, .8, .8]) \n",
    "    ax = binary_heatmap(normals[i], ax=ax, cbar=False)\n",
    "    if i == 0:\n",
    "        ax.set_title(\"Adjacency Matrices\", loc=\"right\", fontsize=20)\n",
    "    rm_ticks(ax, top=False, right=False)\n",
    "    ax.vlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "    ax.hlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "\n",
    "\n",
    "# add arrow\n",
    "arrow_ax = fig.add_axes([.8, .3, .3, .1])\n",
    "rm_ticks(arrow_ax, left=True, bottom=True)\n",
    "plt.arrow(x=0, y=0, dx=1, dy=0, width=.1, color=\"black\") \n",
    "\n",
    "# add stack of heatmaps\n",
    "for i in range(5):\n",
    "    left, bottom, width, height = [.02*i + 1.15, -.02*i, .55, .8]\n",
    "    ax = fig.add_axes([left, bottom, width, height]) \n",
    "    right = left + width\n",
    "    top = bottom + height\n",
    "    rm_ticks(ax, top=False, right=False)\n",
    "\n",
    "ax.text(.5, .5, 'Classifiers', transform=ax.transAxes, horizontalalignment='center', \n",
    "        verticalalignment='center', fontdict={'fontsize': 26})\n",
    "\n",
    "# add second arrow\n",
    "arrow_ax = fig.add_axes([1.85, .3, .3, .1])\n",
    "rm_ticks(arrow_ax, left=True, bottom=True)\n",
    "plt.arrow(x=0, y=0, dx=1, dy=0, width=.1, color=\"black\") \n",
    "\n",
    "# classify\n",
    "latents = MASE(n_components=2).fit_transform(normals+abnormals)\n",
    "labels = GMM(n_components=2).fit_predict(latents)\n",
    "ax = fig.add_axes([2.2, -.02*3, .55, .8])\n",
    "plot_latents(latents, ax=ax, title=\"Classification\", \n",
    "             fontdict={'fontsize': 20}, labels=labels)\n",
    "rm_ticks(ax, top=False, right=False)\n",
    "\n",
    "plt.suptitle(\"Classifier Ensemble\", x=1.5, y=1.1, fontsize=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "# add stack of heatmaps\n",
    "for i in range(5):\n",
    "    ax = fig.add_axes([.02*i, -.02*i, .8, .8]) \n",
    "    ax = binary_heatmap(normals[i], ax=ax, cbar=False)\n",
    "    if i == 0:\n",
    "        ax.set_title(\"Adjacency Matrices\", loc=\"right\", fontsize=16)\n",
    "    rm_ticks(ax, top=False, right=False)\n",
    "    ax.vlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "    ax.hlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "\n",
    "\n",
    "# add arrow\n",
    "arrow_ax = fig.add_axes([.8, .3, .3, .1])\n",
    "rm_ticks(arrow_ax, left=True, bottom=True)\n",
    "plt.arrow(x=0, y=0, dx=1, dy=0, width=.1, color=\"black\") \n",
    "\n",
    "# add joint matrix\n",
    "omni_ax = fig.add_axes([1, -.02*3, .8, .8])\n",
    "A = _get_omni_matrix(normals+abnormals)\n",
    "a_hm = heatmap(A, ax=omni_ax, title=\"Joint Matrix\", cbar=False)\n",
    "for _, spine in a_hm.spines.items():\n",
    "    spine.set_visible(True)\n",
    "    \n",
    "# add second arrow\n",
    "arrow_ax = fig.add_axes([1.75, .3, .3, .1])\n",
    "rm_ticks(arrow_ax, left=True, bottom=True)\n",
    "plt.arrow(x=0, y=0, dx=1, dy=0, width=.1, color=\"black\") \n",
    "\n",
    "# add omni embedding\n",
    "latents_omni = OMNI(n_components=2).fit_transform(normals+abnormals).mean(axis=0)\n",
    "omni_embed_ax = fig.add_axes([2.1, -.02*3, .55, .8])\n",
    "plot_latents(latents_omni, ax=omni_embed_ax, title=\"Joint Embedding\", \n",
    "             fontdict={'fontsize': 16})\n",
    "rm_ticks(omni_embed_ax, top=False, right=False)\n",
    "\n",
    "# add third arrow\n",
    "arrow_ax = fig.add_axes([2.7, .3, .3, .1])\n",
    "rm_ticks(arrow_ax, left=True, bottom=True)\n",
    "plt.arrow(x=0, y=0, dx=1, dy=0, width=.1, color=\"black\") \n",
    "\n",
    "# classify\n",
    "labels_normal = GMM(n_components=2).fit_predict(latents_normal)\n",
    "mase_ax = fig.add_axes([3.05, -.02*3, .55, .8])\n",
    "plot_latents(latents_omni, ax=mase_ax, title=\"Classification\", \n",
    "             fontdict={'fontsize': 16}, labels=labels_normal)\n",
    "\n",
    "plt.suptitle(\"Dissimilarity Combination\", x=2, y=1.1, fontsize=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "# add stack of heatmaps\n",
    "for i in range(5):\n",
    "    ax = fig.add_axes([.02*i, -.02*i, .5, .5]) \n",
    "    ax = binary_heatmap(normals[i], ax=ax, cbar=False)\n",
    "    if i == 0:\n",
    "        ax.set_title(\"Adjacency Matrices\", loc=\"right\")\n",
    "    rm_ticks(ax, top=False, right=False)\n",
    "    ax.vlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "    ax.hlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "\n",
    "# add arrow\n",
    "arrow_ax = fig.add_axes([.5, .2, .3, .1])\n",
    "rm_ticks(arrow_ax, left=True, bottom=True)\n",
    "plt.arrow(x=0, y=0, dx=1, dy=0, width=.1, color=\"black\") \n",
    "\n",
    "# add stack of latent plots\n",
    "for i in range(5):\n",
    "    ax = fig.add_axes([.8+.02*i, -.02*i, .35, .5])\n",
    "    if i == 0:\n",
    "        ax.set_title(\"Separate Embeddings\")\n",
    "    latents = ase.fit_transform(normals[i])\n",
    "    plot = sns.scatterplot(latents[:, 0], latents[:, 1], \n",
    "                       s=10, ax=ax, color=\"black\")\n",
    "    rm_ticks(ax, top=False, right=False)\n",
    "    \n",
    "# add second arrow\n",
    "arrow_ax = fig.add_axes([1.25, .2, .3, .1])\n",
    "rm_ticks(arrow_ax, left=True, bottom=True)\n",
    "plt.arrow(x=0, y=0, dx=1, dy=0, width=.1, color=\"black\") \n",
    "\n",
    "# add group embeddings\n",
    "mase = MASE(n_components=2)\n",
    "latents_mase = mase.fit_transform(normals + abnormals)\n",
    "mase_ax = fig.add_axes([1.57, -.03, .35, .5])\n",
    "plot_latents(latents_mase, ax=mase_ax, title=\"Joint Embedding\")\n",
    "rm_ticks(mase_ax, top=False, right=False)\n",
    "\n",
    "# add third arrow\n",
    "arrow_ax = fig.add_axes([1.95, .2, .3, .1])\n",
    "rm_ticks(arrow_ax, left=True, bottom=True)\n",
    "plt.arrow(x=0, y=0, dx=1, dy=0, width=.1, color=\"black\") \n",
    "\n",
    "# classify\n",
    "labels_normal = GMM(n_components=2).fit_predict(latents_normal)\n",
    "mase_ax = fig.add_axes([2.27, -.03, .35, .5])\n",
    "plot_latents(latents_mase, ax=mase_ax, title=\"Classification\", \n",
    "             labels=labels_normal)\n",
    "\n",
    "plt.suptitle(\"Embedding Product\", x=1.4, y=.7, fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll explore the strengths and weaknesses of different types of multigraph representation learning. Multiple Adjacency Spectral Embedding (MASE) is a technique which embeds a bunch of networks separately (with normal Adjacency Spectral Embedding), and then re-embeds all the separate results into a single space. MASE is nice because you don't actually need each network to be generated from the same distribution - you only need the nodes of the different networks to be aligned and for them to belong to the same communities. Omnibus embedding combines the adjacency matrix of all of the matrices into a single super-matrix, and then embeds that super-matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Adjacency Spectral Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first algorithm we'll explore is called MASE, and is probably the easiest to understand if you know how Adjacency Spectral Embeddings work. Say you have some number of networks, and (like we said above) their nodes are aligned. The goal of MASE is to embed the networks into a single space, with each point in that space representing a single node - but, unlike simply averaging, MASE lets you use networks which aren't necessarily drawn from the same distribution. MASE is based on the common subspace independent-edge (COSIE) model from the multi-network models section of chapter 5, so we're operating under the assumption that there *is* some low-dimensional space common to all of our networks that we can embed into in the first place.\n",
    "\n",
    "Let's try MASE on our group of normal and abnormal brains -- then, we'll dive deeper into what's going on under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.embed import MultipleASE as MASE\n",
    "\n",
    "# Use MASE to embed everything\n",
    "mase = MASE(n_components=2)\n",
    "latents_mase = mase.fit_transform(normals + abnormals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plot_latents(latents_mase, title=\"Embedding when we use MASE on everything together\", labels=labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike simply averaging all of our networks together, MASE manages to keep the community structure that we found when we averaged the normal and abnormal networks separately. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's Going On Under The Hood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure below shows how MASE works. First, we embed the adjacency matrices of a bunch of networks separately, using our standard Adjacency Spectral Embedding algorithm. Then, we take all of those embeddings, concatenate them into a single matrix, and embed the entire concatenated matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../Images/mase1.jpeg\n",
    "---\n",
    "height: 400px\n",
    "name: mase-fig\n",
    "---\n",
    "The MASE algorithm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Collection of Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a set of networks generated from Stochastic Block Models with two communities in each network. The networks have aligned nodes -- meaning that the $i_{th}$ row of all of their adjacency matrices represent the same nodes. The nodes also all belong to the same communities. However, edge probabilities might change depending on the network - in the first network, you might have nodes in the same community having a high chance of connecting to each other, whereas in the second network, nodes are much more likely to be connected to other nodes in different communities. Your goal is to find a common space in which to represent all of these networks, that captures the common community structure in all of these.\n",
    "\n",
    "Below is Python code which generates four networks with Stochastic Block Models. The labels are the same across the networks (which means that nodes have a consistent community no matter which network you're looking at), but the block probability matrices are quite different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from graspologic.simulations import sbm\n",
    "\n",
    "n = 100\n",
    "p1, p2, p3 = .12, .06, .03\n",
    "A1, labels = make_network(p1, p3, p3, p1, \n",
    "                      return_labels=True)\n",
    "A2 = make_network(p1, p3, p3, p2)\n",
    "A3 = make_network(p3, p2, p2, p3)\n",
    "A4 = make_network(p1, p3, p3, p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from graspologic.plot import binary_heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(7,7))\n",
    "for ax, graph in zip(axs.flat, [A1, A2, A3, A4]):\n",
    "    hmap = binary_heatmap(graph, ax=ax, cbar=False)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "    hmap.vlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "    hmap.hlines(n, 0, n*2, colors=\"black\", lw=.9, linestyle=\"dashed\", alpha=.8)\n",
    "    \n",
    "plt.suptitle(\"Four different networks\", fontsize=26, y=.95)\n",
    "fig.subplots_adjust(hspace=.05, wspace=.05)\n",
    "\n",
    "cmap = ListedColormap([\"white\", \"black\"])\n",
    "cbar_ax = fig.add_axes([.95, 0.13, 0.07, 0.75])\n",
    "cbar = fig.colorbar(hmap.imshow(A1, cmap=cmap), cax=cbar_ax)\n",
    "cbar.set_ticks([0.25, 0.75])\n",
    "cbar.set_ticklabels([\"No Edge\", \"Edge\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to embed each of the four networks separately. Doing this lets us see what the individual embeddings of the networks each look like. We'll also need these embeddings to unify the networks all into a single space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.embed import AdjacencySpectralEmbed as ASE\n",
    "\n",
    "networks = [A1, A2, A3, A4]\n",
    "latents = []\n",
    "for network in networks:\n",
    "    ase = ASE(n_components=2)\n",
    "    latent = ase.fit_transform(network)\n",
    "    latents.append(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(7,7), sharex=True, sharey=True)\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    plot_latents(latents[i], title=None, labels=labels, ax=ax)\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "plt.suptitle(\"Embeddings of our four networks\", fontsize=20);\n",
    "\n",
    "# TODO: add legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to take these individual embeddings, concatenate them into a single matrix, and then embed the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.embed import selectSVD\n",
    "\n",
    "concatenated = np.hstack(latents)\n",
    "joint_embedding, *_ = selectSVD(concatenated, n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plot_latents(joint_embedding, title=\"Joint embedding of our four networks\",\n",
    "             labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Graspologic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.embed import MultipleASE as MASE\n",
    "\n",
    "mase = MASE(n_components=2)\n",
    "latents = mase.fit_transform(networks)\n",
    "\n",
    "plot_latents(latents, title=\"MASE embedding\", labels=labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
