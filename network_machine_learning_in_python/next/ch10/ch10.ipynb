{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "funky-robertson",
   "metadata": {},
   "source": [
    "(ch10:next)=\n",
    "# Where do we go from here?\n",
    "\n",
    "Congratulations on making it to the final section of this book. Hopefully, you've learned a lot so far in your journey and how, armed with some statistical intuition and insight, you can bring new approaches to best visualize, represent, and apply network learning techniques to your work, research, personal musings, or any other domain in which you might come across network-valued data. If you enjoyed this book, we have great news: the field is in its infancy, and is simultaneously rapidly expanding. This means that there are a lot of directions that you can go from here to further your knowledge and keep up with the field of network machine learning. We focused a lot of this book on simple networks for simplicity, but most of the techniques described in here (the statistical models, spectral embeddings, and applications in particular) can be easily extended to more complicated networks. \n",
    "\n",
    "Finally, there are many techniques that, in the interest of keeping the book as cohesive and concise as possible, we haven't quite covered yet! To finish this book off, we wanted to give you a brief introduction to network machine learning approaches that rely on *implicit* construction of netework representations to learn. These techniques broadly can be described as *graph neural networks* (or GNNs) for short. In this section, we'll cover the following two applications:\n",
    "\n",
    "1. {ref}`ch10:gnns`\n",
    "2. {ref}`ch10:diffusion`\n",
    "\n",
    "These topics might feel slightly tangential to the overall flavor of the book, as they cannot *quite* be described as statistical learning techniques, but we will present them alongside related statistical learning techniques along with some intuition as to how they differ to hopefully give you some insight into how they are working under the hood in conjunction with a lot of the intuition you've already developed. With any luck, even if your domain of interest does not involve statistical learning directly, a lot of the intuition carries over and can be extremely helpful in conceptualizing the inner workings of some of these techniques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
