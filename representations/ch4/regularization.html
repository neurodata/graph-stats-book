
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>4.4. Regularization &#8212; Hands-on Network Machine Learning with Scikit-Learn and Graspologic</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="5. Why Use Statistical Models?" href="../ch5/ch5.html" />
    <link rel="prev" title="4.3. Representations of Networks" href="network-representations.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Hands-on Network Machine Learning with Scikit-Learn and Graspologic</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../coverpage.html">
                    Hands-on Network Machine Learning with Scikit-Learn and Graspologic
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/terminology.html">
   Terminology
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch1/ch1.html">
   1. The Network Machine Learning Landscape
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/what-is-a-network.html">
     1.1. What is network machine learning?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/why-study-networks.html">
     1.2. How do we study networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/types-nml-problems.html">
     1.3. Types of Network Machine Learning Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/challenges-of-nml.html">
     1.4. Challenges of Network Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/examples-of-applications.html">
     1.5. Examples of applications
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch2/ch2.html">
   2. End-to-end Biology Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/big-picture.html">
     2.1. Look at the big picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/get-the-data.html">
     2.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/prepare-the-data.html">
     2.3. Prepare the Data for Network Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/discover-and-visualize.html">
     2.4. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch3/ch3.html">
   3. End-to-end Business Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/big-picture.html">
     3.1. Look at the Big Picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/get-the-data.html">
     3.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/discover-and-visualize.html">
     3.3. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/prepare-the-data.html">
     3.4. Prepare the Data for Network Algorithms
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Representations
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="ch4.html">
   4. Properties of Networks as a Statistical Object
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="matrix-representations.html">
     4.1. Matrix Representations Of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="properties-of-networks.html">
     4.2. Properties of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="network-representations.html">
     4.3. Representations of Networks
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     4.4. Regularization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch5/ch5.html">
   5. Why Use Statistical Models?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/why-use-models.html">
     5.1. Why Use Statistical Models?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/single-network-models_ER.html">
     5.2. Erdös-Rényi (ER) Random Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/single-network-models_SBM.html">
     5.3. Stochastic Block Models (SBM)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/single-network-models_RDPG.html">
     5.4. Random Dot Product Graphs (RDPG)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/single-network-models_IER.html">
     5.5. Inhomogeneous Erdos Renyi (IER) Random Network Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/multi-network-models.html">
     5.6. Multiple Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/models-with-covariates.html">
     5.7. Network Models with Covariates
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch6/ch6.html">
   6. Learning Network Representations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/estimating-parameters_mle.html">
     6.1. Estimating Parameters in Network Models via MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/spectral-embedding.html">
     6.2. Spectral Embedding Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/estimating-parameters_spectral.html">
     6.3. Estimating Parameters for the RDPG
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/random-walk-diffusion-methods.html">
     6.4. Random walk and diffusion-based methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/graph-neural-networks.html">
     6.5. Graph Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/multigraph-representation-learning.html">
     6.6. Multiple-Network Representation Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/joint-representation-learning.html">
     6.7. Joint Representation Learning
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch7/ch7.html">
   7. Applications When You Have One Network
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch7/community-detection.html">
     7.1. Community Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch7/testing-differences.html">
     7.2. Testing for Differences between Groups of Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch7/model-selection.html">
     7.3. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch7/single-vertex-nomination.html">
     7.4. Single-Network Vertex Nomination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch7/out-of-sample.html">
     7.5. Out-of-sample Embedding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch8/ch8.html">
   8. Applications for Two Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/two-sample-hypothesis.html">
     8.1. Latent Two-Sample Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/significant-communities.html">
     8.2. Two-sample hypothesis testing in SBMs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/graph-matching-vertex.html">
     8.3. Graph Matching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/multiple-vertex-nomination.html">
     8.4. Vertex Nomination For Two Networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch9/ch9.html">
   9. Applications for Many Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/anomaly-detection.html">
     9.1. Anomaly Detection For Timeseries of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/significant-edges.html">
     9.2. Testing for Significant Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/significant-vertices.html">
     9.3. Testing for Significant Vertices
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Appendix
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../appendix/ch10/ch10.html">
   10. Representations (Extended)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch10/alt-reps.html">
     10.1. Alternative Network Representations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../appendix/ch11/ch11.html">
   11. Network Model Theory
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch11/background.html">
     11.1. Background
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch11/foundation.html">
     11.2. Foundation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch11/ers.html">
     11.3. Erdös-Rényi (ER) Random Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch11/sbms.html">
     11.4. Stochastic Block Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch11/rdpgs.html">
     11.5. RDPGs and more general network models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../appendix/ch12/ch12.html">
   12. Learning Representations Theory
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch12/mle-theory.html">
     12.1. Maximum Likelihood Estimate Theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch12/spectral-theory.html">
     12.2. Spectral Method Theory
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://graspologic.readthedocs.io/en/latest/">
   Graspologic Documentation
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/neurodata/graph-stats-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/neurodata/graph-stats-book/issues/new?title=Issue%20on%20page%20%2Frepresentations/ch4/regularization.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/neurodata/graph-stats-book/edit/master/network_machine_learning_in_python/representations/ch4/regularization.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/representations/ch4/regularization.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regularization-of-the-nodes">
   4.4.1. Regularization of the Nodes
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-largest-connected-component-is-the-largest-subnetwork-of-connected-nodes">
     4.4.1.1. The Largest Connected Component is the largest subnetwork of connected nodes
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#degree-trimming-removes-nodes-with-low-degree">
     4.4.1.2. Degree trimming removes nodes with low degree
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regularizing-the-edges">
   4.4.2. Regularizing the Edges
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#symmetrizing-the-network-gives-us-undirectedness">
     4.4.2.1. Symmetrizing the network gives us undirectedness
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#ignoring-a-triangle-of-the-adjacency-matrix">
       4.4.2.1.1. Ignoring a “triangle” of the adjacency matrix
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#taking-a-function-of-the-two-values">
       4.4.2.1.2. Taking a function of the two values
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#diagonal-augmentation">
     4.4.2.2. Diagonal augmentation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lowering-edge-bias">
     4.4.2.3. Lowering edge bias
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#thresholding-converts-weighted-networks-to-binary-networks">
       4.4.2.3.1. Thresholding converts weighted networks to binary networks
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sparsification-removes-potentially-spurious-low-weight-edges">
       4.4.2.3.2. Sparsification removes potentially spurious low-weight edges
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#edge-weight-normalization">
       4.4.2.3.3. Edge-weight normalization
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#z-scoring-standardizes-edge-weights-using-the-normal-distribution">
         4.4.2.3.3.1.
         <span class="math notranslate nohighlight">
          \(z\)
         </span>
         -scoring standardizes edge weights using the normal distribution
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#ranking-edges-preserves-ordinal-relationships">
         4.4.2.3.3.2. Ranking edges preserves ordinal relationships
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#logging-reduces-magnitudinal-differences-between-edges">
         4.4.2.3.3.3. Logging reduces magnitudinal differences between edges
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Regularization</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regularization-of-the-nodes">
   4.4.1. Regularization of the Nodes
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-largest-connected-component-is-the-largest-subnetwork-of-connected-nodes">
     4.4.1.1. The Largest Connected Component is the largest subnetwork of connected nodes
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#degree-trimming-removes-nodes-with-low-degree">
     4.4.1.2. Degree trimming removes nodes with low degree
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regularizing-the-edges">
   4.4.2. Regularizing the Edges
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#symmetrizing-the-network-gives-us-undirectedness">
     4.4.2.1. Symmetrizing the network gives us undirectedness
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#ignoring-a-triangle-of-the-adjacency-matrix">
       4.4.2.1.1. Ignoring a “triangle” of the adjacency matrix
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#taking-a-function-of-the-two-values">
       4.4.2.1.2. Taking a function of the two values
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#diagonal-augmentation">
     4.4.2.2. Diagonal augmentation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lowering-edge-bias">
     4.4.2.3. Lowering edge bias
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#thresholding-converts-weighted-networks-to-binary-networks">
       4.4.2.3.1. Thresholding converts weighted networks to binary networks
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sparsification-removes-potentially-spurious-low-weight-edges">
       4.4.2.3.2. Sparsification removes potentially spurious low-weight edges
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#edge-weight-normalization">
       4.4.2.3.3. Edge-weight normalization
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#z-scoring-standardizes-edge-weights-using-the-normal-distribution">
         4.4.2.3.3.1.
         <span class="math notranslate nohighlight">
          \(z\)
         </span>
         -scoring standardizes edge weights using the normal distribution
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#ranking-edges-preserves-ordinal-relationships">
         4.4.2.3.3.2. Ranking edges preserves ordinal relationships
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#logging-reduces-magnitudinal-differences-between-edges">
         4.4.2.3.3.3. Logging reduces magnitudinal differences between edges
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="regularization">
<h1><span class="section-number">4.4. </span>Regularization<a class="headerlink" href="#regularization" title="Permalink to this headline">#</a></h1>
<p>In practice, many networks you will encounter in network machine learning will <em>not</em> be simple networks. As we discussed in the preceding discussion, many of the techniques we discuss will be just fine to use with weighted networks. Unfortunately, real world networks are often extremely noisy, and so the analysis of one real world network might not generalize very well to a similar real world network. For this reason, we turn to <em>regularization</em>.</p>
<p><strong>Regularization</strong> is the process by which you either:</p>
<ol class="simple">
<li><p>Modify data for the purpose of mitigating overfitting due to idiosyncrasies of the observed data, and/or</p></li>
<li><p>Modify the function you are estimating due to the fragility of the function you estimating to idiosyncracies of the observed data.</p></li>
</ol>
<p>In network machine learning, the first step is to typically modify the network (or networks) themselves to allow better generalization of your statistical inference to new datasets. Later chapters, such as [Chapter 6] and many areas of the Applications, will cover approaches in which you modify the function you are estimating.</p>
<p>For each of the following subsections, we’ll pose an example, a simulation, and code for how to implement the desired regularization approach. It is important to realize that you might use several of these techniques simultaneously in practice, or you might have a reason to use these techniques that go outside of our working examples.</p>
<p>To start this section off, we’re going to introduce an example that’s going to be fundamental in many future sections you see in this book. You have a group of <span class="math notranslate nohighlight">\(50\)</span> local students who attend a school in your area. The first <span class="math notranslate nohighlight">\(25\)</span> of the students polled are athletes, and thhhe second <span class="math notranslate nohighlight">\(25\)</span> of the students polled are in marching band. You want to analyze how good of friends the students are, and to do so, you will use network machine learning. The nodes of the network will be the students. Next, we will describe how the two networks are collected:</p>
<ol class="simple">
<li><p>Activity/Hobby Network: To collect the first network, you ask each student to select from a list of <span class="math notranslate nohighlight">\(50\)</span> school activities and outside hobbies that they enjoy. For a pair of students <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>, the weight of their interest alignment will be a score between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(50\)</span> indicating how many activities or hobbies that they have in common. We will refer to this network as the activity/hobby network. This network is obviously undirected, since if student <span class="math notranslate nohighlight">\(i\)</span> shares <span class="math notranslate nohighlight">\(x\)</span> activities or hobbies with student <span class="math notranslate nohighlight">\(j\)</span>, then student <span class="math notranslate nohighlight">\(j\)</span> also shares <span class="math notranslate nohighlight">\(x\)</span> activities or hobbies with student <span class="math notranslate nohighlight">\(i\)</span>. This network is weighted, since the score is between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(50\)</span>. Finally, this network is loopless, because it would not make sense to look at the activity/hobby alignment of a student with themself, since this number would be largely uninformative as every student would have perfect alignment of activities and hobbies with him or herself.</p></li>
<li><p>Friendship Network: To collect the second network, you ask each student to rate how good of friends they are with other students, on a scale from <span class="math notranslate nohighlight">\(0\)</span> to <span class="math notranslate nohighlight">\(1\)</span>. A score of <span class="math notranslate nohighlight">\(0\)</span> means they are not friends with the student or do not know the student, and a score of <span class="math notranslate nohighlight">\(1\)</span> means the student is their best friend. We will refer to this network as the friendship network. This network is clearly directed, since two students may differ on their understanding of how good of friends they are. This network is weighted, since the score is between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span>. Finally, this network is also loopless, because it would not make sense to ask somebody how good of friends they are with themself.</p></li>
</ol>
<p>Our scientific question of interest is how well activities and hobbies align with perceived notions of friendship. You want to use the preceding networks to learn about a hypothetical third network, a network whose nodes are identical to the two networks above, but whose edges are whether the two individuals are friends (or not) on facebook. To answer this question, you have quite the job to do to make your networks better suited to the task! You begin by simulating some example data, shown below as adjacency matrix heatmaps:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">sbm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">wtargsa</span> <span class="o">=</span> <span class="p">[[</span><span class="nb">dict</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">.09</span><span class="p">),</span> <span class="nb">dict</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">.02</span><span class="p">)],</span>
          <span class="p">[</span><span class="nb">dict</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">.02</span><span class="p">),</span> <span class="nb">dict</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">.06</span><span class="p">)]]</span>

<span class="n">wtargsf</span> <span class="o">=</span> <span class="p">[[</span><span class="nb">dict</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="nb">dict</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">5</span><span class="p">)],</span>
          <span class="p">[</span><span class="nb">dict</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span> <span class="nb">dict</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">2</span><span class="p">)]]</span>

<span class="c1"># activity network</span>
<span class="n">A_activity</span> <span class="o">=</span> <span class="n">sbm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">25</span><span class="p">],</span> <span class="n">p</span><span class="o">=</span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span> <span class="n">wt</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">binomial</span><span class="p">,</span> <span class="n">wtargs</span><span class="o">=</span><span class="n">wtargsa</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># friend network</span>
<span class="n">A_friend</span> <span class="o">=</span> <span class="n">sbm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">25</span><span class="p">],</span> <span class="n">p</span><span class="o">=</span><span class="p">[[</span><span class="mf">.8</span><span class="p">,</span> <span class="mf">.4</span><span class="p">],</span> <span class="p">[</span><span class="mf">.4</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">wt</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">wtargs</span><span class="o">=</span><span class="n">wtargsf</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">sbm</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">heatmap</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A_activity</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Activities/Hobbies Network&quot;</span><span class="p">)</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">A_friend</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Directed Friendship Network&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/regularization_2_0.png" src="../../_images/regularization_2_0.png" />
</div>
</div>
<section id="regularization-of-the-nodes">
<h2><span class="section-number">4.4.1. </span>Regularization of the Nodes<a class="headerlink" href="#regularization-of-the-nodes" title="Permalink to this headline">#</a></h2>
<section id="the-largest-connected-component-is-the-largest-subnetwork-of-connected-nodes">
<h3><span class="section-number">4.4.1.1. </span>The Largest Connected Component is the largest subnetwork of connected nodes<a class="headerlink" href="#the-largest-connected-component-is-the-largest-subnetwork-of-connected-nodes" title="Permalink to this headline">#</a></h3>
<p>You have already learned about the LCC in the preceding section, so we won’t cover the in-depth, but it is important to realize that this is a node regularization technique.</p>
</section>
<section id="degree-trimming-removes-nodes-with-low-degree">
<h3><span class="section-number">4.4.1.2. </span>Degree trimming removes nodes with low degree<a class="headerlink" href="#degree-trimming-removes-nodes-with-low-degree" title="Permalink to this headline">#</a></h3>
<p>Let’s imagine that in your friendship network, there were an additional three athlete students from a nearby school. Perhaps one of these students had a friend in the first school he met at a sports camp, so these students are not a separate component of the network entirely. Even though these students are not <em>totally</em> disconnected from the rest of the network entirely and would not be removed by computing the LCC, their presence in your analysis might still lead to stability issues in future network machine learning tasks. For this reason, it may be advantageous to remove nodes whose degrees are much different from the other nodes in the network.</p>
</section>
</section>
<section id="regularizing-the-edges">
<h2><span class="section-number">4.4.2. </span>Regularizing the Edges<a class="headerlink" href="#regularizing-the-edges" title="Permalink to this headline">#</a></h2>
<section id="symmetrizing-the-network-gives-us-undirectedness">
<h3><span class="section-number">4.4.2.1. </span>Symmetrizing the network gives us undirectedness<a class="headerlink" href="#symmetrizing-the-network-gives-us-undirectedness" title="Permalink to this headline">#</a></h3>
<p>If you wanted to learn from the friendship network about whether two people were friends on facebook, a reasonable first place to start might be to <em>symmetrize</em> the friendship network. The facebook network is <em>undirected</em>, which means that if a student <span class="math notranslate nohighlight">\(i\)</span> is friends on facebook with student <span class="math notranslate nohighlight">\(j\)</span>, then student <span class="math notranslate nohighlight">\(j\)</span> is also friends with student <span class="math notranslate nohighlight">\(i\)</span>. On the other hand, as you learned above, the friendship network was directed. Since your question of interest is about an undirected network but the network you have is directed, it might be useful if you could take the directed friendship network and learn an undirected network from it. This relates directly to the concept of <em>interpretability</em>, in that you need to represent your friendship network in a form that will produce an answer for us about your facebook network which you can understand.</p>
<p>Another reason you might seek to symmetrize the friendship network is that you might think that asymmetries that exist in the network are just <em>noise</em>. You might assume that the adjacency entries <span class="math notranslate nohighlight">\(a_{ij}\)</span> and <span class="math notranslate nohighlight">\(a_{ji}\)</span> relate to one another, so together they might be able to produce a single summary number that better summarizes their relationship all together.</p>
<p>As a final reason, you might think that the asymmetries are meaningful, but that they <em>are not feasible to consider</em>. Many statistical models for networks, and many techniques developed to analyze networks, might only have interpretations for undirected networks. This means that if you want to use these techniques, you might have to settle for making your network undirected first.</p>
<p>There are many other reasons you might want undirected networks, these are just a small subset of the reasons.</p>
<p>Remember that in a symmetric matrix (for an undirected network), <span class="math notranslate nohighlight">\(a_{ij} = a_{ji}\)</span>, so in an <em>asymmetric</em> matrix (for a directed network), <span class="math notranslate nohighlight">\(a_{ij} \neq a_{ji}\)</span>. To symmetrize the friendship network, what you want is a <em>new</em> adjacency value, which we will call <span class="math notranslate nohighlight">\(w_{ij}\)</span>, which will be a function of <span class="math notranslate nohighlight">\(a_{ij}\)</span> and <span class="math notranslate nohighlight">\(a_{ji}\)</span>. Then, you will construct a new adjacency matrix <span class="math notranslate nohighlight">\(A'\)</span>, where each entry <span class="math notranslate nohighlight">\(a_{ij}'\)</span> <em>and</em> <span class="math notranslate nohighlight">\(a_{ji}'\)</span> are set equal to <span class="math notranslate nohighlight">\(w_{ij}\)</span>.  The little apostrophe just signifies that this is a potentially different value than either <span class="math notranslate nohighlight">\(a_{ij}\)</span> or <span class="math notranslate nohighlight">\(a_{ji}\)</span>. Note that by construction, <span class="math notranslate nohighlight">\(A'\)</span> is in fact symmetric, because <span class="math notranslate nohighlight">\(a_{ij}' = a_{ji}'\)</span> due to how you built <span class="math notranslate nohighlight">\(A'\)</span>.</p>
<section id="ignoring-a-triangle-of-the-adjacency-matrix">
<h4><span class="section-number">4.4.2.1.1. </span>Ignoring a “triangle” of the adjacency matrix<a class="headerlink" href="#ignoring-a-triangle-of-the-adjacency-matrix" title="Permalink to this headline">#</a></h4>
<p>The easiest way to symmetrize a network <span class="math notranslate nohighlight">\(A\)</span> is to just ignore part of it entirely. In the adjacency matrix <span class="math notranslate nohighlight">\(A\)</span>, you will remember that you have an upper and a lower triangular part of the matrix:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    A &amp;= \begin{bmatrix}
        a_{11} &amp; \color{red}{a_{12}} &amp; \color{red}{...} &amp; \color{red}{a_{1n}} \\
        \color{blue}{a_{21}} &amp; \ddots &amp; \color{red}{\ddots} &amp; \color{red}{\vdots} \\
        \color{blue}{\vdots} &amp;\color{blue}{\ddots} &amp;\ddots &amp; \color{red}{a_{n-1, n}}\\
        \color{blue}{a_{n1}} &amp; \color{blue}{...} &amp; \color{blue}{a_{n,n-1}} &amp; a_{nn}
    \end{bmatrix},
\end{align*}\]</div>
<p>The entries which are listed in <font color="red">red</font> are called the <strong>upper right triangle of the adjacency matrix above the diagonal</strong>. You will notice that for the entries in the upper right triangle of the adjacency matrix, <span class="math notranslate nohighlight">\(a_{ij}\)</span> is such that <span class="math notranslate nohighlight">\(j\)</span> is <em>always</em> greater than <span class="math notranslate nohighlight">\(i\)</span>. Similarly, the entries which are listed in <font color="blue">blue</font> are called the <strong>lower left triangle of the adjacency matrix below the diagonal</strong>. In the lower left triangle, <span class="math notranslate nohighlight">\(i\)</span> is <em>always</em> greater than <span class="math notranslate nohighlight">\(j\)</span>. These are called <em>triangles</em> because of the shape they make when you look at them in matrix form: notice, for instance, that in the upper right triangle, you have a triangle with three corners of values: <span class="math notranslate nohighlight">\(a_{12}\)</span>, <span class="math notranslate nohighlight">\(a_{1n}\)</span>, and <span class="math notranslate nohighlight">\(a_{n-1, n}\)</span>.</p>
<p>So, how do you ignore a triangle all-together? Well, it’s really quite simple! We will visually show how to ignore the lower left triangle of the adjacency matrix. You start by forming a triangle matrix, <span class="math notranslate nohighlight">\(\Delta\)</span>, as follows:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \Delta &amp;= \begin{bmatrix}
        0 &amp; \color{red}{a_{12}} &amp; \color{red}{...} &amp; \color{red}{a_{1n}} \\
        \color{blue}{0} &amp; \ddots &amp; \color{red}{\ddots} &amp; \color{red}{\vdots} \\
        \color{blue}{\vdots} &amp;\color{blue}{\ddots} &amp;\ddots &amp; \color{red}{a_{n-1, n}}\\
        \color{blue}{0} &amp; \color{blue}{...} &amp; \color{blue}{0} &amp; 0
    \end{bmatrix},
\end{align*}\]</div>
<p>Notice that this matrix <em>keeps</em> all of the upper right triangle of the adjacency matrix above the diagonal the same as in the matrix <span class="math notranslate nohighlight">\(A\)</span>, but replaces the lower left triangle of the adjacency matrix below the diagonal and the diagonal with <span class="math notranslate nohighlight">\(0\)</span>s. Notice that the transpose of <span class="math notranslate nohighlight">\(\Delta\)</span> is the matrix:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \Delta^\top &amp;= \begin{bmatrix}
        0 &amp; \color{blue}{0} &amp; \color{blue}{...} &amp;\color{blue}{0}\\
        \color{red}{a_{12}}&amp; \ddots &amp; \color{blue}{\ddots} &amp; \color{blue}{\vdots} \\
        \color{red}{\vdots}&amp;\color{red}{\ddots} &amp; \ddots &amp; \color{blue}{0} \\
        \color{red}{a_{1n}}&amp;\color{red}{...} &amp;\color{red}{a_{n-1,n}} &amp; 0
    \end{bmatrix}
\end{align*}\]</div>
<p>So when you add the two together, you get this:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \Delta + \Delta^\top &amp;= \begin{bmatrix}
        0 &amp; \color{red}{a_{12}} &amp; \color{red}{...} &amp; \color{red}{a_{1n}} \\
        \color{red}{a_{12}} &amp; \ddots &amp; \color{red}{\ddots} &amp; \color{red}{\vdots} \\
        \color{red}{\vdots}&amp;\color{red}{\ddots} &amp;\ddots &amp; \color{red}{a_{n-1, n}}\\
        \color{red}{a_{1n}}&amp;\color{red}{...} &amp;\color{red}{a_{n-1,n}} &amp; 0
    \end{bmatrix},
\end{align*}\]</div>
<p>You’re almost there! You just need to add back the diagonal of <span class="math notranslate nohighlight">\(A\)</span>, which you will do using the matrix <span class="math notranslate nohighlight">\(diag(A)\)</span> which has values <span class="math notranslate nohighlight">\(diag(A)_{ii} = a_{ii}\)</span>, and <span class="math notranslate nohighlight">\(diag(A)_{ij} = 0\)</span> for any <span class="math notranslate nohighlight">\(i \neq j\)</span>:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    A' &amp;= \Delta + \Delta^\top + diag(A) = \begin{bmatrix}
        a_{11} &amp; \color{red}{a_{12}} &amp; \color{red}{...} &amp; \color{red}{a_{1n}} \\
        \color{red}{a_{12}} &amp; \ddots &amp; \color{red}{\ddots} &amp; \color{red}{\vdots} \\
        \color{red}{\vdots}&amp;\color{red}{\ddots} &amp;\ddots &amp; \color{red}{a_{n-1, n}}\\
        \color{red}{a_{1n}}&amp;\color{red}{...} &amp;\color{red}{a_{n-1,n}} &amp; a_{nn}
    \end{bmatrix},
\end{align*}\]</div>
<p>Which leaves <span class="math notranslate nohighlight">\(A'\)</span> to be a matrix consisting <em>only</em> of entries which were in the upper right triangle of <span class="math notranslate nohighlight">\(A\)</span>. <span class="math notranslate nohighlight">\(A'\)</span> is obviously symmetric, because <span class="math notranslate nohighlight">\(a_{ij}' = a_{ji}'\)</span> for all <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>. Since the adjacency matrix is symmetric, the network <span class="math notranslate nohighlight">\(A'\)</span> represents is undirected.</p>
<p>So what does this mean in terms of the network itself? This means that the network originally had edge weights <span class="math notranslate nohighlight">\(a_{ij}\)</span>, where <span class="math notranslate nohighlight">\(a_{ij}\)</span> might not be equal to <span class="math notranslate nohighlight">\(a_{ji}\)</span>. Student <span class="math notranslate nohighlight">\(i\)</span> might perceive their friendship with student <span class="math notranslate nohighlight">\(j\)</span> as being stronger or weaker than student <span class="math notranslate nohighlight">\(j\)</span> perceived about student <span class="math notranslate nohighlight">\(i\)</span>. What you did here was you basically just ignored any perceived friendships <span class="math notranslate nohighlight">\(a_{ji}\)</span> when <span class="math notranslate nohighlight">\(j\)</span> exceeded <span class="math notranslate nohighlight">\(i\)</span> (the lower left triangle), and simply “replaced” that perceived friendship with the corresponding entry <span class="math notranslate nohighlight">\(a_{ij}\)</span> in the upper right triangle of the adjacency matrix. This produced for us a single friendship strength <span class="math notranslate nohighlight">\(a_{ij}'\)</span> where <span class="math notranslate nohighlight">\(a_{ij}' = a_{ji}'\)</span>.</p>
<p>In graspologic, you can implement this as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.utils</span> <span class="kn">import</span> <span class="n">symmetrize</span>

<span class="c1"># symmetrize with upper right triangle</span>
<span class="n">A_friend_upright_sym</span> <span class="o">=</span> <span class="n">symmetrize</span><span class="p">(</span><span class="n">A_friend</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;triu&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A_friend</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Directed Friendship Network&quot;</span><span class="p">)</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">A_friend_upright_sym</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Friendship Network, Upper-Right Symmetrized&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/regularization_8_0.png" src="../../_images/regularization_8_0.png" />
</div>
</div>
<p>Likewise, you can lower-left symmetrize as well:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># symmetrize with lower left triangle</span>
<span class="n">A_friend_lowleft_sym</span> <span class="o">=</span> <span class="n">symmetrize</span><span class="p">(</span><span class="n">A_friend</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;tril&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A_friend</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Directed Friendship Network&quot;</span><span class="p">)</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">A_friend_lowleft_sym</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Friendship Network, Lower-Left Symmetrized&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/regularization_11_0.png" src="../../_images/regularization_11_0.png" />
</div>
</div>
</section>
<section id="taking-a-function-of-the-two-values">
<h4><span class="section-number">4.4.2.1.2. </span>Taking a function of the two values<a class="headerlink" href="#taking-a-function-of-the-two-values" title="Permalink to this headline">#</a></h4>
<p>There are many other ways you use a function of <span class="math notranslate nohighlight">\(a_{ij}\)</span> and <span class="math notranslate nohighlight">\(a_{ji}\)</span> to get a symmetric matrix (and an undirected network). One is to just average. That is, you can let the matrix <span class="math notranslate nohighlight">\(A'\)</span> be the matrix with entries <span class="math notranslate nohighlight">\(a'_{ij} = \frac{a_{ij} + a_{ji}}{2}\)</span> for all <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>. In matrix form, this operation looks like this:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    A' &amp;= \frac{1}{2} (A + A^\top) \\
    &amp;= \frac{1}{2}\left(\begin{bmatrix}
        a_{11} &amp; ... &amp; a_{1n} \\
        \vdots &amp; \ddots &amp; \vdots \\
        a_{n1} &amp; ... &amp; a_{nn}
    \end{bmatrix} + \begin{bmatrix}
        a_{11} &amp; ... &amp; a_{n1} \\
        \vdots &amp; \ddots &amp; \vdots \\
        a_{1n} &amp; ... &amp; a_{nn}
    \end{bmatrix}\right)\\
    &amp;= \begin{bmatrix}
        \frac{1}{2}(a_{11} + a_{11}) &amp; ... &amp; \frac{1}{2}(a_{1n} + a_{n1}) \\
        \vdots &amp; \ddots &amp; \vdots \\
        \frac{1}{2} (a_{n1} + a_{1n}) &amp; ... &amp; \frac{1}{2}(a_{nn} + a_{nn})
    \end{bmatrix} \\
    &amp;= \begin{bmatrix}
        a_{11} &amp; ... &amp; \frac{1}{2}(a_{1n} + a_{n1}) \\
        \vdots &amp; \ddots &amp; \vdots \\
        \frac{1}{2} (a_{n1} + a_{1n}) &amp; ... &amp; a_{nn}
    \end{bmatrix}
\end{align*}\]</div>
<p>As you can see, for all of the entries, <span class="math notranslate nohighlight">\(a'_{ij} = \frac{1}{2} (a_{ij} + a_{ji})\)</span>, and also <span class="math notranslate nohighlight">\(a_{ji}' = \frac{1}{2}(a_{ji} + a_{ij})\)</span>. These quantities are the same, so <span class="math notranslate nohighlight">\(a_{ij}' = a_{ji}'\)</span>, and <span class="math notranslate nohighlight">\(A'\)</span> is symmetric. As the adjacency matrix is symmetric, the network that <span class="math notranslate nohighlight">\(A'\)</span> represents is undirected.</p>
<p>Remember that the asymmetry in the friendship network means student <span class="math notranslate nohighlight">\(i\)</span> might perceive their friendship with student <span class="math notranslate nohighlight">\(j\)</span> as being stronger or weaker than student <span class="math notranslate nohighlight">\(j\)</span> perceived about student <span class="math notranslate nohighlight">\(i\)</span>. What you did here was instead of just arbitrarily throwing one of those values away, you said that their friendship might be better indicated by averaging the two values. This produced for us a single friendship strength <span class="math notranslate nohighlight">\(a_{ij}'\)</span> where <span class="math notranslate nohighlight">\(a_{ij}' = a_{ji}'\)</span>.</p>
<p>You can implement this in graspologic as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># symmetrize with averaging</span>
<span class="n">A_friend_avg_sym</span> <span class="o">=</span> <span class="n">symmetrize</span><span class="p">(</span><span class="n">A_friend</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;avg&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A_friend</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Directed Friendship Network&quot;</span><span class="p">)</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">A_friend_avg_sym</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Friendship Network, Symmetrized by Averaging&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/regularization_14_0.png" src="../../_images/regularization_14_0.png" />
</div>
</div>
<p>You will use the friendship network symmetrized by averaging in several of the below examples, which we will call the “undirected friendship network”.</p>
</section>
</section>
<section id="diagonal-augmentation">
<h3><span class="section-number">4.4.2.2. </span>Diagonal augmentation<a class="headerlink" href="#diagonal-augmentation" title="Permalink to this headline">#</a></h3>
<p>In your future works with network machine learning, you will come across numerous techniques which operate on adjacency matrices which are <em>positive semi-definite</em>. This word doesn’t mean a whole lot to us for network machine learning, but it has a big implication when you try to use algorithms on many of your networks. Remember that when you have a loopless network, a common practice in network science is to set the diagonal to zero. What this does is it leads to your adjacency matrices being <em>indefinite</em> (which means, <em>not</em> positive semi-definite). For us, this means that many network machine learning techniques simply cannot operate on these adjacency matrices. However, as we mentioned before, these entries are not actually zero, but simply <em>do not exist</em> and you just didn’t have a better way to represent them. Or do we?</p>
<p><em>Diagonal augmentation</em> is a procedure for imputing the diagonals of adjacency matrices for loopless networks. This gives us “placeholder” values that do not cause this issue of indefiniteness, and allow your network machine learning techniques to still work. Remember that for a simple network, the adjacency matrix will look like this:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    A &amp;= \begin{bmatrix}
        0 &amp; a_{12} &amp; ... &amp; a_{1n} \\
        a_{21}&amp; \ddots &amp; &amp; \vdots \\
        \vdots &amp; &amp; \ddots &amp; a_{n-1, n} \\
        a_{n1} &amp;...&amp; a_{n, n-1} &amp; 0
    \end{bmatrix}
\end{align*}\]</div>
<p>What you do is impute the diagonal entries using the <em>fraction of possible edges which exist</em> for each node. This quantity is simply the node degree <span class="math notranslate nohighlight">\(d_i\)</span> (the number of edges which exist for node <span class="math notranslate nohighlight">\(i\)</span>) divided by the number of possible edges node <span class="math notranslate nohighlight">\(i\)</span> could have (which would be node <span class="math notranslate nohighlight">\(i\)</span> connected to each of the other <span class="math notranslate nohighlight">\(n-1\)</span> nodes). Remembering that the degree matrix <span class="math notranslate nohighlight">\(D\)</span> is the matrix whose diagonal entries are the degrees of each node, the diagonal-augmented adjacency matrix is given by:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    A' &amp;= A + \frac{1}{n-1}D = \begin{bmatrix}
        \frac{d_1}{n-1} &amp; a_{12} &amp; ... &amp; a_{1n} \\
        a_{21}&amp; \ddots &amp; &amp; \vdots \\
        \vdots &amp; &amp; \ddots &amp; a_{n-1, n} \\
        a_{n1} &amp;...&amp; a_{n, n-1} &amp; \frac{d_n}{n-1}
    \end{bmatrix}
\end{align*}\]</div>
<p>When the matrices are directed or weighted, the computation is a little different, but fortunately <code class="docutils literal notranslate"><span class="pre">graspologic</span></code> will handle this for us. Let’s see how you would apply this to the directed friendship network:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.utils</span> <span class="kn">import</span> <span class="n">augment_diagonal</span>

<span class="n">A_friend_aug</span> <span class="o">=</span> <span class="n">augment_diagonal</span><span class="p">(</span><span class="n">A_friend</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A_friend</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Directed Friendship Network, A&quot;</span><span class="p">)</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">A_friend_aug</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;With Diagonal Augmentation, A&#39;&quot;</span><span class="p">)</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">A_friend_aug</span><span class="o">-</span><span class="n">A_friend</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;A&#39; - A&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/regularization_18_0.png" src="../../_images/regularization_18_0.png" />
</div>
</div>
<p>As you can see, the diagonal-augmented friendship network and the original directed friendship network differ only in that the diagonals of the diagonal-augmented friendship network are non-zero.</p>
</section>
<section id="lowering-edge-bias">
<h3><span class="section-number">4.4.2.3. </span>Lowering edge bias<a class="headerlink" href="#lowering-edge-bias" title="Permalink to this headline">#</a></h3>
<p>As you are probably aware, in all of machine learning, you are always concerned with the <em>bias/variance tradeoff</em>. The <a class="reference external" href="https://machinelearningmastery.com/gentle-introduction-to-the-bias-variance-trade-off-in-machine-learning/#:~:text=Bias%20is%20the%20simplifying%20assumptions,change%20given%20different%20training%20data."><strong>bias/variance tradeoff</strong></a> is an unfortunate side-effect that concerns how well a learning technique will generalize to new datasets.</p>
<ol class="simple">
<li><p><strong>Bias</strong> is a simplifying assumption of a model that makes the task easier to estimate. For instance, if you have a friendship network, you might make simplifying assumptions, such as an assumption that two athletes frorm different sports have an equally likely chance of being friends with a member of the band.</p></li>
<li><p>On the other hand, the <strong>variance</strong> is the degree to which the an estimate of a task will change when given new data. An assumption that if a player is a football player he has a higher chance of being friends with a band member might make sense given that the band performs at football games.</p></li>
</ol>
<p>The “trade-off” is that these two factors tend to be somewhat at odds, in that raising the bias tends to lower the variance, and vice-versa:</p>
<ol class="simple">
<li><p><strong>High bias, but low variance</strong>: Whereas a lower variance model might be better suited to the situation where the data you expect to see is noisy, it might not as faithfully represent the underlying dynamics you think the network possesses. A low variance model might ignore that athletes might have a different chance of being friends with a band member based on their sport all together. This means that while you won’t get the student relationships <em>correct</em>, you might still be able to get a reasonable estimate that you think is not due to overfitting. In this case, you’ve smoothed away <em>signal</em> from the data at the expense of avoiding <em>noise</em>.</p></li>
<li><p><strong>Low bias, but high variance</strong>: Whereas a low bias model might more faithfully model true relationships in your training data, it might fit your training data a little <em>too</em> well. Fitting the training data too well is a problem known as <strong>overfitting</strong>. If you only had three football team members and tried to assume that football players were better friends with band members, you might not be able to well approximate this relationship because of how few individuals you have who reflect this situation.</p></li>
</ol>
<p>Here, we show several strategies to reduce the bias due to edge weight noise in network machine learning.</p>
<section id="thresholding-converts-weighted-networks-to-binary-networks">
<h4><span class="section-number">4.4.2.3.1. </span>Thresholding converts weighted networks to binary networks<a class="headerlink" href="#thresholding-converts-weighted-networks-to-binary-networks" title="Permalink to this headline">#</a></h4>
<p>The simplest way to reduce edge bias is the process of <em>thresholding</em>. Through thresholding, you choose a threshold value, <span class="math notranslate nohighlight">\(t\)</span>. Next, you simply set all of the entries of the adjacency matrix less than or equal to <span class="math notranslate nohighlight">\(t\)</span> to zero, and the entries of the adjacency matrix above <span class="math notranslate nohighlight">\(t\)</span> to one.</p>
<p>The most common approaches to choosing this threshold are:</p>
<ol class="simple">
<li><p>Set the threshhold to zero: set all non-zero weighted entries to one, and all zero-weight entries to zero. This is most commonly used when you see zero-inflated networks, or weighted networks where you see frequent zero weights,</p></li>
<li><p>Set te threshold to the mean: All values below the mean, then, would be set to zero, and all values above the mean edge-weight to one,</p></li>
<li><p>Use a quantile: A quantile is a percentile divided by <span class="math notranslate nohighlight">\(100\)</span>. In this strategy, you identify a target quantile of the edge-weight distribution. What this means is that you are selecting the lowest <em>fraction</em> of the edge-weights (where that fraction is the quantile that you choose) and setting these edges to <span class="math notranslate nohighlight">\(0\)</span>, and selecting the remaining edges to <span class="math notranslate nohighlight">\(1\)</span>. If you select a quantile of <span class="math notranslate nohighlight">\(0.5\)</span>, this means that you take the smallest <span class="math notranslate nohighlight">\(50\%\)</span> of edges and set them to zero, and the largest <span class="math notranslate nohighlight">\(50\%\)</span> of edges and set them to <span class="math notranslate nohighlight">\(1\)</span>.</p></li>
</ol>
<p>We will show how to use the percentile approach to binarization, with both your activity/hobby and friendship networks. You will threshold using the edge-weight in the <span class="math notranslate nohighlight">\(50^{th}\)</span> percentile. Our example networks of activity/hobby and friendship were loopless, as you could see above. Remember as you learned in the preceding section, that if the network itself is loopless, the diagonal entries simply <em>do not exist</em>; <span class="math notranslate nohighlight">\(0\)</span> is simply a commonly used placeholder. For this reason, when you compute percentiles of edge-weights, you need to <em>exclude the diagonal</em> if the network is loopless. Further, since this network is undirected, you also need to restrict your attention to one triangle of the corresponding adjacency matrix. You choose the upper-right triangle arbitrarily, as the adjacency matrix’s symmetry means the upper-right triangle and lower-right triangle have identical edge-weight distributions. You begin by using this procedure on the friendship network. To complete this processs, you first look at the edge-weight distribution for the friendship network, which is shown below, and identified the edge-weight at the <span class="math notranslate nohighlight">\(0.5\)</span> quartile:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># find the indices which are in the upper triangle and not in the diagonal</span>
<span class="n">upper_tri_non_diag_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">A_friend_avg_sym</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">))</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">A_friend_avg_sym</span><span class="p">[</span><span class="n">upper_tri_non_diag_idx</span><span class="p">],</span> <span class="n">q</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">seaborn</span> <span class="kn">import</span> <span class="n">histplot</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">histplot</span><span class="p">(</span><span class="n">A_friend_avg_sym</span><span class="p">[</span><span class="n">upper_tri_non_diag_idx</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Edge Weight&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Number of Edges&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Undirected Friendship Network Off-Diagonal Edge-Weight Distribution&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;dashed&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="mf">.03</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="s2">&quot;0.5 quantile, t = </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/regularization_23_0.png" src="../../_images/regularization_23_0.png" />
</div>
</div>
<p>The <span class="math notranslate nohighlight">\(0.5\)</span> quantile, it turns out, is about <span class="math notranslate nohighlight">\(0.3\)</span>. This is because about <span class="math notranslate nohighlight">\(50\%\)</span> of the edges are less than this threshold, and about <span class="math notranslate nohighlight">\(50\%\)</span> of the edges are greater than this threshold. There is exactly one more edge in less than or equal to <span class="math notranslate nohighlight">\(t\)</span>, because this edge is exactly the median (an alternative name for the <span class="math notranslate nohighlight">\(0.5\)</span> quartile) value:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of edges less than or equal to t: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A_friend_avg_sym</span><span class="p">[</span><span class="n">upper_tri_non_diag_idx</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">t</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of edges greater than or equal to t: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A_friend_avg_sym</span><span class="p">[</span><span class="n">upper_tri_non_diag_idx</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">t</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of edges less than or equal to t: 613
Number of edges greater than or equal to t: 612
</pre></div>
</div>
</div>
</div>
<p>Next, you will assign the edges less than or equal to <span class="math notranslate nohighlight">\(t\)</span> to zero, and the edges greater than or equal to <span class="math notranslate nohighlight">\(t\)</span> to one:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">copy</span>
<span class="n">A_friend_thresh</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">A_friend_avg_sym</span><span class="p">)</span>  <span class="c1"># copy the network over</span>

<span class="c1"># threshold using t</span>
<span class="n">A_friend_thresh</span><span class="p">[</span><span class="n">A_friend_thresh</span> <span class="o">&lt;=</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">A_friend_thresh</span><span class="p">[</span><span class="n">A_friend_thresh</span> <span class="o">&gt;</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A_friend_avg_sym</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Undirected Friendship Network, Weighted&quot;</span><span class="p">)</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">A_friend_thresh</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Undirected Friendship Network, Thresholded at 50-ptile&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/regularization_28_0.png" src="../../_images/regularization_28_0.png" />
</div>
</div>
<p>Since the friendship network is now undirected (you made the adjacency matrix symmetric through averaging), loopless (because we defined it that way), and binary (because you thresholded the edges), you have now turned it into a <em>simple</em> network! Great job. Next, we will discuss an important property as to <em>why</em> thresholding using a quantile tends to be a very common tactic to obtaining simple networks from networks which are undirected and loopless. Remember that in the last section, we defined the network density for a simple network as:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    density(A) &amp;= \frac{2\sum_{j &gt; i}a_{ij}}{n(n - 1)}.
\end{align*}\]</div>
<p>Since you have thresholded at the <span class="math notranslate nohighlight">\(50^{th}\)</span> percentile for the symmetric friendship network, this means that about <span class="math notranslate nohighlight">\(50\)</span> percent of the possible edges will exist (the <em>largest</em> <span class="math notranslate nohighlight">\(50\)</span> percent of edges), and <span class="math notranslate nohighlight">\(50\)</span> percent of the possible edges will not exist (the <em>smallest</em> <span class="math notranslate nohighlight">\(50\)</span> percent of edges). Remembering that the number of possible edges was <span class="math notranslate nohighlight">\(\frac{1}{2}n(n - 1)\)</span> for an undirected network, this means that <span class="math notranslate nohighlight">\(\sum_{j &gt; i}a_{ij}\)</span> must be half of <span class="math notranslate nohighlight">\(\frac{1}{2}n(n - 1)\)</span>, or <span class="math notranslate nohighlight">\(\frac{1}{4}n(n - 1)\)</span>. Therefore:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    density(A) &amp;= \frac{2\sum_{j &gt; i}a_{ij}}{n(n - 1)}, \\
    &amp;= \frac{2\cdot \frac{1}{4}n(n - 1)}{n(n - 1)},\;\;\;\sum_{j &gt; i}a_{ij} = \frac{1}{4}n(n - 1) \\
    &amp;= 0.5.
\end{align*}\]</div>
<p>So when you threshold the network at a quantile <span class="math notranslate nohighlight">\(t\)</span>, you end with a network of density also equal to <span class="math notranslate nohighlight">\(t\)</span>! Let’s confirm that this is the case for your symmetric friendship network:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.utils</span> <span class="kn">import</span> <span class="n">is_unweighted</span><span class="p">,</span> <span class="n">is_loopless</span><span class="p">,</span> <span class="n">is_symmetric</span>

<span class="k">def</span> <span class="nf">simple_network_dens</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="c1"># make sure the network is simple</span>
    <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">is_unweighted</span><span class="p">(</span><span class="n">X</span><span class="p">))</span> <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="n">is_loopless</span><span class="p">(</span><span class="n">X</span><span class="p">))</span> <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="n">is_symmetric</span><span class="p">(</span><span class="n">X</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Network is not simple!&quot;</span><span class="p">)</span>
    <span class="c1"># count the non-zero entries in the upper-right triangle</span>
    <span class="c1"># for a simple network X</span>
    <span class="n">nnz</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="c1"># number of nodes</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># number of possible edges is 1/2 * n * (n-1)</span>
    <span class="n">poss_edges</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">n</span><span class="o">*</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">nnz</span><span class="o">/</span><span class="n">poss_edges</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Network Density: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">simple_network_dens</span><span class="p">(</span><span class="n">A_friend_thresh</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Network Density: 0.500
</pre></div>
</div>
</div>
</div>
<p>This is desirable for network machine learning because many network properties (such as the summary statistics we have discussed so far, and numerous other properties we will discuss in later chapters) can vary when the network density changes. This means that a network of a different density might have a higher clustering coefficient than a network of a lower density simply due to the fact that its density is higher (and therefore, there are more opportunities for closed triangles because each node has more connections). This means that when you threshold groups of networks and compare them, thresholding using a quantile will be very valuable.</p>
<p>Note that a common pitfall you might run into with thresholding (and the broader class of techniques known as <em>sparsification</em> approaches) that rely on quantiles occurs when a weighted network can only take non-negative edge-weights. This corresponds to a network with an adjacency matrix <span class="math notranslate nohighlight">\(A\)</span> where every <span class="math notranslate nohighlight">\(a_{ij}\)</span> is greater than or equal to <span class="math notranslate nohighlight">\(0\)</span>. In this case, one must be careful to choose a threshold which is not zero. Let’s consider a network were <span class="math notranslate nohighlight">\(60\%\)</span> of the entries are zeros, and <span class="math notranslate nohighlight">\(40\%\)</span> of the entries take a random value between <span class="math notranslate nohighlight">\(5\)</span> and <span class="math notranslate nohighlight">\(10\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">er_nm</span>

<span class="c1"># 10 nodes</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">10</span>
<span class="c1"># total number of edges is 40% of the number of possible edges</span>
<span class="c1"># 1/2 * n * (n-1)</span>
<span class="n">m</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.4</span><span class="o">*</span><span class="mf">0.5</span><span class="o">*</span><span class="n">n</span><span class="o">*</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">er_nm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">wt</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">,</span> <span class="n">wtargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Network with 40</span><span class="si">% o</span><span class="s2">f possible edges&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/regularization_33_0.png" src="../../_images/regularization_33_0.png" />
</div>
</div>
<p>If you threshold at the <span class="math notranslate nohighlight">\(50^{th}\)</span> percentile, since <span class="math notranslate nohighlight">\(60\)</span> percent of the edges do not exist, then the <span class="math notranslate nohighlight">\(50^{th}\)</span> percentile is still just zero:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># use the quantile function to obtain the threshold</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">))],</span> <span class="n">q</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>  <span class="c1"># quantile = percentile / 100</span>
<span class="n">A_thresh</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>  <span class="c1"># copy the network over</span>

<span class="c1"># threshold using t</span>
<span class="n">A_thresh</span><span class="p">[</span><span class="n">A_thresh</span> <span class="o">&lt;=</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">A_thresh</span><span class="p">[</span><span class="n">A_thresh</span> <span class="o">&gt;</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Threshold for 50th percentile: </span><span class="si">{:d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">t</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Threshold for 50th percentile: 8
</pre></div>
</div>
</div>
</div>
<p>And you don’t actually end up with a network having a density of <span class="math notranslate nohighlight">\(0.5\)</span>, but rather, the same as the fraction of non-zero edges in the original network (which was <span class="math notranslate nohighlight">\(40\%\)</span>, or <span class="math notranslate nohighlight">\(0.4\)</span>):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dens</span> <span class="o">=</span> <span class="n">simple_network_dens</span><span class="p">(</span><span class="n">A_thresh</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A_thresh</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;50 ptile thresholded network; dens = </span><span class="si">{:.1f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dens</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/regularization_38_0.png" src="../../_images/regularization_38_0.png" />
</div>
</div>
<p>So the take-home message is that you need to be careful that if you want to conclude that two percentile-thresholded networks have the same network density (equal to the percentile you thresholded at), that you have enough non-zero entries to threshold with across both (or all) of the networks.</p>
</section>
<section id="sparsification-removes-potentially-spurious-low-weight-edges">
<h4><span class="section-number">4.4.2.3.2. </span>Sparsification removes potentially spurious low-weight edges<a class="headerlink" href="#sparsification-removes-potentially-spurious-low-weight-edges" title="Permalink to this headline">#</a></h4>
<p>The next simplest edge-weight regularization technique is called <em>sparsificiation</em>. Remember that your undirected friendship network looked like this:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A_friend_avg_sym</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Undirected Friendship Network&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/regularization_40_0.png" src="../../_images/regularization_40_0.png" />
</div>
</div>
<p>Notice that for a <em>lot</em> of the off-diagonal entries, many of the values are really tiny compared to the maximum value in the network which is almost <span class="math notranslate nohighlight">\(1\)</span>. What if the way you measured these edges was very sensitive to high values, but had trouble discerning whether a value was actually zero, or was just really small?</p>
<p>For this particular situation, we turn to <em>sparsification</em>. Through sparsification, you proceed very similar to thresholding like you did above. Remember that you chose a threshold, <span class="math notranslate nohighlight">\(t\)</span>, and first set all adjacency values less than or equal to <span class="math notranslate nohighlight">\(t\)</span> to zero. Now, you’re done! You simply skip the step of setting values greater than <span class="math notranslate nohighlight">\(t\)</span> to one. Let’s try an example where you take the friendship network, and sparsify the network using the <span class="math notranslate nohighlight">\(0.7\)</span> quantile. Note that this will lead to the smallest <span class="math notranslate nohighlight">\(70\)</span> percent of edges to take the value of zero, and the largest <span class="math notranslate nohighlight">\(30\)</span> percent of edges will keep their original edge-weights:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">q</span><span class="o">=</span><span class="mf">0.7</span>  <span class="c1"># the quantile to sparsify with</span>

<span class="c1"># use the quantile function to obtain the threshold</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">A_friend_avg_sym</span><span class="p">[</span><span class="n">upper_tri_non_diag_idx</span><span class="p">],</span> <span class="n">q</span><span class="o">=</span><span class="n">q</span><span class="p">)</span>  <span class="c1"># quantile = percentile / 100</span>
<span class="n">A_friend_sparse</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">A_friend_avg_sym</span><span class="p">)</span>  <span class="c1"># copy the network over</span>

<span class="c1"># sparsify using t</span>
<span class="n">A_friend_sparse</span><span class="p">[</span><span class="n">A_friend_sparse</span> <span class="o">&lt;=</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A_friend_avg_sym</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Undirected Friendship Network&quot;</span><span class="p">)</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">A_friend_sparse</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Undirected Friendship Network, Sparsified at 70th ptile&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/regularization_43_0.png" src="../../_images/regularization_43_0.png" />
</div>
</div>
<p>Notice that many of the small entries in the off-diagonal areas now have a value of zero. Again, you have the same pitfalls for sparsification as you did with thresholding, where if the network takes only non-negative edge weights and the percentile you choose corresponds to a threshold of zero, you might not actually end up changing anything.</p>
</section>
<section id="edge-weight-normalization">
<h4><span class="section-number">4.4.2.3.3. </span>Edge-weight normalization<a class="headerlink" href="#edge-weight-normalization" title="Permalink to this headline">#</a></h4>
<p>With weighted networks, it is often the case that you might want to reshape the distributions of edge-weights in your networks to highlight particular properties. Notice that the edge-weights for your friendship network takes values between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span>, but your activity network takes values between <span class="math notranslate nohighlight">\(0\)</span> and almost <span class="math notranslate nohighlight">\(15\)</span>. How can you possibly compare between these two networks when the edge-weights take such different ranges of values? You turn to standardization, which allows us to place values from different networks on the same scale.</p>
<section id="z-scoring-standardizes-edge-weights-using-the-normal-distribution">
<h5><span class="section-number">4.4.2.3.3.1. </span><span class="math notranslate nohighlight">\(z\)</span>-scoring standardizes edge weights using the normal distribution<a class="headerlink" href="#z-scoring-standardizes-edge-weights-using-the-normal-distribution" title="Permalink to this headline">#</a></h5>
<p>The first approach to edge-weight standardization is known commonly as <span class="math notranslate nohighlight">\(z\)</span>-scoring. Suppose that <span class="math notranslate nohighlight">\(A\)</span> is the adjacency matrix, with entries <span class="math notranslate nohighlight">\(a_{ij}\)</span>. With a <span class="math notranslate nohighlight">\(z\)</span>-score, you will rescale the weights of the adjacency matrix, such that the new edge-weights (called <span class="math notranslate nohighlight">\(z\)</span>-scores) are approximately normally distributed. The reason this can be useful is that the normal distribution is pretty ubiquitous across many branches of science, and therefore, a <span class="math notranslate nohighlight">\(z\)</span>-score is relatively easy to communicate with other scientists. Further, many things that exist in nature can be well-approximated by a normal distribution, so it seems like a reasonable place to start to use a <span class="math notranslate nohighlight">\(z\)</span>-score for edge-weights, too! The <span class="math notranslate nohighlight">\(z\)</span>-score is defined as follows. You will construct the <span class="math notranslate nohighlight">\(z\)</span>-scored adjacency matrix <span class="math notranslate nohighlight">\(Z\)</span>, whose entries <span class="math notranslate nohighlight">\(z_{ij}\)</span> are the corresponding <span class="math notranslate nohighlight">\(z\)</span>-scores of the adjacency matrix’s entries <span class="math notranslate nohighlight">\(a_{ij}\)</span>. For a weighted, loopless network, you use an estimate of the <em>mean</em>, <span class="math notranslate nohighlight">\(\hat \mu\)</span>, and the <em>unbiased</em> estimate of the <em>variance</em>, <span class="math notranslate nohighlight">\(\hat \sigma^2\)</span>), which can be computed as follows:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \hat\mu &amp;= \frac{1}{n}\sum_{i \neq j}a_{ij},\\
    \hat\sigma^2 &amp;= \frac{1}{n - 1}\sum_{i \neq j} (a_{ij} - \hat\mu)^2.
\end{align*}\]</div>
<p>The <span class="math notranslate nohighlight">\(z\)</span>-score for the <span class="math notranslate nohighlight">\((i,j)\)</span> entry is simply the quantity:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    z_{ij} &amp;= \frac{a_{ij} - \hat\mu}{\hat\sigma}
\end{align*}\]</div>
<p>Since your network is loopless, notice that these sums are for all <em>non-diagonal</em> entries where <span class="math notranslate nohighlight">\(i \neq j\)</span>. If the network were not loopless, you would include diagonal entries in the calculation, and instead would sum over all possible combinations of <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>. the interpretation of the <span class="math notranslate nohighlight">\(z\)</span>-score <span class="math notranslate nohighlight">\(z_{ij}\)</span> is the <em>number of stadard deviations</em> that the entry <span class="math notranslate nohighlight">\(a_{ij}\)</span> is from the mean, <span class="math notranslate nohighlight">\(\hat \mu\)</span>.</p>
<p>We will demonstrate on the directed friendship network. You can implement <span class="math notranslate nohighlight">\(z\)</span>-scoring as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">zscore</span>

<span class="k">def</span> <span class="nf">z_score_loopless</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_loopless</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;The network has loops!&quot;</span><span class="p">)</span>
    <span class="c1"># the entries of the adjacency matrix that are not on the diagonal</span>
    <span class="n">non_diag_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">))</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">Z</span><span class="p">[</span><span class="n">non_diag_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">zscore</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">non_diag_idx</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">Z</span>

<span class="n">ZA_friend</span> <span class="o">=</span> <span class="n">z_score_loopless</span><span class="p">(</span><span class="n">A_friend</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A_friend</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Directed Friendship Network&quot;</span><span class="p">)</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">ZA_friend</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Directed Friendship Network, After Z-score&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/regularization_47_0.png" src="../../_images/regularization_47_0.png" />
</div>
</div>
<p>Next, you will look at the edge-weight histogram for the directed friendship network before and after <span class="math notranslate nohighlight">\(z\)</span>-scoring. Remember that the network is loopless, so again you exclude the diagonal entries:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">seaborn</span> <span class="kn">import</span> <span class="n">histplot</span>

<span class="n">non_diag_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">A_friend</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">))</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">histplot</span><span class="p">(</span><span class="n">A_friend</span><span class="p">[</span><span class="n">non_diag_idx</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Edge Weight&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Number of Edges&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Directed Friendship Network, Before Z-score&quot;</span><span class="p">);</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">histplot</span><span class="p">(</span><span class="n">ZA_friend</span><span class="p">[</span><span class="n">non_diag_idx</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Z-score&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Number of Edges&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Directed Friendship Network, After Z-score&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/regularization_49_0.png" src="../../_images/regularization_49_0.png" />
</div>
</div>
<p>The theory for when, and why, to use <span class="math notranslate nohighlight">\(z\)</span>-scoring for network machine learning tends to go something like this: many things tend to be normally distributed with the same mean and variance, so perhaps that is a reasonable expectation for your network, too. Unfortunately, we find this often to <em>not</em> be the case. In fact, we often find that the specific distribution of edge weights itself often might be lamost infeasible to identify in a population of networks, and therefore <em>almost</em> irrelevant all-together. To this end, we turn to instead <em>ranking</em> the edges.</p>
</section>
<section id="ranking-edges-preserves-ordinal-relationships">
<h5><span class="section-number">4.4.2.3.3.2. </span>Ranking edges preserves ordinal relationships<a class="headerlink" href="#ranking-edges-preserves-ordinal-relationships" title="Permalink to this headline">#</a></h5>
<p>The idea behind ranking is as follows. You don’t really know much useful information as to how the distribution of edge weights varies between a given pair of networks. For this reason, you want to virtually eliminate the impact of that distribution <em>almost</em> entirely. However, you know that if one edge-weight is larger than another edge-weight, that you do in fact trust that relationship. What this means is that you want something which preserves <em>ordinal</em> relationships in your edge-weights, but ignores other properties of the edge-weights. An ordinal relationship just means that you have a natural ordering to the edge-weights. This means that you can identify a largest edge-weight, a smallest edge-weight, and every position in between. When you want to preserve ordinal relationships in your network, you do something called <em>passing the non-zero edge-weights to ranks</em>. We will often use the abbreviation <code class="docutils literal notranslate"><span class="pre">ptr</span></code> to define this function because it is so useful for weighted networks. You pass non-zero edge-weights to ranks as follows:</p>
<ol class="simple">
<li><p>Identify all of the non-zero entries of the adjacency matrix <span class="math notranslate nohighlight">\(A\)</span>.</p></li>
<li><p>Count the number of non-zero entries of the adjacency matrix <span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(n_{nz}\)</span>.</p></li>
<li><p>Rank all of the non-zero edges in the adjacency matrix <span class="math notranslate nohighlight">\(A\)</span>, where for a non-zero entry <span class="math notranslate nohighlight">\(a_{ij}\)</span>, <span class="math notranslate nohighlight">\(rank(a_{ij}) = 1\)</span> if <span class="math notranslate nohighlight">\(a_{ij}\)</span> is the smallest non-zero edge-weight, and <span class="math notranslate nohighlight">\(rank(a_{ij}) = n_{nz}\)</span> if <span class="math notranslate nohighlight">\(a_{ij}\)</span> is the largest edge-weight. Ties are settled by using the average rank of the two entries.</p></li>
<li><p>Report the weight of each non-zero entry <span class="math notranslate nohighlight">\((i,j)\)</span> as <span class="math notranslate nohighlight">\(r_{ij} = \frac{rank(a_{ij})}{n_{nz} + 1}\)</span>, and for eachh zero entry as <span class="math notranslate nohighlight">\(r_{ij} = 0\)</span>.</p></li>
</ol>
<p>Below, you pass-to-ranks the directed friendship network using <code class="docutils literal notranslate"><span class="pre">graspologic</span></code>, showing both the adjacency matrix and the edge-weight distribution before and after <code class="docutils literal notranslate"><span class="pre">ptr</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.utils</span> <span class="kn">import</span> <span class="n">pass_to_ranks</span>

<span class="n">RA_friend</span> <span class="o">=</span> <span class="n">pass_to_ranks</span><span class="p">(</span><span class="n">A_friend</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A_friend</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Directed Friendship Network&quot;</span><span class="p">)</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">RA_friend</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Directed Friendship Network, After PTR&quot;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/regularization_52_0.png" src="../../_images/regularization_52_0.png" />
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">histplot</span><span class="p">(</span><span class="n">A_friend</span><span class="p">[</span><span class="n">non_diag_idx</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Edge Weight&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Number of Edges&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Directed Friendship Network, Before PTR&quot;</span><span class="p">);</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">histplot</span><span class="p">(</span><span class="n">RA_friend</span><span class="p">[</span><span class="n">non_diag_idx</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">binrange</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;normalized rank&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Number of Edges&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Directed Friendship Network, After PTR&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/regularization_53_0.png" src="../../_images/regularization_53_0.png" />
</div>
</div>
<p>The edge-weights for the adjacency matrix <span class="math notranslate nohighlight">\(R\)</span> after <code class="docutils literal notranslate"><span class="pre">ptr</span></code> has the interpretation that each entry <span class="math notranslate nohighlight">\(r_{ij}\)</span> which is non-zero is the <em>quantile</em> of that entry amongst <em>the other non-zero entries</em>. This is unique in that it is completely <em>distribution-free</em>, which means that you don’t need to assume anything about the distribution of the edge-weights to have an interpretable quantity. On the other hand, the <span class="math notranslate nohighlight">\(z\)</span>-score had the interpretation of the number of standard deviations from the mean, which is only a sensible quantity to compare if you assume the population of edge-weights are normally distributed.</p>
<p>Another useful quantity related to pass-to-ranks is known as the zero-boosted pass-to-ranks. Zero-boosted pass-to-ranks is conducted as follows:</p>
<ol class="simple">
<li><p>Identify all of the non-zero entries of the adjacency matrix <span class="math notranslate nohighlight">\(A\)</span>.</p></li>
<li><p>Count the number of non-zero entries of the adjacency matrix <span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(n_{nz}\)</span>, <em>and</em> the number of zero-entries of the adjacency matrix <span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(n_z\)</span>. Note that since the values of the adjacency matrix are either zero or non-zero, that <span class="math notranslate nohighlight">\(n_{nz} + n_z = n^2\)</span>, as <span class="math notranslate nohighlight">\(A\)</span> is an <span class="math notranslate nohighlight">\(n \times n\)</span> matrix and therefore has <span class="math notranslate nohighlight">\(n^2\)</span> total entries.</p></li>
<li><p>Rank all of the non-zero edges in the adjacency matrix <span class="math notranslate nohighlight">\(A\)</span>, where for a non-zero entry <span class="math notranslate nohighlight">\(a_{ij}\)</span>, <span class="math notranslate nohighlight">\(rank(a_{ij}) = 1\)</span> if <span class="math notranslate nohighlight">\(a_{ij}\)</span> is the smallest non-zero edge-weight, and <span class="math notranslate nohighlight">\(rank(a_{ij}) = n_{nz}\)</span> if <span class="math notranslate nohighlight">\(a_{ij}\)</span> is the largest edge-weight. Ties are settled by using the average rank of the two entries.</p></li>
<li><p>Report the weight of each non-zero entry <span class="math notranslate nohighlight">\((i,j)\)</span> as <span class="math notranslate nohighlight">\(r_{ij}' = \frac{n_z + rank(a_{ij})}{n^2 + 1}\)</span>, and for each zero entry as <span class="math notranslate nohighlight">\(r_{ij}' = 0\)</span>.</p></li>
</ol>
<p>The edge-weights for the adjacency matrix <span class="math notranslate nohighlight">\(R'\)</span> after zero-boosted <code class="docutils literal notranslate"><span class="pre">ptr</span></code> have the interpretation that each entry <span class="math notranslate nohighlight">\(r_{ij}'\)</span> is the quantile of that entry amongst <em>all</em> of the entries. Let’s instead use zero-boosted <code class="docutils literal notranslate"><span class="pre">ptr</span></code> on your network:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">RA_friend_zb</span> <span class="o">=</span> <span class="n">pass_to_ranks</span><span class="p">(</span><span class="n">A_friend</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;zero-boost&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">histplot</span><span class="p">(</span><span class="n">A_friend</span><span class="p">[</span><span class="n">non_diag_idx</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Edge Weight&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Number of Edges&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Directed Friendship Network, Before zb-PTR&quot;</span><span class="p">);</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">histplot</span><span class="p">(</span><span class="n">RA_friend_zb</span><span class="p">[</span><span class="n">non_diag_idx</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">binrange</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">23</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Edge quantile&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Number of Edges&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Directed Friendship Network, After zb-PTR&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/regularization_56_0.png" src="../../_images/regularization_56_0.png" />
</div>
</div>
</section>
<section id="logging-reduces-magnitudinal-differences-between-edges">
<h5><span class="section-number">4.4.2.3.3.3. </span>Logging reduces magnitudinal differences between edges<a class="headerlink" href="#logging-reduces-magnitudinal-differences-between-edges" title="Permalink to this headline">#</a></h5>
<p>When you look at the distribution of non-zero edge-weights for the activity/hobby network or the friendship network, you notice a strange pattern, known as a <em>right-skew</em>:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">histplot</span><span class="p">(</span><span class="n">A_activity</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Edge Weight&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Number of Edges&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Activity/Hobby Network Edge Distribution&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/regularization_59_0.png" src="../../_images/regularization_59_0.png" />
</div>
</div>
<p>Notice that <em>most</em> of the edges have weights which are comparatively small, between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(34\)</span>, but some of the edges have weights which are much (much) larger. A <strong>right-skew</strong> exists when the majority of edge-weights are small, but some of the edge-weights take values which are much larger.</p>
<p>What if you want to make these large values more similar in relation to the smaller values, but you simultaneously want to preserve properties of the underlying distribution of the edge-weights? Well, you can’t use <code class="docutils literal notranslate"><span class="pre">ptr</span></code>, because <code class="docutils literal notranslate"><span class="pre">ptr</span></code> will throw away all of the information about the edge-weight distribution other than the ordinal relationship between pairs of edges. To interpret what this means, you might think that there is a big difference between sharing no interests compared to three interests in common, but there is not as much of a difference in sharing ten interests compared to thirteen interests in common.</p>
<p>To do this, you instead turn to the logarithm function. The logarithm function <span class="math notranslate nohighlight">\(log_{10}(x)\)</span> is defined for positive values <span class="math notranslate nohighlight">\(x\)</span> as the value <span class="math notranslate nohighlight">\(c_x\)</span> where <span class="math notranslate nohighlight">\(x = 10^{c_x}\)</span>. In this sense, it is the “number of powers of ten” to obtain the value <span class="math notranslate nohighlight">\(x\)</span>. You will notice that the logarithm function looks like this:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">logxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">logxs</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;$log_</span><span class="si">{10}</span><span class="s2">(x)$&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/regularization_61_0.png" src="../../_images/regularization_61_0.png" />
</div>
</div>
<p>What is key to noice about this function is that, as <span class="math notranslate nohighlight">\(x\)</span> increases, the log of <span class="math notranslate nohighlight">\(x\)</span> increases by a <em>decreasing</em> amount. Let’s imagine you have three values, <span class="math notranslate nohighlight">\(x = .001\)</span>, <span class="math notranslate nohighlight">\(y = .1\)</span>, and <span class="math notranslate nohighlight">\(z = 10\)</span>. A calculator will give you that <span class="math notranslate nohighlight">\(log_{10}(x) = -3, log_{10}(y) = -1\)</span>, and <span class="math notranslate nohighlight">\(log_{10}(z) = 1\)</span>. Even though <span class="math notranslate nohighlight">\(y\)</span> is only <span class="math notranslate nohighlight">\(.099\)</span> units bigger than <span class="math notranslate nohighlight">\(x\)</span>, its logarithm <span class="math notranslate nohighlight">\(log_{10}(y)\)</span> exceeds <span class="math notranslate nohighlight">\(log_{10}(x)\)</span> by two units. on the other hand, <span class="math notranslate nohighlight">\(z\)</span> is <span class="math notranslate nohighlight">\(9.9\)</span> units bigger than <span class="math notranslate nohighlight">\(y\)</span>, but yet its logarithm <span class="math notranslate nohighlight">\(log_{10}(z)\)</span> is still the same two units bigger than <span class="math notranslate nohighlight">\(log_{10}(y)\)</span>. This is because thhe logarithm is instead looking at the fact that <span class="math notranslate nohighlight">\(z\)</span> is <em>one</em> power of ten, <span class="math notranslate nohighlight">\(y\)</span> is <span class="math notranslate nohighlight">\(-1\)</span> powers of ten, and <span class="math notranslate nohighlight">\(z\)</span> is <span class="math notranslate nohighlight">\(-3\)</span> powers of ten. The logarithm has <em>collapsed</em> the huge size difference between <span class="math notranslate nohighlight">\(z\)</span> and the other two values <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> by using exponentiation with <em>base</em> ten.</p>
<p>In this sense, you can also use the logarithm function for your network to reduce the huge size difference between the values in your activity/hobby network. However, we must first add a slight twist: to do this properly and yield an interpretable adjacency matrix, you need to <em>augment</em> the entries of the adjacency matrix <em>if</em> it contains zeros. This is because the <span class="math notranslate nohighlight">\(log_{10}(0)\)</span> is <em>not defined</em>. To augment the adjacency matrix, you will use the following strategy:</p>
<ol class="simple">
<li><p>Identify the entries of <span class="math notranslate nohighlight">\(A\)</span> which take a value of zero.</p></li>
<li><p>Identify the smallest entry of <span class="math notranslate nohighlight">\(A\)</span> which is not-zero, and call it <span class="math notranslate nohighlight">\(a_m\)</span>.</p></li>
<li><p>Compute a value <span class="math notranslate nohighlight">\(\epsilon\)</span> which is an <em>order of magnitude</em> smaller than <span class="math notranslate nohighlight">\(a_m\)</span>. Since you are taking powers of ten, a single order of magnitude would give us that <span class="math notranslate nohighlight">\(\epsilon = \frac{a_m}{10}\)</span>.</p></li>
<li><p>Take the augmented adjacency matrix <span class="math notranslate nohighlight">\(A'\)</span> to be defined with entries <span class="math notranslate nohighlight">\(a_{ij}' = a_{ij} + \epsilon\)</span>.</p></li>
</ol>
<p>Next, since your matrix has values which are now all greater than zero, you can just take the logarithm:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">augment_zeros</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">X</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;The logarithm is not defined for negative values!&quot;</span><span class="p">)</span>
    <span class="n">am</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">X</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)])</span>  <span class="c1"># the smallest non-zero entry of X</span>
    <span class="n">eps</span> <span class="o">=</span> <span class="n">am</span><span class="o">/</span><span class="mi">10</span>  <span class="c1"># epsilon is one order of magnitude smaller than the smallest non-zero entry</span>
    <span class="k">return</span> <span class="n">X</span> <span class="o">+</span> <span class="n">eps</span>  <span class="c1"># augment all entries of X by epsilon</span>

<span class="n">A_activity_aug</span> <span class="o">=</span> <span class="n">augment_zeros</span><span class="p">(</span><span class="n">A_activity</span><span class="p">)</span>
<span class="c1"># log-transform using base 10</span>
<span class="n">A_activity_log</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">A_activity_aug</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A_activity</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Activity/Hobby Network Network&quot;</span><span class="p">)</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">A_activity_log</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Activity/Hobby Network, After Augmentation + log&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/regularization_64_0.png" src="../../_images/regularization_64_0.png" />
</div>
</div>
<p>When you plot the augmented and log-transformed data, what you see is that many of the edge-weights you originally might have thought were zero if you only looked at a plot were, in actuality, <em>not</em> zero. In this sense, for non-negative weighted networks, log transforming after zero-augmentation is often very useful for visualization to get a sense of the magnitudinal differences that might be present between edges.</p>
<p>Our edge-weight histogram becomes:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">histplot</span><span class="p">(</span><span class="n">A_activity_log</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;$log_</span><span class="si">{10}</span><span class="s2">($Edge Weight$ + \epsilon)$&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Number of Edges&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Activity/Hobby Network Edge Distribution after log&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/regularization_66_0.png" src="../../_images/regularization_66_0.png" />
</div>
</div>
</section>
</section>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./representations/ch4"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="network-representations.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">4.3. </span>Representations of Networks</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../ch5/ch5.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">5. </span>Why Use Statistical Models?</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Eric Bridgeford, Alex Loftus, and Joshua Vogelstein<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>