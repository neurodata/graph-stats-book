
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>5.5. Multiple Network Models &#8212; Hands-on Network Machine Learning with Scikit-Learn and Graspologic</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >let toggleHintShow = 'Click to show';</script>
    <script >let toggleHintHide = 'Click to hide';</script>
    <script >let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script >const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="5.6. Network Models with Covariates" href="models-with-covariates.html" />
    <link rel="prev" title="5.4. Random Dot Product Graphs (RDPG)" href="single-network-models_RDPG.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Hands-on Network Machine Learning with Scikit-Learn and Graspologic</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../coverpage.html">
   Hands-on Network Machine Learning with Scikit-Learn and Graspologic
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/terminology.html">
   Terminology and Math Refresher
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch1/ch1.html">
   1. The Network Machine Learning Landscape
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/what-is-a-network.html">
     1.1. What Is A Network?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/why-study-networks.html">
     1.2. Why Study Networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/examples-of-applications.html">
     1.3. Examples of applications
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/types-of-learning-probs.html">
     1.4. Approaches for Network Learning Problems
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch2/ch2.html">
   2. End-to-end Biology Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/big-picture.html">
     2.1. Look at the big picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/get-the-data.html">
     2.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/prepare-the-data.html">
     2.3. Prepare the Data for Network Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/discover-and-visualize.html">
     2.4. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch3/ch3.html">
   3. End-to-end Business Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/big-picture.html">
     3.1. Look at the Big Picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/get-the-data.html">
     3.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/discover-and-visualize.html">
     3.3. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/prepare-the-data.html">
     3.4. Prepare the Data for Network Algorithms
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Representations
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch4/ch4.html">
   4. Properties of Networks as a Statistical Object
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/matrix-representations.html">
     4.1. Matrix Representations Of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/properties-of-networks.html">
     4.2. Properties of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/network-representations.html">
     4.3. Representations of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/regularization.html">
     4.4. Regularization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="ch5.html">
   5. Why Use Statistical Models?
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="why-use-models.html">
     5.1. Why Use Statistical Models?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="single-network-models_ER.html">
     5.2. Erdös-Rényi (ER) Random Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="single-network-models_SBM.html">
     5.3. Stochastic Block Models (SBM)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="single-network-models_RDPG.html">
     5.4. Random Dot Product Graphs (RDPG)
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     5.5. Multiple Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="models-with-covariates.html">
     5.6. Network Models with Covariates
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch6/ch6.html">
   6. Learning Network Representations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/estimating-parameters_mle.html">
     6.1. Estimating Parameters in Network Models via MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/why-embed-networks.html">
     6.2. Why embed networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/spectral-embedding.html">
     6.3. Spectral Embedding Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/estimating-parameters_spectral.html">
     6.4. Estimating Parameters for the RDPG
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/random-walk-diffusion-methods.html">
     6.5. Random walk and diffusion-based methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/graph-neural-networks.html">
     6.6. Graph Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/multigraph-representation-learning.html">
     6.7. Multiple-Network Representation Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/joint-representation-learning.html">
     6.8. Joint Representation Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch7/ch7.html">
   7. Theoretical Results
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/theory-single-network.html">
     7.1. Theory for Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/theory-multigraph.html">
     7.2. Maximum Likelihood Estimate Theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/theory-matching.html">
     7.3. Spectral Method Theory
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch8/ch8.html">
   8. Applications When You Have One Network
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/community-detection.html">
     8.1. Community Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/testing-differences.html">
     8.2. Testing for Differences between Groups of Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/model-selection.html">
     8.3. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/single-vertex-nomination.html">
     8.4. Single-Network Vertex Nomination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/out-of-sample.html">
     8.5. Out-of-sample Embedding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch9/ch9.html">
   9. Applications for Two Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/two-sample-hypothesis.html">
     9.1. Latent Two-Sample Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/significant-communities.html">
     9.2. Differences in Block Matrices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/graph-matching-vertex.html">
     9.3. Graph Matching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/multiple-vertex-nomination.html">
     9.4. Vertex Nomination For Two Networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch10/ch10.html">
   10. Applications for Many Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch10/anomaly-detection.html">
     10.1. Anomaly Detection For Timeseries of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch10/significant-edges.html">
     10.2. Testing for Significant Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch10/significant-vertices.html">
     10.3. Testing for Significant Vertices
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://graspologic.readthedocs.io/en/latest/">
   Graspologic Documentation
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/representations/ch5/multi-network-models.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/neurodata/graph-stats-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/neurodata/graph-stats-book/issues/new?title=Issue%20on%20page%20%2Frepresentations/ch5/multi-network-models.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/neurodata/graph-stats-book/edit/master/network_machine_learning_in_python/representations/ch5/multi-network-models.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/neurodata/graph-stats-book/master?urlpath=tree/network_machine_learning_in_python/representations/ch5/multi-network-models.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#joint-random-dot-product-graphs-jrdpg-model">
   5.5.1. Joint Random Dot Product Graphs (JRDPG) Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-jrdpg-model-does-not-allow-us-to-convey-unique-aspects-about-the-networks">
     5.5.1.1. The JRDPG model does not allow us to convey unique aspects about the networks
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-inhomogeous-erdos-renyi-ier-random-network">
     5.5.1.2. The Inhomogeous Erdos-Renyi (IER) Random Network
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#common-subspace-independent-edge-cosie-model">
   5.5.2. Common Subspace Independent Edge (COSIE) Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-cosie-model-is-defined-by-a-collection-of-score-matrices-and-a-shared-low-rank-subspace">
     5.5.2.1. The COSIE Model is defined by a collection of score matrices and a shared low-rank subspace
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-shared-latent-position-matrix-describes-similarities">
       5.5.2.1.1. The Shared Latent Position Matrix Describes Similarities
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#score-matrices-describe-differences">
       5.5.2.1.2. Score Matrices Describe Differences
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#correlated-network-models">
   5.5.3. Correlated Network Models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rho-correlated-rdpg">
     5.5.3.1.
     <span class="math notranslate nohighlight">
      \(\rho\)
     </span>
     -Correlated RDPG
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Multiple Network Models</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#joint-random-dot-product-graphs-jrdpg-model">
   5.5.1. Joint Random Dot Product Graphs (JRDPG) Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-jrdpg-model-does-not-allow-us-to-convey-unique-aspects-about-the-networks">
     5.5.1.1. The JRDPG model does not allow us to convey unique aspects about the networks
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-inhomogeous-erdos-renyi-ier-random-network">
     5.5.1.2. The Inhomogeous Erdos-Renyi (IER) Random Network
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#common-subspace-independent-edge-cosie-model">
   5.5.2. Common Subspace Independent Edge (COSIE) Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-cosie-model-is-defined-by-a-collection-of-score-matrices-and-a-shared-low-rank-subspace">
     5.5.2.1. The COSIE Model is defined by a collection of score matrices and a shared low-rank subspace
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-shared-latent-position-matrix-describes-similarities">
       5.5.2.1.1. The Shared Latent Position Matrix Describes Similarities
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#score-matrices-describe-differences">
       5.5.2.1.2. Score Matrices Describe Differences
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#correlated-network-models">
   5.5.3. Correlated Network Models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rho-correlated-rdpg">
     5.5.3.1.
     <span class="math notranslate nohighlight">
      \(\rho\)
     </span>
     -Correlated RDPG
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="multiple-network-models">
<h1><span class="section-number">5.5. </span>Multiple Network Models<a class="headerlink" href="#multiple-network-models" title="Permalink to this headline">¶</a></h1>
<p>Up to this point, we have studied network models which are useful for a single network. What do we do if we have multiple networks?</p>
<p>Let’s imagine that we have a company with <span class="math notranslate nohighlight">\(45\)</span> total employees. <span class="math notranslate nohighlight">\(10\)</span> of these employees are company administrative executives, <span class="math notranslate nohighlight">\(25\)</span> of these employees are network machine learning experts, and <span class="math notranslate nohighlight">\(10\)</span> of these employees are marketing experts. We study the social media habits of our employees on facebook, twitter, and linkedin. For a given social networking site, an edge is said to exist between a pair of employees if they are connected on the social media site (by being friends, following one another, or being connected, respectively). As it turns out, individuals tend to most closely associate with the colleagues whom they work most closely: we might expect some sort of community structure to our network, wherein network machine learning experts are more connected with network machine learning experts, marketing experts are more connected with marketing experts, so on and so forth. What we will see below is that all of the networks appear to have the same community organization, though on Linkedin, we see that the administrative executives tend to be a little more connected. This is reflected in the fact that there are more connections between Adm. members on Linkedin:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">heatmap</span>
<span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">sbm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">K</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">B1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">K</span><span class="p">,</span><span class="n">K</span><span class="p">))</span>

<span class="n">B1</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">B1</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">.05</span>
<span class="n">B1</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">.05</span>
<span class="n">B1</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">.05</span>
<span class="n">B1</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">.05</span>
<span class="n">B1</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">B1</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">.05</span>
<span class="n">B1</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">.05</span>
<span class="n">B1</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.3</span>

<span class="n">B2</span> <span class="o">=</span> <span class="n">B1</span>

<span class="n">B3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">B1</span><span class="p">)</span>
<span class="n">B3</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.9</span>

<span class="n">ns</span> <span class="o">=</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="n">A1</span> <span class="o">=</span> <span class="n">sbm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">ns</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">B1</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;ML&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ns</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;Adm.&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ns</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">ns</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">ns</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;Mar.&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ns</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">ns</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">ns</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">ns</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">ns</span><span class="p">[</span><span class="mi">2</span><span class="p">])]</span>

<span class="n">A2</span> <span class="o">=</span> <span class="n">sbm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">ns</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">B2</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">A3</span> <span class="o">=</span> <span class="n">sbm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">ns</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">B3</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A1</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$A^{(1)}$ Facebook&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;sequential&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">ys</span><span class="p">);</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A2</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$A^{(2)}$ Twitter&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;sequential&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">ys</span><span class="p">);</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A3</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$A^{(3)}$ Linkedin&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;sequential&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">ys</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">FileNotFoundError</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="nn">Input In [1],</span> in <span class="ni">&lt;cell line: 1&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">heatmap</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">sbm</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">File</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">hostedtoolcache</span><span class="o">/</span><span class="n">Python</span><span class="o">/</span><span class="mf">3.8.12</span><span class="o">/</span><span class="n">x64</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.8</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">graphbook_code</span><span class="o">/</span><span class="fm">__init__</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">27</span><span class="p">,</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span> <span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span>     <span class="s2">&quot;binary_heatmap&quot;</span><span class="p">,</span>  <span class="c1"># plotting</span>
<span class="g g-Whitespace">     </span><span class="mi">11</span>     <span class="s2">&quot;heatmap&quot;</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">23</span>     <span class="s2">&quot;ier&quot;</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">24</span> <span class="p">]</span>
<span class="g g-Whitespace">     </span><span class="mi">26</span> <span class="c1"># star imports work only because we have __all__ defined</span>
<span class="ne">---&gt; </span><span class="mi">27</span> <span class="kn">from</span> <span class="nn">.plotting</span> <span class="kn">import</span> <span class="o">*</span>
<span class="g g-Whitespace">     </span><span class="mi">28</span> <span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="o">*</span>
<span class="g g-Whitespace">     </span><span class="mi">29</span> <span class="kn">from</span> <span class="nn">.siem</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">File</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">hostedtoolcache</span><span class="o">/</span><span class="n">Python</span><span class="o">/</span><span class="mf">3.8.12</span><span class="o">/</span><span class="n">x64</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.8</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">graphbook_code</span><span class="o">/</span><span class="n">plotting</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">8</span><span class="p">,</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">Colormap</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="c1"># from graspologic.plot.plot import _check_common_inputs, _process_graphs, _plot_groups</span>
<span class="ne">----&gt; </span><span class="mi">8</span> <span class="kn">from</span> <span class="nn">graspologic.plot.plot</span> <span class="kn">import</span> <span class="p">(</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span>     <span class="n">_check_common_inputs</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span>     <span class="n">_process_graphs</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">11</span>     <span class="n">make_axes_locatable</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span>     <span class="n">_plot_brackets</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">13</span>     <span class="n">_sort_inds</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span>     <span class="n">_unique_like</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">15</span>     <span class="n">_get_freqs</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">16</span> <span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">17</span> <span class="kn">from</span> <span class="nn">graspologic.utils</span> <span class="kn">import</span> <span class="n">import_graph</span>
<span class="g g-Whitespace">     </span><span class="mi">18</span> <span class="kn">import</span> <span class="nn">warnings</span>

<span class="n">File</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">hostedtoolcache</span><span class="o">/</span><span class="n">Python</span><span class="o">/</span><span class="mf">3.8.12</span><span class="o">/</span><span class="n">x64</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.8</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">graspologic</span><span class="o">/</span><span class="fm">__init__</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">9</span><span class="p">,</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="kn">import</span> <span class="nn">graspologic.embed</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span> <span class="kn">import</span> <span class="nn">graspologic.inference</span>
<span class="ne">----&gt; </span><span class="mi">9</span> <span class="kn">import</span> <span class="nn">graspologic.layouts</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span> <span class="kn">import</span> <span class="nn">graspologic.models</span>
<span class="g g-Whitespace">     </span><span class="mi">11</span> <span class="kn">import</span> <span class="nn">graspologic.nominate</span>

<span class="n">File</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">hostedtoolcache</span><span class="o">/</span><span class="n">Python</span><span class="o">/</span><span class="mf">3.8.12</span><span class="o">/</span><span class="n">x64</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.8</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">graspologic</span><span class="o">/</span><span class="n">layouts</span><span class="o">/</span><span class="fm">__init__</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">6</span><span class="p">,</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># Copyright (c) Microsoft Corporation.</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="c1"># Licensed under the MIT license.</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="kn">from</span> <span class="nn">.classes</span> <span class="kn">import</span> <span class="n">NodePosition</span>
<span class="ne">----&gt; </span><span class="mi">6</span> <span class="kn">from</span> <span class="nn">.colors</span> <span class="kn">import</span> <span class="n">categorical_colors</span><span class="p">,</span> <span class="n">sequential_colors</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="kn">from</span> <span class="nn">.render</span> <span class="kn">import</span> <span class="n">save_graph</span><span class="p">,</span> <span class="n">show_graph</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span> <span class="kn">from</span> <span class="nn">.auto</span> <span class="kn">import</span> <span class="n">layout_tsne</span><span class="p">,</span> <span class="n">layout_umap</span>  <span class="c1"># isort:skip</span>

<span class="n">File</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">hostedtoolcache</span><span class="o">/</span><span class="n">Python</span><span class="o">/</span><span class="mf">3.8.12</span><span class="o">/</span><span class="n">x64</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.8</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">graspologic</span><span class="o">/</span><span class="n">layouts</span><span class="o">/</span><span class="n">colors</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">36</span><span class="p">,</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">     </span><span class="mi">32</span>     <span class="n">dark</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="n">thematic_json</span><span class="p">[</span><span class="s2">&quot;dark&quot;</span><span class="p">]</span>
<span class="g g-Whitespace">     </span><span class="mi">33</span>     <span class="k">return</span> <span class="n">light</span><span class="p">,</span> <span class="n">dark</span>
<span class="ne">---&gt; </span><span class="mi">36</span> <span class="n">_CACHED_LIGHT</span><span class="p">,</span> <span class="n">_CACHED_DARK</span> <span class="o">=</span> <span class="n">_load_thematic_json</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">39</span> <span class="k">def</span> <span class="nf">_get_colors</span><span class="p">(</span><span class="n">light_background</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">theme_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="g g-Whitespace">     </span><span class="mi">40</span>     <span class="n">light</span> <span class="o">=</span> <span class="n">_CACHED_LIGHT</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/graspologic/layouts/colors.py:29,</span> in <span class="ni">_load_thematic_json</span><span class="nt">(path)</span>
<span class="g g-Whitespace">     </span><span class="mi">26</span>     <span class="n">include_path</span> <span class="o">=</span> <span class="n">pkg_resources</span><span class="o">.</span><span class="n">resource_filename</span><span class="p">(</span><span class="n">__package__</span><span class="p">,</span> <span class="s2">&quot;include&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">27</span>     <span class="n">colors_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">include_path</span><span class="p">,</span> <span class="s2">&quot;colors-100.json&quot;</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">29</span> <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">colors_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">thematic_json_io</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">30</span>     <span class="n">thematic_json</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">thematic_json_io</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">31</span> <span class="n">light</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="n">thematic_json</span><span class="p">[</span><span class="s2">&quot;light&quot;</span><span class="p">]</span>

<span class="ne">FileNotFoundError</span>: [Errno 2] No such file or directory: &#39;/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/graspologic/layouts/include/colors-100.json&#39;
</pre></div>
</div>
</div>
</div>
<p>Remember that a random network has an adjacency matrix denoted by a boldfaced uppercase <span class="math notranslate nohighlight">\(\mathbf A\)</span>, and has network realizations <span class="math notranslate nohighlight">\(A\)</span> (which we just call “networks”). When we have multiple networks, we will need to be able to index them individually. For this reason, in this section, we will use the convention that a random network’s adjacency matrix is denoted by a boldfaced uppercase <span class="math notranslate nohighlight">\(\mathbf A^{(m)}\)</span>, where <span class="math notranslate nohighlight">\(m\)</span> tells us which network in our collection we are talking about. The capital letter <span class="math notranslate nohighlight">\(M\)</span> defines the <em>total</em> number of random networks in our collection. In our social network example, since we have connection networks for <span class="math notranslate nohighlight">\(3\)</span> sites, <span class="math notranslate nohighlight">\(N\)</span> is <span class="math notranslate nohighlight">\(3\)</span>. When we use the letter <span class="math notranslate nohighlight">\(m\)</span> itself, we will typically be referring to an arbitrary random network amongst the collection of random networks, where <span class="math notranslate nohighlight">\(m\)</span> beween <span class="math notranslate nohighlight">\(1\)</span> and <span class="math notranslate nohighlight">\(N\)</span>. When we have <span class="math notranslate nohighlight">\(M\)</span> total networks, we will write down the entire <strong>collection of random networks</strong> using the notation <span class="math notranslate nohighlight">\(\left\{\mathbf A^{(1)}, ..., \mathbf A^{(M)}\right\}\)</span>. With what we already know, for a random network <span class="math notranslate nohighlight">\(\mathbf A^{(m)}\)</span>, we would be able to use a single nework model to describe <span class="math notranslate nohighlight">\(\mathbf A^{(m)}\)</span>. This means, for instance, if we thought that each social network could be represented by an RDPG, that we would have a <em>different</em> latent position matrix <span class="math notranslate nohighlight">\(X^{(m)}\)</span> to define each of the <span class="math notranslate nohighlight">\(30\)</span> networks. In symbols, we would write that each <span class="math notranslate nohighlight">\(\mathbf A^{(m)}\)</span> is an RDPG random nework with latent position matrix <span class="math notranslate nohighlight">\(X^{(m)}\)</span>. What is the problem with this description?</p>
<p>What this description lacks is that the three networks share a <em>lot</em> of common information. We might expect that, on some level, the latent position matrices should also show some sort of common structure. However, since we used a <em>unique</em> latent position matrix <span class="math notranslate nohighlight">\(X^{(m)}\)</span> for each random network <span class="math notranslate nohighlight">\(\mathbf A^{(m)}\)</span>, we have inherently stated that we think that the networks have completely distinct latent position matrices. If we were to perform a task downstream, such as whether we could identify which employees are in which community, we would have to analyze each latent position matrix individually, and we would not be able to learn a latent position matrix with shared structure across the three networks. Before we jump into multiple network models, let’s provide some context as to how we will build these up.</p>
<p>In the below descriptions, we will tend to build off the Random Dot Product Graph (RDPG), and closely related variations of it. Why? Well, as it turns out, the RDPG is extremely flexible, in that we can represent both ER and SBMs as RDPGs, too. This means that building off the RDPG gives us multiple random network models that will be inherently flexible. Further, as we will see in the later section on <a class="reference external" href="#link?">Estimation</a>, the RDPG is extremely well-suited for the situation in which we want to analyze SBMs, but do not know which communities the nodes are in ahead of time. This situation is extremely common across numerous disciplines of network machine learning, such as social networking, neuroscience, and many other fields.</p>
<p>So, how can we model our collection of random networks with shared structure?</p>
<div class="section" id="joint-random-dot-product-graphs-jrdpg-model">
<h2><span class="section-number">5.5.1. </span>Joint Random Dot Product Graphs (JRDPG) Model<a class="headerlink" href="#joint-random-dot-product-graphs-jrdpg-model" title="Permalink to this headline">¶</a></h2>
<p>In our example on social networks, notice that the facebook and twitter connections do not look <em>too</em> qualitatively different. It looks like they have relatively similar connectivity patterns between the different employee working groups, and we might even think that the underlying random process that governs these two social networks are <em>identical</em>. In statisical science, when we have a collection of <span class="math notranslate nohighlight">\(M\)</span> random networks that have the same underlying random process, we describe this with the term <strong>homogeneity</strong>. Let’s put what this means into context using our coin flip example. If a pair of coins are <em>homogeneous</em>, this means that the probability that they land on heads is identical. Likewise, this intuition extends directly to random networks. A <strong>homogeneous</strong> collection of random networks <span class="math notranslate nohighlight">\(\left\{\mathbf A^{(1)}, ..., \mathbf A^{(M)}\right\}\)</span> is one in which <em>all</em> of the <span class="math notranslate nohighlight">\(M\)</span> random networks have the <em>same probability matrix</em>. Remember that the probability matrix <span class="math notranslate nohighlight">\(P^{(m)}\)</span> is the matrix whose entries <span class="math notranslate nohighlight">\(p^{(m)}_{ij}\)</span> indicate the probability that an edge exists between nodes <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>. On the other hand, a <strong>heterogeneous</strong> collection of random networks is a collection of networks <span class="math notranslate nohighlight">\(\left\{\mathbf A^{(1)}, ..., \mathbf A^{(M)}\right\}\)</span> is one in which the probability matrices are <em>not</em> the same for all of the <span class="math notranslate nohighlight">\(M\)</span> networks.</p>
<p>The probability matrices <span class="math notranslate nohighlight">\(P^{(1)}\)</span> and <span class="math notranslate nohighlight">\(P^{(2)}\)</span> for the random networks <span class="math notranslate nohighlight">\(\mathbf A^{(1)}\)</span> and <span class="math notranslate nohighlight">\(\mathbf A^{(2)}\)</span> for facebook and twitter are shown in the following figure. We also show the difference between the two probability matrices, to make really clear that they are the same:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">cmaps</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="k">def</span> <span class="nf">p_from_block</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">ns</span><span class="p">):</span>
    <span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ns</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ns</span><span class="p">)))</span>
    <span class="n">ns_cumsum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">ns</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">n1</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ns_cumsum</span><span class="p">[</span><span class="mi">0</span><span class="p">:(</span><span class="nb">len</span><span class="p">(</span><span class="n">ns_cumsum</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)]):</span>
        <span class="k">for</span> <span class="n">l</span><span class="p">,</span> <span class="n">n2</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ns_cumsum</span><span class="p">[</span><span class="n">k</span><span class="p">:(</span><span class="nb">len</span><span class="p">(</span><span class="n">ns_cumsum</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)]):</span>
            <span class="n">P</span><span class="p">[</span><span class="n">ns_cumsum</span><span class="p">[</span><span class="n">k</span><span class="p">]:</span><span class="n">ns_cumsum</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">ns_cumsum</span><span class="p">[</span><span class="n">l</span><span class="o">+</span><span class="n">k</span><span class="p">]:</span><span class="n">ns_cumsum</span><span class="p">[</span><span class="n">l</span><span class="o">+</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span><span class="n">l</span><span class="o">+</span><span class="n">k</span><span class="p">]</span>
            <span class="n">P</span><span class="p">[</span><span class="n">ns_cumsum</span><span class="p">[</span><span class="n">l</span><span class="o">+</span><span class="n">k</span><span class="p">]:</span><span class="n">ns_cumsum</span><span class="p">[</span><span class="n">l</span><span class="o">+</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span><span class="n">ns_cumsum</span><span class="p">[</span><span class="n">k</span><span class="p">]:</span><span class="n">ns_cumsum</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">B</span><span class="p">[</span><span class="n">l</span><span class="o">+</span><span class="n">k</span><span class="p">,</span><span class="n">k</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">P</span>

<span class="n">P1</span> <span class="o">=</span> <span class="n">p_from_block</span><span class="p">(</span><span class="n">B1</span><span class="p">,</span> <span class="n">ns</span><span class="p">)</span>
<span class="n">U1</span><span class="p">,</span> <span class="n">S1</span><span class="p">,</span> <span class="n">V1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">P1</span><span class="p">)</span>
<span class="n">X1</span> <span class="o">=</span> <span class="n">U1</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">S1</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]))</span>

<span class="n">P2</span> <span class="o">=</span> <span class="n">p_from_block</span><span class="p">(</span><span class="n">B2</span><span class="p">,</span> <span class="n">ns</span><span class="p">)</span>
<span class="n">U2</span><span class="p">,</span> <span class="n">S2</span><span class="p">,</span> <span class="n">V2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">P2</span><span class="p">)</span>
<span class="n">X2</span> <span class="o">=</span> <span class="n">U2</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">S2</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]))</span>

<span class="n">P3</span> <span class="o">=</span> <span class="n">p_from_block</span><span class="p">(</span><span class="n">B3</span><span class="p">,</span> <span class="n">ns</span><span class="p">)</span>
<span class="n">U3</span><span class="p">,</span> <span class="n">S3</span><span class="p">,</span> <span class="n">V3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">P3</span><span class="p">)</span>
<span class="n">X3</span> <span class="o">=</span> <span class="n">U3</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">S3</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]))</span>

<span class="k">def</span> <span class="nf">plot_prob_block_annot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">nodename</span><span class="o">=</span><span class="s2">&quot;Employee&quot;</span><span class="p">,</span> <span class="n">nodetix</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
             <span class="n">nodelabs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    
    <span class="k">with</span> <span class="n">sns</span><span class="o">.</span><span class="n">plotting_context</span><span class="p">(</span><span class="s2">&quot;talk&quot;</span><span class="p">,</span> <span class="n">font_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">annot</span><span class="p">:</span>
            <span class="n">X_annot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;U4&#39;</span><span class="p">)</span>
            <span class="n">X_annot</span><span class="p">[</span><span class="mi">13</span><span class="p">,</span> <span class="mi">13</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">13</span><span class="p">,</span><span class="mi">13</span><span class="p">]))</span>
            <span class="n">X_annot</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">30</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span><span class="mi">30</span><span class="p">]))</span>
            <span class="n">X_annot</span><span class="p">[</span><span class="mi">40</span><span class="p">,</span><span class="mi">40</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">40</span><span class="p">,</span><span class="mi">40</span><span class="p">]))</span>
            <span class="n">X_annot</span><span class="p">[</span><span class="mi">13</span><span class="p">,</span> <span class="mi">30</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">13</span><span class="p">,</span><span class="mi">30</span><span class="p">]))</span>
            <span class="n">X_annot</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span><span class="mi">13</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span><span class="mi">13</span><span class="p">]))</span>
            <span class="n">X_annot</span><span class="p">[</span><span class="mi">13</span><span class="p">,</span><span class="mi">40</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">23</span><span class="p">,</span><span class="mi">40</span><span class="p">]))</span>
            <span class="n">X_annot</span><span class="p">[</span><span class="mi">40</span><span class="p">,</span><span class="mi">13</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">40</span><span class="p">,</span><span class="mi">13</span><span class="p">]))</span>
            <span class="n">X_annot</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span><span class="mi">40</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span><span class="mi">40</span><span class="p">]))</span>
            <span class="n">X_annot</span><span class="p">[</span><span class="mi">40</span><span class="p">,</span><span class="mi">30</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">40</span><span class="p">,</span><span class="mi">30</span><span class="p">]))</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Purples&quot;</span><span class="p">,</span>
                            <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">cbar_kws</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">shrink</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_annot</span><span class="p">),</span>
                            <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Purples&quot;</span><span class="p">,</span>
                            <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">cbar_kws</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">shrink</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        <span class="n">cbar</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">collections</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="n">nodename</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="n">nodename</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">nodetix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">nodelabs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">nodetix</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">nodelabs</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">nodetix</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">nodelabs</span><span class="p">)</span>
        <span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">set_frame_on</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plot_prob_block_annot</span><span class="p">(</span><span class="n">P1</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$P^{(1)}$ facebook Prob. Matrix&quot;</span><span class="p">)</span>
<span class="n">plot_prob_block_annot</span><span class="p">(</span><span class="n">P2</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$P^{(2)}$ twitter Prob. Matrix&quot;</span><span class="p">)</span>
<span class="n">plot_prob_block_annot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">P1</span> <span class="o">-</span> <span class="n">P2</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">annot</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$|P^{(1)} - P^{(2)}|$&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The Joint Random Dot Product Graphs (JRDPG) is the simplest way we can extend the RDPG random network model to multiple random networks. The way we can think of the JRDPG model is that for each of our <span class="math notranslate nohighlight">\(M\)</span> total random neworks, the edges depend on a latent position matrix <span class="math notranslate nohighlight">\(X\)</span>. We say that a collection of random networks <span class="math notranslate nohighlight">\(\left\{\mathbf A^{(1)}, ..., \mathbf A^{(N)}\right\}\)</span> with <span class="math notranslate nohighlight">\(n\)</span> nodes is <span class="math notranslate nohighlight">\(JRDPG_{n,M}(X)\)</span> if each random network <span class="math notranslate nohighlight">\(\mathbf A^{(m)}\)</span> is <span class="math notranslate nohighlight">\(RDPG_n(X)\)</span> and if the <span class="math notranslate nohighlight">\(N\)</span> networks are independent.</p>
<div class="section" id="the-jrdpg-model-does-not-allow-us-to-convey-unique-aspects-about-the-networks">
<h3><span class="section-number">5.5.1.1. </span>The JRDPG model does not allow us to convey unique aspects about the networks<a class="headerlink" href="#the-jrdpg-model-does-not-allow-us-to-convey-unique-aspects-about-the-networks" title="Permalink to this headline">¶</a></h3>
<p>Under the JRDPG model, each of the <span class="math notranslate nohighlight">\(M\)</span> random networks share the same latent position matrix. Remember that for an RDPG, the probability matrix <span class="math notranslate nohighlight">\(P = XX^\top\)</span>. This means that for all of the <span class="math notranslate nohighlight">\(N\)</span> networks, <span class="math notranslate nohighlight">\(P^{(m)} = XX^\top\)</span> under the JRDPG model. hence, <span class="math notranslate nohighlight">\(P^{(1)} = P^{(2)} = ... = P^{(N)}\)</span>, and <em>all</em> of the probability matrices are <em>identical</em>! This means that the <span class="math notranslate nohighlight">\(N\)</span> random networks are <strong>homogeneous</strong>.</p>
<p>For an RDPG, since <span class="math notranslate nohighlight">\(P = XX^\top\)</span>, the probability matrix depends <em>only</em> on the latent positions <span class="math notranslate nohighlight">\(X\)</span>. This means that we can tell whether a collection of networks are homogeneous just by looking at the latent position matrices! It turns out that the random networks underlying the realizations for the social networks in our given example were just SBMs. From the section on <a class="reference external" href="#link?">Random Dot Product Graphs</a>, we learned that SBMs are just RDPGs with a special latent position matrix. Let’s try this first by looking at the latent position matrices for <span class="math notranslate nohighlight">\(\mathbf A^{(1)}\)</span> and <span class="math notranslate nohighlight">\(\mathbf A^{(2)}\)</span> from the random networks for facebook and twitter first:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="kn">import</span> <span class="n">svd</span>

<span class="k">def</span> <span class="nf">plot_latent</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">nodename</span><span class="o">=</span><span class="s2">&quot;Employee&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Latent Dimension&quot;</span><span class="p">,</span>
                <span class="n">nodetix</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">nodelabs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dimtix</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dimlabs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    
    <span class="k">with</span> <span class="n">sns</span><span class="o">.</span><span class="n">plotting_context</span><span class="p">(</span><span class="s2">&quot;talk&quot;</span><span class="p">,</span> <span class="n">font_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">lim_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">vmin</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">vmin</span> <span class="o">=</span> <span class="o">-</span><span class="n">lim_max</span>
        <span class="k">if</span> <span class="n">vmax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">vmax</span> <span class="o">=</span> <span class="n">lim_max</span>
        <span class="n">X_annot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">45</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;U6&#39;</span><span class="p">)</span>
        <span class="n">X_annot</span><span class="p">[</span><span class="mi">13</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">13</span><span class="p">,</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">X_annot</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">X_annot</span><span class="p">[</span><span class="mi">40</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">40</span><span class="p">,</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">X_annot</span><span class="p">[</span><span class="mi">13</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">13</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">X_annot</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">X_annot</span><span class="p">[</span><span class="mi">40</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">40</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">X_annot</span><span class="p">[</span><span class="mi">13</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">13</span><span class="p">,</span><span class="mi">2</span><span class="p">]))</span>
        <span class="n">X_annot</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span><span class="mi">2</span><span class="p">]))</span>
        <span class="n">X_annot</span><span class="p">[</span><span class="mi">40</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">40</span><span class="p">,</span><span class="mi">2</span><span class="p">]))</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmaps</span><span class="p">[</span><span class="s2">&quot;divergent&quot;</span><span class="p">],</span>
                        <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">cbar_kws</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">shrink</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span>
                        <span class="n">annot</span><span class="o">=</span><span class="n">X_annot</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        <span class="n">cbar</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">collections</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="n">nodename</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="n">ylabel</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">nodetix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">nodelabs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">nodetix</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">nodelabs</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">dimtix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">dimlabs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">dimtix</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">dimlabs</span><span class="p">)</span>
        <span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">set_frame_on</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">vmin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">([</span><span class="n">X1</span><span class="p">,</span><span class="n">X2</span><span class="p">,</span><span class="n">X3</span><span class="p">]);</span> <span class="n">vmax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">X3</span><span class="p">])</span>
<span class="n">plot_latent</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">nodetix</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="mi">34</span><span class="p">,</span><span class="mi">44</span><span class="p">],</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span> <span class="n">nodelabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;25&quot;</span><span class="p">,</span> <span class="s2">&quot;35&quot;</span><span class="p">,</span> <span class="s2">&quot;45&quot;</span><span class="p">],</span>
            <span class="n">dimtix</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dimlabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;2&quot;</span><span class="p">,</span> <span class="s2">&quot;3&quot;</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$X^{(1)}$ facebook LPM&quot;</span><span class="p">)</span>
<span class="n">plot_latent</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span> <span class="n">nodetix</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="mi">34</span><span class="p">,</span><span class="mi">44</span><span class="p">],</span> <span class="n">nodelabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;25&quot;</span><span class="p">,</span> <span class="s2">&quot;35&quot;</span><span class="p">,</span> <span class="s2">&quot;45&quot;</span><span class="p">],</span>
            <span class="n">dimtix</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span> <span class="n">dimlabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;2&quot;</span><span class="p">,</span> <span class="s2">&quot;3&quot;</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$X^{(2)}$ twitter LPM&quot;</span><span class="p">)</span>
<span class="n">plot_latent</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X1</span> <span class="o">-</span> <span class="n">X2</span><span class="p">),</span> <span class="n">nodetix</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="mi">34</span><span class="p">,</span><span class="mi">44</span><span class="p">],</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span> <span class="n">nodelabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;25&quot;</span><span class="p">,</span> <span class="s2">&quot;35&quot;</span><span class="p">,</span> <span class="s2">&quot;45&quot;</span><span class="p">],</span>
            <span class="n">dimtix</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">dimlabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;2&quot;</span><span class="p">,</span> <span class="s2">&quot;3&quot;</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$|X^{(1)} - X^{(2)}|$&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>So the latent position matrices for facebook and twitter are exactly identical. Therefore, the collection of random networks <span class="math notranslate nohighlight">\(\left\{\mathbf A^{(1)}, \mathbf A^{(2)}\right\}\)</span> are homogeneous, and we could model this pair of networks using the JRDPG.</p>
<p>What about linkedin? Well, as it turns out, linkedin had a <em>different</em> latent position matrix from both facebook and twitter:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">vmin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">([</span><span class="n">X1</span><span class="p">,</span><span class="n">X2</span><span class="p">,</span><span class="n">X3</span><span class="p">]);</span> <span class="n">vmax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">X3</span><span class="p">])</span>
<span class="n">plot_latent</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">nodetix</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="mi">34</span><span class="p">,</span><span class="mi">44</span><span class="p">],</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span> <span class="n">nodelabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;25&quot;</span><span class="p">,</span> <span class="s2">&quot;35&quot;</span><span class="p">,</span> <span class="s2">&quot;45&quot;</span><span class="p">],</span>
            <span class="n">dimtix</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dimlabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;2&quot;</span><span class="p">,</span> <span class="s2">&quot;3&quot;</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$X^{(1)}$ facebook LPM&quot;</span><span class="p">)</span>
<span class="n">plot_latent</span><span class="p">(</span><span class="n">X3</span><span class="p">,</span> <span class="n">nodetix</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="mi">34</span><span class="p">,</span><span class="mi">44</span><span class="p">],</span> <span class="n">nodelabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;25&quot;</span><span class="p">,</span> <span class="s2">&quot;35&quot;</span><span class="p">,</span> <span class="s2">&quot;45&quot;</span><span class="p">],</span>
            <span class="n">dimtix</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span> <span class="n">dimlabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;2&quot;</span><span class="p">,</span> <span class="s2">&quot;3&quot;</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$X^{(3)}$ linkedin LPM&quot;</span><span class="p">)</span>
<span class="n">plot_latent</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X1</span> <span class="o">-</span> <span class="n">X3</span><span class="p">),</span> <span class="n">nodetix</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="mi">34</span><span class="p">,</span><span class="mi">44</span><span class="p">],</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span> <span class="n">nodelabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;25&quot;</span><span class="p">,</span> <span class="s2">&quot;35&quot;</span><span class="p">,</span> <span class="s2">&quot;45&quot;</span><span class="p">],</span>
            <span class="n">dimtix</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">dimlabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;2&quot;</span><span class="p">,</span> <span class="s2">&quot;3&quot;</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$|X^{(1)} - X^{(3)}|$&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>So, <span class="math notranslate nohighlight">\(\mathbf A^{(1)}\)</span> and <span class="math notranslate nohighlight">\(\mathbf A^{(3)}\)</span> do not have the same latent position matrices. This means that the collections of random networks <span class="math notranslate nohighlight">\(\left\{\mathbf A^{(1)}, \mathbf A^{(3)}\right\}\)</span>, <span class="math notranslate nohighlight">\(\left\{\mathbf A^{(2)}, \mathbf A^{(3)}\right\}\)</span>, and <span class="math notranslate nohighlight">\(\left\{\mathbf A^{(1)}, \mathbf A^{(2)}, \mathbf A^{(3)}\right\}\)</span> are <em>heterogeneous</em>, because their probability matrices will be different. So, unfortunately, the JRDPG cannot handle the hetereogeneity between the random networks of facebook and twitter with the random network for linkedin. To remove this restrictive homogeneity property of the JRDPG, we will need a new single network model, called the Inhomogeneous Erdos-Renyi (IER) random network model.</p>
</div>
<div class="section" id="the-inhomogeous-erdos-renyi-ier-random-network">
<h3><span class="section-number">5.5.1.2. </span>The Inhomogeous Erdos-Renyi (IER) Random Network<a class="headerlink" href="#the-inhomogeous-erdos-renyi-ier-random-network" title="Permalink to this headline">¶</a></h3>
<p>The IER random network is the most general random network model for a binary graph. The way we can think of the <span class="math notranslate nohighlight">\(IER\)</span> random network is that a probability matrix <span class="math notranslate nohighlight">\(P\)</span> with <span class="math notranslate nohighlight">\(n\)</span> rows and <span class="math notranslate nohighlight">\(n\)</span> columns defines each of the edge-existence probabilities for pairs of nodes in the network. For each pair of nodes <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>, we have a unique coin which has a <span class="math notranslate nohighlight">\(p_{ij}\)</span> chance of landing on heads, and a <span class="math notranslate nohighlight">\(1 - p_{ij}\)</span> chance of landing on tails. If the coin lands on heads, the edge between nodes <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> exists, and if the coin lands on tails, the edge between nodes <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> does not exist. This coin flip is performed independently of the coin flips for all of the other edges. If <span class="math notranslate nohighlight">\(\mathbf A\)</span> is a random network which is <span class="math notranslate nohighlight">\(IER\)</span> with a probability matrix <span class="math notranslate nohighlight">\(P\)</span>, we say that <span class="math notranslate nohighlight">\(\mathbf A\)</span> is an <span class="math notranslate nohighlight">\(IER_n(P)\)</span> random network.</p>
<p>As before, we can develop a procedure to produce for us a network <span class="math notranslate nohighlight">\(A\)</span>, which has nodes and edges, where the underlying random network <span class="math notranslate nohighlight">\(\mathbf A\)</span> is an <span class="math notranslate nohighlight">\(IER_n(P)\)</span> random network:</p>
<div class="admonition-simulating-a-realization-from-an-ier-n-p-random-network admonition">
<p class="admonition-title">Simulating a realization from an <span class="math notranslate nohighlight">\(IER_n(P)\)</span> random network</p>
<ol class="simple">
<li><p>Determine a probability matrix <span class="math notranslate nohighlight">\(P\)</span>, whose entries <span class="math notranslate nohighlight">\(p_{ij}\)</span> are probabilities.</p></li>
<li><p>For each pair of nodes <span class="math notranslate nohighlight">\(i\)</span> an <span class="math notranslate nohighlight">\(j\)</span>:</p>
<ul class="simple">
<li><p>Obtain a weighted coin <span class="math notranslate nohighlight">\((i,j)\)</span> which has a probability <span class="math notranslate nohighlight">\(p_{ij}\)</span> of landing on heads, and a <span class="math notranslate nohighlight">\(1 - p_{ij}\)</span> probability of landing on tails.</p></li>
<li><p>Flip the <span class="math notranslate nohighlight">\((i,j)\)</span> coin, and if it lands on heads, the corresponding entry <span class="math notranslate nohighlight">\(a_{ij}\)</span> in the adjacency matrix is <span class="math notranslate nohighlight">\(1\)</span>. If the coin lands on tails, the corresponding entry <span class="math notranslate nohighlight">\(a_{ij}\)</span> is <span class="math notranslate nohighlight">\(0\)</span>.</p></li>
</ul>
</li>
<li><p>The adjacency matrix we produce, <span class="math notranslate nohighlight">\(A\)</span>, is a realization of an <span class="math notranslate nohighlight">\(IER_n(P)\)</span> random network.</p></li>
</ol>
</div>
<p>It is important to realize that all of the networks we have described so far are also <span class="math notranslate nohighlight">\(IER_n(P)\)</span> random networks. The previous single network models we have described to date simply place restrictions on the way in which we acquire <span class="math notranslate nohighlight">\(P\)</span>. For instance, in an <span class="math notranslate nohighlight">\(ER_n(p)\)</span> random network, all entries <span class="math notranslate nohighlight">\(p_{ij}\)</span> of <span class="math notranslate nohighlight">\(P\)</span> are equal to <span class="math notranslate nohighlight">\(p\)</span>. To see that an <span class="math notranslate nohighlight">\(SBM_n(\vec z, B)\)</span> random network is also <span class="math notranslate nohighlight">\(IER_n(P)\)</span>, we can construct the probability matrix <span class="math notranslate nohighlight">\(P\)</span> such that <span class="math notranslate nohighlight">\(p_{ij} = b_{kl}\)</span> of the block matrix <span class="math notranslate nohighlight">\(B\)</span> when the community of node <span class="math notranslate nohighlight">\(i\)</span> is <span class="math notranslate nohighlight">\(z_i = k\)</span> and the community of node <span class="math notranslate nohighlight">\(j\)</span> is <span class="math notranslate nohighlight">\(z_j = l\)</span>. To see that an <span class="math notranslate nohighlight">\(RDPG_n(X)\)</span> random network is also <span class="math notranslate nohighlight">\(IER_n(P)\)</span>, we can construct the probability matrix <span class="math notranslate nohighlight">\(P\)</span> such that <span class="math notranslate nohighlight">\(P = XX^\top\)</span>. This shows that the IER random network is the most general of the single network models we have studied so far. Next, let’s see how the IER random network can help us address this heterogeneity.</p>
</div>
</div>
<div class="section" id="common-subspace-independent-edge-cosie-model">
<h2><span class="section-number">5.5.2. </span>Common Subspace Independent Edge (COSIE) Model<a class="headerlink" href="#common-subspace-independent-edge-cosie-model" title="Permalink to this headline">¶</a></h2>
<p>In our example on social networks, notice that the facebook and linkedin connections looked relatively similar, but had an important difference: on linkedin, there was an administrative meeting, and the employees on the administrative team exchanged far more connections than usual amongst one another. It turns out that, in fact, the random networks <span class="math notranslate nohighlight">\(\mathbf A^{(1)}\)</span> and <span class="math notranslate nohighlight">\(\mathbf A^{(3)}\)</span> which underly the social networks <span class="math notranslate nohighlight">\(A^{(1)}\)</span> and <span class="math notranslate nohighlight">\(A^{(3)}\)</span> were also different, because the probability matrices were different:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plot_prob_block_annot</span><span class="p">(</span><span class="n">P1</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$P^{(1)}$ facebook Prob. Matrix&quot;</span><span class="p">)</span>
<span class="n">plot_prob_block_annot</span><span class="p">(</span><span class="n">P3</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$P^{(3)}$ linkedin Prob. Matrix&quot;</span><span class="p">)</span>
<span class="n">plot_prob_block_annot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">P1</span> <span class="o">-</span> <span class="n">P3</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$|P^{(1)} - P^{(3)}|$&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Notice that the difference in the probability of a connection being shared between the members of the administrative team is <span class="math notranslate nohighlight">\(0.6\)</span> higher in the probability matrix for linkedin than for facebook. This is because the random networks <span class="math notranslate nohighlight">\(\mathbf A^{(1)}\)</span> and <span class="math notranslate nohighlight">\(\mathbf A^{(3)}\)</span> are heterogeneous. To reflect this heterogeneity, we will need to turn to the COmmon Subspace Independent Edge (COSIE) model.</p>
<div class="section" id="the-cosie-model-is-defined-by-a-collection-of-score-matrices-and-a-shared-low-rank-subspace">
<h3><span class="section-number">5.5.2.1. </span>The COSIE Model is defined by a collection of score matrices and a shared low-rank subspace<a class="headerlink" href="#the-cosie-model-is-defined-by-a-collection-of-score-matrices-and-a-shared-low-rank-subspace" title="Permalink to this headline">¶</a></h3>
<p>Even though <span class="math notranslate nohighlight">\(P^{(1)}\)</span> and <span class="math notranslate nohighlight">\(P^{(3)}\)</span> are not <em>identical</em>, we can see they still share <em>some</em> structure: the employee teams are the same between the two social networks, and much of the probability matrix is unchanged. For this reason, it will be useful for us to have a network model which allows us to convey <em>some</em> shared structure, but still lets us convey aspects of the different networks which are <em>unique</em>. The COSIE model will accomplish this using a <em>shared latent position matrix</em>, and unique <em>score matrices</em> for each of the random networks.</p>
<div class="section" id="the-shared-latent-position-matrix-describes-similarities">
<h4><span class="section-number">5.5.2.1.1. </span>The Shared Latent Position Matrix Describes Similarities<a class="headerlink" href="#the-shared-latent-position-matrix-describes-similarities" title="Permalink to this headline">¶</a></h4>
<p>The <em>shared latent position matrix</em> for the COSIE model is quite similar to the latent position matrix for an RDPG. Like the latent position matrix, the shared latent position matrix <span class="math notranslate nohighlight">\(V\)</span> is a matrix with <span class="math notranslate nohighlight">\(n\)</span> rows (one for each node) and <span class="math notranslate nohighlight">\(d\)</span> columns. The <span class="math notranslate nohighlight">\(d\)</span> columns behave very similarly to the <span class="math notranslate nohighlight">\(d\)</span> columns ffor the latent position matrix of an RDPG, and <span class="math notranslate nohighlight">\(d\)</span> is referred to as the <em>latent dimensionality</em> of the COSIE random networks. Like before, each row of the shared latent position matrix <span class="math notranslate nohighlight">\(v_i\)</span> will be referred to as the shared latent position vector for node <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p>We will also add an additional restriction to <span class="math notranslate nohighlight">\(V\)</span>: it will be a matrix with orthonormal columns. What this means is that for each column of <span class="math notranslate nohighlight">\(V\)</span>, the dot product of the column with itself is <span class="math notranslate nohighlight">\(1\)</span>, and the dot product of the column with any other column is <span class="math notranslate nohighlight">\(0\)</span>. This has the implication that <span class="math notranslate nohighlight">\(V^\top V = I\)</span>, the identity matrix.</p>
<p>The shared latent position matrix conveys the <em>common structure</em> between the COSIE random networks, and will be a parameter for each of the neworks. Remember that with the <span class="math notranslate nohighlight">\(JRDPG_n(X)\)</span> model, we were able to capture the homogeneity of the social networks on facebook and twitter, but we could not capture the heterogeneity of the social nework on linkedin. However, we want the shared latent position matrix <span class="math notranslate nohighlight">\(V\)</span> to convey the commonality amongst the three social networks; that is, that the employees are are always working on the same employee teams. Let’s take a look at the shared latent position matrix <span class="math notranslate nohighlight">\(V\)</span> for the social network example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.embed</span> <span class="kn">import</span> <span class="n">MultipleASE</span> <span class="k">as</span> <span class="n">MASE</span>

<span class="n">embedder</span> <span class="o">=</span> <span class="n">MASE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">V</span> <span class="o">=</span> <span class="n">embedder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">([</span><span class="n">P1</span><span class="p">,</span> <span class="n">P2</span><span class="p">,</span> <span class="n">P3</span><span class="p">])</span>

<span class="n">plot_latent</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">nodetix</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="mi">34</span><span class="p">,</span><span class="mi">44</span><span class="p">],</span> <span class="n">nodelabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;25&quot;</span><span class="p">,</span> <span class="s2">&quot;35&quot;</span><span class="p">,</span> <span class="s2">&quot;45&quot;</span><span class="p">],</span>
            <span class="n">dimtix</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">],</span> <span class="n">dimlabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;2&quot;</span><span class="p">,</span> <span class="s2">&quot;3&quot;</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$V$, Shared Latent Positions&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><span class="math notranslate nohighlight">\(V\)</span> reflects the fact that the first <span class="math notranslate nohighlight">\(25\)</span> employees are the ML experts, and all <span class="math notranslate nohighlight">\(25\)</span> have the same latent position vector. The next <span class="math notranslate nohighlight">\(10\)</span> employees are the administrative members, and share a different latent position vector from the ML experts. Finally, the last <span class="math notranslate nohighlight">\(10\)</span> employees are the marketing members, share a different latent position vector from the ML experts and the administrative team. In this way, the orthonormal matrix <span class="math notranslate nohighlight">\(V\)</span> has conveyed the community structure (the employee roles and who they tend to connect amongst) that is shared across all three days.</p>
</div>
<div class="section" id="score-matrices-describe-differences">
<h4><span class="section-number">5.5.2.1.2. </span>Score Matrices Describe Differences<a class="headerlink" href="#score-matrices-describe-differences" title="Permalink to this headline">¶</a></h4>
<p>The <em>score matrices</em> for the COSIE random networks essentially tell us how to assemble the shared latent position matrix to obtain the unique probability matrix for each network. The score matrix <span class="math notranslate nohighlight">\(R^{(m)}\)</span> for a random network <span class="math notranslate nohighlight">\(m\)</span> is a matrix with <span class="math notranslate nohighlight">\(d\)</span> columns and <span class="math notranslate nohighlight">\(d\)</span> rows. Therefore, it is a square matrix whose number of dimensions is equal to the latent dimensionality of the COSIE random networks.</p>
<p>The probability matrix for each network under the COSIE model is the matrix:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    P^{(m)} &amp;= VR^{(m)}V^\top
\end{align*}\]</div>
<p>In our social network example, we want the score matrices to reflect that facebook and twitter share a probability matrix, but facebook and linkedin do not. Consequently, we would expect that the score matrices from facebook and twitter should be the same, but the score matrix for linkedin will be different:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">blockname</span><span class="o">=</span><span class="s2">&quot;Employee Group&quot;</span><span class="p">,</span> <span class="n">blocktix</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">],</span>
               <span class="n">blocklabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;ML&quot;</span><span class="p">,</span> <span class="s2">&quot;Adm.&quot;</span><span class="p">,</span> <span class="s2">&quot;Mark.&quot;</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    
    <span class="k">with</span> <span class="n">sns</span><span class="o">.</span><span class="n">plotting_context</span><span class="p">(</span><span class="s2">&quot;talk&quot;</span><span class="p">,</span> <span class="n">font_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Purples&quot;</span><span class="p">,</span>
                        <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">cbar_kws</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">shrink</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        <span class="n">cbar</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">collections</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="n">blockname</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="n">blockname</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">blocktix</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">blocklabs</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">blocktix</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">blocklabs</span><span class="p">)</span>
        <span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">set_frame_on</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span>

<span class="n">vmin</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">embedder</span><span class="o">.</span><span class="n">scores_</span><span class="p">);</span> <span class="n">vmax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">embedder</span><span class="o">.</span><span class="n">scores_</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">R1</span> <span class="o">=</span> <span class="n">embedder</span><span class="o">.</span><span class="n">scores_</span><span class="p">[</span><span class="mi">0</span><span class="p">,:,:]</span>
<span class="n">R2</span> <span class="o">=</span> <span class="n">embedder</span><span class="o">.</span><span class="n">scores_</span><span class="p">[</span><span class="mi">1</span><span class="p">,:,:]</span>
<span class="n">R3</span> <span class="o">=</span> <span class="n">embedder</span><span class="o">.</span><span class="n">scores_</span><span class="p">[</span><span class="mi">2</span><span class="p">,:,:]</span>

<span class="n">plot_score</span><span class="p">(</span><span class="n">R1</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$R^{(1)}$ facebook Scores&quot;</span><span class="p">)</span>
<span class="n">plot_score</span><span class="p">(</span><span class="n">R2</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$R^{(2)}$ twitter Scores&quot;</span><span class="p">)</span>
<span class="n">plot_score</span><span class="p">(</span><span class="n">R3</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$R^{(3)}$ linkedin Scores&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As we can see, the scores <span class="math notranslate nohighlight">\(R^{(1)}\)</span> and <span class="math notranslate nohighlight">\(R^{(2)}\)</span> are the same for facebook and twitter, but different for <span class="math notranslate nohighlight">\(R^{(3)}\)</span> linkedin.</p>
<p>Finally, let’s relate all of this back to the COSIE model. The way we can think about the COSIE model is that for each random network <span class="math notranslate nohighlight">\(m\)</span> of our <span class="math notranslate nohighlight">\(M\)</span> total networks, the probability matrix <span class="math notranslate nohighlight">\(P^{((m)}\)</span> depends on the shared latent position matrix <span class="math notranslate nohighlight">\(V\)</span> and the score matrix <span class="math notranslate nohighlight">\(R^{(m)}\)</span>. The probability matrix <span class="math notranslate nohighlight">\(P^{(m)}\)</span> for the <span class="math notranslate nohighlight">\(m^{th}\)</span> random network is defined so that <span class="math notranslate nohighlight">\(P^{(m)} = VR^{(m)}V^\top\)</span>. This means that each entry <span class="math notranslate nohighlight">\(p_{ij}^{(m)} = \vec v_i^\top R^{(m)} \vec v_j\)</span>. We say that a collection of random networks <span class="math notranslate nohighlight">\(\left\{\mathbf A^{(1)}, ..., \mathbf A^{(M)}\right\}\)</span> with <span class="math notranslate nohighlight">\(n\)</span> nodes is <span class="math notranslate nohighlight">\(COSIE_{n,M}\left(V, \left\{R^{(1)},...,R^{(M)}\right\}\right)\)</span> if each random network <span class="math notranslate nohighlight">\(\mathbf A^{(m)}\)</span> is <span class="math notranslate nohighlight">\(IER(P^{(m)})\)</span>. Stated another way, each of the <span class="math notranslate nohighlight">\(N\)</span> random networks share the same orthonormal matrix <span class="math notranslate nohighlight">\(V\)</span>, but a unique score matrix <span class="math notranslate nohighlight">\(R^{(m)}\)</span>. This allows the random networks to share some underlying structure (which is conveyed by <span class="math notranslate nohighlight">\(V\)</span>) but each random network still has a combination of this shared structure (conveyed by <span class="math notranslate nohighlight">\(R^{(m)}\)</span>).</p>
<p>Since the probability matrix <span class="math notranslate nohighlight">\(P^{(m)} = VR^{(m)}V^\top\)</span>, we can see that two random networks with the same score matrix will be homogeneous, and two random networks with different score matrices will be heterogeneous. In this way, we were able to capture the homogeneity between the random networks for facebook and twitter connections, while also capturing the heterogeneity between the random networks for facebook and linkedin connections.</p>
</div>
</div>
</div>
<div class="section" id="correlated-network-models">
<h2><span class="section-number">5.5.3. </span>Correlated Network Models<a class="headerlink" href="#correlated-network-models" title="Permalink to this headline">¶</a></h2>
<p>Finally, we get to a special case of network models, known as correlated network models. Let’s say that we have a group of people in a city, and we know that each people in our group have both a Facebook and a Twitter. The nodes in our network are the people we have. The first network consists of Facebook connections amongst the people, where an edge exists between two people if they are friends on Facebook. The second network consists of Twitter connections amongst the people, where an edge exists between two people if they follow one another on Twitter. We think that if two people are friends on Facebook, there is a good chance that they follow one another on Twitter, and vice versa. How do we reflect this similarity through a multiple network model?</p>
<p>At a high level, network correlation between a pair of networks describes the property that the existence of edges in one network provides us with some level of information about edges in the other network, much like the Facebook/Twitter example we just discussed. In this book, we will focus on the <span class="math notranslate nohighlight">\(\rho\)</span>-<em>correlated</em> network models. What the <span class="math notranslate nohighlight">\(\rho\)</span>-correlated network models focus on is that given two random networks with the same number of nodes, each edge has a correlation of <span class="math notranslate nohighlight">\(\rho\)</span> between the two networks. To define this a little more rigorously, a pair of random networks <span class="math notranslate nohighlight">\(\mathbf A^{(1)}\)</span> and <span class="math notranslate nohighlight">\(\mathbf A^{(2)}\)</span> are called <span class="math notranslate nohighlight">\(\rho\)</span>-<strong>correlated</strong> if all of the edges across both networks are mutually independent, except that for all pairs of indices <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>, <span class="math notranslate nohighlight">\(corr(\mathbf a_{ij}^{(1)}, \mathbf a_{ij}^{(2)}) = \rho\)</span>, where <span class="math notranslate nohighlight">\(corr(\mathbf x, \mathbf y)\)</span> is the Pearson correlation between two random variables <span class="math notranslate nohighlight">\(\mathbf x\)</span> and <span class="math notranslate nohighlight">\(\mathbf y\)</span>. In our example, this means that whether two people are friends on Facebook is <em>correlated</em> with whether they are following one another on Twitter.</p>
<p>At a high level, the Pearson correlation describes whether one variable being large/small gives information that the other variable is large/small (positive correlation, between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span>) or whether one variable being large/small gives information that the other variable will be small/large (negative correlation, between <span class="math notranslate nohighlight">\(-1\)</span> and <span class="math notranslate nohighlight">\(0\)</span>). If the two networks are positively correlated and we know that one of the edges <span class="math notranslate nohighlight">\(\mathbf a_{ij}^{(1)}\)</span> has a value of one, then we have information that <span class="math notranslate nohighlight">\(\mathbf a_{ij}^{(2)}\)</span> might also be one, and vice-versa for taking values of zero. If the two networks are negatively correlated and we know that one of the edges <span class="math notranslate nohighlight">\(\mathbf a_{ij}^{(1)}\)</span> has a value of one, then we have information that <span class="math notranslate nohighlight">\(\mathbf a_{ij}^{(2)}\)</span> might be zero, and vice-versa. If the two networks are not correlated (<span class="math notranslate nohighlight">\(\rho = 0\)</span>) we do not learn anything about edges of network two by looking at edges from network one.</p>
<div class="section" id="rho-correlated-rdpg">
<h3><span class="section-number">5.5.3.1. </span><span class="math notranslate nohighlight">\(\rho\)</span>-Correlated RDPG<a class="headerlink" href="#rho-correlated-rdpg" title="Permalink to this headline">¶</a></h3>
<p>The <span class="math notranslate nohighlight">\(\rho\)</span>-correlated RDPG is the most general correlated network model we will need for the purposes of this book. Remembering that both ER and SBM random networks are special cases of the RDPG (for a given choice of the latent position matrix), the <span class="math notranslate nohighlight">\(\rho\)</span>-correlated RDPG can therefore be used to construct <span class="math notranslate nohighlight">\(\rho\)</span>-correlated ER and <span class="math notranslate nohighlight">\(\rho\)</span>-correlated SBMs, too. The way we can think about the <span class="math notranslate nohighlight">\(\rho\)</span>-correlated RDPG is that like for the normal RDPG, a latent position matrix <span class="math notranslate nohighlight">\(X\)</span> with <span class="math notranslate nohighlight">\(n\)</span> rows and a latent dimensionality of <span class="math notranslate nohighlight">\(d\)</span> is used to define the edge-existence probabilities for the networks <span class="math notranslate nohighlight">\(\mathbf A^{(1)}\)</span> and <span class="math notranslate nohighlight">\(\mathbf A^{(2)}\)</span>. We begin by defining that <span class="math notranslate nohighlight">\(\mathbf A^{(1)}\)</span> is <span class="math notranslate nohighlight">\(RDPG_n(X)\)</span>. Next, we define the second network as follows. We use a coin for each edge <span class="math notranslate nohighlight">\((i, j)\)</span>, which has a probability that depends on the values that the first network takes. If the edge <span class="math notranslate nohighlight">\(\mathbf a_{ij}^{(1)}\)</span> takes the value of one, then we use a coin which has a probability of landing on heads of <span class="math notranslate nohighlight">\(\vec x_i^\top \vec x_j + \rho(1 - \vec x_i^\top \vec x_j)\)</span>. If the edge <span class="math notranslate nohighlight">\(\mathbf a_{ij}^{(1)}\)</span> takes the value of zero, then we use a coin which has a probability of landing on heads of <span class="math notranslate nohighlight">\((1 - \rho)\vec x_i^\top \vec x_j\)</span>. We flip this coin, and if it lands on heads, then the edge <span class="math notranslate nohighlight">\(\mathbf a_{ij}^{(2)}\)</span> takes the value of one. If it lands on tails, then the edge <span class="math notranslate nohighlight">\(\mathbf a_{ij}^{(2)}\)</span> takes the value of zero. If <span class="math notranslate nohighlight">\(\mathbf A^{(1)}\)</span> and <span class="math notranslate nohighlight">\(A^{(2)}\)</span> are random networks which are <span class="math notranslate nohighlight">\(\rho\)</span>-correlated RDPGs with latent position matrix <span class="math notranslate nohighlight">\(X\)</span>, we say that the pair <span class="math notranslate nohighlight">\(\left\{\mathbf A^{(1)}, A^{(2)}\right\}\)</span> are <span class="math notranslate nohighlight">\(\rho-RDPG_n(X)\)</span>.</p>
<div class="admonition-simulating-realizations-of-rho-correlated-rdpgs admonition">
<p class="admonition-title">Simulating realizations of <span class="math notranslate nohighlight">\(\rho\)</span>-correlated RDPGs</p>
<ol class="simple">
<li><p>Determine a latent position matrix <span class="math notranslate nohighlight">\(X\)</span>, where rows <span class="math notranslate nohighlight">\(\vec x_i\)</span> are the latent position vectors for the nodes <span class="math notranslate nohighlight">\(i\)</span>.</p></li>
<li><p>Determine a correlation between the two networks of <span class="math notranslate nohighlight">\(\rho\)</span>, where <span class="math notranslate nohighlight">\(\rho \geq -1\)</span> and <span class="math notranslate nohighlight">\(\rho \leq 1\)</span>.</p></li>
<li><p>Simulate a realization <span class="math notranslate nohighlight">\(A^{(1)}\)</span> which is a realization  of an <span class="math notranslate nohighlight">\(RDPG_n(X)\)</span> random network.</p></li>
<li><p>For each pair of nodes <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>:</p>
<ul class="simple">
<li><p>If the edge <span class="math notranslate nohighlight">\(a_{ij}^{(1)}\)</span> has a value of one, obtain a coin which has a probability of landing on heads of <span class="math notranslate nohighlight">\(\vec x_i^\top \vec x_j + \rho(1 - \vec x_i^\top \vec x_j)\)</span>. If the edge <span class="math notranslate nohighlight">\(a_{ij}^{(2)}\)</span> has a value of zero, obtain a coin which has a probability of landing on heads of <span class="math notranslate nohighlight">\((1 - \rho)\vec x_i^\top \vec x_j\)</span>.</p></li>
<li><p>Flip the <span class="math notranslate nohighlight">\((i,j)\)</span> coin, andd if it lands on heads, the corresponding entry <span class="math notranslate nohighlight">\(a_{ij}^{(2)}\)</span> in the adjacency matrix is <span class="math notranslate nohighlight">\(1\)</span>. If the coin lands on tails, the corresponding entry <span class="math notranslate nohighlight">\(a_{ij}^{(2)}\)</span> is <span class="math notranslate nohighlight">\(0\)</span>.</p></li>
</ul>
</li>
<li><p>The adjacency matrices <span class="math notranslate nohighlight">\(A^{(1)}\)</span> and <span class="math notranslate nohighlight">\(A^{(2)}\)</span> are realizations of <span class="math notranslate nohighlight">\(\rho-RDPG_n(X)\)</span> random networks.</p></li>
</ol>
</div>
<p>Fortunately, graspologic makes sampling <span class="math notranslate nohighlight">\(\rho\)</span>-correlated RDPGs relatively simple. Let’s say that in our Facebook/Twitter example, we have <span class="math notranslate nohighlight">\(100\)</span> people across two schools, like our standard example from the SBM section. The first <span class="math notranslate nohighlight">\(50\)</span> students attend school one, and the second <span class="math notranslate nohighlight">\(50\)</span> students attend school two. To recap, the latent position matrix looks like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="kn">import</span> <span class="n">svd</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># deine a probability matrix for a stochastic block model with two communities</span>
<span class="c1"># where the first 50 students are from community one and the second 50 students are</span>
<span class="c1"># from community two</span>
<span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">))</span>
<span class="n">P</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">50</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">50</span><span class="p">]</span> <span class="o">=</span> <span class="mf">.5</span>
<span class="n">P</span><span class="p">[</span><span class="mi">50</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">:</span><span class="mi">100</span><span class="p">]</span> <span class="o">=</span> <span class="mf">.3</span>
<span class="n">P</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">50</span><span class="p">,</span><span class="mi">50</span><span class="p">:</span><span class="mi">100</span><span class="p">]</span> <span class="o">=</span> <span class="mf">.2</span>
<span class="n">P</span><span class="p">[</span><span class="mi">50</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">50</span><span class="p">]</span> <span class="o">=</span> <span class="mf">.2</span>

<span class="c1"># use the singular value decomposition to obtain the corresponding latent</span>
<span class="c1"># position matrix</span>
<span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">svd</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">U</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">S</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">cmaps</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="k">def</span> <span class="nf">plot_latent</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">nodename</span><span class="o">=</span><span class="s2">&quot;Student&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Latent Dimension&quot;</span><span class="p">,</span>
                <span class="n">nodetix</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">nodelabs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dimtix</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dimlabs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    
    <span class="k">with</span> <span class="n">sns</span><span class="o">.</span><span class="n">plotting_context</span><span class="p">(</span><span class="s2">&quot;talk&quot;</span><span class="p">,</span> <span class="n">font_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">lim_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
        <span class="n">vmin</span> <span class="o">=</span> <span class="o">-</span><span class="n">lim_max</span><span class="p">;</span> <span class="n">vmax</span> <span class="o">=</span> <span class="n">lim_max</span>
        <span class="n">X_annot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;U6&#39;</span><span class="p">)</span>
        <span class="n">X_annot</span><span class="p">[</span><span class="mi">25</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">25</span><span class="p">,</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">X_annot</span><span class="p">[</span><span class="mi">75</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">75</span><span class="p">,</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">X_annot</span><span class="p">[</span><span class="mi">25</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">25</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">X_annot</span><span class="p">[</span><span class="mi">75</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">75</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmaps</span><span class="p">[</span><span class="s2">&quot;divergent&quot;</span><span class="p">],</span>
                        <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">cbar_kws</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">shrink</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span>
                        <span class="n">annot</span><span class="o">=</span><span class="n">X_annot</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        <span class="n">cbar</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">collections</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="n">nodename</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="n">ylabel</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">nodetix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">nodelabs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">nodetix</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">nodelabs</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">dimtix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">dimlabs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">dimtix</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">dimlabs</span><span class="p">)</span>
        <span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">set_frame_on</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span>


<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_latent</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Latent Position Matrix&quot;</span><span class="p">,</span> <span class="n">nodetix</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">49</span><span class="p">,</span> <span class="mi">99</span><span class="p">],</span>
              <span class="n">nodelabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;50&quot;</span><span class="p">,</span> <span class="s2">&quot;100&quot;</span><span class="p">],</span> <span class="n">dimtix</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">],</span> <span class="n">dimlabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;2&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>To sample two networks which are <span class="math notranslate nohighlight">\(\rho\)</span>-correlated SBMs, let’s assume that the correlation between the two networks is high, so we will assume <span class="math notranslate nohighlight">\(\rho = 0.7\)</span>. We use the graspologic function to obtain a realization for each network. We show the two networks, as well as the edges which are different between the two networks. We summarize this edge difference plot with <span class="math notranslate nohighlight">\(diff(A^{(F)} - A^{(T)})\)</span>, which simply counts the number of edges which are different:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">rdpg_corr</span>

<span class="n">rho</span> <span class="o">=</span> <span class="mf">0.7</span>
<span class="n">A_facebook</span><span class="p">,</span> <span class="n">A_twitter</span> <span class="o">=</span> <span class="n">rdpg_corr</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="n">rho</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">ys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;1&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;2&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">)]</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A_facebook</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$A^{(F)}$ Facebook Network&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;sequential&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">ys</span><span class="p">);</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A_twitter</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$A^{(T)}$ Twitter Network&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;sequential&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">ys</span><span class="p">);</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">A_facebook</span> <span class="o">-</span> <span class="n">A_twitter</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$diff(A^{(F)} - A^{(T)}) = </span><span class="si">%d</span><span class="s2">, </span><span class="se">\\</span><span class="s2">rho = 0.7$&quot;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">A_facebook</span> <span class="o">-</span> <span class="n">A_twitter</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> 
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;sequential&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">ys</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>On the other hand, if the correlation were <span class="math notranslate nohighlight">\(\rho = 0\)</span> (the two networks are uncorrelated), we can see that the number of edges which are different is much higher:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rho</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="n">A_facebook</span><span class="p">,</span> <span class="n">A_twitter</span> <span class="o">=</span> <span class="n">rdpg_corr</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="n">rho</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">ys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;1&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;2&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">)]</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A_facebook</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$A^{(F)}$ Facebook Network&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;sequential&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">ys</span><span class="p">);</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A_twitter</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$A^{(T)}$ Twitter Network&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;sequential&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">ys</span><span class="p">);</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">A_facebook</span> <span class="o">-</span> <span class="n">A_twitter</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$diff(A^{(F)} - A^{(T)}) = </span><span class="si">%d</span><span class="s2">, </span><span class="se">\\</span><span class="s2">rho = 0$&quot;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">A_facebook</span> <span class="o">-</span> <span class="n">A_twitter</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;sequential&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">ys</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./representations/ch5"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="single-network-models_RDPG.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">5.4. </span>Random Dot Product Graphs (RDPG)</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="models-with-covariates.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">5.6. </span>Network Models with Covariates</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Joshua Vogelstein, Eric Bridgeford, and Alex Loftus<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>