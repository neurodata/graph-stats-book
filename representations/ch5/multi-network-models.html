
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>5.6. Multiple Network Models &#8212; Hands-on Network Machine Learning with Scikit-Learn and Graspologic</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="5.7. Network Models with Covariates" href="models-with-covariates.html" />
    <link rel="prev" title="5.5. Random Dot Product Graphs (RDPG)" href="single-network-models_RDPG.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Hands-on Network Machine Learning with Scikit-Learn and Graspologic</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../coverpage.html">
   Hands-on Network Machine Learning with Scikit-Learn and Graspologic
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/terminology.html">
   Terminology and Math Refresher
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch1/ch1.html">
   1. The Network Machine Learning Landscape
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/what-is-a-network.html">
     1.1. What Is A Network?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/why-study-networks.html">
     1.2. Why Study Networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/examples-of-applications.html">
     1.3. Examples of applications
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/types-of-networks.html">
     1.4. Types of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/types-of-learning-probs.html">
     1.5. Types of Network Learning Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/main-challenges.html">
     1.6. Main Challenges of Network Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/exercises.html">
     1.7. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch2/ch2.html">
   2. End-to-end Biology Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/big-picture.html">
     2.1. Look at the big picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/get-the-data.html">
     2.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/prepare-the-data.html">
     2.3. Prepare the Data for Network Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/transformation-techniques.html">
     2.4. Transformation Techniques
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/select-and-train.html">
     2.5. Select and Train a Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/fine-tune.html">
     2.6. Fine-Tune your Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch3/ch3.html">
   3. End-to-end Business Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/big-picture.html">
     3.1. Look at the Big Picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/get-the-data.html">
     3.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/discover-and-visualize.html">
     3.3. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/prepare-the-data.html">
     3.4. Prepare the Data for Network Algorithms
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Representations
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch4/ch4.html">
   4. Properties of Networks as a Statistical Object
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/matrix-representations.html">
     4.1. Matrix Representations Of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/network-representations.html">
     4.2. Representations of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/properties-of-networks.html">
     4.3. Properties of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/regularization.html">
     4.4. Regularization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="ch5.html">
   5. Why Use Statistical Models?
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="why-use-models.html">
     5.1. Why Use Statistical Models?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="single-network-models.html">
     5.2. Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="single-network-models_ER.html">
     5.3. Erdös-Rényi (ER) Random Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="single-network-models_SBM.html">
     5.4. Stochastic Block Models (SBM)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="single-network-models_RDPG.html">
     5.5. Random Dot Product Graphs (RDPG)
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     5.6. Multiple Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="models-with-covariates.html">
     5.7. Network Models with Covariates
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="single-network-models_theory.html">
     5.8. Single network model theory
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch6/ch6.html">
   6. Learning Network Representations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/estimating-parameters_mle.html">
     6.1. Estimating Parameters in Network Models via MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/why-embed-networks.html">
     6.2. Why embed networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/spectral-embedding.html">
     6.3. Spectral Embedding Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/estimating-parameters_spectral.html">
     6.4. Estimating Parameters in Network Models via Spectral Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/random-walk-diffusion-methods.html">
     6.5. Random-Walk and Diffusion-based Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/graph-neural-networks.html">
     6.6. Graph Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/multigraph-representation-learning.html">
     6.7. Multiple-Network Representation Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/joint-representation-learning.html">
     6.8. Joint Representation Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/estimating-parameters_theory.html">
     6.9. Model Estimation Theory
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch7/ch7.html">
   7. Theoretical Results
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/theory-single-network.html">
     7.1. Theory for Single Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/theory-multigraph.html">
     7.2. Theory for Multiple-Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/theory-matching.html">
     7.3. Theory for Graph Matching
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch8/ch8.html">
   8. Applications When You Have One Network
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/community-detection.html">
     8.1. Community Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/testing-differences.html">
     8.2. Testing for Differences between Communities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/model-selection.html">
     8.3. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/vertex-nomination.html">
     8.4. Single-Network Vertex Nomination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/anomaly-detection.html">
     8.5. Anomaly Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/out-of-sample.html">
     8.6. Out-of-sample Embedding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch9/ch9.html">
   9. Leveraging Representations for Multiple Graph Applications
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/two-sample-hypothesis.html">
     9.1. Two-Sample Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/graph-matching-vertex.html">
     9.2. Graph Matching and Vertex Nomination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/vertex-nomination.html">
     9.3. Vertex Nomination
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch10/ch10.html">
   10. Algorithms for more than 2 graphs
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch10/anomaly-detection.html">
     10.1. Anomaly Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch10/significant-edges.html">
     10.2. Testing for Significant Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch10/significant-vertices.html">
     10.3. Testing for Significant Vertices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch10/significant-communities.html">
     10.4. Testing for Significant Communities
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://graspologic.readthedocs.io/en/latest/">
   Graspologic Documentation
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/representations/ch5/multi-network-models.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/neurodata/graph-stats-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/neurodata/graph-stats-book/issues/new?title=Issue%20on%20page%20%2Frepresentations/ch5/multi-network-models.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/neurodata/graph-stats-book/edit/master/network_machine_learning_in_python/representations/ch5/multi-network-models.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/neurodata/graph-stats-book/master?urlpath=tree/network_machine_learning_in_python/representations/ch5/multi-network-models.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#joint-random-dot-product-graphs-jrdpg-model">
   5.6.1. Joint Random Dot Product Graphs (JRDPG) Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-jrdpg-model-does-not-allow-us-to-convey-unique-aspects-about-the-networks">
     5.6.1.1. The JRDPG model does not allow us to convey unique aspects about the networks
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-inhomogeous-erdos-renyi-random-network">
     5.6.1.2. The Inhomogeous Erdos-Renyi Random Network
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#common-subspace-independent-edge-cosie-model">
   5.6.2. Common Subspace Independent Edge (COSIE) Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-cosie-model-is-defined-by-a-collection-of-score-matrices-and-a-shared-low-rank-subspace">
     5.6.2.1. The COSIE Model is defined by a collection of score matrices and a shared low-rank subspace
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-the-cosie-model-for-emails">
     5.6.2.2. Using the COSIE Model for Emails
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="multiple-network-models">
<h1><span class="section-number">5.6. </span>Multiple Network Models<a class="headerlink" href="#multiple-network-models" title="Permalink to this headline">¶</a></h1>
<p>To this point in the book, we have studied network models which are relevant for only a single network. What do we do if we have multiple networks?</p>
<p>Remember that a random network is denoted by a boldfaced uppercase <span class="math notranslate nohighlight">\(\mathbf A\)</span>, and has realizations <span class="math notranslate nohighlight">\(A\)</span>. When we have multiple networks, we will need to be able to index them individually. For this reason, in this section, we will use the convention that a random network is denoted by a boldfaced uppercase <span class="math notranslate nohighlight">\(\mathbf A^{(m)}\)</span>, where <span class="math notranslate nohighlight">\(m\)</span> tells us which of the collection of networks we are talking about. The capital letter <span class="math notranslate nohighlight">\(N\)</span> defines the <em>total</em> number of random networks in our collection. When we use the letter <span class="math notranslate nohighlight">\(m\)</span> itself, we will typically be referring to an arbitrary random network amongst the collection of random networks, where <span class="math notranslate nohighlight">\(m\)</span> beween <span class="math notranslate nohighlight">\(1\)</span> and <span class="math notranslate nohighlight">\(N\)</span>. When we have <span class="math notranslate nohighlight">\(N\)</span> total networks, we will write down the entire <strong>collection of random networks</strong> using the notation <span class="math notranslate nohighlight">\(\left\{\mathbf A^{(1)}, ..., \mathbf A^{(N)}\right\}\)</span>. With what we have learned to date, for a random network <span class="math notranslate nohighlight">\(\mathbf A^{(m)}\)</span>, we would be able to use a single nework model to describe <span class="math notranslate nohighlight">\(\mathbf A^{(m)}\)</span>. This means, for instance, if we thought that each network could be represented by an RDPG, that we would have a latent position matrix <span class="math notranslate nohighlight">\(X^{(m)}\)</span> to define each of the <span class="math notranslate nohighlight">\(m\)</span> networks. In symbols, we would write that each <span class="math notranslate nohighlight">\(\mathbf A^{(m)}\)</span> is an <span class="math notranslate nohighlight">\(RDPG_n(X^{(m)})\)</span> random nework. What is the problem with this descripion?</p>
<p>Let’s think about this with an example. Let’s imagine that we have a company with <span class="math notranslate nohighlight">\(20\)</span> total employees which is focused on developing software for network machine learning for business uses. <span class="math notranslate nohighlight">\(10\)</span> of these employees are company administrative executives, <span class="math notranslate nohighlight">\(25\)</span> of these employees are network machine learning experts, and that <span class="math notranslate nohighlight">\(10\)</span> of these employees are marketing experts. For each day over the course of a full <span class="math notranslate nohighlight">\(30\)</span>-day month, we study the emails that go back and forth between the employees in the company. We summarize the emailing habits within the company using a nework, where the nodes of the network are employees, and the edges indicate the emailing behaviors between each pair of employees. An edge is said to exist if the two employees have exchanged an email on that day, and an edge does not exist if the two employees have not exchanged an email on that day. In most companies, it is common for employees in a similar role to tend to work more closely together, so we might expect that there is some level of a community structure to the emailing habits. For instance, if two employees are both network machine learning experts, they might exchange more emails between one another than a machine learning expert and a marketing expert. For the sake of this example, we will assume that the networks are organized such that the first day is a Monday, the second day is a Tuesday, so on and so forth. Let’s take a look at an example of some possible realizations of the first <span class="math notranslate nohighlight">\(3\)</span> days worth of emails. What we will see below is that all of the random networks appear to have the same community organization, though on Wednesday, we will assume there was an executive board meeting, and in the morning leading up to the board meeting, the executives of the company exchanged more emails than on other days. This is reflected in the fact that there are more emails going back and forth between board members in the network for “Wednesday”:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">heatmap</span>
<span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">sbm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">K</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">B1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">K</span><span class="p">,</span><span class="n">K</span><span class="p">))</span>

<span class="n">B1</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">B1</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">.05</span>
<span class="n">B1</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">.05</span>
<span class="n">B1</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">.05</span>
<span class="n">B1</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">.05</span>
<span class="n">B1</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">B1</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">.05</span>
<span class="n">B1</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">.05</span>
<span class="n">B1</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.3</span>

<span class="n">B2</span> <span class="o">=</span> <span class="n">B1</span>

<span class="n">B3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">B1</span><span class="p">)</span>
<span class="n">B3</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.9</span>

<span class="n">ns</span> <span class="o">=</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="n">A1</span> <span class="o">=</span> <span class="n">sbm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">ns</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">B1</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;ML&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ns</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;Adm.&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ns</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">ns</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">ns</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;Mar.&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ns</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">ns</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">ns</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">ns</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">ns</span><span class="p">[</span><span class="mi">2</span><span class="p">])]</span>

<span class="n">A2</span> <span class="o">=</span> <span class="n">sbm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">ns</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">B2</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">A3</span> <span class="o">=</span> <span class="n">sbm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">ns</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">B3</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A1</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$A^{(1)}$ Monday Emails&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;sequential&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">ys</span><span class="p">);</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A2</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$A^{(2)}$ Tuesday Emails&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;sequential&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">ys</span><span class="p">);</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A3</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$A^{(3)}$ Wednesday Emails&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;sequential&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">ys</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/multi-network-models_1_0.png" src="../../_images/multi-network-models_1_0.png" />
</div>
</div>
<p>If we were to summarize this situation with an RDPG, we might say that <span class="math notranslate nohighlight">\(\mathbf A^{(m)}\)</span> is an <span class="math notranslate nohighlight">\(RDPG_n(X^{(m)})\)</span> random network, where <span class="math notranslate nohighlight">\(m\)</span> goes from <span class="math notranslate nohighlight">\(1\)</span> to <span class="math notranslate nohighlight">\(30\)</span>. What this description lacks is that, over the course of a given <span class="math notranslate nohighlight">\(30\)</span> days, a <em>lot</em> of the networks are going to show similar emailing patterns. We might expect that this implies that, on some level, the latent position matrices should also show some sort of common structure. However, since we used a <em>unique</em> latent position matrix <span class="math notranslate nohighlight">\(X^{(m)}\)</span> for each random network <span class="math notranslate nohighlight">\(\mathbf A^{(m)}\)</span>, we have inherently stated that we think that the networks have a completely distinct latent position matrix. If we were to perform a task downstream, such as whether we could identify which employees are in which community, we would have to analyze each latent position matrix individually, and we would not be able to learn a latent position matrix with shared structure across all <span class="math notranslate nohighlight">\(30\)</span> days.</p>
<p>A final point: in the below descriptions, we will tend to build off the Random Dot Product Graph (RDPG), and closely related variations of it. Why? Well, as it turns out, the RDPG is extremely flexible, in that we can represent both ER and SBMs as RDPGs, too. This means that building off the RDPG gives us multiple random network models that will be inherently flexible. Further, as we will see in the later section on <a class="reference external" href="#link?">Estimation</a>, the RDPG is extremely well-suited for the situation in which we want to analyze SBMs, but do not know which communities the nodes are in ahead of time. This situation is extremely common across numerous disciplines of network machine learning, such as social networking, neuroscience, and many other fields.</p>
<p>So, how can we think about our collection of random networks and reflect this shared structure?</p>
<div class="section" id="joint-random-dot-product-graphs-jrdpg-model">
<h2><span class="section-number">5.6.1. </span>Joint Random Dot Product Graphs (JRDPG) Model<a class="headerlink" href="#joint-random-dot-product-graphs-jrdpg-model" title="Permalink to this headline">¶</a></h2>
<p>The Joint Random Dot Product Graphs (JRDPG) is the simplest way we can extend the RDPG random network model to multiple random networks. The way we can think of the JRDPG model is that for each of our <span class="math notranslate nohighlight">\(N\)</span> total random neworks, the edges in the random networks depend on a latent position matrix <span class="math notranslate nohighlight">\(X\)</span>. We say that a collection of random networks <span class="math notranslate nohighlight">\(\left\{\mathbf A^{(1)}, ..., \mathbf A^{(N)}\right\}\)</span> with <span class="math notranslate nohighlight">\(n\)</span> nodes is <span class="math notranslate nohighlight">\(JRDPG_n(X)\)</span> if each random network <span class="math notranslate nohighlight">\(\mathbf A^{(m)}\)</span> is <span class="math notranslate nohighlight">\(RDPG_n(X)\)</span> and if the <span class="math notranslate nohighlight">\(N\)</span> networks are independent. Stated another way, all of the <span class="math notranslate nohighlight">\(N\)</span> random networks share the same latent position matrix under the <span class="math notranslate nohighlight">\(JRDPG_n(X)\)</span> multiple random network model.</p>
<div class="section" id="the-jrdpg-model-does-not-allow-us-to-convey-unique-aspects-about-the-networks">
<h3><span class="section-number">5.6.1.1. </span>The JRDPG model does not allow us to convey unique aspects about the networks<a class="headerlink" href="#the-jrdpg-model-does-not-allow-us-to-convey-unique-aspects-about-the-networks" title="Permalink to this headline">¶</a></h3>
<p>Under the JRDPG model, each of the <span class="math notranslate nohighlight">\(N\)</span> random networks share the same latent position matrix. This means that the <span class="math notranslate nohighlight">\(N\)</span> random networks are <strong>homogeneous</strong>. A <strong>homogeneous</strong> collection of random networks <span class="math notranslate nohighlight">\(\left\{\mathbf A^{(1)}, ..., \mathbf A^{(N)}\right\}\)</span> is a collection of random neworks in which <em>all</em> of the <span class="math notranslate nohighlight">\(N\)</span> random networks have the same marginal distribution. For instance, in the case of the <span class="math notranslate nohighlight">\(JRDPG_n(X)\)</span> multiple random network model, all of the <span class="math notranslate nohighlight">\(N\)</span> networks have the marginal distribution <span class="math notranslate nohighlight">\(RDPG_n(X)\)</span>. Stated another way, the <em>parameters</em> that underly the random network (which, for a <span class="math notranslate nohighlight">\(RDPG_n(X)\)</span> network, is the latent position matrix <span class="math notranslate nohighlight">\(X\)</span>) are the <em>same</em> for the entire collection.</p>
<p>To make this a little more concrete, let’s circle back to our email network above. First, we will make this example a little more beefed up so we can study it in the context of network homogeneity. The network realizations for Monday, Tuesday, and Wednesday were <span class="math notranslate nohighlight">\(A^{(1)}\)</span>, <span class="math notranslate nohighlight">\(A^{(2)}\)</span>, and <span class="math notranslate nohighlight">\(A^{(3)}\)</span>. These realizations are realizations of random networks <span class="math notranslate nohighlight">\(\mathbf A^{(1)}\)</span>, <span class="math notranslate nohighlight">\(\mathbf A^{(2)}\)</span>, and <span class="math notranslate nohighlight">\(\mathbf A^{(3)}\)</span>. All of the random networks <span class="math notranslate nohighlight">\(\mathbf A^{(m)}\)</span> are <span class="math notranslate nohighlight">\(SBM_n(\vec z, B^{(m)})\)</span> random networks, which means that they are also <span class="math notranslate nohighlight">\(RDPG_n(X^{(m)})\)</span> random networks, since as we learned in the section on <a class="reference external" href="#link?">RDPG</a>, SBM random networks can be represented as RDPG random networks. Remember that the realizations of the emails that have gone back and forth in the company looked like this:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/multi-network-models_3_0.png" src="../../_images/multi-network-models_3_0.png" />
</div>
</div>
<p>Remember that for an RDPG random network, the parameter is a latent position matrix, <span class="math notranslate nohighlight">\(X^{(m)}\)</span>. Let’s take a look at the latent position matrix for the random networks that underlie the given realizations:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="kn">import</span> <span class="n">svd</span>
<span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">cmaps</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="k">def</span> <span class="nf">p_from_block</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">ns</span><span class="p">):</span>
    <span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ns</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ns</span><span class="p">)))</span>
    <span class="n">ns_cumsum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">ns</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">n1</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ns_cumsum</span><span class="p">[</span><span class="mi">0</span><span class="p">:(</span><span class="nb">len</span><span class="p">(</span><span class="n">ns_cumsum</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)]):</span>
        <span class="k">for</span> <span class="n">l</span><span class="p">,</span> <span class="n">n2</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ns_cumsum</span><span class="p">[</span><span class="n">k</span><span class="p">:(</span><span class="nb">len</span><span class="p">(</span><span class="n">ns_cumsum</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)]):</span>
            <span class="n">P</span><span class="p">[</span><span class="n">ns_cumsum</span><span class="p">[</span><span class="n">k</span><span class="p">]:</span><span class="n">ns_cumsum</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">ns_cumsum</span><span class="p">[</span><span class="n">l</span><span class="o">+</span><span class="n">k</span><span class="p">]:</span><span class="n">ns_cumsum</span><span class="p">[</span><span class="n">l</span><span class="o">+</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span><span class="n">l</span><span class="o">+</span><span class="n">k</span><span class="p">]</span>
            <span class="n">P</span><span class="p">[</span><span class="n">ns_cumsum</span><span class="p">[</span><span class="n">l</span><span class="o">+</span><span class="n">k</span><span class="p">]:</span><span class="n">ns_cumsum</span><span class="p">[</span><span class="n">l</span><span class="o">+</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span><span class="n">ns_cumsum</span><span class="p">[</span><span class="n">k</span><span class="p">]:</span><span class="n">ns_cumsum</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">B</span><span class="p">[</span><span class="n">l</span><span class="o">+</span><span class="n">k</span><span class="p">,</span><span class="n">k</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">P</span>

<span class="n">P1</span> <span class="o">=</span> <span class="n">p_from_block</span><span class="p">(</span><span class="n">B1</span><span class="p">,</span> <span class="n">ns</span><span class="p">)</span>
<span class="n">U1</span><span class="p">,</span> <span class="n">S1</span><span class="p">,</span> <span class="n">V1</span> <span class="o">=</span> <span class="n">svd</span><span class="p">(</span><span class="n">P1</span><span class="p">)</span>
<span class="n">X1</span> <span class="o">=</span> <span class="n">U1</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">S1</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]))</span>

<span class="n">P2</span> <span class="o">=</span> <span class="n">p_from_block</span><span class="p">(</span><span class="n">B2</span><span class="p">,</span> <span class="n">ns</span><span class="p">)</span>
<span class="n">U2</span><span class="p">,</span> <span class="n">S2</span><span class="p">,</span> <span class="n">V2</span> <span class="o">=</span> <span class="n">svd</span><span class="p">(</span><span class="n">P2</span><span class="p">)</span>
<span class="n">X2</span> <span class="o">=</span> <span class="n">U2</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">S2</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]))</span>

<span class="n">P3</span> <span class="o">=</span> <span class="n">p_from_block</span><span class="p">(</span><span class="n">B3</span><span class="p">,</span> <span class="n">ns</span><span class="p">)</span>
<span class="n">U3</span><span class="p">,</span> <span class="n">S3</span><span class="p">,</span> <span class="n">V3</span> <span class="o">=</span> <span class="n">svd</span><span class="p">(</span><span class="n">P3</span><span class="p">)</span>
<span class="n">X3</span> <span class="o">=</span> <span class="n">U3</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">S3</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]))</span>

<span class="k">def</span> <span class="nf">plot_latent</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">nodename</span><span class="o">=</span><span class="s2">&quot;Employee&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Latent Dimension&quot;</span><span class="p">,</span>
                <span class="n">nodetix</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">nodelabs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dimtix</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dimlabs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    
    <span class="k">with</span> <span class="n">sns</span><span class="o">.</span><span class="n">plotting_context</span><span class="p">(</span><span class="s2">&quot;talk&quot;</span><span class="p">,</span> <span class="n">font_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">lim_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
        <span class="n">vmin</span> <span class="o">=</span> <span class="o">-</span><span class="n">lim_max</span><span class="p">;</span> <span class="n">vmax</span> <span class="o">=</span> <span class="n">lim_max</span>
        <span class="n">X_annot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">45</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;U6&#39;</span><span class="p">)</span>
        <span class="n">X_annot</span><span class="p">[</span><span class="mi">13</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">13</span><span class="p">,</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">X_annot</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">X_annot</span><span class="p">[</span><span class="mi">40</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">40</span><span class="p">,</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">X_annot</span><span class="p">[</span><span class="mi">13</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">13</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">X_annot</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">X_annot</span><span class="p">[</span><span class="mi">40</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">40</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">X_annot</span><span class="p">[</span><span class="mi">13</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">13</span><span class="p">,</span><span class="mi">2</span><span class="p">]))</span>
        <span class="n">X_annot</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span><span class="mi">2</span><span class="p">]))</span>
        <span class="n">X_annot</span><span class="p">[</span><span class="mi">40</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">40</span><span class="p">,</span><span class="mi">2</span><span class="p">]))</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmaps</span><span class="p">[</span><span class="s2">&quot;divergent&quot;</span><span class="p">],</span>
                        <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">cbar_kws</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">shrink</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span>
                        <span class="n">annot</span><span class="o">=</span><span class="n">X_annot</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        <span class="n">cbar</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">collections</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="n">nodename</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="n">ylabel</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">nodetix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">nodelabs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">nodetix</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">nodelabs</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">dimtix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">dimlabs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">dimtix</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">dimlabs</span><span class="p">)</span>
        <span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">set_frame_on</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plot_latent</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">nodetix</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="mi">34</span><span class="p">,</span><span class="mi">44</span><span class="p">],</span> <span class="n">nodelabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;25&quot;</span><span class="p">,</span> <span class="s2">&quot;35&quot;</span><span class="p">,</span> <span class="s2">&quot;45&quot;</span><span class="p">],</span>
            <span class="n">dimtix</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dimlabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;2&quot;</span><span class="p">,</span> <span class="s2">&quot;3&quot;</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$X^{(1)}$ Monday LPM&quot;</span><span class="p">)</span>
<span class="n">plot_latent</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span> <span class="n">nodetix</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="mi">34</span><span class="p">,</span><span class="mi">44</span><span class="p">],</span> <span class="n">nodelabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;25&quot;</span><span class="p">,</span> <span class="s2">&quot;35&quot;</span><span class="p">,</span> <span class="s2">&quot;45&quot;</span><span class="p">],</span>
            <span class="n">dimtix</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dimlabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;2&quot;</span><span class="p">,</span> <span class="s2">&quot;3&quot;</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$X^{(2)}$ Tuesday LPM&quot;</span><span class="p">)</span>
<span class="n">plot_latent</span><span class="p">(</span><span class="n">X3</span><span class="p">,</span> <span class="n">nodetix</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="mi">34</span><span class="p">,</span><span class="mi">44</span><span class="p">],</span> <span class="n">nodelabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;25&quot;</span><span class="p">,</span> <span class="s2">&quot;35&quot;</span><span class="p">,</span> <span class="s2">&quot;45&quot;</span><span class="p">],</span>
            <span class="n">dimtix</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">dimlabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;2&quot;</span><span class="p">,</span> <span class="s2">&quot;3&quot;</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$X^{(3)}$ Wednesday LPM&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/multi-network-models_6_0.png" src="../../_images/multi-network-models_6_0.png" />
</div>
</div>
<p>As we can see above, <span class="math notranslate nohighlight">\(X^{(1)} = X^{(2)}\)</span>, but <span class="math notranslate nohighlight">\(X^{(1)}\)</span> and <span class="math notranslate nohighlight">\(X^{(2)}\)</span> are not equal to <span class="math notranslate nohighlight">\(X^{(3)}\)</span>. Since <span class="math notranslate nohighlight">\(\mathbf A^{(m)}\)</span> are <span class="math notranslate nohighlight">\(RDPG_n(X^{(m)})\)</span>, if the latent position matrices for a pair of networks are equal, then the two networks are homogeneous (they have the same marginal distribution). Therefore, the collection of random networks <span class="math notranslate nohighlight">\(\left\{\mathbf A^{(1)}, \mathbf A^{(2)}\right\}\)</span> is homogeneous, but the collections <span class="math notranslate nohighlight">\(\left\{\mathbf A^{(1)}, \mathbf A^{(3)}\right\}\)</span> and <span class="math notranslate nohighlight">\(\left\{\mathbf A^{(2)}, \mathbf A^{(3)}\right\}\)</span> are not homogeneous.</p>
<p>So, unfortunately, we cannot represent our email example using the JRDPG, because the JRDPG cannot handle the hetereogeneity between the random networks of Monday and Tuesday with the random network for Wednesday.</p>
</div>
<div class="section" id="the-inhomogeous-erdos-renyi-random-network">
<h3><span class="section-number">5.6.1.2. </span>The Inhomogeous Erdos-Renyi Random Network<a class="headerlink" href="#the-inhomogeous-erdos-renyi-random-network" title="Permalink to this headline">¶</a></h3>
<p>To remove this restrictive homogeneity property of the JRDPG, we will need a new single network model, called the Inhomogeneous Erdos-Renyi (IER) random network model. The way we can think of the <span class="math notranslate nohighlight">\(IER\)</span> random network is that a probability matrix <span class="math notranslate nohighlight">\(P\)</span> with <span class="math notranslate nohighlight">\(n\)</span> rows and <span class="math notranslate nohighlight">\(n\)</span> columns defines each of the edge-existence probabilities for pairs of nodes in the network. For each pair of nodes <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>, we have a unique coin which has a <span class="math notranslate nohighlight">\(p_{ij}\)</span> chance of landing on heads, and a <span class="math notranslate nohighlight">\(1 - p_{ij}\)</span> chance of laanding on tails. If the coin laands on heads, the edge between nodes <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> exists, and if the coin lands on tails, the edge between nodes <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> does not exist. This coin flip is performed independent of the coin flips for all of the other edges. If <span class="math notranslate nohighlight">\(\mathbf A\)</span> is a random network which is <span class="math notranslate nohighlight">\(IER\)</span> with a probability matrix <span class="math notranslate nohighlight">\(P\)</span>, we say that <span class="math notranslate nohighlight">\(\mathbf A\)</span> is an <span class="math notranslate nohighlight">\(IER_n(P)\)</span> random network.</p>
<p>As before, we can develop a procedure to produce for us a network <span class="math notranslate nohighlight">\(A\)</span>, which has nodes and edges, where the underlying random network <span class="math notranslate nohighlight">\(\mathbf A\)</span> is an <span class="math notranslate nohighlight">\(IER_n(P)\)</span> random network:</p>
<div class="admonition-simulating-a-realization-from-an-ier-n-p-random-network admonition">
<p class="admonition-title">Simulating a realization from an <span class="math notranslate nohighlight">\(IER_n(P)\)</span> random network</p>
<ol class="simple">
<li><p>Determine a probability matrix <span class="math notranslate nohighlight">\(P\)</span>, whose entries <span class="math notranslate nohighlight">\(p_{ij}\)</span> are probabilities.</p></li>
<li><p>For each pair of nodes <span class="math notranslate nohighlight">\(i\)</span> an <span class="math notranslate nohighlight">\(j\)</span>:</p>
<ul class="simple">
<li><p>Obtain a weighted coin <span class="math notranslate nohighlight">\((i,j)\)</span> which has a probability <span class="math notranslate nohighlight">\(p_{ij}\)</span> of landing on heads, and a <span class="math notranslate nohighlight">\(1 - p_{ij}\)</span> probability of landing on tails.</p></li>
<li><p>Flip the <span class="math notranslate nohighlight">\((i,j)\)</span> coin, andd if it lands on heads, the corresponding entry <span class="math notranslate nohighlight">\(a_{ij}\)</span> in the adjacency matrix is <span class="math notranslate nohighlight">\(1\)</span>. If the coin lands on tails, the corresponding entry <span class="math notranslate nohighlight">\(a_{ij}\)</span> is <span class="math notranslate nohighlight">\(0\)</span>.</p></li>
</ul>
</li>
<li><p>The adjacency matrix we produce, <span class="math notranslate nohighlight">\(A\)</span>, is a realization of an <span class="math notranslate nohighlight">\(IER_n(P)\)</span> random network.</p></li>
</ol>
</div>
<p>It is important to realize that all of the networks we have described so far are also <span class="math notranslate nohighlight">\(IER_n(P)\)</span> random networks. The previous single network models we have described to date simply place restrictions on the way in which we acquire <span class="math notranslate nohighlight">\(P\)</span>. For instance, in an <span class="math notranslate nohighlight">\(ER_n(p)\)</span> random network, all entries <span class="math notranslate nohighlight">\(p_{ij}\)</span> of <span class="math notranslate nohighlight">\(P\)</span> are equal to <span class="math notranslate nohighlight">\(p\)</span>.</p>
</div>
</div>
<div class="section" id="common-subspace-independent-edge-cosie-model">
<h2><span class="section-number">5.6.2. </span>Common Subspace Independent Edge (COSIE) Model<a class="headerlink" href="#common-subspace-independent-edge-cosie-model" title="Permalink to this headline">¶</a></h2>
<p>Unlike the JRDPG model, the Common Subspace Independent Edge (COSIE) model allows for heterogeneity amongst the the <span class="math notranslate nohighlight">\(N\)</span> random networks. A <strong>heterogeneous</strong> collection of random networks is a collection of networks <span class="math notranslate nohighlight">\(\left\{\mathbf A^{(1)}, ..., \mathbf A^{(N)}\right\}\)</span> is a collection of random networks in which the <span class="math notranslate nohighlight">\(N\)</span> networks do not have the same marginal distribution.</p>
<div class="section" id="the-cosie-model-is-defined-by-a-collection-of-score-matrices-and-a-shared-low-rank-subspace">
<h3><span class="section-number">5.6.2.1. </span>The COSIE Model is defined by a collection of score matrices and a shared low-rank subspace<a class="headerlink" href="#the-cosie-model-is-defined-by-a-collection-of-score-matrices-and-a-shared-low-rank-subspace" title="Permalink to this headline">¶</a></h3>
<p>For the RDPG, remember that we used the latent position matrix <span class="math notranslate nohighlight">\(X\)</span> to define the edge-existence probabilities within the network. Let’s imagine that the random network <span class="math notranslate nohighlight">\(\mathbf A\)</span> is <span class="math notranslate nohighlight">\(RDPG_n(X)\)</span>, where <span class="math notranslate nohighlight">\(X\)</span> is the latent position matrix. We used the probability matrix, <span class="math notranslate nohighlight">\(P\)</span>, where <span class="math notranslate nohighlight">\(P\)</span> could be defined where <span class="math notranslate nohighlight">\(P=XX^\top\)</span>. The edge existence probability <span class="math notranslate nohighlight">\(p_{ij}\)</span> between a pair of nodes <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> was the inner product <span class="math notranslate nohighlight">\(\vec x_i^\top \vec x_j\)</span> of the <span class="math notranslate nohighlight">\(i^{th}\)</span> row and the <span class="math notranslate nohighlight">\(j^{th}\)</span> row of the latent position matrix <span class="math notranslate nohighlight">\(X\)</span>. Stated another way, we thought of the edge between a pair of nodes <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> being represented by a coin flip, where the coin had a <span class="math notranslate nohighlight">\(\vec x_i^\top \vec x_j\)</span> chance of landing on heads. If the coin lands on heads, an edge exists, and if the coin does not land on heads (with a <span class="math notranslate nohighlight">\(1 - \vec x_i^\top \vec x_j\)</span> chance of happening) the edge does not exist. We will use a similar intuition to describe the COSIE model.</p>
<p>Here, we will use a matrix <span class="math notranslate nohighlight">\(V\)</span>, which is largely similar in intuition to the latent position matrix <span class="math notranslate nohighlight">\(X\)</span>. The matrix <span class="math notranslate nohighlight">\(V\)</span> will have <span class="math notranslate nohighlight">\(n\)</span> rows (the number of <em>nodes</em> in each of the <span class="math notranslate nohighlight">\(N\)</span> networks) and <span class="math notranslate nohighlight">\(d\)</span> columns. Like for the RDPG, <span class="math notranslate nohighlight">\(d\)</span> will again refer to the latent dimensionality of the collection of random networks. The matrix <span class="math notranslate nohighlight">\(V\)</span> has the special property that the <span class="math notranslate nohighlight">\(d\)</span> columns of <span class="math notranslate nohighlight">\(V\)</span> are <strong>orthonormal</strong>. The matrix <span class="math notranslate nohighlight">\(V\)</span> looks like this:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    V &amp;= \begin{bmatrix}
        \top &amp; \top &amp; &amp; \top \\
        \vec v_1 &amp; \vec v_2 &amp; ... &amp; \vec v_d \\
        \perp &amp; \perp &amp; &amp; \perp
    \end{bmatrix}
\end{align*}\]</div>
<p>That <span class="math notranslate nohighlight">\(V\)</span> is orthonormal means that, for any column <span class="math notranslate nohighlight">\(k\)</span> of the <span class="math notranslate nohighlight">\(d\)</span> total columns, that <span class="math notranslate nohighlight">\(v_k ^\top v_k = 1\)</span>, and for any pair of columns <span class="math notranslate nohighlight">\(k\)</span> and <span class="math notranslate nohighlight">\(l\)</span> where <span class="math notranslate nohighlight">\(k \neq l\)</span>, then <span class="math notranslate nohighlight">\(v_k^\top v_l = 0\)</span>.</p>
<p>For the COSIE model, we also have a collection of score matrices, <span class="math notranslate nohighlight">\(\left\{R^{(1)}, ..., R^{(N)}\right\}\)</span>. Each score matrix <span class="math notranslate nohighlight">\(R^{(m)}\)</span> is a matrix with <span class="math notranslate nohighlight">\(d\)</span> columns and <span class="math notranslate nohighlight">\(d\)</span> rows which is symmetric. That <span class="math notranslate nohighlight">\(R^{(m)}\)</span> is symmetric means that for any two latent dimensions <span class="math notranslate nohighlight">\(k\)</span> and <span class="math notranslate nohighlight">\(l\)</span>, that <span class="math notranslate nohighlight">\(R^{(m)}_{kl} = R^{(m)}_{lk}\)</span>. the matrix <span class="math notranslate nohighlight">\(R^{(m)}\)</span> looks like this:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    R^{(m)} &amp;= \begin{bmatrix}
        r_{11}^{(m)} &amp; ... &amp; r_{1d}^{(m)} \\
        \vdots &amp; \ddots &amp; \vdots \\
        r_{d1}^{(m)} &amp; ... &amp; r_{dd}^{(m)}
    \end{bmatrix}
\end{align*}\]</div>
<p>The way we can think about the COSIE model is that for each random network <span class="math notranslate nohighlight">\(m\)</span> of our <span class="math notranslate nohighlight">\(N\)</span> total networks, the edges in the <span class="math notranslate nohighlight">\(m^{th}\)</span> network depend on the orthonormal matrix <span class="math notranslate nohighlight">\(V\)</span> and the score matrix <span class="math notranslate nohighlight">\(R^{(m)}\)</span>. The probability matrix <span class="math notranslate nohighlight">\(P^{(m)}\)</span> for the <span class="math notranslate nohighlight">\(m^{th}\)</span> random network is defined so that <span class="math notranslate nohighlight">\(P^{(m)} = VR^{(m)}V^\top\)</span>. This means that each entry <span class="math notranslate nohighlight">\(p_{ij}^{(m)} = \vec v_i^\top R^{(m)} \vec v_j\)</span>. We say that a collection of random networks <span class="math notranslate nohighlight">\(\left\{\mathbf A^{(1)}, ..., \mathbf A^{(N)}\right\}\)</span> with <span class="math notranslate nohighlight">\(n\)</span> nodes is <span class="math notranslate nohighlight">\(COSIE_n\left(V, \left\{R^{(1)},...,R^{(N)}\right\}\right)\)</span> if each random network <span class="math notranslate nohighlight">\(\mathbf A^{(m)}\)</span> is <span class="math notranslate nohighlight">\(IER(P^{(m)})\)</span>. Stated another way, each of the <span class="math notranslate nohighlight">\(N\)</span> random networks share the same orthonormal matrix <span class="math notranslate nohighlight">\(V\)</span>, but a unique score matrix <span class="math notranslate nohighlight">\(R^{(m)}\)</span>. This allows the random networks to share some underlying structure (which is conveyed by <span class="math notranslate nohighlight">\(V\)</span>) but each random network still has a combination of this shared structure (conveyed by <span class="math notranslate nohighlight">\(R^{(m)}\)</span>).</p>
</div>
<div class="section" id="using-the-cosie-model-for-emails">
<h3><span class="section-number">5.6.2.2. </span>Using the COSIE Model for Emails<a class="headerlink" href="#using-the-cosie-model-for-emails" title="Permalink to this headline">¶</a></h3>
<p>We will circle back to our email example yet again. Remember that with the <span class="math notranslate nohighlight">\(JRDPG_n(X)\)</span> model, we were able to capture the homogeneity of the email networks on Monday and Tuesday, but we could not capture the heterogeneity of the email nework on Wednesday. We wanted a model which allowed us to capture this heterogeneity, because even though the underlying random variables do not have the same distribution, there is still some degree of shared structure (the employee working teams were the same across all three days). For this reason, we turn to the COSIE model. We begin by showing the shared latent positions <span class="math notranslate nohighlight">\(V\)</span> for the COSIE model:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.embed</span> <span class="kn">import</span> <span class="n">MultipleASE</span> <span class="k">as</span> <span class="n">MASE</span>

<span class="n">embedder</span> <span class="o">=</span> <span class="n">MASE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">V</span> <span class="o">=</span> <span class="n">embedder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">([</span><span class="n">P1</span><span class="p">,</span> <span class="n">P2</span><span class="p">,</span> <span class="n">P3</span><span class="p">])</span>

<span class="n">plot_latent</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">nodetix</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="mi">34</span><span class="p">,</span><span class="mi">44</span><span class="p">],</span> <span class="n">nodelabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;25&quot;</span><span class="p">,</span> <span class="s2">&quot;35&quot;</span><span class="p">,</span> <span class="s2">&quot;45&quot;</span><span class="p">],</span>
            <span class="n">dimtix</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">],</span> <span class="n">dimlabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;2&quot;</span><span class="p">,</span> <span class="s2">&quot;3&quot;</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$V$, Shared Latent Positions&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/multi-network-models_8_0.png" src="../../_images/multi-network-models_8_0.png" />
</div>
</div>
<p>Next, we look at the score matrices <span class="math notranslate nohighlight">\(S^{(m)}\)</span> for each of the random networks:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">blockname</span><span class="o">=</span><span class="s2">&quot;Employee Group&quot;</span><span class="p">,</span> <span class="n">blocktix</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">],</span>
               <span class="n">blocklabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;ML&quot;</span><span class="p">,</span> <span class="s2">&quot;Adm.&quot;</span><span class="p">,</span> <span class="s2">&quot;Mark.&quot;</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    
    <span class="k">with</span> <span class="n">sns</span><span class="o">.</span><span class="n">plotting_context</span><span class="p">(</span><span class="s2">&quot;talk&quot;</span><span class="p">,</span> <span class="n">font_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Purples&quot;</span><span class="p">,</span>
                        <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">cbar_kws</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">shrink</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        <span class="n">cbar</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">collections</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="n">blockname</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="n">blockname</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">blocktix</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">blocklabs</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">blocktix</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">blocklabs</span><span class="p">)</span>
        <span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">set_frame_on</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span>

<span class="n">vmin</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">embedder</span><span class="o">.</span><span class="n">scores_</span><span class="p">);</span> <span class="n">vmax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">embedder</span><span class="o">.</span><span class="n">scores_</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">R1</span> <span class="o">=</span> <span class="n">embedder</span><span class="o">.</span><span class="n">scores_</span><span class="p">[</span><span class="mi">0</span><span class="p">,:,:]</span>
<span class="n">R2</span> <span class="o">=</span> <span class="n">embedder</span><span class="o">.</span><span class="n">scores_</span><span class="p">[</span><span class="mi">1</span><span class="p">,:,:]</span>
<span class="n">R3</span> <span class="o">=</span> <span class="n">embedder</span><span class="o">.</span><span class="n">scores_</span><span class="p">[</span><span class="mi">2</span><span class="p">,:,:]</span>

<span class="n">plot_score</span><span class="p">(</span><span class="n">R1</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$R^{(1)}$ Monday Scores&quot;</span><span class="p">)</span>
<span class="n">plot_score</span><span class="p">(</span><span class="n">R2</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$R^{(2)}$ Tuesday Scores&quot;</span><span class="p">)</span>
<span class="n">plot_score</span><span class="p">(</span><span class="n">R3</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$R^{(3)}$ Wednesday Scores&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/multi-network-models_10_0.png" src="../../_images/multi-network-models_10_0.png" />
</div>
</div>
<p>As we can see, the COSIE model was able to capture the heterogeneity from Monday and Tuesday to Wednesday through a unique score matrix for Wednesday, whereas Monday and Tuesday (which are homogeneous) have the same score matrix.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./representations/ch5"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="single-network-models_RDPG.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title"><span class="section-number">5.5. </span>Random Dot Product Graphs (RDPG)</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="models-with-covariates.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title"><span class="section-number">5.7. </span>Network Models with Covariates</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Joshua Vogelstein, Alex Loftus, and Eric Bridgeford<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>