
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>6.5. Random walk and diffusion-based methods &#8212; Hands-on Network Machine Learning with Scikit-Learn and Graspologic</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >let toggleHintShow = 'Click to show';</script>
    <script >let toggleHintHide = 'Click to hide';</script>
    <script >let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script >const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="6.6. Graph Neural Networks" href="graph-neural-networks.html" />
    <link rel="prev" title="6.4. Estimating Parameters for the RDPG" href="estimating-parameters_spectral.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Hands-on Network Machine Learning with Scikit-Learn and Graspologic</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../coverpage.html">
   Hands-on Network Machine Learning with Scikit-Learn and Graspologic
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/terminology.html">
   Terminology and Math Refresher
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch1/ch1.html">
   1. The Network Machine Learning Landscape
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/what-is-a-network.html">
     1.1. What Is A Network?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/why-study-networks.html">
     1.2. Why Study Networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/examples-of-applications.html">
     1.3. Examples of applications
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/types-of-learning-probs.html">
     1.4. Approaches for Network Learning Problems
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch2/ch2.html">
   2. End-to-end Biology Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/big-picture.html">
     2.1. Look at the big picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/get-the-data.html">
     2.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/prepare-the-data.html">
     2.3. Prepare the Data for Network Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/discover-and-visualize.html">
     2.4. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch3/ch3.html">
   3. End-to-end Business Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/big-picture.html">
     3.1. Look at the Big Picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/get-the-data.html">
     3.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/discover-and-visualize.html">
     3.3. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/prepare-the-data.html">
     3.4. Prepare the Data for Network Algorithms
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Representations
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch4/ch4.html">
   4. Properties of Networks as a Statistical Object
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/matrix-representations.html">
     4.1. Matrix Representations Of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/network-representations.html">
     4.2. Representations of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/properties-of-networks.html">
     4.3. Properties of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/regularization.html">
     4.4. Regularization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch5/ch5.html">
   5. Why Use Statistical Models?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/why-use-models.html">
     5.1. Why Use Statistical Models?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/single-network-models_ER.html">
     5.2. Erdös-Rényi (ER) Random Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/single-network-models_SBM.html">
     5.3. Stochastic Block Models (SBM)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/single-network-models_RDPG.html">
     5.4. Random Dot Product Graphs (RDPG)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/multi-network-models.html">
     5.5. Multiple Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/models-with-covariates.html">
     5.6. Network Models with Covariates
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="ch6.html">
   6. Learning Network Representations
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="estimating-parameters_mle.html">
     6.1. Estimating Parameters in Network Models via MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="why-embed-networks.html">
     6.2. Why embed networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="spectral-embedding.html">
     6.3. Spectral Embedding Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="estimating-parameters_spectral.html">
     6.4. Estimating Parameters for the RDPG
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     6.5. Random walk and diffusion-based methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="graph-neural-networks.html">
     6.6. Graph Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="multigraph-representation-learning.html">
     6.7. Multiple-Network Representation Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="joint-representation-learning.html">
     6.8. Joint Representation Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="estimating-parameters_theory.html">
     6.9. Model Estimation Theory
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch7/ch7.html">
   7. Theoretical Results
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/theory-single-network.html">
     7.1. Theory for Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/theory-multigraph.html">
     7.2. Maximum Likelihood Estimate Theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/theory-matching.html">
     7.3. Spectral Method Theory
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch8/ch8.html">
   8. Applications When You Have One Network
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/community-detection.html">
     8.1. Community Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/testing-differences.html">
     8.2. Testing for Differences between Groups of Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/model-selection.html">
     8.3. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/single-vertex-nomination.html">
     8.4. Single-Network Vertex Nomination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/out-of-sample.html">
     8.5. Out-of-sample Embedding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch9/ch9.html">
   9. Applications for Two Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/two-sample-hypothesis.html">
     9.1. Two-Sample Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/significant-communities.html">
     9.2. Differences in Block Matrices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/graph-matching-vertex.html">
     9.3. Graph Matching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/multiple-vertex-nomination.html">
     9.4. Vertex Nomination For Multiple Networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch10/ch10.html">
   10. Applications for Many Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch10/anomaly-detection.html">
     10.1. Anomaly Detection For Timeseries of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch10/significant-edges.html">
     10.2. Testing for Significant Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch10/significant-vertices.html">
     10.3. Testing for Significant Vertices
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://graspologic.readthedocs.io/en/latest/">
   Graspologic Documentation
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/representations/ch6/random-walk-diffusion-methods.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/neurodata/graph-stats-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/neurodata/graph-stats-book/issues/new?title=Issue%20on%20page%20%2Frepresentations/ch6/random-walk-diffusion-methods.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/neurodata/graph-stats-book/edit/master/network_machine_learning_in_python/representations/ch6/random-walk-diffusion-methods.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-simplified-first-order-random-walk-on-a-network">
   6.5.1. A simplified first-order random walk on a network
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#markov-chains-and-the-markov-property">
     6.5.1.1. Markov chains and the markov property
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#first-order-random-walks-on-a-network-as-a-markov-chain">
       6.5.1.1.1. First-order random walks on a network as a markov chain
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-do-markov-chains-and-random-walks-have-to-do-with-embedding-networks">
   6.5.2. What do markov chains and random walks have to do with embedding networks?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#second-order-biased-random-walk">
     6.5.2.1. Second-order biased random walk
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-bias-factor-lets-us-control-our-ability-to-leave-or-remain-amongst-a-neighborhood-of-nodes">
       6.5.2.1.1. The bias factor lets us control our ability to
       <em>
        leave
       </em>
       or
       <em>
        remain
       </em>
       amongst a neighborhood of nodes
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#adjusting-the-transition-probabilities-with-the-bias-vector">
       6.5.2.1.2. Adjusting the transition probabilities with the bias vector
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#node2vec">
   6.5.3. node2vec
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#extending-to-weighted-networks">
   6.5.4. Extending to weighted networks
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Random walk and diffusion-based methods</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-simplified-first-order-random-walk-on-a-network">
   6.5.1. A simplified first-order random walk on a network
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#markov-chains-and-the-markov-property">
     6.5.1.1. Markov chains and the markov property
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#first-order-random-walks-on-a-network-as-a-markov-chain">
       6.5.1.1.1. First-order random walks on a network as a markov chain
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-do-markov-chains-and-random-walks-have-to-do-with-embedding-networks">
   6.5.2. What do markov chains and random walks have to do with embedding networks?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#second-order-biased-random-walk">
     6.5.2.1. Second-order biased random walk
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-bias-factor-lets-us-control-our-ability-to-leave-or-remain-amongst-a-neighborhood-of-nodes">
       6.5.2.1.1. The bias factor lets us control our ability to
       <em>
        leave
       </em>
       or
       <em>
        remain
       </em>
       amongst a neighborhood of nodes
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#adjusting-the-transition-probabilities-with-the-bias-vector">
       6.5.2.1.2. Adjusting the transition probabilities with the bias vector
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#node2vec">
   6.5.3. node2vec
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#extending-to-weighted-networks">
   6.5.4. Extending to weighted networks
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="random-walk-and-diffusion-based-methods">
<h1><span class="section-number">6.5. </span>Random walk and diffusion-based methods<a class="headerlink" href="#random-walk-and-diffusion-based-methods" title="Permalink to this headline">¶</a></h1>
<p>Although this book puts a heavy emphasis on spectral methods, there are many ways in which you can learn lower-dimensional representations for networks which don’t involve spectral approaches. As opposed to spectral methods, a <strong>random walk on a network</strong> is a random process which focuses on the analysis of paths which start at a node in the network, and proceed to generate successions of random steps to other nodes in the network. The manner in which these random processes materialize is a function of the topology of the random network, including the nodes, edges, and (optionally, if the network is weighted), the edge weights.</p>
<div class="section" id="a-simplified-first-order-random-walk-on-a-network">
<h2><span class="section-number">6.5.1. </span>A simplified first-order random walk on a network<a class="headerlink" href="#a-simplified-first-order-random-walk-on-a-network" title="Permalink to this headline">¶</a></h2>
<p>For instance, let’s consider an extremely simplified approach for a first-order random walk on the network that you saw back in <a class="reference external" href="#link?">Chapter 4</a>, which was our New York example. To begin, let’s redefine the nodes and edges of the network. The nodes of the network are the five boroughs of New York City (Staten Island SI, Brooklyn BK, Queens Q, the Bronx BX, and Manhattan MH). The nodes in your network are the five boroughs. The edges <span class="math notranslate nohighlight">\((i,j)\)</span> of your network exist if one can travel from borough <span class="math notranslate nohighlight">\(i\)</span> to borough <span class="math notranslate nohighlight">\(j\)</span> along a bridge.</p>
<p>Below, you will look at a map of New York City, with the bridges connecting the different boroughs. In the middle, you look at this map as a network layout plot. The arrows indicate the direction of travel. On the right, you look at this map as an adjacency matrix:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># define the node names</span>
<span class="n">node_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;SI&quot;</span><span class="p">,</span> <span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="s2">&quot;BK&quot;</span><span class="p">,</span> <span class="s2">&quot;Q&quot;</span><span class="p">,</span> <span class="s2">&quot;BX&quot;</span><span class="p">]</span>
<span class="c1"># define the adjacency matrix</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>  <span class="c1"># staten island is neighbors of brooklyn</span>
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>  <span class="c1"># manhattan is neighbors of all but staten island</span>
              <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>  <span class="c1"># brooklyn is neighbors of staten island and manhattan</span>
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>  <span class="c1"># queens is neighbors of manhattan and bronx</span>
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]])</span> <span class="c1"># bronx is neighbors of manhattan and queens</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.image</span> <span class="k">as</span> <span class="nn">mpimg</span>
<span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">heatmap</span>

<span class="n">img</span> <span class="o">=</span> <span class="n">mpimg</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;../ch4/img/newyork.png&#39;</span><span class="p">)</span>

<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">()</span>

<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;SI&quot;</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;BK&quot;</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;Q&quot;</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;BX&quot;</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>

<span class="n">pos</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">get_node_attributes</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="s1">&#39;pos&#39;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;SI&quot;</span><span class="p">,</span> <span class="s2">&quot;BK&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="s2">&quot;BK&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="s2">&quot;Q&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="s2">&quot;BX&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;Q&quot;</span><span class="p">,</span> <span class="s2">&quot;BX&quot;</span><span class="p">)</span>

<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;BK&quot;</span><span class="p">,</span> <span class="s2">&quot;SI&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;BK&quot;</span><span class="p">,</span> <span class="s2">&quot;MH&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;Q&quot;</span><span class="p">,</span> <span class="s2">&quot;MH&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;BX&quot;</span><span class="p">,</span> <span class="s2">&quot;MH&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;BX&quot;</span><span class="p">,</span> <span class="s2">&quot;Q&quot;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">23</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.8</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Map of New York City Boroughs and Connections&quot;</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span>
        <span class="n">font_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s2">&quot;whitesmoke&quot;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Layout Plot of New York City Boroughs and Connections&quot;</span><span class="p">)</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">xticklabels</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">4.5</span><span class="p">],</span> <span class="n">yticklabels</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">4.5</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Adjacency Matrix of New York City Boroughs and Connections&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">node_names</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">node_names</span><span class="p">)</span>
<span class="n">fig</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/random-walk-diffusion-methods_3_0.png" src="../../_images/random-walk-diffusion-methods_3_0.png" />
</div>
</div>
<p>You are staying at a hotel which is located in Manhattan, and you decide that you are going to explore the city as follows. When you are in a given borough <span class="math notranslate nohighlight">\(i\)</span>, you will determine the next borough you will explore by letting random chance do the work for you. To better define a first-order random walk, we need to introduce a background concept first: the Markov chain and the Markov property.</p>
<div class="section" id="markov-chains-and-the-markov-property">
<h3><span class="section-number">6.5.1.1. </span>Markov chains and the markov property<a class="headerlink" href="#markov-chains-and-the-markov-property" title="Permalink to this headline">¶</a></h3>
<p>A <strong>finite-space markov chain</strong> is a model of a random system in which we have a sequence of possible events which can occur which are <em>finite</em> (the boroughs we will visit on a day <span class="math notranslate nohighlight">\(t\)</span>) in which the probability of each event depends <em>only</em> on the event in which you were previously. For network analysis, we only need to think about <em>finite-space</em> Markov chains, because the network has a <em>finite</em> collection of possible events which can occur (the nodes in the network being visited). To put this down quantitatively, the markov chain is represented by the sequence <span class="math notranslate nohighlight">\(\mathbf s_0, \mathbf s_1, \mathbf s_2, ...\)</span>, where each <span class="math notranslate nohighlight">\(\mathbf s_t\)</span> takes the value of one of the <span class="math notranslate nohighlight">\(n\)</span> total nodes in the network.</p>
<p>You will notice that in our definition of the finite-space markov chain, we made a disclaimer: the probability of each event depends <em>only</em> on the state in which we were previously. This is called the <strong>markov property</strong>. The idea is that, if we were in Manhattan at the previous step in time <span class="math notranslate nohighlight">\(t - 1\)</span> (e.g., <span class="math notranslate nohighlight">\(\mathbf s_{t-1}\)</span> realized the value <span class="math notranslate nohighlight">\(v_{MH}\)</span>, or <span class="math notranslate nohighlight">\(\mathbf s_{t-1} = v_{MH}\)</span> for short), that if our current step in the Markov Chain were Brooklyn (<span class="math notranslate nohighlight">\(\mathbf s_t = v_{BK}\)</span>), that the next step in the Markov chain would not depend <em>at all</em> on the fact that we already saw Manhattan.</p>
<div class="section" id="first-order-random-walks-on-a-network-as-a-markov-chain">
<h4><span class="section-number">6.5.1.1.1. </span>First-order random walks on a network as a markov chain<a class="headerlink" href="#first-order-random-walks-on-a-network-as-a-markov-chain" title="Permalink to this headline">¶</a></h4>
<p>To exhibit the ideas of a markov chain, we’ll define a first-order random walk on your New York Boroughs. Remember that the borough you are at, <span class="math notranslate nohighlight">\(i\)</span>, has <span class="math notranslate nohighlight">\(d_i\)</span> possible neighboring boroughs, where <span class="math notranslate nohighlight">\(d_i\)</span> was the <em>degree</em> of node <span class="math notranslate nohighlight">\(i\)</span>. You will visit one of the other nodes in the network as follows. If borough <span class="math notranslate nohighlight">\(j\)</span> is a neighbor of borough <span class="math notranslate nohighlight">\(i\)</span> (an edge exists from borough <span class="math notranslate nohighlight">\(i\)</span> to borough <span class="math notranslate nohighlight">\(j\)</span>), you will visit borough <span class="math notranslate nohighlight">\(j\)</span> with probability <span class="math notranslate nohighlight">\(\frac{1}{d_i}\)</span>. The idea is that you will visit neighbors of each borough at random, depending only on whether you can get to that borough along an edge of the network. This is called a <strong>first-order random walk</strong> because it is a random walk where you <em>ignore</em> everything about the path you have taken to get to your current <em>borough</em> to date, except for the fact that you are at that borough <em>now</em>. This means that your next borough will not depend <em>at all</em> on whether you have already been to that borough in your exploration of the city. If the node is not a neighbor of your current borough, you will visit it with probability <span class="math notranslate nohighlight">\(0\)</span>. Stated another way, if you are in node <span class="math notranslate nohighlight">\(i\)</span>, the probability of going to another node <span class="math notranslate nohighlight">\(j\)</span> is defined as:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    p_{ij} &amp;= \begin{cases}
        \frac{1}{d_i}  &amp; \text{edge $(i,j)$ exists} \\
        0  &amp; \text{edge $(i,j)$ does not exist}
    \end{cases}
\end{align*}\]</div>
<p>Note that these probabilities, called the <strong>transition probability</strong> from node <span class="math notranslate nohighlight">\(i\)</span> to node <span class="math notranslate nohighlight">\(j\)</span>, do not have <em>anything</em> to do with which nodes we have visited yet, and these transition probabilities are <em>always the same</em>! For this reason, they are often organized into a matrix, called the <strong>transition probability matrix</strong> <span class="math notranslate nohighlight">\(P\)</span>. In this case, the transition probability matrix looks like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute the degree of each node</span>
<span class="n">di</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># the probability matrix is the adjacency divided by</span>
<span class="c1"># degree of the starting node</span>
<span class="n">P</span> <span class="o">=</span> <span class="p">(</span><span class="n">A</span> <span class="o">/</span> <span class="n">di</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span>
        <span class="n">font_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s2">&quot;whitesmoke&quot;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Layout Plot of New York City Boroughs and Connections&quot;</span><span class="p">)</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">xticklabels</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">4.5</span><span class="p">],</span> <span class="n">yticklabels</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">4.5</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Transition probability matrix $P$ for New York Random Walk&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s2">&quot;SI&quot;</span><span class="p">,</span> <span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="s2">&quot;BK&quot;</span><span class="p">,</span> <span class="s2">&quot;Q&quot;</span><span class="p">,</span> <span class="s2">&quot;BX&quot;</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([</span><span class="s2">&quot;SI&quot;</span><span class="p">,</span> <span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="s2">&quot;BK&quot;</span><span class="p">,</span> <span class="s2">&quot;Q&quot;</span><span class="p">,</span> <span class="s2">&quot;BX&quot;</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Starting borough $i$&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Next borough $j$&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/random-walk-diffusion-methods_6_0.png" src="../../_images/random-walk-diffusion-methods_6_0.png" />
</div>
</div>
<p>To understand this transition probability matrix, let’s think about the individual rows. Notice that if you are in Staten Island, there is only one borough you can go from here, so with probability <span class="math notranslate nohighlight">\(1\)</span>, you will visit its only neighbor: Brooklyn. If you are in Manhattan, you could go to any of its three neighbors (Brooklyn, Queens, or Bronx), with equal probability <span class="math notranslate nohighlight">\(\frac{1}{3}\)</span>. If you were in Brooklyn, you could visit any of its two neighbors (Manhattan or Staten Island) with equal probability <span class="math notranslate nohighlight">\(\frac{1}{2}\)</span>. This continues for each node in the network until you have successfully generated the transition probability matrix <span class="math notranslate nohighlight">\(P\)</span>.</p>
<p>There are a lot of interesting properties you can use the transition probability matrix <span class="math notranslate nohighlight">\(P\)</span> to learn about, but we won’t cover them all here. If you want some more details on transition probability matrices and Markov chains in general, we would recommend that you check out a book on stochastic processes, such as the author’s favorite by Dean Isaacson, called <a class="reference external" href="https://www.amazon.com/dp/0471428620?tag=uuid10-20">Markov Chains: Theory and Applications</a>.</p>
<p>Next, let’s use this transition probability matrix to generate a random walk on the New York City boroughs. As we mentioned, your hotel is in Manhattan, so you are going to start your random walk through the city here. In other words, <span class="math notranslate nohighlight">\(\mathbf s_0 = v_{MH}\)</span>. For your next step in the Markov chain, you will visit either Brooklyn, Bronx, or Queens with probability <span class="math notranslate nohighlight">\(\frac{1}{3}\)</span>, or Staten Island with probability <span class="math notranslate nohighlight">\(0\)</span>. In the following figure, we show the place you start out at, Manhattan, in blue, and the other nodes in gray:</p>
<p>You can visit each of the neighboring nodes, shown in the next plot with green, and the probabilities of visiting each of these nodes are correspondingly highlighted in the transition probability matrix with a green block:</p>
<p>You then choose the next node to visit, using these transition probabilities, by generating the probability vector of the <em>next step</em> in the random walk <em>given the current step</em>. We will denote this probability vector with the symbol <span class="math notranslate nohighlight">\(\vec p^{(t+1)}_i\)</span>, which is the probability vector for which node you will visit at the next step <span class="math notranslate nohighlight">\(t+1\)</span> given that you are currently at node <span class="math notranslate nohighlight">\(i\)</span>. Notice that this is just the entries of the <span class="math notranslate nohighlight">\(i^{th}\)</span> row of the transition probability matrix, which can be calculated using the relationship:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \vec p^{(t+1)}_i &amp;= P^\top \vec x^{(i)}
\end{align*}\]</div>
<p>where <span class="math notranslate nohighlight">\(\vec x^{(i)}\)</span> is the vector which has a value of <span class="math notranslate nohighlight">\(0\)</span> for all entries except for entry <span class="math notranslate nohighlight">\(i\)</span>, where it has a value of <span class="math notranslate nohighlight">\(1\)</span>. This ends up <em>pulling out</em> the <span class="math notranslate nohighlight">\(i^{th}\)</span> row of <span class="math notranslate nohighlight">\(P\)</span>, because every multiplication except for those against the <span class="math notranslate nohighlight">\(i^{th}\)</span> column of <span class="math notranslate nohighlight">\(P^\top\)</span> (which is the <span class="math notranslate nohighlight">\(i^{th}\)</span> row of <span class="math notranslate nohighlight">\(P\)</span>, by definition of a transpose) will end up just being <span class="math notranslate nohighlight">\(0\)</span>! We can see this with the following detailed exploration:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \vec p^{(t+1)}_i &amp;= \begin{bmatrix}
    p_{11} &amp; ... &amp; p_{1n} \\
    \vdots &amp; \ddots &amp; \vdots \\
    p_{n1} &amp; ... &amp; p_{nn}
    \end{bmatrix}^\top\vec x^{(i)} \\
     &amp;= \begin{bmatrix}
    p_{11} &amp; ... &amp; p_{n1} \\
    \vdots &amp; \ddots &amp; \vdots \\
    p_{1n} &amp; ... &amp; p_{nn}
    \end{bmatrix}^\top\vec x^{(i)},\;\;\;\text{in this step, we just transposed $P$} \\
    &amp;= \begin{bmatrix}
        p_{11}x_{1}^{(i)} + p_{21} x_2^{(i)} + ... p_{n1}x_n^{(i)} \\
        \vdots \\
        p_{1n}x_{1}^{(i)} + p_{2n} x_2^{(i)} + ... p_{nn}x_n^{(i)} 
    \end{bmatrix} \\
    &amp;= \begin{bmatrix}
        p_{i1} \\
        \vdots \\
        p_{in}
    \end{bmatrix}
\end{align*}\]</div>
<p>where the last step in the multiplication is because <span class="math notranslate nohighlight">\(x_{i}^{(i)}\)</span> is the only entry which has a value of <span class="math notranslate nohighlight">\(1\)</span>, so all of the other multipilications are just <span class="math notranslate nohighlight">\(0\)</span>. We can pick the next node easily by just using <code class="docutils literal notranslate"><span class="pre">numpy</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xMH</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># x vector indicating we start at MH</span>
<span class="n">p_1_startat_MH</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">xMH</span>  <span class="c1"># p vector for timestep 1 starting at MH</span>
<span class="c1"># choose the next node using the probability vector we calculated</span>
<span class="n">next_node</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">node_names</span><span class="p">)),</span> <span class="n">p</span><span class="o">=</span><span class="n">p_1_startat_MH</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Next node: </span><span class="si">{:s}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">node_names</span><span class="p">[</span><span class="n">next_node</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Next node: Q
</pre></div>
</div>
</div>
</div>
<p>We indicate the path we took between Manhattan and our realization in green, shown below:</p>
<p>This gives us a realization of <span class="math notranslate nohighlight">\(\mathbf s_1\)</span> as the indicated node in the network, conditional on the starting node being <span class="math notranslate nohighlight">\(\mathbf s_0 = v_{MH}\)</span>. We repeat this process again to give us a realization of <span class="math notranslate nohighlight">\(\mathbf s_2\)</span>, conditional on <span class="math notranslate nohighlight">\(\mathbf s_1\)</span>’s value which we just calculated a realization of.</p>
<p>We then repeat this procedure over and over again on the network to obtain a realization of a random walk on the New York boroughs, given only the starting node <span class="math notranslate nohighlight">\(\mathbf s_0 = v_{MH}\)</span>.</p>
</div>
</div>
</div>
<div class="section" id="what-do-markov-chains-and-random-walks-have-to-do-with-embedding-networks">
<h2><span class="section-number">6.5.2. </span>What do markov chains and random walks have to do with embedding networks?<a class="headerlink" href="#what-do-markov-chains-and-random-walks-have-to-do-with-embedding-networks" title="Permalink to this headline">¶</a></h2>
<p>In the preface for this section, we said we were going to cover how to use a random walk to embed our network, but we’ve ignored that thus far! To get us to what this has to do with embeddings, we need to introduce a slight variation of the random walk we developed in the preceding section, called the second-order biased random walk.</p>
<div class="section" id="second-order-biased-random-walk">
<h3><span class="section-number">6.5.2.1. </span>Second-order biased random walk<a class="headerlink" href="#second-order-biased-random-walk" title="Permalink to this headline">¶</a></h3>
<p>Remember when we developed our first-order random walk, we did something kind of nonsensical: we ignored all of the previous boroughs of New York you had already seen, and said that the next borough was <em>only</em> a function of the current borough you are at. You could certainly imagine that you get caught in a legitimate random walk (it is a <em>possible realization</em> because all of the transition probabilities are <em>positive</em>) where you explore going from Manhattan to Brooklyn, and then over to Staten Island, and then back to Brooklyn, and then back to Staten Island, so on and so forth, because you <em>totally ignored</em> the previous places you had been when making your decision for where to go from your current borough.</p>
<p>If you are a tourist trying to explore New York, you obviously will want to get a better sense of <em>all</em> of the city, and want to favor the boroughs you haven’t been to as recently! In the second-order biased random walk, we introduce the idea of the return and in-out parameters, <span class="math notranslate nohighlight">\(p\)</span> and <span class="math notranslate nohighlight">\(q\)</span>, respectively.</p>
<div class="section" id="the-bias-factor-lets-us-control-our-ability-to-leave-or-remain-amongst-a-neighborhood-of-nodes">
<h4><span class="section-number">6.5.2.1.1. </span>The bias factor lets us control our ability to <em>leave</em> or <em>remain</em> amongst a neighborhood of nodes<a class="headerlink" href="#the-bias-factor-lets-us-control-our-ability-to-leave-or-remain-amongst-a-neighborhood-of-nodes" title="Permalink to this headline">¶</a></h4>
<p>Remember that the steps in our random walk, <span class="math notranslate nohighlight">\(\left\{\mathbf s_0, \mathbf s_1, ..., \mathbf s_{t-1}, \mathbf s_t, ...\right\}\)</span>, were sequences of random variables which took values of our nodes in the network. Let’s assume that we have a random walk so far, where at our previous state, <span class="math notranslate nohighlight">\(\mathbf s_{t-1} = s_{t-1}\)</span>, and we are currently at node <span class="math notranslate nohighlight">\(i\)</span>, <span class="math notranslate nohighlight">\(\mathbf s_t = i\)</span>. Here, <span class="math notranslate nohighlight">\(s_{t-1}\)</span> is some other node which we just came from to get to node <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p>The <strong>in-out</strong> parameter <span class="math notranslate nohighlight">\(q\)</span> is a value which indicates a bias factor of <span class="math notranslate nohighlight">\(\frac{1}{q}\)</span> that we will go to some node <span class="math notranslate nohighlight">\(j\)</span> that is <em>totally</em> disconnected from the previous node that we visited, <span class="math notranslate nohighlight">\(s_{t-1}\)</span>. This means that in our network, there is no edge starting at node <span class="math notranslate nohighlight">\(j\)</span> and going to node <span class="math notranslate nohighlight">\(s_{t-1}\)</span>. If the in-out parameter <span class="math notranslate nohighlight">\(q\)</span> takes big values, then <span class="math notranslate nohighlight">\(\frac{1}{q}\)</span> will be very small, and we will be biased <em>against</em> visiting nodes which are not connected to the previous node we visited. If <span class="math notranslate nohighlight">\(q\)</span> is small, then <span class="math notranslate nohighlight">\(\frac{1}{q}\)</span> will be very big, and we will be biased <em>towards</em> visiting nodes which are not connected to the previous node we visited.</p>
<p>The <strong>return</strong> parameter <span class="math notranslate nohighlight">\(p\)</span> is a value which indicates a bias factor of <span class="math notranslate nohighlight">\(\frac{1}{p}\)</span> that we will <em>go back</em> to the node which we visited previously in the last state <span class="math notranslate nohighlight">\(s_{t-1}\)</span>. If the return parameter <span class="math notranslate nohighlight">\(p\)</span> takes big values, <span class="math notranslate nohighlight">\(\frac{1}{p}\)</span> will be very small, and we will be biased <em>against</em> visiting a node we have just been to. If <span class="math notranslate nohighlight">\(p\)</span> is small, then <span class="math notranslate nohighlight">\(\frac{1}{p}\)</span> will be very big, and we will be biased <em>towards</em> visiting a node which we were just at.</p>
<p>If a node satisfies neither of these conditions, the bias factor is just left at <span class="math notranslate nohighlight">\(1\)</span>. Together, these relationships are summarized with the <strong>bias factor</strong> <span class="math notranslate nohighlight">\(\alpha_{ij}^{(t+1)}(p,q, s_{t-1})\)</span> starting at node <span class="math notranslate nohighlight">\(i\)</span> and proceeding to node <span class="math notranslate nohighlight">\(j\)</span> with parameters <span class="math notranslate nohighlight">\(p\)</span> and <span class="math notranslate nohighlight">\(q\)</span> for the next step <span class="math notranslate nohighlight">\(t+1\)</span> given that we just left state <span class="math notranslate nohighlight">\(s_{t-1}\)</span> as:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \alpha_{ij}(p,q,s_{t-1}) &amp;= \begin{cases}
        \frac{1}{p} &amp; \text{$s_{t-1} = j$} \\
        \frac{1}{q} &amp; \text{$s_{t-1} \neq j$} \\
        1 &amp; \text{otherwise}
    \end{cases}
\end{align*}\]</div>
<p>And the corresponding bias vector <span class="math notranslate nohighlight">\(\vec \alpha_i(p,q, s_{t-1})\)</span>, which is a vector of each of the bias factors for all of the <span class="math notranslate nohighlight">\(n\)</span> nodes in the network (which are indexed by <span class="math notranslate nohighlight">\(j\)</span>).</p>
</div>
<div class="section" id="adjusting-the-transition-probabilities-with-the-bias-vector">
<h4><span class="section-number">6.5.2.1.2. </span>Adjusting the transition probabilities with the bias vector<a class="headerlink" href="#adjusting-the-transition-probabilities-with-the-bias-vector" title="Permalink to this headline">¶</a></h4>
<p>In our second order random walk, instead of the transition probabilities being a function only of the <em>current</em> state, they are also a function of the preceding state we were at <span class="math notranslate nohighlight">\(s_{t-1}\)</span>. This means that our transition probability matrix is going to look <em>different</em> based on which node we just came from. The transition probabilities are defined using the indexed <em>triplet</em> <span class="math notranslate nohighlight">\(p_{s_{t-1}ij}(p,q)\)</span>, where <span class="math notranslate nohighlight">\(s_{t-1}\)</span> is the preceding node we visited, <span class="math notranslate nohighlight">\(i\)</span> is the current node we are at, <span class="math notranslate nohighlight">\(j\)</span> is any other node in the network, and <span class="math notranslate nohighlight">\(p\)</span> and <span class="math notranslate nohighlight">\(q\)</span> are the return and in-out parameters respectively. The <strong>second-order bias-adjusted transition factors</strong> the terms:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \beta_{s_{t-1}ij}(p,q) &amp;= \alpha_{ij}(p, q, s_{t-1})p_{ij}
\end{align*}\]</div>
<p>where <span class="math notranslate nohighlight">\(p_{ij}\)</span> are the first-order markov transition probabilities we used previously. These are called <em>second-order</em> because they depend on the current node, <span class="math notranslate nohighlight">\(i\)</span>, as well as the preceding node, <span class="math notranslate nohighlight">\(s_{t-1}\)</span>.</p>
<p>In effect, what this statement says is that all we do is <em>up</em> or <em>down</em>-weight (or don’t change it at all, if the bias factor is <span class="math notranslate nohighlight">\(1\)</span>) the probability <span class="math notranslate nohighlight">\(p_{ij}\)</span> of going from node <span class="math notranslate nohighlight">\(i\)</span> to node <span class="math notranslate nohighlight">\(j\)</span> based on the <em>bias factor</em> <span class="math notranslate nohighlight">\(\alpha_{ij}(p, q, s_{t-1})\)</span>. These are no longer probabilities, because starting at a node <span class="math notranslate nohighlight">\(i\)</span>, we might end up with the bias-adjusted transition factors no longer summing to one. This is because we did not require anything about how <span class="math notranslate nohighlight">\(\alpha_{ij}^{(t+1)}(p,q,s_{t-1})\)</span> behaved across all possible nodes <span class="math notranslate nohighlight">\(j\)</span> we could transition to from our current node <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p>Finally, we then use the bias-adjusted transition factors to compute the <strong>second-order biased transition probabilities</strong>. These are just normalized versions of the bias-adjusted transition factors, where we normalize to make sure that they all sum up to one (and hence, produce a valid transition probability from node <span class="math notranslate nohighlight">\(i\)</span> outwards):</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    p_{s_{t-1}ij}(p,q) &amp;= \frac{\beta_{s_{t-1}ij}(p,q)}{\sum_{j' = 1}^n\beta_{s_{t-1}ij'}(p,q)}
\end{align*}\]</div>
<p>Notice that in the denominator, that we are just normalizing the bias-adjusted transition factor by the sum of all the other bias-adjusted transition factors from node <span class="math notranslate nohighlight">\(i\)</span> to any other nodes <span class="math notranslate nohighlight">\(j'\)</span> in the network.</p>
</div>
</div>
</div>
<div class="section" id="node2vec">
<h2><span class="section-number">6.5.3. </span>node2vec<a class="headerlink" href="#node2vec" title="Permalink to this headline">¶</a></h2>
<p>node2vec is one such method. Instead of relying on taking eigenvectors or eigenvalues, like a Laplacian, node2vec uses a random walk to preserve the relationships between nodes and their <em>local neighborhoods</em>: all of the nodes which you can get to by walking along a small number of edges from your starting node. For example, take</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.embed</span> <span class="kn">import</span> <span class="n">node2vec_embed</span>
<span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">sbm</span>
<span class="kn">from</span> <span class="nn">graspologic.plot</span> <span class="kn">import</span> <span class="n">heatmap</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>

<span class="c1"># Start with some simple parameters</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">300</span>  <span class="c1"># Total number of nodes</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">N</span> <span class="o">//</span> <span class="mi">3</span>  <span class="c1"># Nodes per community</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">.6</span><span class="p">,</span> <span class="mf">.3</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">.3</span><span class="p">]])</span>  <span class="c1"># Our block probability matrix</span>

<span class="c1"># Make our Stochastic Block Model</span>
<span class="n">A</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">sbm</span><span class="p">([</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">],</span> <span class="n">B</span><span class="p">,</span> <span class="n">return_labels</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:&gt;
</pre></div>
</div>
<img alt="../../_images/random-walk-diffusion-methods_24_1.png" src="../../_images/random-walk-diffusion-methods_24_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.embed</span> <span class="kn">import</span> <span class="n">AdjacencySpectralEmbed</span> <span class="k">as</span> <span class="n">ASE</span>

<span class="n">ase</span> <span class="o">=</span> <span class="n">ASE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">latents</span> <span class="o">=</span> <span class="n">ase</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="n">pairplot</span><span class="p">(</span><span class="n">latents</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">Input In [7],</span> in <span class="ni">&lt;cell line: 6&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">ase</span> <span class="o">=</span> <span class="n">ASE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">latents</span> <span class="o">=</span> <span class="n">ase</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">6</span> <span class="n">pairplot</span><span class="p">(</span><span class="n">latents</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;pairplot&#39; is not defined
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.plot</span> <span class="kn">import</span> <span class="n">pairplot</span>

<span class="n">networkx_sbm</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">a</span><span class="p">,</span> <span class="n">nodes</span> <span class="o">=</span> <span class="n">node2vec_embed</span><span class="p">(</span><span class="n">networkx_sbm</span><span class="p">,</span> <span class="n">dimensions</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">walk_length</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">pairplot</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">24</span><span class="o">-</span><span class="mi">996282</span><span class="n">b86c3d</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> 
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">networkx_sbm</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">4</span> <span class="n">a</span><span class="p">,</span> <span class="n">nodes</span> <span class="o">=</span> <span class="n">node2vec_embed</span><span class="p">(</span><span class="n">networkx_sbm</span><span class="p">,</span> <span class="n">dimensions</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">walk_length</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="n">pairplot</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;node2vec_embed&#39; is not defined
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="extending-to-weighted-networks">
<h2><span class="section-number">6.5.4. </span>Extending to weighted networks<a class="headerlink" href="#extending-to-weighted-networks" title="Permalink to this headline">¶</a></h2>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./representations/ch6"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="estimating-parameters_spectral.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">6.4. </span>Estimating Parameters for the RDPG</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="graph-neural-networks.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">6.6. </span>Graph Neural Networks</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Joshua Vogelstein, Eric Bridgeford, and Alex Loftus<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>