
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>6.4. Random walk and diffusion-based methods &#8212; Hands-on Network Machine Learning with Scikit-Learn and Graspologic</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >let toggleHintShow = 'Click to show';</script>
    <script >let toggleHintHide = 'Click to hide';</script>
    <script >let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script >const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="6.5. Graph Neural Networks" href="graph-neural-networks.html" />
    <link rel="prev" title="6.3. Estimating Parameters for the RDPG" href="estimating-parameters_spectral.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Hands-on Network Machine Learning with Scikit-Learn and Graspologic</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../coverpage.html">
   Hands-on Network Machine Learning with Scikit-Learn and Graspologic
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/terminology.html">
   Terminology and Math Refresher
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch1/ch1.html">
   1. The Network Machine Learning Landscape
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/what-is-a-network.html">
     1.1. What is network machine learning?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/why-study-networks.html">
     1.2. How do we study networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/examples-of-applications.html">
     1.3. Examples of applications
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/types-of-learning-probs.html">
     1.4. Approaches for Network Learning Problems
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch2/ch2.html">
   2. End-to-end Biology Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/big-picture.html">
     2.1. Look at the big picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/get-the-data.html">
     2.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/prepare-the-data.html">
     2.3. Prepare the Data for Network Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/discover-and-visualize.html">
     2.4. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch3/ch3.html">
   3. End-to-end Business Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/big-picture.html">
     3.1. Look at the Big Picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/get-the-data.html">
     3.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/discover-and-visualize.html">
     3.3. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/prepare-the-data.html">
     3.4. Prepare the Data for Network Algorithms
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Representations
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch4/ch4.html">
   4. Properties of Networks as a Statistical Object
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/matrix-representations.html">
     4.1. Matrix Representations Of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/properties-of-networks.html">
     4.2. Properties of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/network-representations.html">
     4.3. Representations of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/regularization.html">
     4.4. Regularization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch5/ch5.html">
   5. Why Use Statistical Models?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/why-use-models.html">
     5.1. Why Use Statistical Models?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/single-network-models_ER.html">
     5.2. Erdös-Rényi (ER) Random Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/single-network-models_SBM.html">
     5.3. Stochastic Block Models (SBM)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/single-network-models_RDPG.html">
     5.4. Random Dot Product Graphs (RDPG)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/single-network-models_IER.html">
     5.5. Inhomogeneous Erdos Renyi (IER) Random Network Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/multi-network-models.html">
     5.6. Multiple Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/models-with-covariates.html">
     5.7. Network Models with Covariates
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="ch6.html">
   6. Learning Network Representations
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="estimating-parameters_mle.html">
     6.1. Estimating Parameters in Network Models via MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="spectral-embedding.html">
     6.2. Spectral Embedding Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="estimating-parameters_spectral.html">
     6.3. Estimating Parameters for the RDPG
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     6.4. Random walk and diffusion-based methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="graph-neural-networks.html">
     6.5. Graph Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="multigraph-representation-learning.html">
     6.6. Multiple-Network Representation Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="joint-representation-learning.html">
     6.7. Joint Representation Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch7/ch7.html">
   7. Theoretical Results
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/theory-single-network.html">
     7.1. Theory for Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/theory-multigraph.html">
     7.2. Maximum Likelihood Estimate Theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/theory-matching.html">
     7.3. Spectral Method Theory
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch8/ch8.html">
   8. Applications When You Have One Network
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/community-detection.html">
     8.1. Community Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/testing-differences.html">
     8.2. Testing for Differences between Groups of Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/model-selection.html">
     8.3. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/single-vertex-nomination.html">
     8.4. Single-Network Vertex Nomination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/out-of-sample.html">
     8.5. Out-of-sample Embedding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch9/ch9.html">
   9. Applications for Two Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/two-sample-hypothesis.html">
     9.1. Latent Two-Sample Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/significant-communities.html">
     9.2. Differences in Block Matrices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/graph-matching-vertex.html">
     9.3. Graph Matching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/multiple-vertex-nomination.html">
     9.4. Vertex Nomination For Two Networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch10/ch10.html">
   10. Applications for Many Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch10/anomaly-detection.html">
     10.1. Anomaly Detection For Timeseries of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch10/significant-edges.html">
     10.2. Testing for Significant Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch10/significant-vertices.html">
     10.3. Testing for Significant Vertices
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://graspologic.readthedocs.io/en/latest/">
   Graspologic Documentation
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/representations/ch6/random-walk-diffusion-methods.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/neurodata/graph-stats-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/neurodata/graph-stats-book/issues/new?title=Issue%20on%20page%20%2Frepresentations/ch6/random-walk-diffusion-methods.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/neurodata/graph-stats-book/edit/master/network_machine_learning_in_python/representations/ch6/random-walk-diffusion-methods.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-simplified-first-order-random-walk-on-a-network">
   6.4.1. A simplified first-order random walk on a network
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#markov-chains-and-the-markov-property">
     6.4.1.1. Markov chains and the markov property
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#first-order-random-walks-on-a-network-as-a-markov-chain">
       6.4.1.1.1. First-order random walks on a network as a markov chain
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-do-markov-chains-and-random-walks-have-to-do-with-embedding-networks">
   6.4.2. What do markov chains and random walks have to do with embedding networks?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#second-order-biased-random-walk">
     6.4.2.1. Second-order biased random walk
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-bias-factor-lets-us-control-our-ability-to-leave-or-remain-amongst-a-neighborhood-of-nodes">
       6.4.2.1.1. The bias factor lets us control our ability to
       <em>
        leave
       </em>
       or
       <em>
        remain
       </em>
       amongst a neighborhood of nodes
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#adjusting-the-transition-probabilities-with-the-bias-vector">
       6.4.2.1.2. Adjusting the transition probabilities with the bias vector
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#node2vec-embedding">
   6.4.3. node2vec embedding
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#word2vec">
     6.4.3.1. Word2vec
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-node2vec-to-embed-the-network">
     6.4.3.2. Using node2vec to embed the network
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-do-we-need-a-second-order-biased-random-walk-to-generate-an-embedding">
     6.4.3.3. Why do we need a second-order biased random walk to generate an embedding?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#extending-to-weighted-and-directed-networks">
   6.4.4. Extending to weighted and directed networks
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Random walk and diffusion-based methods</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-simplified-first-order-random-walk-on-a-network">
   6.4.1. A simplified first-order random walk on a network
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#markov-chains-and-the-markov-property">
     6.4.1.1. Markov chains and the markov property
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#first-order-random-walks-on-a-network-as-a-markov-chain">
       6.4.1.1.1. First-order random walks on a network as a markov chain
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-do-markov-chains-and-random-walks-have-to-do-with-embedding-networks">
   6.4.2. What do markov chains and random walks have to do with embedding networks?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#second-order-biased-random-walk">
     6.4.2.1. Second-order biased random walk
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-bias-factor-lets-us-control-our-ability-to-leave-or-remain-amongst-a-neighborhood-of-nodes">
       6.4.2.1.1. The bias factor lets us control our ability to
       <em>
        leave
       </em>
       or
       <em>
        remain
       </em>
       amongst a neighborhood of nodes
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#adjusting-the-transition-probabilities-with-the-bias-vector">
       6.4.2.1.2. Adjusting the transition probabilities with the bias vector
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#node2vec-embedding">
   6.4.3. node2vec embedding
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#word2vec">
     6.4.3.1. Word2vec
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-node2vec-to-embed-the-network">
     6.4.3.2. Using node2vec to embed the network
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-do-we-need-a-second-order-biased-random-walk-to-generate-an-embedding">
     6.4.3.3. Why do we need a second-order biased random walk to generate an embedding?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#extending-to-weighted-and-directed-networks">
   6.4.4. Extending to weighted and directed networks
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="random-walk-and-diffusion-based-methods">
<h1><span class="section-number">6.4. </span>Random walk and diffusion-based methods<a class="headerlink" href="#random-walk-and-diffusion-based-methods" title="Permalink to this headline">¶</a></h1>
<p>Although this book puts a heavy emphasis on spectral methods, there are many ways in which you can learn lower-dimensional representations for networks which don’t involve spectral approaches. As opposed to spectral methods, a <strong>random walk on a network</strong> is a random process which focuses on the analysis of paths which start at a node in the network, and proceed to generate successions of random steps to other nodes in the network. The manner in which these random processes materialize is a function of the topology of the random network, including the nodes, edges, and (optionally, if the network is weighted), the edge weights.</p>
<div class="section" id="a-simplified-first-order-random-walk-on-a-network">
<h2><span class="section-number">6.4.1. </span>A simplified first-order random walk on a network<a class="headerlink" href="#a-simplified-first-order-random-walk-on-a-network" title="Permalink to this headline">¶</a></h2>
<p>For instance, let’s consider an extremely simplified approach for a first-order random walk on the network that you saw back in <a class="reference external" href="#link?">Chapter 4</a>, which was our New York example. To begin, let’s redefine the nodes and edges of the network. The nodes of the network are the five boroughs of New York City (Staten Island SI, Brooklyn BK, Queens Q, the Bronx BX, and Manhattan MH). The nodes in your network are the five boroughs. The edges <span class="math notranslate nohighlight">\((i,j)\)</span> of your network exist if one can travel from borough <span class="math notranslate nohighlight">\(i\)</span> to borough <span class="math notranslate nohighlight">\(j\)</span> along a bridge.</p>
<p>Below, you will look at a map of New York City, with the bridges connecting the different boroughs. In the middle, you look at this map as a network layout plot. The arrows indicate the direction of travel. On the right, you look at this map as an adjacency matrix:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># define the node names</span>
<span class="n">node_names</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s2">&quot;SI&quot;</span><span class="p">,</span> <span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="s2">&quot;BK&quot;</span><span class="p">,</span> <span class="s2">&quot;Q&quot;</span><span class="p">,</span> <span class="s2">&quot;BX&quot;</span><span class="p">])</span>
<span class="c1"># define the adjacency matrix</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>  <span class="c1"># staten island is neighbors of brooklyn</span>
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>  <span class="c1"># manhattan is neighbors of all but staten island</span>
              <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>  <span class="c1"># brooklyn is neighbors of staten island and manhattan</span>
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>  <span class="c1"># queens is neighbors of manhattan and bronx</span>
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]])</span> <span class="c1"># bronx is neighbors of manhattan and queens</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.image</span> <span class="k">as</span> <span class="nn">mpimg</span>
<span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">heatmap</span>

<span class="n">img</span> <span class="o">=</span> <span class="n">mpimg</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;../ch4/img/newyork.png&#39;</span><span class="p">)</span>

<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">()</span>

<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;SI&quot;</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;BK&quot;</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;Q&quot;</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;BX&quot;</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>

<span class="n">pos</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">get_node_attributes</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="s1">&#39;pos&#39;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;SI&quot;</span><span class="p">,</span> <span class="s2">&quot;BK&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="s2">&quot;BK&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="s2">&quot;Q&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="s2">&quot;BX&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;Q&quot;</span><span class="p">,</span> <span class="s2">&quot;BX&quot;</span><span class="p">)</span>

<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;BK&quot;</span><span class="p">,</span> <span class="s2">&quot;SI&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;BK&quot;</span><span class="p">,</span> <span class="s2">&quot;MH&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;Q&quot;</span><span class="p">,</span> <span class="s2">&quot;MH&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;BX&quot;</span><span class="p">,</span> <span class="s2">&quot;MH&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;BX&quot;</span><span class="p">,</span> <span class="s2">&quot;Q&quot;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">23</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.8</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Map of New York City Boroughs and Connections&quot;</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span>
        <span class="n">font_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s2">&quot;whitesmoke&quot;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Layout Plot of New York City Boroughs and Connections&quot;</span><span class="p">)</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">xticklabels</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">4.5</span><span class="p">],</span> <span class="n">yticklabels</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">4.5</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Adjacency Matrix of New York City Boroughs and Connections&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">node_names</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">node_names</span><span class="p">)</span>
<span class="n">fig</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/random-walk-diffusion-methods_3_0.png" src="../../_images/random-walk-diffusion-methods_3_0.png" />
</div>
</div>
<p>You are staying at a hotel which is located in Manhattan, and you decide that you are going to explore the city as follows. When you are in a given borough <span class="math notranslate nohighlight">\(i\)</span>, you will determine the next borough you will explore by letting random chance do the work for you. To better define a first-order random walk, we need to introduce a background concept first: the Markov chain and the Markov property.</p>
<div class="section" id="markov-chains-and-the-markov-property">
<h3><span class="section-number">6.4.1.1. </span>Markov chains and the markov property<a class="headerlink" href="#markov-chains-and-the-markov-property" title="Permalink to this headline">¶</a></h3>
<p>A <strong>finite-space markov chain</strong> is a model of a random system in which we have a sequence of possible events which can occur which are <em>finite</em> (the boroughs we will visit on a day <span class="math notranslate nohighlight">\(t\)</span>) in which the probability of each event depends <em>only</em> on the event in which you were previously. For network analysis, we only need to think about <em>finite-space</em> Markov chains, because the network has a <em>finite</em> collection of possible events which can occur (the nodes in the network being visited). To put this down quantitatively, the markov chain is represented by the sequence <span class="math notranslate nohighlight">\(\mathbf s_0, \mathbf s_1, \mathbf s_2, ...\)</span>, where each <span class="math notranslate nohighlight">\(\mathbf s_t\)</span> takes the value of one of the <span class="math notranslate nohighlight">\(n\)</span> total nodes in the network.</p>
<p>You will notice that in our definition of the finite-space markov chain, we made a disclaimer: the probability of each event depends <em>only</em> on the state in which we were previously. This is called the <strong>markov property</strong>. The idea is that, if we were in Manhattan at the previous step in time <span class="math notranslate nohighlight">\(t - 1\)</span> (e.g., <span class="math notranslate nohighlight">\(\mathbf s_{t-1}\)</span> realized the value <span class="math notranslate nohighlight">\(v_{MH}\)</span>, or <span class="math notranslate nohighlight">\(\mathbf s_{t-1} = v_{MH}\)</span> for short), that if our current step in the Markov Chain were Brooklyn (<span class="math notranslate nohighlight">\(\mathbf s_t = v_{BK}\)</span>), that the next step in the Markov chain would not depend <em>at all</em> on the fact that we already saw Manhattan.</p>
<div class="section" id="first-order-random-walks-on-a-network-as-a-markov-chain">
<h4><span class="section-number">6.4.1.1.1. </span>First-order random walks on a network as a markov chain<a class="headerlink" href="#first-order-random-walks-on-a-network-as-a-markov-chain" title="Permalink to this headline">¶</a></h4>
<p>To exhibit the ideas of a markov chain, we’ll define a first-order random walk on your New York Boroughs. Remember that the borough you are at, <span class="math notranslate nohighlight">\(i\)</span>, has <span class="math notranslate nohighlight">\(d_i\)</span> possible neighboring boroughs, where <span class="math notranslate nohighlight">\(d_i\)</span> was the <em>degree</em> of node <span class="math notranslate nohighlight">\(i\)</span>. You will visit one of the other nodes in the network as follows. If borough <span class="math notranslate nohighlight">\(j\)</span> is a neighbor of borough <span class="math notranslate nohighlight">\(i\)</span> (an edge exists from borough <span class="math notranslate nohighlight">\(i\)</span> to borough <span class="math notranslate nohighlight">\(j\)</span>), you will visit borough <span class="math notranslate nohighlight">\(j\)</span> with probability <span class="math notranslate nohighlight">\(\frac{1}{d_i}\)</span>. The idea is that you will visit neighbors of each borough at random, depending only on whether you can get to that borough along an edge of the network. This is called a <strong>first-order random walk</strong> because it is a random walk where you <em>ignore</em> everything about the path you have taken to get to your current <em>borough</em> to date, except for the fact that you are at that borough <em>now</em>. This means that your next borough will not depend <em>at all</em> on whether you have already been to that borough in your exploration of the city. If the node is not a neighbor of your current borough, you will visit it with probability <span class="math notranslate nohighlight">\(0\)</span>. Stated another way, if you are in node <span class="math notranslate nohighlight">\(i\)</span>, the probability of going to another node <span class="math notranslate nohighlight">\(j\)</span> is defined as:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    p_{ij} &amp;= \begin{cases}
        \frac{1}{d_i}  &amp; \text{edge $(i,j)$ exists} \\
        0  &amp; \text{edge $(i,j)$ does not exist}
    \end{cases}
\end{align*}\]</div>
<p>Note that these probabilities, called the <strong>transition probability</strong> from node <span class="math notranslate nohighlight">\(i\)</span> to node <span class="math notranslate nohighlight">\(j\)</span>, do not have <em>anything</em> to do with which nodes we have visited yet, and these transition probabilities are <em>always the same</em>! For this reason, they are often organized into a matrix, called the <strong>transition probability matrix</strong> <span class="math notranslate nohighlight">\(P\)</span>. In this case, the transition probability matrix looks like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute the degree of each node</span>
<span class="n">di</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># the probability matrix is the adjacency divided by</span>
<span class="c1"># degree of the starting node</span>
<span class="n">P</span> <span class="o">=</span> <span class="p">(</span><span class="n">A</span> <span class="o">/</span> <span class="n">di</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span>
        <span class="n">font_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s2">&quot;whitesmoke&quot;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Layout Plot of New York City Boroughs and Connections&quot;</span><span class="p">)</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">xticklabels</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">4.5</span><span class="p">],</span> <span class="n">yticklabels</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">4.5</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Transition probability matrix $P$ for New York Random Walk&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s2">&quot;SI&quot;</span><span class="p">,</span> <span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="s2">&quot;BK&quot;</span><span class="p">,</span> <span class="s2">&quot;Q&quot;</span><span class="p">,</span> <span class="s2">&quot;BX&quot;</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([</span><span class="s2">&quot;SI&quot;</span><span class="p">,</span> <span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="s2">&quot;BK&quot;</span><span class="p">,</span> <span class="s2">&quot;Q&quot;</span><span class="p">,</span> <span class="s2">&quot;BX&quot;</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Starting borough $i$&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Next borough $j$&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/random-walk-diffusion-methods_6_0.png" src="../../_images/random-walk-diffusion-methods_6_0.png" />
</div>
</div>
<p>To understand this transition probability matrix, let’s think about the individual rows. Notice that if you are in Staten Island, there is only one borough you can go from here, so with probability <span class="math notranslate nohighlight">\(1\)</span>, you will visit its only neighbor: Brooklyn. If you are in Manhattan, you could go to any of its three neighbors (Brooklyn, Queens, or Bronx), with equal probability <span class="math notranslate nohighlight">\(\frac{1}{3}\)</span>. If you were in Brooklyn, you could visit any of its two neighbors (Manhattan or Staten Island) with equal probability <span class="math notranslate nohighlight">\(\frac{1}{2}\)</span>. This continues for each node in the network until you have successfully generated the transition probability matrix <span class="math notranslate nohighlight">\(P\)</span>.</p>
<p>There are a lot of interesting properties you can use the transition probability matrix <span class="math notranslate nohighlight">\(P\)</span> to learn about, but we won’t cover them all here. If you want some more details on transition probability matrices and Markov chains in general, we would recommend that you check out a book on stochastic processes, such as the author’s favorite by Dean Isaacson, called <a class="reference external" href="https://www.amazon.com/dp/0471428620?tag=uuid10-20">Markov Chains: Theory and Applications</a>.</p>
<p>Next, let’s use this transition probability matrix to generate a random walk on the New York City boroughs. As we mentioned, your hotel is in Manhattan, so you are going to start your random walk through the city here. In other words, <span class="math notranslate nohighlight">\(\mathbf s_0 = v_{MH}\)</span>. For your next step in the Markov chain, you will visit either Brooklyn, Bronx, or Queens with probability <span class="math notranslate nohighlight">\(\frac{1}{3}\)</span>, or Staten Island with probability <span class="math notranslate nohighlight">\(0\)</span>. In the following figure, we show the place you start out at, Manhattan, in blue, and the other nodes in gray:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">()</span>

<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;SI&quot;</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;BK&quot;</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;Q&quot;</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;BX&quot;</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>

<span class="n">pos</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">get_node_attributes</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="s1">&#39;pos&#39;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;SI&quot;</span><span class="p">,</span> <span class="s2">&quot;BK&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="s2">&quot;BK&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="s2">&quot;Q&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="s2">&quot;BX&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;Q&quot;</span><span class="p">,</span> <span class="s2">&quot;BX&quot;</span><span class="p">)</span>

<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;BK&quot;</span><span class="p">,</span> <span class="s2">&quot;SI&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;BK&quot;</span><span class="p">,</span> <span class="s2">&quot;MH&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;Q&quot;</span><span class="p">,</span> <span class="s2">&quot;MH&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;BX&quot;</span><span class="p">,</span> <span class="s2">&quot;MH&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;BX&quot;</span><span class="p">,</span> <span class="s2">&quot;Q&quot;</span><span class="p">)</span>

<span class="n">Ghl</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">()</span>
<span class="n">Ghl</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;MH&quot;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;tab:gray&quot;</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span>
        <span class="n">font_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s2">&quot;whitesmoke&quot;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">Ghl</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span>
        <span class="n">font_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s2">&quot;whitesmoke&quot;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/random-walk-diffusion-methods_8_0.png" src="../../_images/random-walk-diffusion-methods_8_0.png" />
</div>
</div>
<p>You can visit each of the neighboring nodes, shown in the next plot teal yellow, and the probabilities of visiting each of these nodes are correspondingly highlighted in the transition probability matrix with a blue block:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.patches</span> <span class="k">as</span> <span class="nn">patches</span>
<span class="n">Gn</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">()</span>
<span class="n">Gn</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;BX&quot;</span><span class="p">)</span>
<span class="n">Gn</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;BK&quot;</span><span class="p">)</span>
<span class="n">Gn</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;Q&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;tab:gray&quot;</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span>
        <span class="n">font_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s2">&quot;whitesmoke&quot;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">Ghl</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span>
        <span class="n">font_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s2">&quot;whitesmoke&quot;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">Gn</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;teal&quot;</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span>
        <span class="n">font_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s2">&quot;whitesmoke&quot;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Possible next nodes from MH&quot;</span><span class="p">)</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">xticklabels</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">4.5</span><span class="p">],</span> <span class="n">yticklabels</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">4.5</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Transition probabilities from MH&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s2">&quot;SI&quot;</span><span class="p">,</span> <span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="s2">&quot;BK&quot;</span><span class="p">,</span> <span class="s2">&quot;Q&quot;</span><span class="p">,</span> <span class="s2">&quot;BX&quot;</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([</span><span class="s2">&quot;SI&quot;</span><span class="p">,</span> <span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="s2">&quot;BK&quot;</span><span class="p">,</span> <span class="s2">&quot;Q&quot;</span><span class="p">,</span> <span class="s2">&quot;BX&quot;</span><span class="p">])</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span>
     <span class="n">patches</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">(</span>
         <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span>
         <span class="mf">5.0</span><span class="p">,</span>
         <span class="mf">1.0</span><span class="p">,</span>
         <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span>
         <span class="n">fill</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
         <span class="n">lw</span><span class="o">=</span><span class="mi">4</span>
     <span class="p">)</span> <span class="p">)</span>

<span class="n">fig</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/random-walk-diffusion-methods_10_0.png" src="../../_images/random-walk-diffusion-methods_10_0.png" />
</div>
</div>
<p>You then choose the next node to visit, using these transition probabilities, by generating the probability vector of the <em>next step</em> in the random walk <em>given the current step</em>. We will denote this probability vector with the symbol <span class="math notranslate nohighlight">\(\vec p^{(t+1)}_i\)</span>, which is the probability vector for which node you will visit at the next step <span class="math notranslate nohighlight">\(t+1\)</span> given that you are currently at node <span class="math notranslate nohighlight">\(i\)</span>. Notice that this is just the entries of the <span class="math notranslate nohighlight">\(i^{th}\)</span> row of the transition probability matrix, which can be calculated using the relationship:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \vec p^{(t+1)}_i &amp;= P^\top \vec x^{(i)}
\end{align*}\]</div>
<p>where <span class="math notranslate nohighlight">\(\vec x^{(i)}\)</span> is the vector which has a value of <span class="math notranslate nohighlight">\(0\)</span> for all entries except for entry <span class="math notranslate nohighlight">\(i\)</span>, where it has a value of <span class="math notranslate nohighlight">\(1\)</span>. This ends up <em>pulling out</em> the <span class="math notranslate nohighlight">\(i^{th}\)</span> row of <span class="math notranslate nohighlight">\(P\)</span>, because every multiplication except for those against the <span class="math notranslate nohighlight">\(i^{th}\)</span> column of <span class="math notranslate nohighlight">\(P^\top\)</span> (which is the <span class="math notranslate nohighlight">\(i^{th}\)</span> row of <span class="math notranslate nohighlight">\(P\)</span>, by definition of a transpose) will end up just being <span class="math notranslate nohighlight">\(0\)</span>! We can see this with the following detailed exploration:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \vec p^{(t+1)}_i &amp;= \begin{bmatrix}
    p_{11} &amp; ... &amp; p_{1n} \\
    \vdots &amp; \ddots &amp; \vdots \\
    p_{n1} &amp; ... &amp; p_{nn}
    \end{bmatrix}^\top\vec x^{(i)} \\
     &amp;= \begin{bmatrix}
    p_{11} &amp; ... &amp; p_{n1} \\
    \vdots &amp; \ddots &amp; \vdots \\
    p_{1n} &amp; ... &amp; p_{nn}
    \end{bmatrix}^\top\vec x^{(i)},\;\;\;\;\text{in this step, we just transposed $P$} \\
    &amp;= \begin{bmatrix}
        p_{11}x_{1}^{(i)} + p_{21} x_2^{(i)} + ... p_{n1}x_n^{(i)} \\
        \vdots \\
        p_{1n}x_{1}^{(i)} + p_{2n} x_2^{(i)} + ... p_{nn}x_n^{(i)} 
    \end{bmatrix},\;\;\;\;\text{the definition of matrix multiplication} \\
    &amp;= \begin{bmatrix}
        p_{i1} \\
        \vdots \\
        p_{in}
    \end{bmatrix}
\end{align*}\]</div>
<p>where the last step in the multiplication is because <span class="math notranslate nohighlight">\(x_{i}^{(i)}\)</span> is the only entry which has a value of <span class="math notranslate nohighlight">\(1\)</span>, so all of the other multipilications are just <span class="math notranslate nohighlight">\(0\)</span>. We can pick the next node easily by just using <code class="docutils literal notranslate"><span class="pre">numpy</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># x vector indicating we start at MH</span>
<span class="n">pt2</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">xt</span>  <span class="c1"># p vector for timestep t+1 starting at node MH at time t</span>
<span class="c1"># choose the next node using the probability vector we calculated</span>
<span class="n">next_node</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">node_names</span><span class="p">)),</span> <span class="n">p</span><span class="o">=</span><span class="n">pt2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Next node: </span><span class="si">{:s}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">node_names</span><span class="p">[</span><span class="n">next_node</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Next node: BK
</pre></div>
</div>
</div>
</div>
<p>We indicate the path we took between Manhattan and our realized next node in green, shown below:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">next_name</span> <span class="o">=</span> <span class="n">node_names</span><span class="p">[</span><span class="n">next_node</span><span class="p">]</span>
<span class="n">Gnext</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">()</span>
<span class="n">Gnext</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;MH&quot;</span><span class="p">)</span>
<span class="n">Gnext</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">next_name</span><span class="p">)</span>
<span class="n">Gnext</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="n">next_name</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;tab:gray&quot;</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span>
        <span class="n">font_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s2">&quot;whitesmoke&quot;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">Gnext</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;tab:green&quot;</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span>
        <span class="n">font_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s2">&quot;whitesmoke&quot;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">edge_color</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">Ghl</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span>
        <span class="n">font_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s2">&quot;whitesmoke&quot;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;1-step of a first-order random walk starting at MH&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/random-walk-diffusion-methods_14_0.png" src="../../_images/random-walk-diffusion-methods_14_0.png" />
</div>
</div>
<p>This gives us a realization of <span class="math notranslate nohighlight">\(\mathbf s_1\)</span> as the indicated node in the network, conditional on the starting node being <span class="math notranslate nohighlight">\(\mathbf s_0 = v_{MH}\)</span>. We can generate a <span class="math notranslate nohighlight">\(T\)</span>-step first-order random walk along the network <span class="math notranslate nohighlight">\(G\)</span> using this approach:</p>
<div class="admonition-generating-a-realization-of-a-first-order-random-walk admonition">
<p class="admonition-title">Generating a realization of a first-order random walk</p>
<p>Now that we’ve learned how to make a single step in a first-order random walk, we are ready to generate a realization of a first-order random walk. Given a source node <span class="math notranslate nohighlight">\(s_0 = i\)</span>, a network <span class="math notranslate nohighlight">\(G\)</span> with nodes and edges, an in-out parameter <span class="math notranslate nohighlight">\(q\)</span>, a return parameter <span class="math notranslate nohighlight">\(p\)</span>, and a number of steps to proceed <span class="math notranslate nohighlight">\(T\)</span>, we take the following procedure:</p>
<ol class="simple">
<li><p>Generate the first-order transition probability matrix, <span class="math notranslate nohighlight">\(P\)</span>, using the adjacency matrix of the network, <span class="math notranslate nohighlight">\(A\)</span>.</p></li>
<li><p>For <span class="math notranslate nohighlight">\(t = 1:T\)</span>:</p>
<ul class="simple">
<li><p>choose the next node to visit <span class="math notranslate nohighlight">\(s_{t}\)</span>, by selecting a node <span class="math notranslate nohighlight">\(j\)</span> with probability <span class="math notranslate nohighlight">\(p_{s_tj}\)</span>.</p></li>
</ul>
</li>
</ol>
<p>The sequence <span class="math notranslate nohighlight">\(\{s_0, s_1, ..., s_T\}\)</span> is a realization of a <span class="math notranslate nohighlight">\(T\)</span>-step first-order random walk along the network <span class="math notranslate nohighlight">\(G\)</span>.</p>
</div>
</div>
</div>
</div>
<div class="section" id="what-do-markov-chains-and-random-walks-have-to-do-with-embedding-networks">
<h2><span class="section-number">6.4.2. </span>What do markov chains and random walks have to do with embedding networks?<a class="headerlink" href="#what-do-markov-chains-and-random-walks-have-to-do-with-embedding-networks" title="Permalink to this headline">¶</a></h2>
<p>In the preface for this section, we said we were going to cover how to use a random walk to embed our network, but we’ve ignored that thus far! To get us to what this has to do with embeddings, we need to introduce a slight variation of the random walk we developed in the preceding section, called the second-order biased random walk.</p>
<div class="section" id="second-order-biased-random-walk">
<h3><span class="section-number">6.4.2.1. </span>Second-order biased random walk<a class="headerlink" href="#second-order-biased-random-walk" title="Permalink to this headline">¶</a></h3>
<p>Remember when we developed our first-order random walk, we did something kind of nonsensical: we ignored all of the previous boroughs of New York you had already seen, and said that the next borough was <em>only</em> a function of the current borough you are at. You could certainly imagine that you get caught in a legitimate random walk (it is a <em>possible realization</em> because all of the transition probabilities are <em>positive</em>) where you explore going from Manhattan to Brooklyn, and then over to Staten Island, and then back to Brooklyn, and then back to Staten Island, so on and so forth, because you <em>totally ignored</em> the previous places you had been when making your decision for where to go from your current borough.</p>
<p>If you are a tourist trying to explore New York, you obviously will want to get a better sense of <em>all</em> of the city, and want to favor the boroughs you haven’t been to as recently! In the second-order biased random walk, we introduce the idea of the return and in-out parameters, <span class="math notranslate nohighlight">\(p\)</span> and <span class="math notranslate nohighlight">\(q\)</span>, respectively.</p>
<div class="section" id="the-bias-factor-lets-us-control-our-ability-to-leave-or-remain-amongst-a-neighborhood-of-nodes">
<h4><span class="section-number">6.4.2.1.1. </span>The bias factor lets us control our ability to <em>leave</em> or <em>remain</em> amongst a neighborhood of nodes<a class="headerlink" href="#the-bias-factor-lets-us-control-our-ability-to-leave-or-remain-amongst-a-neighborhood-of-nodes" title="Permalink to this headline">¶</a></h4>
<p>Remember that the steps in our random walk, <span class="math notranslate nohighlight">\(\left\{\mathbf s_0, \mathbf s_1, ..., \mathbf s_{t-1}, \mathbf s_t, ...\right\}\)</span>, were sequences of random variables which took values of our nodes in the network. Let’s assume that we have a random walk so far, where at our previous state, <span class="math notranslate nohighlight">\(\mathbf s_{t-1} = s_{t-1}\)</span>, and we are currently at node <span class="math notranslate nohighlight">\(i\)</span>, <span class="math notranslate nohighlight">\(\mathbf s_t = i\)</span>. Here, <span class="math notranslate nohighlight">\(s_{t-1}\)</span> is some other node which we just came from to get to node <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p>The <strong>in-out</strong> parameter <span class="math notranslate nohighlight">\(q\)</span> is a value which indicates a bias factor of <span class="math notranslate nohighlight">\(\frac{1}{q}\)</span> that we will go to some node <span class="math notranslate nohighlight">\(j\)</span> that is <em>totally</em> disconnected from the previous node that we visited, <span class="math notranslate nohighlight">\(s_{t-1}\)</span>. This means that in our network, there is no edge starting at node <span class="math notranslate nohighlight">\(j\)</span> and going to node <span class="math notranslate nohighlight">\(s_{t-1}\)</span>. If the in-out parameter <span class="math notranslate nohighlight">\(q\)</span> takes big values, then <span class="math notranslate nohighlight">\(\frac{1}{q}\)</span> will be very small, and we will be biased <em>against</em> visiting nodes which are not connected to the previous node we visited. If <span class="math notranslate nohighlight">\(q\)</span> is small, then <span class="math notranslate nohighlight">\(\frac{1}{q}\)</span> will be very big, and we will be biased <em>towards</em> visiting nodes which are not connected to the previous node we visited.</p>
<p>The <strong>return</strong> parameter <span class="math notranslate nohighlight">\(p\)</span> is a value which indicates a bias factor of <span class="math notranslate nohighlight">\(\frac{1}{p}\)</span> that we will <em>go back</em> to the node which we visited previously in the last state <span class="math notranslate nohighlight">\(s_{t-1}\)</span>. If the return parameter <span class="math notranslate nohighlight">\(p\)</span> takes big values, <span class="math notranslate nohighlight">\(\frac{1}{p}\)</span> will be very small, and we will be biased <em>against</em> visiting a node we have just been to. If <span class="math notranslate nohighlight">\(p\)</span> is small, then <span class="math notranslate nohighlight">\(\frac{1}{p}\)</span> will be very big, and we will be biased <em>towards</em> visiting a node which we were just at.</p>
<p>If a node satisfies neither of these conditions, the bias factor is just left at <span class="math notranslate nohighlight">\(1\)</span>. Together, these relationships are summarized with the <strong>bias factor</strong> <span class="math notranslate nohighlight">\(\alpha_{ij}^{(t+1)}(p,q, s_{t-1})\)</span> starting at node <span class="math notranslate nohighlight">\(i\)</span> and proceeding to node <span class="math notranslate nohighlight">\(j\)</span> with parameters <span class="math notranslate nohighlight">\(p\)</span> and <span class="math notranslate nohighlight">\(q\)</span> for the next step <span class="math notranslate nohighlight">\(t+1\)</span> given that we just left state <span class="math notranslate nohighlight">\(s_{t-1}\)</span> as:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \alpha_{ij}(p,q,s_{t-1}) &amp;= \begin{cases}
        \frac{1}{p} &amp; \text{$s_{t-1} = j$} \\
        \frac{1}{q} &amp; \text{$s_{t-1} \neq j$ and the edge $(j,s_{t-1})$ exists} \\
        1 &amp; \text{$s_{t-1} \neq j$ and no edge $(j,s_{t-1})$ exists}
    \end{cases}
\end{align*}\]</div>
<p>And the corresponding bias vector <span class="math notranslate nohighlight">\(\vec \alpha_i(p,q, s_{t-1})\)</span>, which is a vector of each of the bias factors for all of the <span class="math notranslate nohighlight">\(n\)</span> nodes in the network (which are indexed by <span class="math notranslate nohighlight">\(j\)</span>).</p>
<p>Let’s use our New York example to get a sense of how these bias vectors work. We’ll consider a random walk at some arbitrary current state <span class="math notranslate nohighlight">\(t\)</span>, where the current node we are on is Manhattan (<span class="math notranslate nohighlight">\(s_t = v_{MH}\)</span>) and is shown in blue, and the previous node we visited was Queens (<span class="math notranslate nohighlight">\(s_{t-1} = v_{Q}\)</span>) and is shown in orange. We just visited node <span class="math notranslate nohighlight">\(Q\)</span>, so the bias factor will be <span class="math notranslate nohighlight">\(\frac{1}{p}\)</span> (the edge is shown in orange). The node for Bronx has an edge back to Queens, so the bias factor will be <span class="math notranslate nohighlight">\(\frac{1}{q}\)</span> (the edge is shown in purple). The node for Brooklyn does not have an edge back to queens, so the bias is <span class="math notranslate nohighlight">\(1\)</span> (and the edge is shown in black):</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;tab:gray&quot;</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span>
                 <span class="n">font_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s2">&quot;whitesmoke&quot;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Bias factors where $s_t = v_</span><span class="si">{MH}</span><span class="s2">$ and $s_{t-1} = v_</span><span class="si">{Q}</span><span class="s2">$&quot;</span><span class="p">)</span>

<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">Ghl</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span>
                 <span class="n">font_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s2">&quot;whitesmoke&quot;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">Gin</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">()</span>
<span class="n">Gin</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;BK&quot;</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">Gin</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">Gin</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="s2">&quot;BK&quot;</span><span class="p">)</span>

<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">Gin</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;tab:purple&quot;</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span>
                 <span class="n">font_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s2">&quot;whitesmoke&quot;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">edge_color</span><span class="o">=</span><span class="s2">&quot;tab:purple&quot;</span><span class="p">,</span>
                 <span class="n">width</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">Gret</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">()</span>
<span class="n">Gret</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;Q&quot;</span><span class="p">)</span>
<span class="n">Gret</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;MH&quot;</span><span class="p">)</span>
<span class="n">Gret</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="s2">&quot;Q&quot;</span><span class="p">)</span>

<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">Gret</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;tab:orange&quot;</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span>
                 <span class="n">font_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s2">&quot;whitesmoke&quot;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">edge_color</span><span class="o">=</span><span class="s2">&quot;tab:orange&quot;</span><span class="p">,</span>
                 <span class="n">width</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">Ghl</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span>
                 <span class="n">font_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s2">&quot;whitesmoke&quot;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s2">&quot;bias: 1/p&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mf">4.75</span><span class="p">,</span> <span class="mf">3.75</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;tab:orange&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s2">&quot;bias: 1/q&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;tab:purple&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/random-walk-diffusion-methods_18_0.png" src="../../_images/random-walk-diffusion-methods_18_0.png" />
</div>
</div>
<p>If we were to tend to bias against returning (a large return parameter, say <span class="math notranslate nohighlight">\(p = 5\)</span>) and towards in-out (a small in-out parameter, say <span class="math notranslate nohighlight">\(q = \frac{1}{2}\)</span>), the bias vector will look like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="mi">5</span>  <span class="c1"># return parameter</span>
<span class="n">q</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span>  <span class="c1"># in-out parameter</span>
<span class="n">bias_vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">node_names</span><span class="p">))</span>
<span class="n">bias_vector</span><span class="p">[</span><span class="n">node_names</span> <span class="o">==</span> <span class="s2">&quot;Q&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">p</span>
<span class="n">bias_vector</span><span class="p">[</span><span class="n">node_names</span> <span class="o">==</span> <span class="s2">&quot;BK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">q</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="k">def</span> <span class="nf">plot_vec</span><span class="p">(</span><span class="n">vec</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">blockname</span><span class="o">=</span><span class="s2">&quot;Destination borough&quot;</span><span class="p">,</span> 
             <span class="n">blocklabs</span><span class="o">=</span><span class="n">node_names</span><span class="p">,</span>
             <span class="n">blocktix</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span> <span class="o">+</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">node_names</span><span class="p">))],</span>
             <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cbar_ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    
    <span class="k">if</span> <span class="n">vmax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">vmax</span> <span class="o">=</span> <span class="n">vec</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">sns</span><span class="o">.</span><span class="n">plotting_context</span><span class="p">(</span><span class="s2">&quot;talk&quot;</span><span class="p">,</span> <span class="n">font_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">cbar_ax</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">vec</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">vec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])),</span> <span class="n">cbar</span><span class="o">=</span><span class="n">cbar</span><span class="p">,</span> <span class="n">cbar_ax</span><span class="o">=</span><span class="n">cbar_ax</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Purples&quot;</span><span class="p">,</span>
                            <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">cbar_kws</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">shrink</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">vec</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">vec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])),</span> <span class="n">cbar</span><span class="o">=</span><span class="n">cbar</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Purples&quot;</span><span class="p">,</span>
                            <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">cbar_kws</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">shrink</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="n">blockname</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">blocktix</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">blocklabs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cbar_ax</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">cbar</span><span class="p">:</span>
            <span class="n">cbar</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">collections</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
            <span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">set_frame_on</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span>

<span class="n">plot_vec</span><span class="p">(</span><span class="n">bias_vector</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Bias vector where $s_t = v_</span><span class="si">{MH}</span><span class="s2">$ and $s_{t-1} = v_</span><span class="si">{Q}</span><span class="s2">$&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/random-walk-diffusion-methods_21_0.png" src="../../_images/random-walk-diffusion-methods_21_0.png" />
</div>
</div>
</div>
<div class="section" id="adjusting-the-transition-probabilities-with-the-bias-vector">
<h4><span class="section-number">6.4.2.1.2. </span>Adjusting the transition probabilities with the bias vector<a class="headerlink" href="#adjusting-the-transition-probabilities-with-the-bias-vector" title="Permalink to this headline">¶</a></h4>
<p>In our second order random walk, instead of the transition probabilities being a function only of the <em>current</em> state, they are also a function of the preceding state we were at <span class="math notranslate nohighlight">\(s_{t-1}\)</span>. This means that our transition probability matrix is going to look <em>different</em> based on which node we just came from. The transition probabilities are defined using the indexed <em>triplet</em> <span class="math notranslate nohighlight">\(p_{s_{t-1}ij}(p,q)\)</span>, where <span class="math notranslate nohighlight">\(s_{t-1}\)</span> is the preceding node we visited, <span class="math notranslate nohighlight">\(i\)</span> is the current node we are at, <span class="math notranslate nohighlight">\(j\)</span> is any other node in the network, and <span class="math notranslate nohighlight">\(p\)</span> and <span class="math notranslate nohighlight">\(q\)</span> are the return and in-out parameters respectively. The <strong>second-order biased transition factors</strong> the terms:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \beta_{s_{t-1}ij}(p,q) &amp;= \alpha_{ij}(p, q, s_{t-1})p_{ij}
\end{align*}\]</div>
<p>where <span class="math notranslate nohighlight">\(p_{ij}\)</span> are the first-order markov transition probabilities we used previously. These are called <em>second-order</em> because they depend on the current node, <span class="math notranslate nohighlight">\(i\)</span>, as well as the preceding node, <span class="math notranslate nohighlight">\(s_{t-1}\)</span>.</p>
<p>In effect, what this statement says is that all we do is <em>up</em> or <em>down</em>-weight (or don’t change it at all, if the bias factor is <span class="math notranslate nohighlight">\(1\)</span>) the probability <span class="math notranslate nohighlight">\(p_{ij}\)</span> of going from node <span class="math notranslate nohighlight">\(i\)</span> to node <span class="math notranslate nohighlight">\(j\)</span> based on the <em>bias factor</em> <span class="math notranslate nohighlight">\(\alpha_{ij}(p, q, s_{t-1})\)</span>. These are no longer probabilities, because starting at a node <span class="math notranslate nohighlight">\(i\)</span>, we might end up with the bias-adjusted transition factors no longer summing to one. This is because we did not require anything about how <span class="math notranslate nohighlight">\(\alpha_{ij}^{(t+1)}(p,q,s_{t-1})\)</span> behaved across all possible nodes <span class="math notranslate nohighlight">\(j\)</span> we could transition to from our current node <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p>Finally, we then use the biased transition factors to compute the <strong>second-order biased transition probabilities</strong>. These are just normalized versions of the biased transition factors, where we normalize to make sure that they all sum up to one (and hence, produce a valid transition probability from node <span class="math notranslate nohighlight">\(i\)</span> outwards):</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    p_{s_{t-1}ij}(p,q) &amp;= \frac{\beta_{s_{t-1}ij}(p,q)}{\sum_{j' = 1}^n\beta_{s_{t-1}ij'}(p,q)}
\end{align*}\]</div>
<p>Notice that in the denominator, that we are just normalizing the bias-adjusted transition factor by the sum of all the other bias-adjusted transition factors from node <span class="math notranslate nohighlight">\(i\)</span> to any other nodes <span class="math notranslate nohighlight">\(j'\)</span> in the network.</p>
<p>Next, we show how this computation works to update the transition probability vector from the Manhattan node to node <span class="math notranslate nohighlight">\(j\)</span> given a previous node of Queens. We begin by first starting with the first-order transition probability vector <span class="math notranslate nohighlight">\(\vec p_i\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xstart</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># starting vector at MH</span>
<span class="n">pvec</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">xstart</span>  <span class="c1"># probability vector is Pt*x</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_vec</span><span class="p">(</span><span class="n">pvec</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;first-order transition probabilities&quot;</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/random-walk-diffusion-methods_24_0.png" src="../../_images/random-walk-diffusion-methods_24_0.png" />
</div>
</div>
<p>Next, we compute the bias vector, exactly as we did previously:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_vec</span><span class="p">(</span><span class="n">bias_vector</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Bias vector where $s_t = v_</span><span class="si">{MH}</span><span class="s2">$ and $s_{t-1} = v_</span><span class="si">{Q}</span><span class="s2">$&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/random-walk-diffusion-methods_26_0.png" src="../../_images/random-walk-diffusion-methods_26_0.png" />
</div>
</div>
<p>The next step is to compute the second-order biased transition factors:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bias_factors</span> <span class="o">=</span> <span class="n">pvec</span><span class="o">*</span><span class="n">bias_vector</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_vec</span><span class="p">(</span><span class="n">bias_factors</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Second-order biased transition factors&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/random-walk-diffusion-methods_29_0.png" src="../../_images/random-walk-diffusion-methods_29_0.png" />
</div>
</div>
<p>And finally, to normalize the bias-adjusted transition factors to obtain the second-order biased transition probabilities. We compare the second-order biased transition probabilities to the first-order transition probabilities, so that you can see the impact that the second-order biasing procedure had on our probability vector:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">biased_pvec</span> <span class="o">=</span> <span class="n">bias_factors</span><span class="o">/</span><span class="n">bias_factors</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">cbar_ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">([</span><span class="mf">.91</span><span class="p">,</span> <span class="mf">.3</span><span class="p">,</span> <span class="mf">.03</span><span class="p">,</span> <span class="mf">.4</span><span class="p">])</span>

<span class="n">prob_vecs</span> <span class="o">=</span> <span class="p">[</span><span class="n">pvec</span><span class="p">,</span> <span class="n">biased_pvec</span><span class="p">,</span> <span class="n">biased_pvec</span><span class="p">]</span>
<span class="n">titles</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;first-order transition probs.&quot;</span><span class="p">,</span> <span class="s2">&quot;Second-order biased transition probs.&quot;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axs</span><span class="o">.</span><span class="n">flat</span><span class="p">):</span>
    <span class="n">plot_vec</span><span class="p">(</span><span class="n">prob_vecs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="n">i</span><span class="o">==</span><span class="mi">2</span><span class="p">,</span> 
             <span class="n">cbar_ax</span><span class="o">=</span> <span class="n">cbar_ax</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">2</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="n">titles</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="n">i</span><span class="o">=</span><span class="mi">2</span>
<span class="n">plot_vec</span><span class="p">(</span><span class="n">biased_pvec</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="n">i</span><span class="o">==</span><span class="mi">2</span><span class="p">,</span> 
             <span class="n">cbar_ax</span><span class="o">=</span> <span class="n">cbar_ax</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Second-order biased transition probs.&quot;</span><span class="p">)</span>
    
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">rect</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">.85</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/random-walk-diffusion-methods_32_0.png" src="../../_images/random-walk-diffusion-methods_32_0.png" />
</div>
</div>
<p>As we can see, our tendency to <em>return</em> to Queens (since we were just there in the previous step, <span class="math notranslate nohighlight">\(s_{t-1} = v_{Q}\)</span>) has decreased from the first-order transition probability to the second-order biased transition probability, due to the fact that the return parameter is big (<span class="math notranslate nohighlight">\(p = 5\)</span>). Further, our tendency to move in-out to Brooklyn (since Brooklyn has no edges to Queens) has increased from the first-order transition probability to the second-order biased transition probability, due to the fact that the in-out parameter is small (<span class="math notranslate nohighlight">\(q = 0.2\)</span>). The transition probability for the remaining nodes, such as BX, with a bias of <span class="math notranslate nohighlight">\(1\)</span> are less affected from the first-order to the second-order biased transition probability. We then just use the second-order biased transition probabilities to decide where to go next, and we take that step, shown in green:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># x vector indicating we start at MH</span>
<span class="c1"># choose the next node using the second-order biased transition probability</span>
<span class="n">next_node</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">node_names</span><span class="p">)),</span> <span class="n">p</span><span class="o">=</span><span class="n">biased_pvec</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Next node: </span><span class="si">{:s}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">node_names</span><span class="p">[</span><span class="n">next_node</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Next node: BX
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">next_name</span> <span class="o">=</span> <span class="n">node_names</span><span class="p">[</span><span class="n">next_node</span><span class="p">]</span>
<span class="n">Gnext</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">()</span>
<span class="n">Gnext</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;MH&quot;</span><span class="p">)</span>
<span class="n">Gnext</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">next_name</span><span class="p">)</span>
<span class="n">Gnext</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;MH&quot;</span><span class="p">,</span> <span class="n">next_name</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;tab:gray&quot;</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span>
        <span class="n">font_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s2">&quot;whitesmoke&quot;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">Gnext</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;tab:green&quot;</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span>
        <span class="n">font_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s2">&quot;whitesmoke&quot;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">edge_color</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">Ghl</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span>
        <span class="n">font_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s2">&quot;whitesmoke&quot;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;1-step of a second-order random walk starting at MH&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/random-walk-diffusion-methods_35_0.png" src="../../_images/random-walk-diffusion-methods_35_0.png" />
</div>
</div>
<div class="admonition-generating-a-realization-of-a-second-order-biased-random-walk admonition">
<p class="admonition-title">Generating a realization of a second-order biased random walk</p>
<p>Now that we’ve learned how to make a single step in a second-order biased random walk, we are ready to generate a realization of a second-order biased random walk. Given a source node <span class="math notranslate nohighlight">\(s_0 = i\)</span>, a network <span class="math notranslate nohighlight">\(G\)</span> with nodes and edges, an in-out parameter <span class="math notranslate nohighlight">\(q\)</span>, a return parameter <span class="math notranslate nohighlight">\(p\)</span>, and a number of steps to proceed <span class="math notranslate nohighlight">\(T\)</span>, we take the following procedure:</p>
<ol class="simple">
<li><p>Generate the first-order transition probability matrix, <span class="math notranslate nohighlight">\(P\)</span>, using the adjacency matrix of the network, <span class="math notranslate nohighlight">\(A\)</span>.</p></li>
<li><p>Perform a first-order random walk from the source node <span class="math notranslate nohighlight">\(i\)</span> to the first step in our random walk, <span class="math notranslate nohighlight">\(s_1 = i'\)</span>.</p></li>
<li><p>For <span class="math notranslate nohighlight">\(t = 2:T\)</span>:</p>
<ul class="simple">
<li><p>compute the bias from <span class="math notranslate nohighlight">\(s_{t-1}\)</span> to all of the other nodes <span class="math notranslate nohighlight">\(j\)</span> in the network given that the preceding node was <span class="math notranslate nohighlight">\(s_{t-2}\)</span>, <span class="math notranslate nohighlight">\(\alpha_{s_{t-2}s_{t-1}j}(p,q)\)</span>.</p></li>
<li><p>using the bias <span class="math notranslate nohighlight">\(\vec\alpha_{s_{t-2}s_{t-1}j}(p,q)\)</span> and the first-order transition probability <span class="math notranslate nohighlight">\(p_{s_{t-1}j}\)</span>, compute the second-order bias factor <span class="math notranslate nohighlight">\(\beta_{s_{t-2}s_{t-1}j}(p,q)\)</span> for each node <span class="math notranslate nohighlight">\(j\)</span> in the network.</p></li>
<li><p>normalize the second-order bias factors <span class="math notranslate nohighlight">\(\beta_{s_{t-2}s_{t-1}j}(p,q)\)</span> to obtain the second-order transition probabilities <span class="math notranslate nohighlight">\(p_{s_{t-2}s_{t-1}j}(p,q)\)</span>.</p></li>
<li><p>choose the next node to visit <span class="math notranslate nohighlight">\(s_t\)</span>, by selecting node <span class="math notranslate nohighlight">\(j\)</span> with probability <span class="math notranslate nohighlight">\(p_{s_{t-2}s_{t-1}j}(p,q)\)</span>.</p></li>
</ul>
</li>
</ol>
<p>The sequence <span class="math notranslate nohighlight">\(\{s_0, s_1, ..., s_T\}\)</span> is a realization of a <span class="math notranslate nohighlight">\(T\)</span>-step second-order biased random walk along the network <span class="math notranslate nohighlight">\(G\)</span> with parameters <span class="math notranslate nohighlight">\((p,q)\)</span>.</p>
</div>
</div>
</div>
</div>
<div class="section" id="node2vec-embedding">
<h2><span class="section-number">6.4.3. </span>node2vec embedding<a class="headerlink" href="#node2vec-embedding" title="Permalink to this headline">¶</a></h2>
<p>Now that we know about second-order biased random walks, we are ready to approach our problem at hand: leveraging random walks to produce structured embeddings. We have one final ingredient to embed our networks: the <code class="docutils literal notranslate"><span class="pre">word2vec</span></code> algorithm.</p>
<div class="section" id="word2vec">
<h3><span class="section-number">6.4.3.1. </span>Word2vec<a class="headerlink" href="#word2vec" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">word2vec</span></code> algorithm is a technique for natural language processing (NLP) developed in 2013 by a team of researchers at Google led by Tomas Mikolov. The algorithm takes in large collections of text data, called a <em>corpus</em>. The algorithm takes this <em>corpus</em> of text along with a desired number of embedding dimensions <span class="math notranslate nohighlight">\(d\)</span>, and embeds every possible word in the corpus into a <span class="math notranslate nohighlight">\(d\)</span>-dimensional space such that the <em>contexts</em> of the words frequently used together are preserved. In this case, a <em>context</em> refers to words which tend to convey similar meaning (they are synonyms), words which tend to precede be used together (for instance, “learning” and “intelligence”), and many other attributes of the words. When we say “preserved”, what we mean is that words that have similar contexts tend to be closer together in the embedded space. This embedding can then be used for many things, such as guessing the synonyms of words, suggesting next words for a sentence, and many other things.</p>
<p>We won’t go into too many details here, because the procedure for <code class="docutils literal notranslate"><span class="pre">word2vec</span></code> requires some heavy background in neural networks which we’ll learn in a much more general context about in the next section when we cover <a class="reference external" href="#link?">Graph Neural Networks</a>. If you want to learn more about <code class="docutils literal notranslate"><span class="pre">word2vec</span></code>, we would suggest you dig up some blog posts on sites like medium, or by checking out the original papers by Mikolov and his team, of which the first can be found <a class="reference external" href="https://arxiv.org/abs/1301.3781">here</a> and the second can be found <a class="reference external" href="https://arxiv.org/abs/1310.4546">here</a>.</p>
</div>
<div class="section" id="using-node2vec-to-embed-the-network">
<h3><span class="section-number">6.4.3.2. </span>Using node2vec to embed the network<a class="headerlink" href="#using-node2vec-to-embed-the-network" title="Permalink to this headline">¶</a></h3>
<p>To begin the <code class="docutils literal notranslate"><span class="pre">node2vec</span></code> procedure, we take our collection of nodes and the desired number of embedding dimensions <span class="math notranslate nohighlight">\(d\)</span>. Then, for each node, we generate a random walk of length <span class="math notranslate nohighlight">\(T\)</span> using the given node as the starting node with parameters <span class="math notranslate nohighlight">\((p,q)\)</span>, as we did above. This gives us a collection of random walks with disparate starting nodes in the network. We repeat this procedure a number of times for each possible starting node. Next, we “pretend” that node names are words, and we simply feed the collections of random walks we generated into <code class="docutils literal notranslate"><span class="pre">word2vec</span></code> algorithm as our “corpus” of text along with the desired number of embedding dimensions <span class="math notranslate nohighlight">\(d\)</span>. This produces for us a structured <span class="math notranslate nohighlight">\(d\)</span>-dimensional embedding of each node in the network. Nodes which tend to be along random walks together tend to end up closer in the embedding space, and nodes which do not tend to be along random walks together tend to end up further in the embedding space.</p>
<p>Let’s try embedding an SBM using <code class="docutils literal notranslate"><span class="pre">node2vec</span></code>. We’re going to leave the in-out and return parameters both equal to one, for now; e.g., <span class="math notranslate nohighlight">\(p = q = 1\)</span>. We will generate <span class="math notranslate nohighlight">\(20\)</span> random walks starting at each node (<span class="math notranslate nohighlight">\(w = 20\)</span>), and each walk will have a length of <span class="math notranslate nohighlight">\(200\)</span> steps (<span class="math notranslate nohighlight">\(T = 200\)</span>). The network is going to be the same network we used from the section on the <a class="reference external" href="#link?">Two-Truths Phenomenon</a>, and we show the probability matrix on the left with a realization on the right:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">graspologic</span> <span class="k">as</span> <span class="nn">gp</span>

<span class="n">n1</span> <span class="o">=</span> <span class="mi">50</span><span class="p">;</span> <span class="n">n2</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">Baff</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]]</span>

<span class="n">zvecaff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s2">&quot;C1&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n1</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;C2&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n2</span><span class="p">)])</span>

<span class="c1"># the probability matrix</span>
<span class="n">zvecaff_ohe</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n1</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n2</span><span class="p">)])</span>
<span class="n">Paff</span> <span class="o">=</span> <span class="n">zvecaff_ohe</span> <span class="o">@</span> <span class="n">Baff</span> <span class="o">@</span> <span class="n">zvecaff_ohe</span><span class="o">.</span><span class="n">T</span>

<span class="n">np1</span> <span class="o">=</span> <span class="mi">15</span><span class="p">;</span> <span class="n">nc</span> <span class="o">=</span> <span class="mi">70</span><span class="p">;</span> <span class="n">np2</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">Bcp</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
      <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
      <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]]</span>


<span class="n">zveccp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s2">&quot;Per.&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np1</span><span class="p">)]</span> <span class="o">+</span>
                  <span class="p">[</span><span class="s2">&quot;Core&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">nc</span><span class="p">)]</span> <span class="o">+</span>
                  <span class="p">[</span><span class="s2">&quot;Per.&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np2</span><span class="p">)])</span>

<span class="c1"># the probability matrix</span>
<span class="n">zveccp_ohe</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np1</span><span class="p">)]</span> <span class="o">+</span> 
                       <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">nc</span><span class="p">)]</span> <span class="o">+</span>
                       <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np2</span><span class="p">)])</span>
<span class="n">Pcp</span> <span class="o">=</span> <span class="n">zveccp_ohe</span> <span class="o">@</span> <span class="n">Bcp</span> <span class="o">@</span> <span class="n">zveccp_ohe</span><span class="o">.</span><span class="n">T</span>

<span class="n">P_aff_and_cp</span> <span class="o">=</span> <span class="p">(</span><span class="n">Pcp</span> <span class="o">+</span> <span class="n">Paff</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="n">A_aff_and_cp</span> <span class="o">=</span>  <span class="n">gp</span><span class="o">.</span><span class="n">simulations</span><span class="o">.</span><span class="n">sample_edges</span><span class="p">(</span><span class="n">P_aff_and_cp</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">cmaps</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>

<span class="n">gp</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">P_aff_and_cp</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">zveccp</span><span class="p">,</span> <span class="n">outer_hier_labels</span><span class="o">=</span><span class="n">zvecaff</span><span class="p">,</span>
                <span class="n">title</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmaps</span><span class="p">[</span><span class="s2">&quot;sequential&quot;</span><span class="p">]);</span>
<span class="n">gp</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">A_aff_and_cp</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">zveccp</span><span class="p">,</span> <span class="n">outer_hier_labels</span><span class="o">=</span><span class="n">zvecaff</span><span class="p">,</span>
                <span class="n">title</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmaps</span><span class="p">[</span><span class="s2">&quot;sequential&quot;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/random-walk-diffusion-methods_38_0.png" src="../../_images/random-walk-diffusion-methods_38_0.png" />
</div>
</div>
<p>The resulting embedding produces node embedding vectors which are organized like this, viewed from a pairs plot:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.embed</span> <span class="kn">import</span> <span class="n">node2vec_embed</span> <span class="k">as</span> <span class="n">node2vec</span>

<span class="n">p</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">q</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">w</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span> <span class="n">T</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">d</span> <span class="o">=</span> <span class="mi">4</span>  <span class="c1"># number of embedding dimensions to use</span>
<span class="n">Xhat</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">node2vec</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">from_numpy_matrix</span><span class="p">(</span><span class="n">A_aff_and_cp</span><span class="p">),</span> <span class="n">return_hyperparameter</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">p</span><span class="p">),</span>
                     <span class="n">inout_hyperparameter</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">q</span><span class="p">),</span> <span class="n">dimensions</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">num_walks</span><span class="o">=</span><span class="n">w</span><span class="p">,</span> <span class="n">walk_length</span><span class="o">=</span><span class="n">T</span><span class="p">,</span>
                     <span class="n">iterations</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.plot</span> <span class="kn">import</span> <span class="n">pairplot</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">pairplot</span><span class="p">(</span><span class="n">Xhat</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">zvecaff</span><span class="p">,</span> <span class="n">legend_name</span><span class="o">=</span><span class="s2">&quot;Community&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/random-walk-diffusion-methods_41_0.png" src="../../_images/random-walk-diffusion-methods_41_0.png" />
</div>
</div>
<p>Looking at this pairs plot, we can see that the disparity between communities one and two is largely captured by the first embedding dimension.</p>
<p>We can also look at this embedding using a heatmap of the individual nodes in the network, like we did for <code class="docutils literal notranslate"><span class="pre">ASE</span></code> and <code class="docutils literal notranslate"><span class="pre">LSE</span></code>:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_lpm</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">xticklabs</span><span class="o">=</span><span class="p">[],</span>
            <span class="n">yticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticklabs</span><span class="o">=</span><span class="p">[],</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="n">cbar</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Latent Dimension&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Node&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">xticks</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">xticklabs</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">yticks</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">yticklabs</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">);</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="n">plot_lpm</span><span class="p">(</span><span class="n">Xhat</span><span class="p">,</span> <span class="n">xticks</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Node2vec embedding of Adj. Matrix&quot;</span><span class="p">,</span>
         <span class="n">xticklabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Dim. 1&quot;</span><span class="p">,</span> <span class="s2">&quot;Dim. 2&quot;</span><span class="p">,</span> <span class="s2">&quot;Dim. 3&quot;</span><span class="p">,</span> <span class="s2">&quot;Dim. 4&quot;</span><span class="p">],</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">49</span><span class="p">],</span> <span class="n">yticklabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;26&quot;</span><span class="p">,</span> <span class="s2">&quot;50&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/random-walk-diffusion-methods_43_0.png" src="../../_images/random-walk-diffusion-methods_43_0.png" />
</div>
</div>
</div>
<div class="section" id="why-do-we-need-a-second-order-biased-random-walk-to-generate-an-embedding">
<h3><span class="section-number">6.4.3.3. </span>Why do we need a second-order biased random walk to generate an embedding?<a class="headerlink" href="#why-do-we-need-a-second-order-biased-random-walk-to-generate-an-embedding" title="Permalink to this headline">¶</a></h3>
<p>You will notice that if we set <span class="math notranslate nohighlight">\(p=q=1\)</span>, the first-order random walk and the second-order biased random walk turn out to be identical. This is because the biases all turn out to be one, so the “bias factors” turn out to really just be the first-order transition probabilities from the normal random walk. So why do we want the flexibility of the second-order biased random walk, if we can embed our network using the first-order random walk?</p>
<p>The reason is that the second-order biased random walk gives us <em>flexibility</em>. You will notice that since the <code class="docutils literal notranslate"><span class="pre">node2vec</span></code> procedure relies on the “corpus” of random walks, that the behavior of these random walks will have a <em>substantial</em> influence on the resulting embedding. Let’s see what happens to our embeddings as we tend to favor moving within the same nodes for our random walks more, which means punishing in-out movements (<span class="math notranslate nohighlight">\(q\)</span> is larger, so let’s use <span class="math notranslate nohighlight">\(q=5\)</span>) and up-weighting return movements (<span class="math notranslate nohighlight">\(p\)</span> is smaller, so let’s use <span class="math notranslate nohighlight">\(p = 0.2\)</span>):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">;</span> <span class="n">q</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">d</span> <span class="o">=</span> <span class="mi">4</span>  <span class="c1"># number of embedding dimensions to use</span>
<span class="n">Xhat</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">node2vec</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">from_numpy_matrix</span><span class="p">(</span><span class="n">A_aff_and_cp</span><span class="p">),</span> <span class="n">return_hyperparameter</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">p</span><span class="p">),</span>
                     <span class="n">inout_hyperparameter</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">q</span><span class="p">),</span> <span class="n">dimensions</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">num_walks</span><span class="o">=</span><span class="n">w</span><span class="p">,</span> <span class="n">walk_length</span><span class="o">=</span><span class="n">T</span><span class="p">,</span>
                     <span class="n">iterations</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">pairplot</span><span class="p">(</span><span class="n">Xhat</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">zvecaff</span><span class="p">,</span> <span class="n">legend_name</span><span class="o">=</span><span class="s2">&quot;Community&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/random-walk-diffusion-methods_46_0.png" src="../../_images/random-walk-diffusion-methods_46_0.png" />
</div>
</div>
<p>It looks like dimensions one and two do a great job of capturing the differences between the two communities.</p>
<p>Simultaneously, when we remember that the <code class="docutils literal notranslate"><span class="pre">node2vec</span></code> algorithm builds off the idea of the <code class="docutils literal notranslate"><span class="pre">word2vec</span></code> algorithm at preserving nodes which have a similar <em>context</em>, we know that the core nodes all share a similar context (they are more strongly connected) than the peripheral nodes (which are less strongly connected). When we plot which nodes are core and which are periphery, we see that:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">pairplot</span><span class="p">(</span><span class="n">Xhat</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">zveccp</span><span class="p">,</span> <span class="n">legend_name</span><span class="o">=</span><span class="s2">&quot;Node type&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/random-walk-diffusion-methods_48_0.png" src="../../_images/random-walk-diffusion-methods_48_0.png" />
</div>
</div>
<p>The core nodes (in blue) all tend to be relatively tightly clustered around the around the center across all of the dimensions, and the periphery nodes (in red) tend to be on the exterior of the blob of data. If we have a clustering technique could determine which nodes were in the center versus which nodes were in the exterior, we could effectively capture the core versus the periphery nodes.</p>
<p>We will learn more about how we can use <code class="docutils literal notranslate"><span class="pre">node2vec</span></code> to capture both “truths” from our data in the section on <a class="reference external" href="#link?">Community Detection</a>. Toying around further with these different parameters can yield us very different ways to represent the same network in Euclidean space, and unlike spectral methods, random-walk based methods can preserve numerous desirable properties of our network such as affinity and core-periphery <em>concurrently</em>.</p>
</div>
</div>
<div class="section" id="extending-to-weighted-and-directed-networks">
<h2><span class="section-number">6.4.4. </span>Extending to weighted and directed networks<a class="headerlink" href="#extending-to-weighted-and-directed-networks" title="Permalink to this headline">¶</a></h2>
<p>It is extremely easy to adapt the strategies we have developed so far to weighted or directed networks. If your network takes non-negative weights, and the weights <span class="math notranslate nohighlight">\(w_{ij}\)</span> can be interpreted to indicate the “strength” of a connection between a node <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>, you can just let the transition probabilities <span class="math notranslate nohighlight">\(p_{ij}\)</span> be the weights normalized by the out-degree from node <span class="math notranslate nohighlight">\(i\)</span>; that is:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    p_{ij} &amp;= \frac{w_{ij}}{d_i}
\end{align*}\]</div>
<p>where the out-degree is the quantity <span class="math notranslate nohighlight">\(d_i = \sum_{j = 1}^n w_{ij}\)</span>.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./representations/ch6"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="estimating-parameters_spectral.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">6.3. </span>Estimating Parameters for the RDPG</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="graph-neural-networks.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">6.5. </span>Graph Neural Networks</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Eric Bridgeford, Alex Loftus, and Joshua Vogelstein<br/>
    
        &copy; Copyright 2022.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>