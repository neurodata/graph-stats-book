
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>8.1. Anomaly Detection For Timeseries of Networks &#8212; Hands-on Network Machine Learning with Scikit-Learn and Graspologic</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="8.2. Testing for Significant Edges" href="significant-edges.html" />
    <link rel="prev" title="8. Applications for Many Networks" href="ch9.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Hands-on Network Machine Learning with Scikit-Learn and Graspologic</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../coverpage.html">
                    Hands-on Network Machine Learning with Scikit-Learn and Graspologic
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/terminology.html">
   Terminology
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch1/ch1.html">
   1. The Network Machine Learning Landscape
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/what-is-a-network.html">
     1.1. What is network machine learning?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/why-study-networks.html">
     1.2. Why do we study networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/types-nml-problems.html">
     1.3. Types of Network Machine Learning Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/examples-of-applications.html">
     1.4. Examples of applications
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/challenges-of-nml.html">
     1.5. Challenges of Network Machine Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch2/ch2.html">
   2. End-to-end Biology Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/big-picture.html">
     2.1. Look at the big picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/get-the-data.html">
     2.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/prepare-the-data.html">
     2.3. Prepare the Data for Network Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/select-and-train.html">
     2.4. Select and Train a Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/fine-tune.html">
     2.5. Fine-Tune your Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/discover-and-visualize.html">
     2.6. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Representations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch4/ch4.html">
   3. Properties of Networks as a Statistical Object
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/matrix-representations.html">
     3.1. Matrix Representations Of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/properties-of-networks.html">
     3.2. Properties of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/network-representations.html">
     3.3. Representations of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/regularization.html">
     3.4. Regularization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch5/ch5.html">
   4. Why Use Statistical Models?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_ER.html">
     4.1. Erdös-Rényi (ER) Random Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_SBM.html">
     4.2. Stochastic Block Models (SBM)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_RDPG.html">
     4.3. Random Dot Product Graphs (RDPG)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_IER.html">
     4.4. Inhomogeneous Erdos Renyi (IER) Random Network Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/multi-network-models.html">
     4.5. Multiple Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/models-with-covariates.html">
     4.6. Network Models with Network Covariates
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch6/ch6.html">
   5. Learning Network Representations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/estimating-parameters_mle.html">
     5.1. Estimating Parameters in Network Models via MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/why-embed-networks.html">
     5.2. Why embed networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/spectral-embedding.html">
     5.3. Spectral embedding methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/multigraph-representation-learning.html">
     5.4. Multiple-Network Representation Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/joint-representation-learning.html">
     5.5. Joint Representation Learning
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch7/ch7.html">
   6. Applications When You Have One Network
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/community-detection.html">
     6.1. Community Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/testing-differences.html">
     6.2. Testing for Differences between Groups of Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/model-selection.html">
     6.3. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/vertex-nomination.html">
     6.4. Single-Network Vertex Nomination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/out-of-sample.html">
     6.5. Out-of-sample Embedding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch8/ch8.html">
   7. Applications for Two Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch8/two-sample-hypothesis.html">
     7.1. Latent Two-Sample Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch8/significant-communities.html">
     7.2. Two-sample hypothesis testing in SBMs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch8/graph-matching-vertex.html">
     7.3. Graph Matching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch8/multiple-vertex-nomination.html">
     7.4. Vertex Nomination For Two Networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="ch9.html">
   8. Applications for Many Networks
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     8.1. Anomaly Detection For Timeseries of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="significant-edges.html">
     8.2. Testing for Significant Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="significant-vertices.html">
     8.3. Testing for Significant Vertices
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Next Steps
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../next/ch10/ch10.html">
   9. Where do we go from here?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../next/ch10/random-walk-diffusion-methods.html">
     9.1. Random walk and diffusion-based methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../next/ch10/gnn.html">
     9.2. Graph classification
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Appendix
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../appendix/ch11/ch11.html">
   10. Representations (Extended)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch11/alt-reps.html">
     10.1. Alternative Network Representations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../appendix/ch12/ch12.html">
   11. Network Model Theory
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch12/background.html">
     11.1. Background
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch12/foundation.html">
     11.2. Foundation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch12/ers.html">
     11.3. Erdös-Rényi (ER) Random Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch12/sbms.html">
     11.4. Stochastic Block Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch12/rdpgs.html">
     11.5. RDPGs and more general network models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../appendix/ch13/ch13.html">
   12. Learning Representations Theory
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch13/mle-theory.html">
     12.1. Maximum Likelihood Estimate Theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch13/lse.html">
     12.2. Finding singular vectors With singular value decomposition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch13/spectral-theory.html">
     12.7. Spectral Method Theory
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../appendix/ch14/ch14.html">
   13. Applications (Extended)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch14/hypothesis.html">
     13.1. Hypothesis Testing with coin flips
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch14/unsupervised.html">
     13.2. Unsupervised learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch14/bayes.html">
     13.3. Bayes Plugin Classifier
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://graspologic.readthedocs.io/en/latest/">
   Graspologic Documentation
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/neurodata/graph-stats-book/master?urlpath=tree/network_machine_learning_in_python/applications/ch9/anomaly-detection.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/neurodata/graph-stats-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/neurodata/graph-stats-book/issues/new?title=Issue%20on%20page%20%2Fapplications/ch9/anomaly-detection.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/neurodata/graph-stats-book/edit/master/network_machine_learning_in_python/applications/ch9/anomaly-detection.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/applications/ch9/anomaly-detection.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulating-network-timeseries-data">
   8.1.1. Simulating Network Timeseries Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#approaches-for-anomaly-detection">
   8.1.2. Approaches for Anomaly Detection
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#challenges-of-anomaly-detection">
     8.1.2.1. Challenges of anomaly detection
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-nonidentifiability-problem">
       8.1.2.1.1. The nonidentifiability problem
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#we-only-get-to-obtain-estimates-of-latent-positions">
       8.1.2.1.2. We only get to obtain estimates of latent positions
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#detecting-if-the-first-time-point-is-an-anomaly">
   8.1.3. Detecting if the First Time Point is an Anomaly
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hypothesis-testing-with-our-test-statistic">
   8.1.4. Hypothesis Testing With our Test Statistic
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generating-the-null-distribution-of-each-pair-of-timepoints-using-the-parametric-bootstrap">
     8.1.4.1. Generating the null distribution of each pair of timepoints using the parametric bootstrap
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#estimating-the-p-value-using-the-bootstrapped-samples">
     8.1.4.2. Estimating the
     <span class="math notranslate nohighlight">
      \(p\)
     </span>
     -value using the bootstrapped samples
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-distribution-of-the-bootstrapped-test-statistic">
   8.1.5. The Distribution of the Bootstrapped Test Statistic
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Anomaly Detection For Timeseries of Networks</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulating-network-timeseries-data">
   8.1.1. Simulating Network Timeseries Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#approaches-for-anomaly-detection">
   8.1.2. Approaches for Anomaly Detection
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#challenges-of-anomaly-detection">
     8.1.2.1. Challenges of anomaly detection
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-nonidentifiability-problem">
       8.1.2.1.1. The nonidentifiability problem
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#we-only-get-to-obtain-estimates-of-latent-positions">
       8.1.2.1.2. We only get to obtain estimates of latent positions
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#detecting-if-the-first-time-point-is-an-anomaly">
   8.1.3. Detecting if the First Time Point is an Anomaly
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hypothesis-testing-with-our-test-statistic">
   8.1.4. Hypothesis Testing With our Test Statistic
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generating-the-null-distribution-of-each-pair-of-timepoints-using-the-parametric-bootstrap">
     8.1.4.1. Generating the null distribution of each pair of timepoints using the parametric bootstrap
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#estimating-the-p-value-using-the-bootstrapped-samples">
     8.1.4.2. Estimating the
     <span class="math notranslate nohighlight">
      \(p\)
     </span>
     -value using the bootstrapped samples
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-distribution-of-the-bootstrapped-test-statistic">
   8.1.5. The Distribution of the Bootstrapped Test Statistic
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="anomaly-detection-for-timeseries-of-networks">
<span id="ch9-anomaly"></span><h1><span class="section-number">8.1. </span>Anomaly Detection For Timeseries of Networks<a class="headerlink" href="#anomaly-detection-for-timeseries-of-networks" title="Permalink to this headline">#</a></h1>
<p>There is a particular type of sea slug which has gills on the outside of its body. When you squirt water at these gills, they withdraw into the slug. The interesting thing about this type of slug is that the brain network involved in this gill withdrawal reflex is entirely mapped out, from the neurons which detect and transmit information about the water into the slug’s brain, to the neurons that leave the brain and fire at its muscles. (For those interested, this is a real thing - look up Eric Kandel’s research on Aplysia!)</p>
<p>Say you’re a researcher studying these sea slugs, and you have a bunch of brain networks of the same slug. We can define each node as a single neuron, and edges denote connections between neurons. Each of the brain networks that you have were taken at different time points: some before water started getting squirted at the slug’s gills, and some as the water was getting squirted. Your goal is to reconstruct when water started to get squirted, using only the networks themselves. You hypothesize that there should be some signal change in your networks which can tell you the particular time at which water started getting squirted. Given the network data you have, how do you figure out which timepoints these are?</p>
<p>The broader class of problems this question addresses is called <em>anomaly detection</em>. The idea, in general, is that you have a bunch of snapshots of the same network over time. Although the nodes are the same, the edges are changing at each time point. Your goal is to figure out which time points correspond to the most change, either in the entire network or in particular groups of nodes. You can think of a network as “anomalous” with respect to time if some potentially small group of nodes within the network concurrently changes behavior at some point in time compared to the recent past, while the remaining nodes continue with whatever noisy, normal behavior they had.</p>
<p>In particular, what we would really like to do is separate the signal from the noise. All of the nodes in the network are likely changing a bit over time, since there is some variability intrinsic in the system. Random noise might just dictate that some edges get randomly deleted and some get randomly created at each step. We want to figure out if there are timepoints where the change isn’t just random noise: we’re trying to figure out a point in time where the probability distribution that the network <em>itself</em> is generated from changes.</p>
<p>Let’s simulate some network timeseries data so that we can explore anomaly detection more thoroughly.</p>
<section id="simulating-network-timeseries-data">
<h2><span class="section-number">8.1.1. </span>Simulating Network Timeseries Data<a class="headerlink" href="#simulating-network-timeseries-data" title="Permalink to this headline">#</a></h2>
<p>For this example, we’re going to assume that our sea slug brain is measured for at <span class="math notranslate nohighlight">\(12\)</span> points in time. Each network has <span class="math notranslate nohighlight">\(100\)</span> nodes, and for each time point, each node has a latent position. The non-anomalous time points (ten of the time points) will have the same latent positions, and the anomalous time points between <span class="math notranslate nohighlight">\(t=6\)</span> and <span class="math notranslate nohighlight">\(t=8\)</span> will have different latent positions.</p>
<p>To make the ten non-anomalous timepoints, we’ll:</p>
<ol class="simple">
<li><p>Generate 100 latent positions. Each latent position <span class="math notranslate nohighlight">\(x_i^{(N)}\)</span> will be a (uniformly) random number between 0.2 and 0.8, for <span class="math notranslate nohighlight">\(i\)</span> from <span class="math notranslate nohighlight">\(1\)</span> to <span class="math notranslate nohighlight">\(100\)</span>.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">graspologic</span></code>’s <code class="docutils literal notranslate"><span class="pre">rdpg</span></code> to sample an adjacency matrix using the one-dimensional latent position matrix, <span class="math notranslate nohighlight">\(X^{(N)}_t\)</span>, whose rows are the latent positions <span class="math notranslate nohighlight">\(x_i^{(N)}\)</span>. Do this ten times, to generate the networks with adjacency matrices <span class="math notranslate nohighlight">\(A^{(t)}\)</span>, where <span class="math notranslate nohighlight">\(t\)</span> is between <span class="math notranslate nohighlight">\(1\)</span> and <span class="math notranslate nohighlight">\(12\)</span> and excluding <span class="math notranslate nohighlight">\(6\)</span> through <span class="math notranslate nohighlight">\(8\)</span>.</p></li>
</ol>
<p>And to make the two perturbed time points, we’ll do the following twice:</p>
<ol class="simple">
<li><p>The first <span class="math notranslate nohighlight">\(20\)</span> latent positions will be uniform random numbers between <span class="math notranslate nohighlight">\(0.6\)</span> and <span class="math notranslate nohighlight">\(1.0\)</span>. These latent positions will be denoted <span class="math notranslate nohighlight">\(x_i^{(A,t)}\)</span> respectively. The remaining <span class="math notranslate nohighlight">\(80\)</span> latent positions will be the same for all nodes as they were for the non-anomalous timepoints, <span class="math notranslate nohighlight">\(x_i^{(N)}\)</span>.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">graspologic</span></code>’s <code class="docutils literal notranslate"><span class="pre">rdpg</span></code> to sample an adjacency matrix using the one-dimensional latent position matrix, <span class="math notranslate nohighlight">\(X_t^{(A, t)}\)</span>, whose first twenty rows are the latent positions <span class="math notranslate nohighlight">\(x_i^{(A, t)}\)</span> and whose remaining <span class="math notranslate nohighlight">\(80\)</span> rows are the latent positions <span class="math notranslate nohighlight">\(x_i^{(N)}\)</span>. This generates the anomalous networks with adjacency matrices <span class="math notranslate nohighlight">\(A^{(t)}\)</span>, which have different latent positions from the non-anomalous networks.</p></li>
</ol>
<p>Once we have this simulated data, we’ll move into some discussion about how we’ll approach detecting the anomalous time points.</p>
<p>Below is code for generating the data. We define a function to generate a particular time-point, with an argument which toggles whether we’ll perturb latent positions for that time point. Then, we just loop through our time-points to sample an adjacency matrix for each one.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">rdpg</span>
    
<span class="n">T</span> <span class="o">=</span> <span class="mi">12</span>  <span class="c1"># number of timepoints</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># number of nodes</span>
<span class="c1"># non-anomalous latent positions</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">.2</span><span class="p">,</span> <span class="mf">.8</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="c1"># array of latent positions for each time point</span>
<span class="n">Xts</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">time</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">time</span> <span class="o">&gt;</span> <span class="mi">4</span> <span class="ow">and</span> <span class="n">time</span> <span class="o">&lt;</span> <span class="mi">7</span><span class="p">:</span>
        <span class="n">Xt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">Xt</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">20</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">.6</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">Xts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Xt</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">Xts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">networks</span> <span class="o">=</span> <span class="p">[</span><span class="n">rdpg</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">for</span> <span class="n">X</span> <span class="ow">in</span> <span class="n">Xts</span><span class="p">]</span>

<span class="n">networks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">networks</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You can see the adjacency matrices we generated below. Note that you can’t really distinguish a difference between the ten non-anomylous time points and the two perturbed time points with the naked eye, even though the difference is there, so it would be pretty difficult to manually mark the time points - and if you have many time points, rather than just a few, you’d want to be able to automate the process.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">heatmap</span><span class="p">,</span> <span class="n">cmaps</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="k">def</span> <span class="nf">rm_ticks</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">();</span>

<span class="c1"># adjacency matrices</span>
<span class="n">perturbed_points</span> <span class="o">=</span> <span class="p">{</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">}</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">time_points</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">perturbed_points</span><span class="p">:</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">([</span><span class="mf">.02</span><span class="o">*</span><span class="n">i</span><span class="p">,</span> <span class="o">-</span><span class="mf">.02</span><span class="o">*</span><span class="n">i</span><span class="p">,</span> <span class="mf">.8</span><span class="p">,</span> <span class="mf">.8</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">([</span><span class="mf">.02</span><span class="o">*</span><span class="n">i</span><span class="o">+</span><span class="mf">.8</span><span class="p">,</span> <span class="o">-</span><span class="mf">.02</span><span class="o">*</span><span class="n">i</span><span class="p">,</span> <span class="mf">.8</span><span class="p">,</span> <span class="mf">.8</span><span class="p">])</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">heatmap</span><span class="p">(</span><span class="n">networks</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Ten Normal Time Points&quot;</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Two Perturbed Time Points&quot;</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">rm_ticks</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">figtext</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mf">.3</span><span class="p">,</span> <span class="s2">&quot;Figure 8.1&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Network Timeseries Data&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="mi">1</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">Input In [2],</span> in <span class="ni">&lt;cell line: 16&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span> <span class="c1"># adjacency matrices</span>
<span class="g g-Whitespace">     </span><span class="mi">15</span> <span class="n">perturbed_points</span> <span class="o">=</span> <span class="p">{</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">}</span>
<span class="ne">---&gt; </span><span class="mi">16</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">time_points</span><span class="p">):</span>
<span class="g g-Whitespace">     </span><span class="mi">17</span>     <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">perturbed_points</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">18</span>         <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">([</span><span class="mf">.02</span><span class="o">*</span><span class="n">i</span><span class="p">,</span> <span class="o">-</span><span class="mf">.02</span><span class="o">*</span><span class="n">i</span><span class="p">,</span> <span class="mf">.8</span><span class="p">,</span> <span class="mf">.8</span><span class="p">])</span>

<span class="ne">NameError</span>: name &#39;time_points&#39; is not defined
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Figure size 432x288 with 0 Axes&gt;
</pre></div>
</div>
</div>
</div>
</section>
<section id="approaches-for-anomaly-detection">
<h2><span class="section-number">8.1.2. </span>Approaches for Anomaly Detection<a class="headerlink" href="#approaches-for-anomaly-detection" title="Permalink to this headline">#</a></h2>
<p>It’s time to start thinking about how we’d approach figuring out which of the time points are anomalies.</p>
<p>One of the simplest approaches to this problem might just be to figure out which node has the highest count of edge changes across your timeseries. For each node across the timeseries, you’d count the number of new edges that appeared (compared to the previous point in time), and the number of existing edges that were deleted. Whichever count is highest could be your anomalous node.</p>
<p>This might give you a rough estimate – and you could even potentially find perturbed time points with this approach – but it’s not necessarily the best solution. Counting edges doesn’t account for other important pieces of information: for instance, you might be interested in which other nodes new edges were formed with. It seems like deleting or creating edges with more important nodes, for instance, should be weighted higher than deleting or creating edges with unimportant nodes.</p>
<p>So let’s try another method. You might actually be able to guess it! The idea will be to simply estimate each network’s latent positions, followed by a hypothesis testing approach. Here’s the idea.</p>
<p>Let’s call the latent positions for our network <span class="math notranslate nohighlight">\(X^{(t)}\)</span> for the snapshot of the network at time <span class="math notranslate nohighlight">\(t\)</span>. You’re trying to find specific time points, <span class="math notranslate nohighlight">\(X^{(i)}\)</span>, which are different from their previous time point <span class="math notranslate nohighlight">\(X^{(i-1)}\)</span>. Here, we’re going to define “different” as the <em>spectral norm of the difference</em>, which is the largest singular value of <span class="math notranslate nohighlight">\(X^{(t)}\)</span> and <span class="math notranslate nohighlight">\(X^{(t - 1)}\)</span>. This is denoted by the quantity <span class="math notranslate nohighlight">\(||X^{(t)} - X^{(t - 1)}||_2\)</span>, which is the <span class="math notranslate nohighlight">\(2\)</span>-norm of the matrix.</p>
<p>This quantity will be relatively big if <span class="math notranslate nohighlight">\(X^{(t)}\)</span> and <span class="math notranslate nohighlight">\(X^{(t-1)}\)</span> are not very similar, and relatively small if <span class="math notranslate nohighlight">\(X^{(t)}\)</span> and <span class="math notranslate nohighlight">\(X^{(t-1)}\)</span> are more similar, because it is summing the squared differences between all of the entries of <span class="math notranslate nohighlight">\(X^{(t)}\)</span> and <span class="math notranslate nohighlight">\(X^{(t - 1)}\)</span>.</p>
<p>In other words, We’re trying to find the time points where the difference in norm between the latent positions at time <span class="math notranslate nohighlight">\(t\)</span> and the latent positions at time <span class="math notranslate nohighlight">\(t-1\)</span> is <em>relatively</em> large. The idea is that non-anomalous time points (where the latent position matrices are the same) will have a difference of zero, but anomalous time points (where the latent position matrices are not the same) will have a difference which exceeds zero.</p>
<p>There’s an alternate problem where you restrict your view to <em>subsets of nodes</em> rather than entire adjacency matrices. The idea is that you’d find time-points which are anomalous for particular nodes or groups of nodes, rather than the entire network. The general idea is the same: you find latent positions, then test for how big the difference is between time point <span class="math notranslate nohighlight">\(t\)</span> and time point <span class="math notranslate nohighlight">\(t-1\)</span>. This time, however, your test is for particular nodes. We’ll be focusing on the problem for whole networks, but you can take a look at the original paper if you’re curious about how to apply it to nodes.</p>
<section id="challenges-of-anomaly-detection">
<h3><span class="section-number">8.1.2.1. </span>Challenges of anomaly detection<a class="headerlink" href="#challenges-of-anomaly-detection" title="Permalink to this headline">#</a></h3>
<p>In practice, however, this is a bit more challenging than just looking for the consecutive time points with differences that exceed zero. Even in a perfect environment, such as under simulation, we run across two variations of problems that we have seen before. To perform timeseries anomaly detection, what you are first going to assume is that each network <span class="math notranslate nohighlight">\(A^{(t)}\)</span> you observe is a sample of an <a class="reference internal" href="../../representations/ch5/single-network-models_RDPG.html#ch5-rdpg"><span class="std std-ref">RDPG</span></a> with a latent position matrix <span class="math notranslate nohighlight">\(X^{(t)}\)</span>, for all timepoints <span class="math notranslate nohighlight">\(t\)</span> from <span class="math notranslate nohighlight">\(1\)</span> to <span class="math notranslate nohighlight">\(T\)</span>. Further, we assume that the latent dimensionality <span class="math notranslate nohighlight">\(d\)</span> is known to be the same across all of the networks.</p>
<p>For each timepoint, we have the following question of interest: are the latent positions equal; that is, <span class="math notranslate nohighlight">\(H_0^{(t)} : X^{(t)} = X^{(t - 1)}W\)</span>, for some rotation matrix <span class="math notranslate nohighlight">\(W\)</span>? Or are the latent positions different; that is, <span class="math notranslate nohighlight">\(H_A^{(t)} : X^{(t)} \neq X^{(t - 1)}W\)</span>?</p>
<section id="the-nonidentifiability-problem">
<h4><span class="section-number">8.1.2.1.1. </span>The nonidentifiability problem<a class="headerlink" href="#the-nonidentifiability-problem" title="Permalink to this headline">#</a></h4>
<p>When you observe the network <span class="math notranslate nohighlight">\(A^{(t)}\)</span>, you only observe the network itself: not the underlying latent position matrix <span class="math notranslate nohighlight">\(X^{(t)}\)</span>. Instead, you estimate the latent position matrix, <span class="math notranslate nohighlight">\(\hat X^{(t)}\)</span>, using <a class="reference internal" href="../../representations/ch6/spectral-embedding.html#ch6-spectral"><span class="std std-ref">spectral embeddings</span></a>. Unfortunately, latent position matrices are rotationally non-identifiable: that is, you cannot identify one latent position matrix <span class="math notranslate nohighlight">\(X^{(t)}\)</span> from another latent position matrix <span class="math notranslate nohighlight">\(Y^{(t)} = X^{(t)}W\)</span> where <span class="math notranslate nohighlight">\(W\)</span> is a rotation, and the same goes for estimates of these quantities <span class="math notranslate nohighlight">\(\hat Y{(t)}\)</span> and <span class="math notranslate nohighlight">\(\hat X^{(t)}\)</span> as well. This means that you will need a strategy which “rotates” all of the latent position estimates into the same space. To overcome this hurdle, we need an approach which takes networks, and produces latent position estimates for each network which are rotationally aligned. Fortunately, you already know how to do this: you can use the <a class="reference internal" href="../../representations/ch6/multigraph-representation-learning.html#ch6-multinet-omni"><span class="std std-ref">OMNI embedding</span></a>. Once your estimates are all aligned in the same latent space, you can ignore the rotation matrix, <span class="math notranslate nohighlight">\(W\)</span>, for all practical purposes for the remainder of this section.</p>
</section>
<section id="we-only-get-to-obtain-estimates-of-latent-positions">
<h4><span class="section-number">8.1.2.1.2. </span>We only get to obtain estimates of latent positions<a class="headerlink" href="#we-only-get-to-obtain-estimates-of-latent-positions" title="Permalink to this headline">#</a></h4>
<p>Now that you have latent position estimates for each network <span class="math notranslate nohighlight">\(\hat X^{(t)}\)</span> that are all rotated into the same space, you are presented with a new problem: the latent position estimates still won’t equal the true, underlying latent positions <span class="math notranslate nohighlight">\(X^{(t)}\)</span>. This means that even if <span class="math notranslate nohighlight">\(X^{(t)} = X^{(t - 1)}\)</span>, and you are able to orient <span class="math notranslate nohighlight">\(\hat X^{(t)}\)</span> and <span class="math notranslate nohighlight">\(X^{(t - 1)}\)</span> so that they are rotationally aligned, your estimates <em>still</em> won’t be equal. Remember these quantities are only <em>estimates</em> of latent positions, which means they will be subject to random noise <em>even if</em> the underlying true latent positions are exactly equal. That means that we aren’t going to be able to just check whether two time points have a <em>Frobenius difference</em> that differs from zero; rather, we’re going to need to figure out what <em>relatively large</em> and <em>relatively small</em> amount to in the context of our sample.</p>
</section>
</section>
</section>
<section id="detecting-if-the-first-time-point-is-an-anomaly">
<h2><span class="section-number">8.1.3. </span>Detecting if the First Time Point is an Anomaly<a class="headerlink" href="#detecting-if-the-first-time-point-is-an-anomaly" title="Permalink to this headline">#</a></h2>
<p>We’ll start with the first time point, which (because we generated the data!) we know in advance is not an anomaly.</p>
<p>So, here’s what’s going on in the code below:</p>
<ol class="simple">
<li><p>We embed the networks <span class="math notranslate nohighlight">\(\{A^{(1)}, ..., A^{(T)}\}\)</span> using <a class="reference internal" href="../../representations/ch6/multigraph-representation-learning.html#ch6-multinet-omni"><span class="std std-ref">OMNI embedding</span></a>, to produce estimates of the latent position matrices <span class="math notranslate nohighlight">\(\{X^{(1)}, ..., X^{(T)}\}\)</span> for all timepoints <span class="math notranslate nohighlight">\(t\)</span>, oriented in the same latent space.</p></li>
<li><p>We compute the norm of the difference between each pair of samples, letting <span class="math notranslate nohighlight">\(s^{(t)} = ||\hat X^{(t)} - \hat X^{(t - 1)}||_2\)</span> with <code class="docutils literal notranslate"><span class="pre">numpy</span></code>, for the timepoint <span class="math notranslate nohighlight">\(t\)</span>. We repeat this for all timepoints except for the first timepoint, so <span class="math notranslate nohighlight">\(t\)</span> goes from <span class="math notranslate nohighlight">\(2\)</span> to <span class="math notranslate nohighlight">\(T\)</span>. With <span class="math notranslate nohighlight">\(T=12\)</span> timepoints in our example, this means that we have <span class="math notranslate nohighlight">\(11\)</span> total test statistics.</p></li>
</ol>
<p>An important point to clarify is that there are a lot of different types of matrix norms: Frobenius norm, spectral norm, and so on. In our case, we’ll be using the <span class="math notranslate nohighlight">\(l_2\)</span> operator norm, which is simply the largest singular value of the matrix. The <code class="docutils literal notranslate"><span class="pre">ord</span></code> parameter argument in numpy determines which norm we use, and <code class="docutils literal notranslate"><span class="pre">ord=2</span></code> is the operator norm.</p>
<p>Again, this norm, intuitively, will tell us how different two matrices are. If the norm of the difference between the true latent positions <span class="math notranslate nohighlight">\(X - Y\)</span> is small, then <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are very similar matrices; whereas if the norm of <span class="math notranslate nohighlight">\(X - Y\)</span> is large, then <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are very different. The norm should be large for anomalies, and small for everything else.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.embed</span> <span class="kn">import</span> <span class="n">OmnibusEmbed</span> <span class="k">as</span> <span class="n">OMNI</span>

<span class="k">def</span> <span class="nf">compute_statistic</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A function which computes the test statistic, the 2-norm.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">Y</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">d</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># embed the networks with OMNI embedding</span>
<span class="n">latents</span> <span class="o">=</span> <span class="n">OMNI</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">networks</span><span class="p">)</span>

<span class="n">stat_observed</span> <span class="o">=</span> <span class="n">compute_statistic</span><span class="p">(</span><span class="n">latents</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">latents</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">yhat</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">stat_observed</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">1.05</span><span class="o">*</span><span class="n">stat_observed</span> <span class="p">,</span> <span class="mf">.5</span><span class="p">,</span> <span class="s2">&quot;$s^{(t)} = ||</span><span class="se">\\</span><span class="s2">hat X^{(2)} - </span><span class="se">\\</span><span class="s2">hat X^{(1)}||_2$&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.4</span><span class="o">*</span><span class="n">stat_observed</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Operator norm of difference&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="hypothesis-testing-with-our-test-statistic">
<h2><span class="section-number">8.1.4. </span>Hypothesis Testing With our Test Statistic<a class="headerlink" href="#hypothesis-testing-with-our-test-statistic" title="Permalink to this headline">#</a></h2>
<p>We observe the test statistic shown with the red line above, which has a value of . If the first two adjacency matrices have the same latent positions, we would hope that their latent position estimates (after adjusting for rotations) are reasonably similar and the statistic would be relatively small. On the other hand, if their latent positions are different, we would hope that their latent position estimates (even after adjusting for rotations) would be reasonably large and the statistic would also be relatively large. However, the word <em>relative</em> is the key word here: <em>relative</em> what? how should we determine whether it’s small enough to say that <span class="math notranslate nohighlight">\(X^{(t)}\)</span> and <span class="math notranslate nohighlight">\(X^{(t - 1)}\)</span> come from the same distribution, and aren’t anomalalous time points?</p>
<p>Well, what if we could use our estimated latent positions <span class="math notranslate nohighlight">\(\hat{X}^{(t)}\)</span> at time <span class="math notranslate nohighlight">\(t\)</span> to generate networks, then make test statistics from those new networks? We’d know for a fact that any pair of those networks are drawn from the same set of latent positions, and we could get a sense for what our test statistic should look like if the latent positions actually were the same.</p>
<p>Back in <a class="reference internal" href="../ch8/two-sample-hypothesis.html#ch8-twosample"><span class="std std-ref">two sample testing</span></a>, we came across this same fundamental problem when attempting to determine whether two latent position matrices were identical, and here we’re going to resort to virtually the same strategy: the parametric bootstrap.</p>
<section id="generating-the-null-distribution-of-each-pair-of-timepoints-using-the-parametric-bootstrap">
<h3><span class="section-number">8.1.4.1. </span>Generating the null distribution of each pair of timepoints using the parametric bootstrap<a class="headerlink" href="#generating-the-null-distribution-of-each-pair-of-timepoints-using-the-parametric-bootstrap" title="Permalink to this headline">#</a></h3>
<p>So: recall, our original question was to determine whether <span class="math notranslate nohighlight">\(H_0^{(t)} : X^{(t)} = X^{(t - 1)}W\)</span> or <span class="math notranslate nohighlight">\(H_A^{(t)} : X^{(t)} \neq X^{(t - 1)}W\)</span>, or that the latent positions are equal/unequal up to a rotation. This is clearly a two-sample test, so how could we adapt the approach we used in <a class="reference internal" href="../ch8/two-sample-hypothesis.html#ch8-twosample"><span class="std std-ref">two-sample testing</span></a> here?</p>
<p>Our approach is going to be as follows. Given a pair of (already-aligned) estimated latent position matrices <span class="math notranslate nohighlight">\(\hat X^{(t)}\)</span> and <span class="math notranslate nohighlight">\(\hat X^{(t - 1)}\)</span>, for a given repetition <span class="math notranslate nohighlight">\(r\)</span>:</p>
<ol class="simple">
<li><p>Generate two pairs of adjacency matrices, <span class="math notranslate nohighlight">\(A^{(t,2,r)}\)</span> and <span class="math notranslate nohighlight">\(A^{(t, 1, r)}\)</span> by sampling independently from an RDPG with latent position matrix <span class="math notranslate nohighlight">\(\hat X^{(t)}\)</span>, and the pair <span class="math notranslate nohighlight">\(A^{(t - 1, 2,r)}\)</span> and <span class="math notranslate nohighlight">\(A^{(t - 1, 1, r)}\)</span> by sampling independently from an RDPG with latent position matrix <span class="math notranslate nohighlight">\(\hat X^{(t - 1)}\)</span>. Notice that each pair of adjacency matrices have an identical underlying latent position matrix, which is the estimate of the latent position matrix we previously produced with OMNI.</p></li>
</ol>
<ul class="simple">
<li><p>For each pair of adjacency matrices for timepoint <span class="math notranslate nohighlight">\(t'\)</span> (which can be either <span class="math notranslate nohighlight">\(t\)</span> or <span class="math notranslate nohighlight">\(t - 1\)</span>), embed the adjacency matrices into <span class="math notranslate nohighlight">\(d\)</span> dimensions using the OMNI embedding, to produce estimates of the latent positions <span class="math notranslate nohighlight">\(\hat X^{(t', 2, r)}\)</span> and <span class="math notranslate nohighlight">\(\hat X^{(t', 1, r)}\)</span>.</p></li>
<li><p>Compute the corresponding statistics for each timepoint <span class="math notranslate nohighlight">\(t'\)</span>, <span class="math notranslate nohighlight">\(s^{(t')}_r = ||\hat X^{(t', 2, r)} - \hat X^{(t', 1, r)}||_2\)</span>, again using <code class="docutils literal notranslate"><span class="pre">numpy</span></code>.</p></li>
</ul>
<p>So, what’s going on here exactly?</p>
<p>For the timepoint of interest <span class="math notranslate nohighlight">\(t\)</span>, what we are doing is effectively <em>using</em> the estimated latent position matrix <span class="math notranslate nohighlight">\(\hat X^{(t)}\)</span> to generate new adjacency matrices (which actually <em>do</em> have the same underlying latent position matrix; namely, <span class="math notranslate nohighlight">\(\hat X^{(t)}\)</span>). Then, we embed these two adjacency matrices to obtain two <em>more</em> estimated latent position matrices,  <span class="math notranslate nohighlight">\(\hat X^{(t', 1, r)}\)</span> and <span class="math notranslate nohighlight">\(\hat X^{(t', 0, r)}\)</span>. Let’s see how this looks in code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_replicate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="n">d</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates two estimated latent position matrices which have the same</span>
<span class="sd">    underlying latent position matrix, X.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">A2</span> <span class="o">=</span> <span class="n">rdpg</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">A1</span> <span class="o">=</span> <span class="n">rdpg</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">latents</span> <span class="o">=</span> <span class="n">OMNI</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">([</span><span class="n">A2</span><span class="p">,</span> <span class="n">A1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">latents</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">latents</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Since these are estimates of latent position matrices from <em>samples</em> of random graphs (which are RDPGs), they won’t be identical, and are in fact, quite useful: they give us an idea of just how much, if the underlying latent position matrix is the same, that the two latent position matrices will differ in terms of the statistic <span class="math notranslate nohighlight">\(s^{(t)}\)</span>! Then, we just repeat this procedure for the proceeding time point as well, since we want to use information from <em>all</em> of our networks relevant to the current timepoint: both <span class="math notranslate nohighlight">\(\hat X^{(t)}\)</span> and <span class="math notranslate nohighlight">\(\hat X^{(t - 1)}\)</span>.</p>
<p>Finally, we aggregate together all of the statistics we computed, giving us a collection of <span class="math notranslate nohighlight">\(2 \times R\)</span> total statistics of interest. These statistics give us a sense of just how large (or small) we would expect the operator norm for our system to be <em>if</em> the underlying latent position matrices were identical. Let’s see how we code this all up:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compute_null_statistics</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">R</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span><span class="n">d</span><span class="o">=</span><span class="n">d</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the test statistics under the null for two latent position</span>
<span class="sd">    matrices, X1 and X2.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">s</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">R</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">X</span> <span class="ow">in</span> <span class="p">[</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">]:</span>
            <span class="n">Xrep2</span><span class="p">,</span> <span class="n">Xrep1</span> <span class="o">=</span> <span class="n">generate_replicate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="n">d</span><span class="p">)</span>
            <span class="n">s</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">compute_statistic</span><span class="p">(</span><span class="n">Xrep2</span><span class="p">,</span> <span class="n">Xrep1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>

<span class="n">null_stats</span> <span class="o">=</span> <span class="n">compute_null_statistics</span><span class="p">(</span><span class="n">latents</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">latents</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, we’ll do exactly what we did in <a class="reference internal" href="../ch8/two-sample-hypothesis.html#ch8-twosample"><span class="std std-ref">two sample testing</span></a>: we’ll compare the statistic we obtained directly from our data, <span class="math notranslate nohighlight">\(s^{(t)}\)</span>, to all of these <em>null replicates</em>. These are called <em>null replicates</em> because they give us a sense of the magnitude of the test statistic <em>if</em> the null hypothesis were true: they indicate the behavior
of the test statistic for two networks which have an identical underlying latent position matrix.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">plot</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">null_stats</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">plot</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Distribution of test statistics with the same latent positions&quot;</span><span class="p">);</span>
<span class="n">plot</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Test statistic value&quot;</span><span class="p">);</span>

<span class="n">plot</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">1.02</span><span class="o">*</span><span class="n">stat_observed</span> <span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="s2">&quot;$s^{(t)} = ||</span><span class="se">\\</span><span class="s2">hat X^{(2)} - </span><span class="se">\\</span><span class="s2">hat X^{(1)}||_2$&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">);</span>
<span class="n">plot</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">.50</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="s2">&quot;Bootstrapped Distribution&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">65</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Fortunately,  looks like it’s within a reasonable range under the assumption that the time-points share latent positions.</p>
</section>
<section id="estimating-the-p-value-using-the-bootstrapped-samples">
<h3><span class="section-number">8.1.4.2. </span>Estimating the <span class="math notranslate nohighlight">\(p\)</span>-value using the bootstrapped samples<a class="headerlink" href="#estimating-the-p-value-using-the-bootstrapped-samples" title="Permalink to this headline">#</a></h3>
<p>We’ll again use this observation to determine a <span class="math notranslate nohighlight">\(p\)</span>-value: the <span class="math notranslate nohighlight">\(p\)</span>-value will be the fraction of times that <span class="math notranslate nohighlight">\(s^{(t)}\)</span> was less extreme (smaller) than an difference between two estimated latent position matrices that had the <em>same</em> underlying latent position matrix. That is, we will measure how many times <span class="math notranslate nohighlight">\(s^{(t)}\)</span> is smaller than <span class="math notranslate nohighlight">\(s^{(t)}_r\)</span>, for all of our null statistics <span class="math notranslate nohighlight">\(s^{(t)}_r\)</span>. Remember that with <span class="math notranslate nohighlight">\(R\)</span> replicates, this means that we will have, for a timestep <span class="math notranslate nohighlight">\(t\)</span>:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    p^{(t)} &amp;= \frac{\text{number of times that $s^{(t)}$ is smaller than $s^{(t)}_r$} + 1}{R \times 2 + 1}
\end{align*}\]</div>
<p>Just like we did for <a class="reference internal" href="../ch8/two-sample-hypothesis.html#ch8-twosample"><span class="std std-ref">two-sample testing</span></a>, we add a <span class="math notranslate nohighlight">\(1\)</span> to the numerator (and denominator) since we already saw a test statistic at least as large as <span class="math notranslate nohighlight">\(s^{(t)}\)</span>: <span class="math notranslate nohighlight">\(s^{(t)}\)</span> itself. We can do this as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">distn_test_anomaly</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">R</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs an anomaly distribution test.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tstat</span> <span class="o">=</span> <span class="n">compute_statistic</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">)</span>
    <span class="n">null_stats</span> <span class="o">=</span> <span class="n">compute_null_statistics</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">R</span><span class="o">=</span><span class="n">R</span><span class="p">)</span>
    <span class="n">pval</span> <span class="o">=</span> <span class="p">((</span><span class="n">null_stats</span> <span class="o">&gt;=</span> <span class="n">tstat</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">null_stats</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tstat</span><span class="p">,</span> <span class="n">pval</span>

<span class="n">tstat</span><span class="p">,</span> <span class="n">pval</span> <span class="o">=</span> <span class="n">distn_test_anomaly</span><span class="p">(</span><span class="n">latents</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">latents</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test statistic: </span><span class="si">{:3f}</span><span class="s2">, p-value: </span><span class="si">{:3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tstat</span><span class="p">,</span> <span class="n">pval</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>When we use a decision threshold of <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>, our results here would indicate that we fail to reject the null hypothesis that the two timepoints (<span class="math notranslate nohighlight">\(1\)</span> and <span class="math notranslate nohighlight">\(0\)</span>) have the same latent position matrix. In the context of the simulation we constructed, this is accurate: we <em>know</em> that timepoints <span class="math notranslate nohighlight">\(1\)</span> and <span class="math notranslate nohighlight">\(0\)</span> had the same latent position matrix, so this is great news!</p>
<p>What happens at the true anomalous timepoints, timepoints <span class="math notranslate nohighlight">\(5\)</span> through <span class="math notranslate nohighlight">\(7\)</span>? Let’s repeat this procedure on all pairs of adjacent network timepoints and take a look:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pvals</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">T</span><span class="p">):</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">pval</span> <span class="o">=</span> <span class="n">distn_test_anomaly</span><span class="p">(</span><span class="n">latents</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="n">latents</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">pvals</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pval</span>
</pre></div>
</div>
</div>
</div>
<p>Again, since we performed multiple comparisons, we adjust the <span class="math notranslate nohighlight">\(p\)</span>-values using <a class="reference internal" href="../ch7/model-selection.html#ch7-modelselect-multitest"><span class="std std-ref">Bonferroni-Holm adjustment</span></a>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">statsmodels.stats.multitest</span> <span class="kn">import</span> <span class="n">multipletests</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">_</span><span class="p">,</span> <span class="n">adj_pvals</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">multipletests</span><span class="p">([</span><span class="nb">float</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pvals</span><span class="o">.</span><span class="n">values</span><span class="p">()],</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;holm&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">cmaps</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fromiter</span><span class="p">(</span><span class="n">adj_pvals</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmaps</span><span class="p">[</span><span class="s2">&quot;sequential&quot;</span><span class="p">],</span> 
                   <span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">);</span>
<span class="n">plot</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;p-values for each pair of timepoints after Bonferroni-Holm&quot;</span><span class="p">);</span>
<span class="n">plot</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([]);</span>
<span class="n">plot</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">pvals</span><span class="o">.</span><span class="n">keys</span><span class="p">()));</span>
<span class="n">plot</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Timepoint pairs&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Our results are consistent with what we would expect based on how the simulation was generated.</p>
<p>The first <span class="math notranslate nohighlight">\(5\)</span> timepoints all have the same underlying latent position matrix, and when we perform our statistical inference for each pair of adjacenct points in this range, we fail to reject the null hypothesis that the latent position matrix underlying the pair of adjacenct time points is the same.</p>
<p>However, the <span class="math notranslate nohighlight">\(6\)</span> and <span class="math notranslate nohighlight">\(7\)</span> timepoints have anomalous latent positions, and the <span class="math notranslate nohighlight">\(p\)</span>-value is small for all timepoints adjacent these two times. Therefore, we have evidence to reject the null hypothesis in favor of the alternative hypothesis that the latent position matrices are different.</p>
<p>Finally, when we get back to the <span class="math notranslate nohighlight">\(8\)</span> through <span class="math notranslate nohighlight">\(12\)</span> timepoint, again the underlying latent positions were the same, and our statistical inference would suggest that we should not reject the null hypothesis.</p>
</section>
</section>
<section id="the-distribution-of-the-bootstrapped-test-statistic">
<h2><span class="section-number">8.1.5. </span>The Distribution of the Bootstrapped Test Statistic<a class="headerlink" href="#the-distribution-of-the-bootstrapped-test-statistic" title="Permalink to this headline">#</a></h2>
<p>One issue that could pop up is that the bootstrapped test statistic is slightly biased. Since we’re generating it from an estimate <span class="math notranslate nohighlight">\(\hat{X}\)</span> of the true latent positions <span class="math notranslate nohighlight">\(X\)</span>, we’ll have a bias of <span class="math notranslate nohighlight">\(|\hat{X} - X|\)</span>. It’s worth comparing the two distributions to determine if that bias is a big deal in practice.</p>
<p>Below you can see the true distribution of the test statistic for the real, unperturbed set of latent positions <span class="math notranslate nohighlight">\(X\)</span> we generated the data from (that’s the blue distribution). You can also see a distribution of test statistics bootstrapped from a <span class="math notranslate nohighlight">\(\hat{X}\)</span>. You can see that in this case, they’re fairly close.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">rdpg</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">graspologic.embed</span> <span class="kn">import</span> <span class="n">OmnibusEmbed</span> <span class="k">as</span> <span class="n">OMNI</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">.2</span><span class="p">,</span> <span class="mf">.8</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">networks</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">networks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rdpg</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="n">networks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rdpg</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">get_statistic</span><span class="p">(</span><span class="n">adjacencies</span><span class="p">,</span> <span class="n">return_latents</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get the operator norm of the difference of two matrices.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">omni</span> <span class="o">=</span> <span class="n">OMNI</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">latents_est</span> <span class="o">=</span> <span class="n">omni</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">adjacencies</span><span class="p">)</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">latents_est</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">latents_est</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">Y</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">return_latents</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">X</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="n">omni</span> <span class="o">=</span> <span class="n">OMNI</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">latents</span> <span class="o">=</span> <span class="n">omni</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">networks</span><span class="p">)</span>

<span class="n">ys_bootstrap</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">A_</span><span class="p">,</span> <span class="n">B_</span> <span class="o">=</span> <span class="n">rdpg</span><span class="p">(</span><span class="n">latents</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">rdpg</span><span class="p">(</span><span class="n">latents</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">y_</span> <span class="o">=</span> <span class="n">get_statistic</span><span class="p">([</span><span class="n">A_</span><span class="p">,</span> <span class="n">B_</span><span class="p">])</span>
    <span class="n">ys_bootstrap</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_</span><span class="p">)</span>
    
<span class="n">ys_true</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">A_</span><span class="p">,</span> <span class="n">B_</span> <span class="o">=</span> <span class="n">rdpg</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">rdpg</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">y_</span> <span class="o">=</span> <span class="n">get_statistic</span><span class="p">([</span><span class="n">A_</span><span class="p">,</span> <span class="n">B_</span><span class="p">])</span>
    <span class="n">ys_true</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_</span><span class="p">)</span>
    
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">ys_true</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;true distribution of $s^{(t)}_r$&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">ys_bootstrap</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;distribution of bootstrapped $s^{(t)}_r$ values&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figtext</span><span class="p">(</span><span class="mf">.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Figure 8.5&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Distribution Comparison For the Bootstrapped and True Test Statistic&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./applications/ch9"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="ch9.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">8. </span>Applications for Many Networks</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="significant-edges.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">8.2. </span>Testing for Significant Edges</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Eric Bridgeford, Alex Loftus, and Joshua Vogelstein<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>