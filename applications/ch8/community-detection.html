
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>8.1. Community Detection &#8212; Hands-on Network Machine Learning with Scikit-Learn and Graspologic</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >let toggleHintShow = 'Click to show';</script>
    <script >let toggleHintHide = 'Click to hide';</script>
    <script >let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script >const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="8.2. Testing for Differences between Groups of Edges" href="testing-differences.html" />
    <link rel="prev" title="8. Applications When You Have One Network" href="ch8.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Hands-on Network Machine Learning with Scikit-Learn and Graspologic</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../coverpage.html">
   Hands-on Network Machine Learning with Scikit-Learn and Graspologic
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/terminology.html">
   Terminology and Math Refresher
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch1/ch1.html">
   1. The Network Machine Learning Landscape
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/what-is-a-network.html">
     1.1. What Is A Network?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/why-study-networks.html">
     1.2. Why Study Networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/examples-of-applications.html">
     1.3. Examples of applications
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/types-of-learning-probs.html">
     1.4. Approaches for Network Learning Problems
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch2/ch2.html">
   2. End-to-end Biology Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/big-picture.html">
     2.1. Look at the big picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/get-the-data.html">
     2.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/prepare-the-data.html">
     2.3. Prepare the Data for Network Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/discover-and-visualize.html">
     2.4. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch3/ch3.html">
   3. End-to-end Business Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/big-picture.html">
     3.1. Look at the Big Picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/get-the-data.html">
     3.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/discover-and-visualize.html">
     3.3. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/prepare-the-data.html">
     3.4. Prepare the Data for Network Algorithms
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Representations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch4/ch4.html">
   4. Properties of Networks as a Statistical Object
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/matrix-representations.html">
     4.1. Matrix Representations Of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/properties-of-networks.html">
     4.2. Properties of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/network-representations.html">
     4.3. Representations of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/regularization.html">
     4.4. Regularization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch5/ch5.html">
   5. Why Use Statistical Models?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/why-use-models.html">
     5.1. Why Use Statistical Models?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_ER.html">
     5.2. Erdös-Rényi (ER) Random Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_SBM.html">
     5.3. Stochastic Block Models (SBM)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_RDPG.html">
     5.4. Random Dot Product Graphs (RDPG)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/multi-network-models.html">
     5.5. Multiple Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/models-with-covariates.html">
     5.6. Network Models with Covariates
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch6/ch6.html">
   6. Learning Network Representations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/estimating-parameters_mle.html">
     6.1. Estimating Parameters in Network Models via MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/why-embed-networks.html">
     6.2. Why embed networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/spectral-embedding.html">
     6.3. Spectral Embedding Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/estimating-parameters_spectral.html">
     6.4. Estimating Parameters for the RDPG
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/random-walk-diffusion-methods.html">
     6.5. Random walk and diffusion-based methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/graph-neural-networks.html">
     6.6. Graph Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/multigraph-representation-learning.html">
     6.7. Multiple-Network Representation Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/joint-representation-learning.html">
     6.8. Joint Representation Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch7/ch7.html">
   7. Theoretical Results
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch7/theory-single-network.html">
     7.1. Theory for Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch7/theory-multigraph.html">
     7.2. Maximum Likelihood Estimate Theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch7/theory-matching.html">
     7.3. Spectral Method Theory
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="ch8.html">
   8. Applications When You Have One Network
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     8.1. Community Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="testing-differences.html">
     8.2. Testing for Differences between Groups of Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="model-selection.html">
     8.3. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="single-vertex-nomination.html">
     8.4. Single-Network Vertex Nomination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="out-of-sample.html">
     8.5. Out-of-sample Embedding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch9/ch9.html">
   9. Applications for Two Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch9/two-sample-hypothesis.html">
     9.1. Latent Two-Sample Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch9/significant-communities.html">
     9.2. Differences in Block Matrices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch9/graph-matching-vertex.html">
     9.3. Graph Matching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch9/multiple-vertex-nomination.html">
     9.4. Vertex Nomination For Two Networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch10/ch10.html">
   10. Applications for Many Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch10/anomaly-detection.html">
     10.1. Anomaly Detection For Timeseries of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch10/significant-edges.html">
     10.2. Testing for Significant Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch10/significant-vertices.html">
     10.3. Testing for Significant Vertices
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://graspologic.readthedocs.io/en/latest/">
   Graspologic Documentation
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/applications/ch8/community-detection.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/neurodata/graph-stats-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/neurodata/graph-stats-book/issues/new?title=Issue%20on%20page%20%2Fapplications/ch8/community-detection.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/neurodata/graph-stats-book/edit/master/network_machine_learning_in_python/applications/ch8/community-detection.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stochastic-block-model-with-unknown-communities-when-you-know-the-number-of-communities-k">
   8.1.1. Stochastic Block Model with unknown communities when you know the number of communities
   <span class="math notranslate nohighlight">
    \(K\)
   </span>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#unsupervised-learning-via-k-means-clustering">
     8.1.1.1. Unsupervised learning via k-means clustering
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluating-k-means-clustering">
     8.1.1.2. Evaluating
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -means clustering
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-confusion-matrix-lets-us-visualize-the-homogeneity-of-predictions-relative-the-true-labels">
       8.1.1.2.1. The confusion matrix lets us visualize the homogeneity of predictions relative the true labels
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#you-can-evaluate-the-homogeneity-of-the-confusion-matrix-using-the-adjusted-rand-index-ari">
       8.1.1.2.2. You can evaluate the homogeneity of the confusion matrix using the adjusted rand index (ARI)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#by-remapping-the-labels-you-can-evaluate-the-error-rate">
       8.1.1.2.3. By remapping the labels, you can evaluate the error rate
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#number-of-communities-k-is-not-known">
   8.1.2. Number of communities
   <span class="math notranslate nohighlight">
    \(K\)
   </span>
   is not known
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-silhouette-score-allows-us-to-compare-unsupervised-clustering-quality">
     8.1.2.1. The Silhouette score allows us to compare unsupervised clustering quality
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-the-silhouette-score-to-deduce-an-appropriate-number-of-communities">
     8.1.2.2. Using the Silhouette score to deduce an appropriate number of communities
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#community-detection-with-other-types-of-embeddings">
   8.1.3. Community detection with other types of embeddings
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#can-you-detect-two-truths-with-one-embedding">
     8.1.3.1. Can you detect “two-truths” with one embedding?
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sometimes-you-have-to-modify-your-data-to-learn-from-it">
       8.1.3.1.1. Sometimes, you have to modify your data to learn from it
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Community Detection</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stochastic-block-model-with-unknown-communities-when-you-know-the-number-of-communities-k">
   8.1.1. Stochastic Block Model with unknown communities when you know the number of communities
   <span class="math notranslate nohighlight">
    \(K\)
   </span>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#unsupervised-learning-via-k-means-clustering">
     8.1.1.1. Unsupervised learning via k-means clustering
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluating-k-means-clustering">
     8.1.1.2. Evaluating
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -means clustering
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-confusion-matrix-lets-us-visualize-the-homogeneity-of-predictions-relative-the-true-labels">
       8.1.1.2.1. The confusion matrix lets us visualize the homogeneity of predictions relative the true labels
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#you-can-evaluate-the-homogeneity-of-the-confusion-matrix-using-the-adjusted-rand-index-ari">
       8.1.1.2.2. You can evaluate the homogeneity of the confusion matrix using the adjusted rand index (ARI)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#by-remapping-the-labels-you-can-evaluate-the-error-rate">
       8.1.1.2.3. By remapping the labels, you can evaluate the error rate
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#number-of-communities-k-is-not-known">
   8.1.2. Number of communities
   <span class="math notranslate nohighlight">
    \(K\)
   </span>
   is not known
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-silhouette-score-allows-us-to-compare-unsupervised-clustering-quality">
     8.1.2.1. The Silhouette score allows us to compare unsupervised clustering quality
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-the-silhouette-score-to-deduce-an-appropriate-number-of-communities">
     8.1.2.2. Using the Silhouette score to deduce an appropriate number of communities
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#community-detection-with-other-types-of-embeddings">
   8.1.3. Community detection with other types of embeddings
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#can-you-detect-two-truths-with-one-embedding">
     8.1.3.1. Can you detect “two-truths” with one embedding?
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sometimes-you-have-to-modify-your-data-to-learn-from-it">
       8.1.3.1.1. Sometimes, you have to modify your data to learn from it
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="community-detection">
<h1><span class="section-number">8.1. </span>Community Detection<a class="headerlink" href="#community-detection" title="Permalink to this headline">¶</a></h1>
<p>In <a class="reference external" href="#link?">Chapter 6</a> you learned how to estimate the parameters for an SBM via Maximum Likelihood Estimation (MLE). Unfortunately, we have skipped a relatively fundamental problem with SBM parameter estimation. You will notice that everything we have covered about the SBM to date assumes that you the assignments to one of <span class="math notranslate nohighlight">\(K\)</span> possible communities for each node, which is given by the node assignment variable <span class="math notranslate nohighlight">\(z_i\)</span> for each node in the network. Why is this problematic? Well, quite simply, when you are learning about <em>many</em> different networks you might come across, you might not actually <em>observe</em> the communities of each node.</p>
<p>Consider, for instance, the school example you have worked extensively with. In the context of the SBM, it makes sense to guess that two individuals will have a higher chaance of being friends if they attend the same school than if they did not go to the same school. Remember, when you knew what school each student was from and could <em>order</em> the students by school ahead of time, the network looked like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">sbm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">ns</span> <span class="o">=</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">]</span>  <span class="c1"># network with 100 nodes</span>
<span class="n">B</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]]</span>  <span class="c1"># block matrix</span>

<span class="c1"># sample a single simple adjacency matrix from SBM(z, B)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">sbm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">ns</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">B</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">zs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">draw_multiplot</span><span class="p">,</span> <span class="n">cmaps</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">draw_multiplot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">zs</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$SBM_n(z, B)$ Simulation, nodes ordered by school&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Error in sys.excepthook:
Traceback (most recent call last):
  File &quot;/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/IPython/core/interactiveshell.py&quot;, line 1979, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;RuntimeError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &quot;/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/IPython/core/interactiveshell.py&quot;, line 1981, in showtraceback
    stb = self.InteractiveTB.structured_traceback(etype,
  File &quot;/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/IPython/core/ultratb.py&quot;, line 1105, in structured_traceback
    return FormattedTB.structured_traceback(
  File &quot;/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/IPython/core/ultratb.py&quot;, line 999, in structured_traceback
    return VerboseTB.structured_traceback(
  File &quot;/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/IPython/core/ultratb.py&quot;, line 851, in structured_traceback
    assert etb is not None
AssertionError
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Original exception was:
RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ImportError</span><span class="g g-Whitespace">                               </span>Traceback (most recent call last)
<span class="nn">Input In [2],</span> in <span class="ni">&lt;cell line: 1&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">draw_multiplot</span><span class="p">,</span> <span class="n">cmaps</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">draw_multiplot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">zs</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$SBM_n(z, B)$ Simulation, nodes ordered by school&quot;</span><span class="p">)</span>

<span class="n">File</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">hostedtoolcache</span><span class="o">/</span><span class="n">Python</span><span class="o">/</span><span class="mf">3.8.12</span><span class="o">/</span><span class="n">x64</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.8</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">graphbook_code</span><span class="o">/</span><span class="fm">__init__</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">30</span><span class="p">,</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">     </span><span class="mi">28</span> <span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="o">*</span>
<span class="g g-Whitespace">     </span><span class="mi">29</span> <span class="kn">from</span> <span class="nn">.siem</span> <span class="kn">import</span> <span class="o">*</span>
<span class="ne">---&gt; </span><span class="mi">30</span> <span class="kn">from</span> <span class="nn">.sbm</span> <span class="kn">import</span> <span class="o">*</span>
<span class="g g-Whitespace">     </span><span class="mi">31</span> <span class="kn">from</span> <span class="nn">.ier</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">File</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">hostedtoolcache</span><span class="o">/</span><span class="n">Python</span><span class="o">/</span><span class="mf">3.8.12</span><span class="o">/</span><span class="n">x64</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.8</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">graphbook_code</span><span class="o">/</span><span class="n">sbm</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">39</span><span class="p">,</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">     </span><span class="mi">37</span> <span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">DataFrame</span>
<span class="g g-Whitespace">     </span><span class="mi">38</span> <span class="kn">from</span> <span class="nn">hyppo.ksample</span> <span class="kn">import</span> <span class="n">KSample</span>
<span class="ne">---&gt; </span><span class="mi">39</span> <span class="kn">from</span> <span class="nn">FisherExact</span> <span class="kn">import</span> <span class="n">fisher_exact</span>
<span class="g g-Whitespace">     </span><span class="mi">42</span> <span class="k">def</span> <span class="nf">_check_common_inputs</span><span class="p">(</span>
<span class="g g-Whitespace">     </span><span class="mi">43</span>     <span class="n">n_components</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
<span class="g g-Whitespace">     </span><span class="mi">44</span>     <span class="n">min_comm</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">47</span>     <span class="n">embed_kws</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
<span class="g g-Whitespace">     </span><span class="mi">48</span> <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">49</span>     <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n_components</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">n_components</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

<span class="n">File</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">hostedtoolcache</span><span class="o">/</span><span class="n">Python</span><span class="o">/</span><span class="mf">3.8.12</span><span class="o">/</span><span class="n">x64</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.8</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">FisherExact</span><span class="o">/</span><span class="fm">__init__</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">14</span><span class="p">,</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># FisherExact Copyright (C) 2016  Emmanuel Noutahi</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="c1"># This program is free software: you can redistribute it and/or modify</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="c1"># it under the terms of the GNU General Public License as published by</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">11</span> <span class="c1"># You should have received a copy of the GNU General Public License</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span> <span class="c1"># along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="ne">---&gt; </span><span class="mi">14</span> <span class="kn">from</span> <span class="nn">.Fisher</span> <span class="kn">import</span> <span class="n">fisher_exact</span>
<span class="g g-Whitespace">     </span><span class="mi">15</span> <span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;fisher_exact&#39;</span><span class="p">]</span>

<span class="n">File</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">hostedtoolcache</span><span class="o">/</span><span class="n">Python</span><span class="o">/</span><span class="mf">3.8.12</span><span class="o">/</span><span class="n">x64</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.8</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">FisherExact</span><span class="o">/</span><span class="n">Fisher</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">4</span><span class="p">,</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">ss</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">gammaln</span> <span class="k">as</span> <span class="n">lgamma</span>
<span class="ne">----&gt; </span><span class="mi">4</span> <span class="kn">from</span> <span class="nn">.statlib</span> <span class="kn">import</span> <span class="n">fexact</span> <span class="k">as</span> <span class="n">f</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="kn">from</span> <span class="nn">.statlib.fexact</span> <span class="kn">import</span> <span class="n">fisher_exact</span> <span class="k">as</span> <span class="n">f_exact</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="kn">from</span> <span class="nn">.statlib.asa159</span> <span class="kn">import</span> <span class="n">rcont2</span>

<span class="ne">ImportError</span>: numpy.core.multiarray failed to import
</pre></div>
</div>
</div>
</div>
<p>The block structure is <em>completely obvious</em>, and it seems like you could almost just guess which nodes are from which communities by looking at the adjacency matrix (with the proper ordering). Ant therein lies the issue: if you did not know which school each student was from, you would have <em>no way</em> of actually using the technique you described in the preceding chapter to estimate parameters for your SBM. If your nodes were just randomly ordered, we might see something instead like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># generate a reordering of the n nodes</span>
<span class="n">vtx_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ns</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ns</span><span class="p">),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">Aperm</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="nb">tuple</span><span class="p">([</span><span class="n">vtx_perm</span><span class="p">])]</span> <span class="p">[:,</span><span class="n">vtx_perm</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">draw_multiplot</span><span class="p">(</span><span class="n">Aperm</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$SBM_n(z, B)$ Simulation, random node order&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>It is extremely unclear which nodes are in which community, because there is no immediate block structure to the network. So, what <em>can</em> you do?</p>
<p>What you will do is use a clever technique we discussed in <a class="reference external" href="#link?">Chapter 6</a>, called an <em>embedding</em>, to learn not only about each edge, but to <em>learn about each node in relation to all of the other nodes</em>. What do we mean by this? What we mean is that, while looking at a single edge in your network, you only have two possible choices: the edge exists or it does not exist. However, if you instead consider nodes in <em>relation</em> to one another, you can start to deduce patterns about how your nodes might be organized in the community sense. While seeing that two students Bill and Stephanie were friends will not tell us whether Bill and Stephanie were in the same school, if you knew that Bill and Stephanie also shared many other friends (such as Denise, Albert, and Kwan), and those friends also tended to be friends, that piece of information might tell us that they all might happen to be school mates.</p>
<p>The embedding technique you will tend to employ, the <em>spectral embedding</em> from <a class="reference external" href="#link?">Chapter 6</a>, allows you to pick up on these <em>community</em> sorts of tendencies. When we call a set of nodes a <strong>community</strong> in the context of a network, what we mean is that these nodes tend to be more connected (more edges exist between and amongst them) than with other nodes in the network. The spectral embeddings will help us to identify these communities of nodes, and hopefully, when you review the communities of nodes you learn, you will be able to derive some sort of insight as to what, exactly, these communities are. For instance, in your school example, ideally, you might pick up on two communities of nodes, one for each school. The process of learning community assignments for nodes in a network is known as <strong>community detection</strong>.</p>
<div class="section" id="stochastic-block-model-with-unknown-communities-when-you-know-the-number-of-communities-k">
<h2><span class="section-number">8.1.1. </span>Stochastic Block Model with unknown communities when you know the number of communities <span class="math notranslate nohighlight">\(K\)</span><a class="headerlink" href="#stochastic-block-model-with-unknown-communities-when-you-know-the-number-of-communities-k" title="Permalink to this headline">¶</a></h2>
<p>When you know the number of communities (even if you don’t know which community each node is in), the procedure for fitting a Stochastic Block Model to a network is relatively straightforward. Let’s consider a similar example to the scenario you had <a class="reference external" href="#link?">in the introduction</a>, but with <span class="math notranslate nohighlight">\(3\)</span> communities instead of <span class="math notranslate nohighlight">\(2\)</span>. You will have a block matrix given by:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    B &amp;= \begin{bmatrix}
        0.4 &amp; 0.2 &amp; 0.2 \\
        0.2 &amp; 0.4 &amp; 0.2 \\
        0.2 &amp; 0.2 &amp; 0.4
    \end{bmatrix}
\end{align*}\]</div>
<p>Which is a Stochastic block model in which the within-community edge probability is <span class="math notranslate nohighlight">\(0.4\)</span>, and exceeds the between-community edge probability of <span class="math notranslate nohighlight">\(0.2\)</span>. You will produce a matrix with <span class="math notranslate nohighlight">\(120\)</span> nodes in total.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">sbm</span>

<span class="n">ns</span> <span class="o">=</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">30</span><span class="p">]</span>
<span class="n">B</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]]</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">sbm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">ns</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">B</span><span class="p">)</span>

<span class="c1"># the true community labels</span>
<span class="n">z</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">ns</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ns</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ns</span><span class="p">[</span><span class="mi">2</span><span class="p">])]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">draw_multiplot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">z</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;A, Simulated $SBM_</span><span class="si">{100}</span><span class="s2">( </span><span class="se">\\</span><span class="s2">vec z, B)$&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Remember, however, that you do not <em>actually</em> know the community labels of each node in <span class="math notranslate nohighlight">\(A\)</span>, so this problem is a little more difficult than it might seem. If you reordered the nodes, the community each node is assigned to would not be as visually obvious as it is here in this example, as you saw in the <span class="xref myst">introduction</span>.</p>
<p>Our goal is to learn about the block matrix, <span class="math notranslate nohighlight">\(B\)</span>, which is the parameter that you care about for the SBM. However, you cannot just plug <span class="math notranslate nohighlight">\(A\)</span> into the <code class="docutils literal notranslate"><span class="pre">SBMEstimator</span></code> class like you did back when you <span class="xref myst">fit an SBM using MLE</span>. This is because the <code class="docutils literal notranslate"><span class="pre">SBMEstimator</span></code> uses node community assignments, which you do not have. Instead, what you will do is turn again to the spectral embedding.</p>
<p>You begin by first embedding <span class="math notranslate nohighlight">\(A\)</span> to estimate a latent position matrix. Remember that to deduce whether there is any latent structure, you take a look at the latent position matrix using a pairplot, like we learned about in <a class="reference external" href="#link?">Chapter 6</a>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.embed</span> <span class="kn">import</span> <span class="n">AdjacencySpectralEmbed</span>

<span class="n">ase</span> <span class="o">=</span> <span class="n">AdjacencySpectralEmbed</span><span class="p">()</span>  <span class="c1"># adjacency spectral embedding, with optimal number of latent dimensions selected using elbow picking</span>
<span class="n">Xhat</span> <span class="o">=</span> <span class="n">ase</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.plot</span> <span class="kn">import</span> <span class="n">pairplot</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">pairplot</span><span class="p">(</span><span class="n">Xhat</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Pairplot of embedding of $A$&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You have some <em>really</em> prominent latent structure here, which is evident from the tightly clustered blobs you have in your pairplot. To see just how “tight” these blobs are, let’s cheat for a second and look at the true labels of each of the points:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">pairplot</span><span class="p">(</span><span class="n">Xhat</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">z</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Pairplot of embedding of $A$&quot;</span><span class="p">,</span> <span class="n">legend_name</span><span class="o">=</span><span class="s2">&quot;Community (Unknown)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>So from what you can see, it’s pretty clear that these extremely tight “blobs” in your dataset correspond <em>exactly</em> to the true community labels of the nodes in your network. So, what you need is a technique which can take a latent position matrix, not know <em>anything</em> about these blobs, and and provide us with a way to learn which points correspond to which blob. For this, we turn to unsupervised learning.</p>
<div class="section" id="unsupervised-learning-via-k-means-clustering">
<h3><span class="section-number">8.1.1.1. </span>Unsupervised learning via k-means clustering<a class="headerlink" href="#unsupervised-learning-via-k-means-clustering" title="Permalink to this headline">¶</a></h3>
<p>To learn about these blobs, or more specifically, <em>clusters</em> in your dataset, you need a technique which will do the following:</p>
<ul class="simple">
<li><p><strong>Given</strong>: Estimates of latent positions, <span class="math notranslate nohighlight">\(\vec x_i\)</span>, for each node <span class="math notranslate nohighlight">\(i\)</span> from <span class="math notranslate nohighlight">\(1\)</span> to <span class="math notranslate nohighlight">\(n\)</span>, and a number of clusters to search for, <span class="math notranslate nohighlight">\(K\)</span>.</p></li>
<li><p><strong>Output</strong>: Predicted labels <span class="math notranslate nohighlight">\(z_i\)</span> for each node <span class="math notranslate nohighlight">\(i\)</span> from <span class="math notranslate nohighlight">\(1\)</span> to <span class="math notranslate nohighlight">\(n\)</span>.</p></li>
</ul>
<p>The way you will do this is using an unsupervised clustering technique known as <span class="math notranslate nohighlight">\(k\)</span>-means clustering. <strong>Unsupervised learning</strong> is the process of learning latent (unknown ahead of time) structure from a dataset. Our problem is <em>unsupervised</em> here because you do not give the algorithm any information as to the structure of which nodes are in which communities.</p>
<p>Through <span class="math notranslate nohighlight">\(k\)</span>-means, you try to find reasonable guesses at the “centers” of the blobs of latent structure in the dataset. You predict that the label of the point is the center which it is closest to. To do this, you first need a definition of close. Throughout this book, we’ve already come across one such definition which will do just fine for now: the Euclidean distance. Remember that the Euclidean distance between two points <span class="math notranslate nohighlight">\(\vec x_i\)</span> and <span class="math notranslate nohighlight">\(\vec x_j\)</span> which each have <span class="math notranslate nohighlight">\(d\)</span>-total dimensions is the quantity:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    ||\vec x_i - \vec x_j||_2 &amp;= \sqrt{\sum_{l = 1}^d (x_{il} - x_{jl})^2}
\end{align*}\]</div>
<p>To illustrate what’s happening graphically, we’re going to take a look at a pairsplot of the second and third dimensions, and work through one loop of the <span class="math notranslate nohighlight">\(k\)</span>-means algorithm. The second and third dimensions look like this:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">DataFrame</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;Dimension 2&quot;</span> <span class="p">:</span> <span class="n">Xhat</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;Dimension 3&quot;</span> <span class="p">:</span> <span class="n">Xhat</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]})</span>
<span class="n">palette</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;0&quot;</span> <span class="p">:</span> <span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">:</span> <span class="s2">&quot;green&quot;</span><span class="p">,</span> <span class="s2">&quot;2&quot;</span><span class="p">:</span> <span class="s2">&quot;red&quot;</span><span class="p">}</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;Dimension 2&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Dimension 3&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Estimates of latent positions&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>To perform <span class="math notranslate nohighlight">\(k\)</span>-means, you need a “starting point” for the centers you will attempt to identify. There are some strategies for doing this strategically (<code class="docutils literal notranslate"><span class="pre">sklearn</span></code>, for instance, uses one called <code class="docutils literal notranslate"><span class="pre">kmeans++</span></code>, which you can read about <a class="reference external" href="https://en.wikipedia.org/wiki/K-means_clustering#initialization-methods">on wikipedia</a>), but for our purposes we’re going to put your centers in basically the worst possible locations: we’ll put them smack dab in the middle of nowhere on your graph. This is problematic for <span class="math notranslate nohighlight">\(k\)</span>-means because of how the “update” step works, but as we’ll see in a few minutes, this really isn’t going to matter in practice for us:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">centers</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">.5</span><span class="p">,</span> <span class="mf">.5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.05</span><span class="p">]])</span>
<span class="n">datcenters</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;Dimension 2&quot;</span><span class="p">:</span> <span class="n">centers</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;Dimension 3&quot;</span><span class="p">:</span> <span class="n">centers</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;Cluster&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;0&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">,</span><span class="s2">&quot;2&quot;</span><span class="p">]})</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;Dimension 2&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Dimension 3&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">datcenters</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;Dimension 2&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Dimension 3&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;Cluster&quot;</span><span class="p">,</span>
                <span class="n">palette</span><span class="o">=</span><span class="n">palette</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Estimates of latent positions with initialized centers&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Next, what you do is you identify which points are “closest” to which cluster center. You do this by computing the distance between each estimate of a latent position and the three centers, and then decide which is the smallest. In the below plot, we recolor each gray point based on which of the centers it is closest to. This is called the points <em>assignment</em> to a particular cluster:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.spatial</span> <span class="kn">import</span> <span class="n">distance_matrix</span>
<span class="n">distances</span> <span class="o">=</span> <span class="n">distance_matrix</span><span class="p">(</span><span class="n">Xhat</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="n">centers</span><span class="p">)</span>
<span class="n">assignment</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">distances</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">data</span><span class="p">[</span><span class="s2">&quot;Closest Center&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">assignment</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;Dimension 2&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Dimension 3&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;Closest Center&quot;</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">palette</span><span class="p">,</span>
                <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">datcenters</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;Dimension 2&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Dimension 3&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;Cluster&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> 
                <span class="n">palette</span><span class="o">=</span><span class="n">palette</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Temporary cluster assignments for estimates of latent positions&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Which is not too bad! It looks like we’ve done a pretty good job at getting some of these blobs assigned to similar clusters when points are in the same blob, but you still have some problems. As you can see, some of your blobs have points which are really similar being colored differently, which is unideal. For this reason, we’re going to do it all again!</p>
<p>Next, you <em>update</em> your centers, by taking the mean value (for each dimension) of the points which are assigned to that cluster. Our centers update like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">centers</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Xhat</span><span class="p">[</span><span class="n">assignment</span> <span class="o">==</span> <span class="n">k</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)])</span>

<span class="n">datcenters</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;Dimension 2&quot;</span><span class="p">:</span> <span class="n">centers</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;Dimension 3&quot;</span><span class="p">:</span> <span class="n">centers</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;Cluster&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;0&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">,</span><span class="s2">&quot;2&quot;</span><span class="p">]})</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;Dimension 2&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Dimension 3&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;Closest Center&quot;</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">palette</span><span class="p">,</span>
                <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">datcenters</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;Dimension 2&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Dimension 3&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;Cluster&quot;</span><span class="p">,</span>
                <span class="n">palette</span><span class="o">=</span><span class="n">palette</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Cluster centers updated based on average of assigned points&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>You can see where we’re going with this, right? You assume again that the points are totally unlabeled (gray), you recompute which center each point is closest to, and then you re-update your centers. This is called the second <em>iteration</em> of the algorithm, because you are doing the exact same process a second time:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">distances</span> <span class="o">=</span> <span class="n">distance_matrix</span><span class="p">(</span><span class="n">Xhat</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="n">centers</span><span class="p">)</span>
<span class="n">assignment</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">distances</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">centers_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Xhat</span><span class="p">[</span><span class="n">assignment</span> <span class="o">==</span> <span class="n">k</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)])</span>

<span class="n">data</span><span class="p">[</span><span class="s2">&quot;Closest Center&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">assignment</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>

<span class="n">color_kwarg</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="s2">&quot;gray&quot;</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;hue&quot;</span><span class="p">:</span> <span class="s2">&quot;Closest Center&quot;</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;hue&quot;</span><span class="p">:</span> <span class="s2">&quot;Closest Center&quot;</span><span class="p">}]</span>
<span class="n">cdat</span> <span class="o">=</span> <span class="p">[</span><span class="n">centers</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">centers_new</span><span class="p">]</span>
<span class="n">titles</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;1. Centers from previous iteration&quot;</span><span class="p">,</span> <span class="s2">&quot;2. Temporary cluster assignments&quot;</span><span class="p">,</span> <span class="s2">&quot;3. Update centers&quot;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axs</span><span class="o">.</span><span class="n">flat</span><span class="p">):</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;Dimension 2&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Dimension 3&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="o">**</span><span class="n">color_kwarg</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                    <span class="n">palette</span><span class="o">=</span><span class="n">palette</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">datcenters</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;Dimension 2&quot;</span><span class="p">:</span> <span class="n">cdat</span><span class="p">[</span><span class="n">i</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;Dimension 3&quot;</span><span class="p">:</span> <span class="n">cdat</span><span class="p">[</span><span class="n">i</span><span class="p">][:,</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;Cluster&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;0&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">,</span><span class="s2">&quot;2&quot;</span><span class="p">]})</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">datcenters</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;Dimension 2&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Dimension 3&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;Cluster&quot;</span><span class="p">,</span>
                    <span class="n">palette</span><span class="o">=</span><span class="n">palette</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">titles</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</pre></div>
</div>
</div>
</div>
<p>And you just keep repeating this 3 step procedure over and over again, until your centers stop changing very much. When you stop again is an area of research interest like the initialization procedure for the centers, known as the <em>stopping criterion</em> for the algorithm. As you can see, after doing this process just <em>twice</em>, you already have homogeneous blobs, in that points from each of the three clusters are all assigned to the same cluster. You can automate this entire process and use the nearest clusters to produce the “predicted labels” using <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="n">labels_kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">Xhat</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You can take a look at the pairs plot now, with the <em>predicted labels</em> and check to ensure that you found the blobs you saw visually as uniform clusters:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">pairplot</span><span class="p">(</span><span class="n">Xhat</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels_kmeans</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Pairplot of embedding of $A$&quot;</span><span class="p">,</span> <span class="n">legend_name</span><span class="o">=</span><span class="s2">&quot;Predicted Cluster&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You use these predicted cluster labels as the <em>predicted communities</em> for your Stochastic Block Model.</p>
</div>
<div class="section" id="evaluating-k-means-clustering">
<h3><span class="section-number">8.1.1.2. </span>Evaluating <span class="math notranslate nohighlight">\(k\)</span>-means clustering<a class="headerlink" href="#evaluating-k-means-clustering" title="Permalink to this headline">¶</a></h3>
<p>Since you have simulated data, you have the benefit of being able to evaluate the quality of your predicted community assignments to the true community assignments. However, there is an important caveat: your predictions might not <em>necessarily</em> align with your true labels. What we mean by this is that, your true communities might impart something meaningful about your dataset (here, they are just 0s, 1s, and 2s, but in a real dataset, they could be more meaningful things, like “School 1”, “School 2”, and “School 3”). Since we did not assume you knew <em>anything</em> about the communities when you ran your clustering, the predicted clusters will not have a correspondance with the original community names. In your example, this means that even though community 0 in the true labels and community 2 in the predicted labels encompass the same points, since the algorithm didn’t know to call those points community 0, it just arbitrarily called them community 2. How can you proceed?</p>
<div class="section" id="the-confusion-matrix-lets-us-visualize-the-homogeneity-of-predictions-relative-the-true-labels">
<h4><span class="section-number">8.1.1.2.1. </span>The confusion matrix lets us visualize the homogeneity of predictions relative the true labels<a class="headerlink" href="#the-confusion-matrix-lets-us-visualize-the-homogeneity-of-predictions-relative-the-true-labels" title="Permalink to this headline">¶</a></h4>
<p>To overcome this limitation for evaluation, we look at something called a confusion matrix. A <strong>confusion matrix</strong> is a matrix you use when you have two sets of labels for a group of data points, one of which you know to be the <em>true</em> labels, and another set of labels for which you do not know (yet) whether there is a correspondance with the true set of labels. If the set of true labels is one of <span class="math notranslate nohighlight">\(L\)</span> possible values and the other set of labels take one of <span class="math notranslate nohighlight">\(K\)</span> possible values, the confusion matrix will be:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>True label</p></th>
<th class="head"><p>Predicted label <span class="math notranslate nohighlight">\(1\)</span></p></th>
<th class="head"><p>…</p></th>
<th class="head"><p>Predicted label <span class="math notranslate nohighlight">\(K\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>True label <span class="math notranslate nohighlight">\(1\)</span></p></td>
<td><p>#points(Predicted label <span class="math notranslate nohighlight">\(1\)</span>, true label <span class="math notranslate nohighlight">\(1\)</span>)</p></td>
<td><p>…</p></td>
<td><p>#points(Predicted label <span class="math notranslate nohighlight">\(K\)</span>, true label <span class="math notranslate nohighlight">\(1\)</span>)</p></td>
</tr>
<tr class="row-odd"><td><p>True label <span class="math notranslate nohighlight">\(2\)</span></p></td>
<td><p>#points(Predicted label <span class="math notranslate nohighlight">\(1\)</span>, true label <span class="math notranslate nohighlight">\(2\)</span>)</p></td>
<td><p>…</p></td>
<td><p>#points(Predicted label <span class="math notranslate nohighlight">\(K\)</span>, true label <span class="math notranslate nohighlight">\(2\)</span>)</p></td>
</tr>
<tr class="row-even"><td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
</tr>
<tr class="row-odd"><td><p>True label <span class="math notranslate nohighlight">\(L\)</span></p></td>
<td><p>#points(Predicted label <span class="math notranslate nohighlight">\(1\)</span>, true label <span class="math notranslate nohighlight">\(L\)</span>)</p></td>
<td><p>…</p></td>
<td><p>#points(Predicted label <span class="math notranslate nohighlight">\(K\)</span>, true label <span class="math notranslate nohighlight">\(L\)</span>)</p></td>
</tr>
</tbody>
</table>
<p>You can compute and plot this matrix using a heatmap:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="c1"># compute the confusion matrix between the true labels z</span>
<span class="c1"># and the predicted labels labels_kmeans</span>
<span class="n">cf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">labels_kmeans</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cf_matrix</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmaps</span><span class="p">[</span><span class="s2">&quot;sequential&quot;</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Confusion matrix&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;True Label&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>What you want to see, in general, in the confusion matrix for a “good” clustering is that the proportion of nodes which have a particular true label are “largely” assigned to the same predicted label. In this case, it’s really obvious, because the predictions are virtually entirely (if not entirely) homogeneous, in that a single predicted label corresponds to a single true label. However, for posterity, a useful exercise is to get used to normalizing this confusion matrix, because things won’t always be quite so obvious. You can do this by the counts by the total number of points assigned to a particular true label, which gives us the normalized confusion matrix:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cfm_norm</span> <span class="o">=</span> <span class="n">cf_matrix</span><span class="o">/</span><span class="n">cf_matrix</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span><span class="kc">None</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cfm_norm</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmaps</span><span class="p">[</span><span class="s2">&quot;sequential&quot;</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Normalized confusion matrix&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;True Label&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Now, it becomes clear that all of the points with a true label of <span class="math notranslate nohighlight">\(0\)</span> are assigned to a predicted label of <span class="math notranslate nohighlight">\(1\)</span>, so on and so forth for all of the individual rows. So, how do you actually determine whether a confusion matrix indicates you did a good job with your predictions, and that your predictions and true labels “align”?</p>
</div>
<div class="section" id="you-can-evaluate-the-homogeneity-of-the-confusion-matrix-using-the-adjusted-rand-index-ari">
<h4><span class="section-number">8.1.1.2.2. </span>You can evaluate the homogeneity of the confusion matrix using the adjusted rand index (ARI)<a class="headerlink" href="#you-can-evaluate-the-homogeneity-of-the-confusion-matrix-using-the-adjusted-rand-index-ari" title="Permalink to this headline">¶</a></h4>
<p>For this purpose, we turn to the Rand Index, or RI. With the rand index, instead of looking at the confusion matrix itself <em>directly</em>, you look at all pairs of your data points. For a given pair of points in your dataset, these points can have true labels that are either the same, or different. Further, these points can have predicted labels that are either the same, or different. We introduce the following two concepts:</p>
<ol class="simple">
<li><p><em>Success</em>: Two points with the same true labels have the same predicted labels, or two points with different true labels have different predicted labels. This means that the two points <em>align homogeneously</em> across the true and predicted labels.</p></li>
<li><p><em>Failure</em>: Two points with different true labels have the same predicted labels, or two points with the same true labels have different predicted labels. This means that the two points have a <em>heterogeneous alignment</em> across the true and predicted labels.
To compute the rand index, you simply take the ratio of successes divided by the total number of comparisons:</p></li>
</ol>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    RI &amp;= \frac{\text{Successes}}{\text{Successes} + \text{Failures}}
\end{align*}\]</div>
<p>The Rand Index will have a value between <span class="math notranslate nohighlight">\(0\)</span> or <span class="math notranslate nohighlight">\(1\)</span>, where a high value corresponds to a majority of the comparisons being successes (and hence, the true labels and predicted labels are homogeneous).</p>
<p>There’s a slight problem here when you want to use this number for evaluating a clustering. What if your true labels are disproportionate, in that one true label has a ton of data points, and the others only a small fraction of data points? By simply <em>guessing</em> that all of the points are from the biggest class, you could still end up with a pretty high RI.</p>
<p>Consider, for instance, a simple example example in the very extreme case. Let’s say that you have <span class="math notranslate nohighlight">\(10\)</span> points, <span class="math notranslate nohighlight">\(9\)</span> of which are in class <span class="math notranslate nohighlight">\(1\)</span>, and <span class="math notranslate nohighlight">\(1\)</span> of which is in class <span class="math notranslate nohighlight">\(2\)</span>. What happens to the RI if you were to learn nothing about the structure of these points, and just guess that all of the points are in class <span class="math notranslate nohighlight">\(1\)</span> without even looking at the data?</p>
<p>You can pick a single point from <span class="math notranslate nohighlight">\(10\)</span> possible points, and then you compare this point to any of the other <span class="math notranslate nohighlight">\(9\)</span> points. This means you will have <span class="math notranslate nohighlight">\(10 \cdot 9 = 90\)</span> comparisons in total. Let’s break down how these comparisons will go. You first choose the first point, which can be one of the <span class="math notranslate nohighlight">\(9\)</span> items in class <span class="math notranslate nohighlight">\(1\)</span>, or the <span class="math notranslate nohighlight">\(1\)</span> item in class <span class="math notranslate nohighlight">\(2\)</span>:</p>
<ol class="simple">
<li><p>The first point is in class <span class="math notranslate nohighlight">\(1\)</span>:</p>
<ul class="simple">
<li><p>The second point is also in class <span class="math notranslate nohighlight">\(1\)</span>: Of the remaining <span class="math notranslate nohighlight">\(9\)</span> points you could choose for the second point, <span class="math notranslate nohighlight">\(8\)</span> of them will have the same true label and predicted label as point <span class="math notranslate nohighlight">\(1\)</span> (since you always guessed items were from class <span class="math notranslate nohighlight">\(1\)</span>). This means you will have <span class="math notranslate nohighlight">\(9\)</span> (number of possible points which are from class <span class="math notranslate nohighlight">\(1\)</span>) times <span class="math notranslate nohighlight">\(8\)</span> (number of remaining points which also have a true label of class <span class="math notranslate nohighlight">\(1\)</span>) <span class="math notranslate nohighlight">\(=72\)</span> successes in which the point has a true label of <span class="math notranslate nohighlight">\(1\)</span> and a predicted label of <span class="math notranslate nohighlight">\(1\)</span>.</p></li>
</ul>
</li>
<li><p>The first point is in class <span class="math notranslate nohighlight">\(2\)</span>:</p>
<ul class="simple">
<li><p>You have no successful comparisons when the first point is in class <span class="math notranslate nohighlight">\(2\)</span>, since the other points all have the same predicted label but a different true label.</p></li>
</ul>
</li>
</ol>
<p>This means that your RI is <span class="math notranslate nohighlight">\(\frac{72}{90} = 0.8\)</span>, which <em>feels</em> really high doesn’t it, since it’s closer to the highest possible value of <span class="math notranslate nohighlight">\(1\)</span> than the lowest possible value of <span class="math notranslate nohighlight">\(0\)</span>?</p>
<p>To overcome this “weakness” in the RI, you instead “adjust” for the possible situations like this where the fractions of points with a particular true label are unevenly dispersed throughout the dataset. This “adjustment” to the RI is aptly named: it is called the <strong>Adjusted Rand Index</strong> (ARI). You can compute the ARI using <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> easily:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">adjusted_rand_score</span>

<span class="n">ari_kmeans</span> <span class="o">=</span> <span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">labels_kmeans</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ARI(predicted communities, true communities) = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ari_kmeans</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="by-remapping-the-labels-you-can-evaluate-the-error-rate">
<h4><span class="section-number">8.1.1.2.3. </span>By remapping the labels, you can evaluate the error rate<a class="headerlink" href="#by-remapping-the-labels-you-can-evaluate-the-error-rate" title="Permalink to this headline">¶</a></h4>
<p>Looking back at the confusion matrix:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cf_matrix</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmaps</span><span class="p">[</span><span class="s2">&quot;sequential&quot;</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Confusion matrix&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;True Label&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>It seems pretty clear that the label correspondance between the true labels and predicted labels is as follows:</p>
<ol class="simple">
<li><p>Nodes which have a true label of <span class="math notranslate nohighlight">\(0\)</span> correspond to a predicted label of <span class="math notranslate nohighlight">\(0\)</span>,</p></li>
<li><p>Nodes which have a true label of <span class="math notranslate nohighlight">\(1\)</span> correspond to a predicted label of <span class="math notranslate nohighlight">\(2\)</span>,</p></li>
<li><p>Nodes which have a true label of <span class="math notranslate nohighlight">\(2\)</span> correspond to a predicted label of <span class="math notranslate nohighlight">\(1\)</span>.
This is because all of the nodes which have a true label of <span class="math notranslate nohighlight">\(0\)</span> are assigned a predicted label of <span class="math notranslate nohighlight">\(0\)</span>, all of the nodes with a true label of <span class="math notranslate nohighlight">\(1\)</span> are assigned a predicted label of <span class="math notranslate nohighlight">\(2\)</span>, and all of the nodes with a true label of <span class="math notranslate nohighlight">\(2\)</span> have a predicted label of <span class="math notranslate nohighlight">\(1\)</span>. But when the results aren’t perfect, this is a little bit harder to do, and involves a bit of background in optimization theory, which is outside of the scope of this book. Fortunately, <code class="docutils literal notranslate"><span class="pre">graspologic</span></code> makes this easy for us, with the <code class="docutils literal notranslate"><span class="pre">remap_labels</span></code> function:</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.utils</span> <span class="kn">import</span> <span class="n">remap_labels</span>

<span class="n">labels_kmeans_remap</span> <span class="o">=</span> <span class="n">remap_labels</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">labels_kmeans</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You can use these remapped labels to understand when <code class="docutils literal notranslate"><span class="pre">KMeans</span></code> is, or is not, producing reasonable labels for your investigation. You begin by first looking at a pairs plot, which now will color the points by their assigned community:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">pairplot</span><span class="p">(</span><span class="n">Xhat</span><span class="p">,</span>
         <span class="n">labels</span><span class="o">=</span><span class="n">labels_kmeans_remap</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;KMeans on embedding, ARI: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">ari_kmeans</span><span class="p">)[:</span><span class="mi">5</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
         <span class="n">legend_name</span><span class="o">=</span><span class="s1">&#39;Predicted label (remapped)&#39;</span><span class="p">,</span>
         <span class="n">height</span><span class="o">=</span><span class="mf">3.5</span><span class="p">,</span>
         <span class="n">palette</span><span class="o">=</span><span class="s1">&#39;muted&#39;</span><span class="p">,);</span>
</pre></div>
</div>
</div>
</div>
<p>The final utility of the pairs plot is that you can investigate which points, if any, the clustering technique is getting wrong. You can do this by looking at the classification error of the nodes to each community:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">error</span> <span class="o">=</span> <span class="n">z</span> <span class="o">-</span> <span class="n">labels_kmeans_remap</span>  <span class="c1"># compute which assigned labels from labels_kmeans_remap differ from the true labels z</span>
<span class="n">error</span> <span class="o">=</span> <span class="n">error</span> <span class="o">!=</span> <span class="mi">0</span>  <span class="c1"># if the difference between the community labels is non-zero, an error has occurred</span>
<span class="n">er_rt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>  <span class="c1"># error rate is the frequency of making an error</span>

<span class="n">palette</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Correct Pred.&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.7</span><span class="p">,</span><span class="mf">0.2</span><span class="p">),</span>
           <span class="s1">&#39;Incorrect Pred.&#39;</span><span class="p">:(</span><span class="mf">0.8</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)}</span>

<span class="n">error_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">*</span><span class="p">[</span><span class="s1">&#39;Correct Pred.&#39;</span><span class="p">])</span>  <span class="c1"># initialize numpy array for each node</span>
<span class="n">error_label</span><span class="p">[</span><span class="n">error</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;Wrong Pred.&#39;</span>  <span class="c1"># add label &#39;Wrong&#39; for each error that is made</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pairplot</span><span class="p">(</span><span class="n">Xhat</span><span class="p">,</span>
         <span class="n">labels</span><span class="o">=</span><span class="n">error_label</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Error from KMeans, Error rate: </span><span class="si">{:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">er_rt</span><span class="p">),</span>
         <span class="n">legend_name</span><span class="o">=</span><span class="s1">&#39;Error label&#39;</span><span class="p">,</span>
         <span class="n">height</span><span class="o">=</span><span class="mf">3.5</span><span class="p">,</span>
         <span class="n">palette</span><span class="o">=</span><span class="n">palette</span><span class="p">,);</span>
</pre></div>
</div>
</div>
</div>
<p>Great! Our classification has not made any errors.</p>
<p>To learn about the block matrix <span class="math notranslate nohighlight">\(B\)</span>, you can now use the <code class="docutils literal notranslate"><span class="pre">SBMEstimator</span></code> class, with your predicted labels:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.models</span> <span class="kn">import</span> <span class="n">SBMEstimator</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SBMEstimator</span><span class="p">(</span><span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">labels_kmeans_remap</span><span class="p">)</span>
<span class="n">Bhat</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">block_p_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.plot</span> <span class="kn">import</span> <span class="n">heatmap</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">mtxs</span> <span class="o">=</span> <span class="p">[</span><span class="n">Bhat</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">B</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">Bhat</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">B</span><span class="p">))]</span>
<span class="n">titles</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;True $B_</span><span class="si">{SBM}</span><span class="s2">$&quot;</span><span class="p">,</span> <span class="s2">&quot; Prediction $\hat B_</span><span class="si">{SBM}</span><span class="s2">$&quot;</span><span class="p">,</span> <span class="s2">&quot;$|\hat B_</span><span class="si">{SBM}</span><span class="s2"> - B_</span><span class="si">{SBM}</span><span class="s2">|$&quot;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axs</span><span class="o">.</span><span class="n">flat</span><span class="p">):</span>
    <span class="n">heatmap</span><span class="p">(</span><span class="n">mtxs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">font_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
            <span class="n">title</span><span class="o">=</span><span class="n">titles</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmaps</span><span class="p">[</span><span class="s2">&quot;sequential&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Which appears to be relatively close to the true block matrix.</p>
<div class="admonition-recap-of-inference-for-stochastic-block-model-with-known-number-of-communities admonition">
<p class="admonition-title">Recap of inference for Stochastic Block Model with known number of communities</p>
<ol class="simple">
<li><p>You learned that the adjacency spectral embedding is a key algorithm for making sense of networks which are realizations of SBM random networks. The estimates of latent positions produced by ASE are critical for learning community assignments.</p></li>
<li><p>You learned that unsuperised learning (such as K-means) allows us to ues the estimated latent positions to learn community assignments for each node in your network.</p></li>
<li><p>You can use <code class="docutils literal notranslate"><span class="pre">remap_labels</span></code> to align predicted labels with true labels, if true labels are known. This is useful for benchmarking techniques on networks with known community labels.</p></li>
<li><p>You evaluate the quality of unsupervised learning by plotting the predicted node labels and (if you know the true labels) the errorfully classified nodes. The ARI and the error rate summarize how effective your unsupervised learning techniques performed.</p></li>
</ol>
</div>
</div>
</div>
</div>
<div class="section" id="number-of-communities-k-is-not-known">
<h2><span class="section-number">8.1.2. </span>Number of communities <span class="math notranslate nohighlight">\(K\)</span> is not known<a class="headerlink" href="#number-of-communities-k-is-not-known" title="Permalink to this headline">¶</a></h2>
<p>In real data, you almost never have the beautiful canonical modular structure obvious to yourom a Stochastic Block Model. This means that it is <em>extremely infrequently</em> going to be the case that you know exactly how you should set the number of communities, <span class="math notranslate nohighlight">\(K\)</span>, ahead of time.</p>
<p>Let’s first remember back to the single network models section, when you took a Stochastic block model with obvious community structure, and let’s see what happens when you just move the nodes of the adjacency matrix around. You begin with a similar adjacency matrix to <span class="math notranslate nohighlight">\(A\)</span> given above, for the <span class="math notranslate nohighlight">\(3\)</span>-community SBM example, but with the within and between-community edge probabilities a bit closer together so that you can see what happens when you experience errors. The communities are still quite apparent from the adjaceny matrix:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">B</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]]</span>
<span class="n">ns</span> <span class="o">=</span> <span class="p">[</span><span class="mi">40</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">40</span><span class="p">]</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">sbm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">ns</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">B</span><span class="p">)</span>

<span class="c1"># the true community labels</span>
<span class="n">z</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">ns</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ns</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ns</span><span class="p">[</span><span class="mi">2</span><span class="p">])]</span>
<span class="n">draw_multiplot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">z</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Simulated SBM($\pi$, B)&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Next, you permute the nodes around to reorder the realized adjacency matrix:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># generate a reordering of the n nodes</span>
<span class="n">vtx_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">A_permuted</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="nb">tuple</span><span class="p">([</span><span class="n">vtx_perm</span><span class="p">])]</span> <span class="p">[:,</span><span class="n">vtx_perm</span><span class="p">]</span>
<span class="n">z_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">z</span><span class="p">)[</span><span class="n">vtx_perm</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">heatmap</span> <span class="k">as</span> <span class="n">hm_code</span> 
<span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">draw_layout_plot</span> <span class="k">as</span> <span class="n">lp_code</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># heatmap</span>
<span class="n">hm</span> <span class="o">=</span> <span class="n">hm_code</span><span class="p">(</span>
    <span class="n">A_permuted</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;sequential&quot;</span><span class="p">,</span>
    <span class="n">xticklabels</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">yticklabels</span><span class="o">=</span><span class="mi">10</span>
<span class="p">)</span>

<span class="c1"># layout plot</span>
<span class="n">lp_code</span><span class="p">(</span><span class="n">A_permuted</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">pos</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">z_perm</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;qualitative&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Simulated $SBM(</span><span class="se">\\</span><span class="s2">vec z, B)$, reordered vertices&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.1</span><span class="p">)</span>

<span class="n">fig</span><span class="p">;</span>
</pre></div>
</div>
</div>
</div>
<p>You only get to see the adjacency matrix in the <em>left</em> panel; the panel in the <em>right</em> is constructed by using the true labels (which you do <em>not</em> have!). This means that you proceed for statistical inference about the random network underlying your realized network using <em>only</em> the heatmap you have at left. It is not immediately obvious that this is the realization of a random network which is an SBM with <span class="math notranslate nohighlight">\(3\)</span> communities.</p>
<p>Our procedure is <em>very</em> similar to what you did previously <a class="reference external" href="#link?">when the number of communities was known</a>. You again embed using the “elbow picking” technique:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ase_perm</span> <span class="o">=</span> <span class="n">AdjacencySpectralEmbed</span><span class="p">()</span>  <span class="c1"># adjacency spectral embedding, with optimal number of latent dimensions selected using elbow picking</span>
<span class="n">Xhat_permuted</span> <span class="o">=</span> <span class="n">ase_perm</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">A_permuted</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You examine the pairs plot, <em>just</em> like in the section on <a class="reference external" href="#link?">pairs plots</a>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">pairplot</span><span class="p">(</span><span class="n">Xhat_permuted</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;SBM adjacency spectral embedding&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You can still see that there is some level of latent community structure apparent in the pairs plot, as you can see some “blob” separation.</p>
<p>Next, you have the biggest difference with the approach you took previously. Since you do <em>not</em> know the optimal number of clusters <span class="math notranslate nohighlight">\(K\)</span> <em>nor</em> the true community assignments, you must choose an unsupervised clustering technique which allows us to <em>compare</em> clusterings with different choices of cluster counts. Fortunately, this is pretty easy for us to do, too, using a simple statistic known as the Silhouette score.</p>
<div class="section" id="the-silhouette-score-allows-us-to-compare-unsupervised-clustering-quality">
<h3><span class="section-number">8.1.2.1. </span>The Silhouette score allows us to compare unsupervised clustering quality<a class="headerlink" href="#the-silhouette-score-allows-us-to-compare-unsupervised-clustering-quality" title="Permalink to this headline">¶</a></h3>
<p>The Silhouette score will provide you with a statistic that you can compare across clusterings with different numbers of clusters. At an extremely high level, the Silhouette score asks the simple question, “How similar are the nodes in the same cluster from other clusters?” If for a given number of clusters, and those clusters are <em>spatially unique</em> (there aren’t too many clusters for what is really just a single blob of points, and likewise, there aren’t single clusters doing a job that might be better served by two clusters), then the Silhouette score will, ideally, be higher. We mention this statistic in particular because it can be reasonably used with <em>any</em> unsupervised learning technique, and won’t pose restrictions on the unsupervised technique chosen, for instance. Other popular techniques, such as the Bayesian Information Criterion (BIC), can <em>only</em> be computed when assumptions are made about the unsupervised learning technique used, but you can read about them on your own time for more information if you want.</p>
<p>To compute the Silhouette score, you need some basic ingredients first. You have data points <span class="math notranslate nohighlight">\(x_i\)</span> for <span class="math notranslate nohighlight">\(i\)</span> from <span class="math notranslate nohighlight">\(1\)</span> to <span class="math notranslate nohighlight">\(n\)</span>, the estimates of latent positions of the nodes in your network, and you have predicted community labels <span class="math notranslate nohighlight">\(z_i\)</span>, which assign each node to one of <span class="math notranslate nohighlight">\(K\)</span> possible clusters. We will call the set of nodes assigned to the cluster with label <span class="math notranslate nohighlight">\(k\)</span> the set <span class="math notranslate nohighlight">\(C_k\)</span>, which is just a collection of indexes of nodes in the network. For instance, if the network had <span class="math notranslate nohighlight">\(10\)</span> nodes and the total number of clusters you were considering was two, where the first five nodes were assigned to cluster <span class="math notranslate nohighlight">\(1\)</span> and the second five nodes were assigned to cluster <span class="math notranslate nohighlight">\(2\)</span>, then <span class="math notranslate nohighlight">\(C_1 = \{1,2,3,4,5\}\)</span>, and <span class="math notranslate nohighlight">\(C_2 = \{6,7,8,9,10\}\)</span>. We will call the total number of nodes which are in community <span class="math notranslate nohighlight">\(k\)</span> the quantity <span class="math notranslate nohighlight">\(n_k\)</span>. You have the following two ingredients:</p>
<ol class="simple">
<li><p>The dissimilarity of a node <span class="math notranslate nohighlight">\(i\)</span> from the other nodes in its community: You compute the average distance between the estimate of the latent position for the node <span class="math notranslate nohighlight">\(i\)</span>, and all of the other nodes which are in the same community as node <span class="math notranslate nohighlight">\(i\)</span>. If you assume that the node <span class="math notranslate nohighlight">\(i\)</span> is in community <span class="math notranslate nohighlight">\(k\)</span>, this is just the quantity:</p></li>
</ol>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    a_i &amp;= \frac{1}{n_k - 1} \sum_{j \in C_k, i \neq j}||\vec x_i - \vec x_j||
\end{align*}\]</div>
<p>where <span class="math notranslate nohighlight">\(||x - y||\)</span> is the Euclidean distance between two vectors <span class="math notranslate nohighlight">\(\vec x_i\)</span> and <span class="math notranslate nohighlight">\(\vec x_j\)</span>. The sum just indicates that you are computing distances over all of the other nodes in community <span class="math notranslate nohighlight">\(k\)</span> which are <em>not</em> node <span class="math notranslate nohighlight">\(i\)</span> (node <span class="math notranslate nohighlight">\(i\)</span> is in community <span class="math notranslate nohighlight">\(k\)</span>, so there are <span class="math notranslate nohighlight">\(n_k - 1\)</span> of these other points), and then you take the average by dividing by the number of points in community <span class="math notranslate nohighlight">\(k\)</span> which are <em>not</em> node <span class="math notranslate nohighlight">\(i\)</span>.
2. The dissimilarity of a node <span class="math notranslate nohighlight">\(i\)</span> from the other nodes in a different community: We compute the average distance between the estimate of the latent position for the node <span class="math notranslate nohighlight">\(i\)</span>, and this time all of the other nodes which are in some other community <span class="math notranslate nohighlight">\(l\)</span> from node <span class="math notranslate nohighlight">\(i\)</span>. If you assume that the node <span class="math notranslate nohighlight">\(i\)</span> is in community <span class="math notranslate nohighlight">\(k\)</span>, this is just the quantity:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    b_{il} &amp;= \frac{1}{n_l} \sum_{j \in C_l}||\vec x_i - \vec x_j||
\end{align*}\]</div>
<p>Node <span class="math notranslate nohighlight">\(i\)</span> is in community <span class="math notranslate nohighlight">\(k\)</span>, so this time, you don’t need to worry about excluding the node <span class="math notranslate nohighlight">\(i\)</span> from your comparisons (and, you can compare to every other node in <span class="math notranslate nohighlight">\(C_l\)</span>).
3. The <em>other</em> community that node <span class="math notranslate nohighlight">\(i\)</span> is most similar to: This is just the community for which has the <em>smallest</em> dissimilarity from node <span class="math notranslate nohighlight">\(i\)</span>, and hence, is the <em>best alternative cluster</em> that you could have assigned <span class="math notranslate nohighlight">\(i\)</span> to:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    d_i &amp;= \min_{l\text{ is a community}}b_{il}
\end{align*}\]</div>
<p>And the Silhouette of node <span class="math notranslate nohighlight">\(i\)</span> in community <span class="math notranslate nohighlight">\(k\)</span> is just:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    s_i &amp;= \begin{cases}
        \frac{d_i - a_i}{\max(a_i, d_i)} &amp; n_k &gt; 1 \\
        0 &amp; n_k = 1
    \end{cases}
\end{align*}\]</div>
<p>In words, if the Silhouette <span class="math notranslate nohighlight">\(s_i\)</span> is near <span class="math notranslate nohighlight">\(1\)</span>, then the node <span class="math notranslate nohighlight">\(i\)</span> is much more similar to points which are in its own cluster than the best alternative, since since a value near <span class="math notranslate nohighlight">\(1\)</span> can only happen if <span class="math notranslate nohighlight">\(d_i\)</span> is much bigger than <span class="math notranslate nohighlight">\(a_i\)</span>. Further, if the Silhouette is near <span class="math notranslate nohighlight">\(-1\)</span>, then the node <span class="math notranslate nohighlight">\(i\)</span> is more similar to points which are in a neighboring cluster which is not the one it was assigned to. This is because negative values can only happen if node <span class="math notranslate nohighlight">\(i\)</span>s dissimilarity from other points in its cluster, <span class="math notranslate nohighlight">\(a_i\)</span>, is higher than its dissimilarity from other points in another cluster, <span class="math notranslate nohighlight">\(d_i\)</span>.</p>
<p>You get the silhouette score for however many clusters you are trying <span class="math notranslate nohighlight">\(K\)</span> by just taking the average of the node-wise silhouettes:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    S_K &amp;= \frac{1}{n} \sum_{i = 1}^n s_i
\end{align*}\]</div>
</div>
<div class="section" id="using-the-silhouette-score-to-deduce-an-appropriate-number-of-communities">
<h3><span class="section-number">8.1.2.2. </span>Using the Silhouette score to deduce an appropriate number of communities<a class="headerlink" href="#using-the-silhouette-score-to-deduce-an-appropriate-number-of-communities" title="Permalink to this headline">¶</a></h3>
<p>Now that you have the Silhouette score, deducing an appropriate number of communities is pretty easy. You choose a range of clusters that you think might be appropriate for your network. Let’s say, for instance, you think there might be as many as <span class="math notranslate nohighlight">\(10\)</span> clusters in your dataset. You perform a clustering using unsupervised learning for all possible numbers of clusters, from <span class="math notranslate nohighlight">\(2\)</span> all the way up to the maximum number of clusters you think could be reasonable. Then, you compute the Silhouette score for this number of clusters. Finally, you choose the number of clusters which has the highest Silhouette score. Let’s see how to do this, using <code class="docutils literal notranslate"><span class="pre">graspologic</span></code>’s <code class="docutils literal notranslate"><span class="pre">KMeansCluster</span></code> function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.cluster</span> <span class="kn">import</span> <span class="n">KMeansCluster</span>

<span class="n">km_clust</span> <span class="o">=</span> <span class="n">KMeansCluster</span><span class="p">(</span><span class="n">max_clusters</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span>
<span class="n">km_clust</span> <span class="o">=</span> <span class="n">km_clust</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xhat_permuted</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Next, you visualize the Silhouette Score as a function of the number of clusters:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">DataFrame</span> <span class="k">as</span> <span class="n">df</span>

<span class="n">nclusters</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>  <span class="c1"># graspologic nclusters goes from 2 to max_clusters</span>
<span class="n">silhouette</span> <span class="o">=</span> <span class="n">km_clust</span><span class="o">.</span><span class="n">silhouette_</span> <span class="c1"># obtain the respective silhouette</span>

<span class="n">bic_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">({</span><span class="s2">&quot;Number of Clusters&quot;</span><span class="p">:</span> <span class="n">nclusters</span><span class="p">,</span> <span class="s2">&quot;Silhouette Score&quot;</span><span class="p">:</span> <span class="n">silhouette</span><span class="p">})</span>  <span class="c1"># place into pandas dataframe</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">bic_df</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;Number of Clusters&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Silhouette Score&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Silhouette Analysis of KMeans Clusterings&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="p">;</span>
</pre></div>
</div>
</div>
</div>
<p>As you can see, Silhouette analysis has indicated the best number of clusters as <span class="math notranslate nohighlight">\(3\)</span> (which, is indeed, <em>correct</em> since we are performing a simulation where we know the right answer). We can get the labels produced by <span class="math notranslate nohighlight">\(k\)</span>-means using automatic number of clusters selection as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">labels_autokmeans</span> <span class="o">=</span> <span class="n">km_clust</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">Xhat_permuted</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As an exercise, you should go through the preceding section, and recompute all the diagnostics we did last time for determining whether our predictions were reasonable. You will do this by comparing the true permuted labels <code class="docutils literal notranslate"><span class="pre">y_perm</span></code> to the predicted labels on the permuted nodes, <code class="docutils literal notranslate"><span class="pre">labels_autokmeans</span></code>.</p>
</div>
</div>
<div class="section" id="community-detection-with-other-types-of-embeddings">
<h2><span class="section-number">8.1.3. </span>Community detection with other types of embeddings<a class="headerlink" href="#community-detection-with-other-types-of-embeddings" title="Permalink to this headline">¶</a></h2>
<p>If you remember from Chapter 6, we also discussed several other embedding techniques, such as <a class="reference external" href="#link?">LSE</a>, <a class="reference external" href="#link?">node2vec</a>, and <a class="reference external" href="#link?">GNNs</a>. These techniques can be used, often interchangeably, with <code class="docutils literal notranslate"><span class="pre">ASE</span></code> as we discussed above to produce similar predicted community assignments for your network, or different depending on the parameters chosen for the embedding technique and the topology of the network. For instance, in the section on the “two-truths” phenomena from <a class="reference external" href="#link?">Chapter 6</a>, you saw an example where <code class="docutils literal notranslate"><span class="pre">ASE</span></code> and <code class="docutils literal notranslate"><span class="pre">LSE</span></code> produced embeddings which yielded different blobs of nodes, where <code class="docutils literal notranslate"><span class="pre">ASE</span></code> separated nodes based on whether the nodes had affinity structure from one another, and <code class="docutils literal notranslate"><span class="pre">LSE</span></code> separated nodes based on whether they were core or periphery nodes.</p>
<div class="section" id="can-you-detect-two-truths-with-one-embedding">
<h3><span class="section-number">8.1.3.1. </span>Can you detect “two-truths” with one embedding?<a class="headerlink" href="#can-you-detect-two-truths-with-one-embedding" title="Permalink to this headline">¶</a></h3>
<p>As a fun exercise, let’s consider an example of an algorithm which can give you latent structure for <em>both</em> truths in the two-truths example, <code class="docutils literal notranslate"><span class="pre">node2vec</span></code>. Let’s get you an adjacency matrix with both affinity and core-periphery structure to work on:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">graspologic</span> <span class="k">as</span> <span class="nn">gp</span>

<span class="n">n1</span> <span class="o">=</span> <span class="mi">50</span><span class="p">;</span> <span class="n">n2</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">Baff</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]]</span>

<span class="n">zvecaff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s2">&quot;C1&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n1</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;C2&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n2</span><span class="p">)])</span>

<span class="c1"># the probability matrix</span>
<span class="n">zvecaff_ohe</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n1</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n2</span><span class="p">)])</span>
<span class="n">Paff</span> <span class="o">=</span> <span class="n">zvecaff_ohe</span> <span class="o">@</span> <span class="n">Baff</span> <span class="o">@</span> <span class="n">zvecaff_ohe</span><span class="o">.</span><span class="n">T</span>

<span class="n">np1</span> <span class="o">=</span> <span class="mi">15</span><span class="p">;</span> <span class="n">nc</span> <span class="o">=</span> <span class="mi">70</span><span class="p">;</span> <span class="n">np2</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">Bcp</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
      <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
      <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]]</span>


<span class="n">zveccp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s2">&quot;Per.&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np1</span><span class="p">)]</span> <span class="o">+</span>
                  <span class="p">[</span><span class="s2">&quot;Core&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">nc</span><span class="p">)]</span> <span class="o">+</span>
                  <span class="p">[</span><span class="s2">&quot;Per.&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np2</span><span class="p">)])</span>

<span class="c1"># the probability matrix</span>
<span class="n">zveccp_ohe</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np1</span><span class="p">)]</span> <span class="o">+</span> 
                       <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">nc</span><span class="p">)]</span> <span class="o">+</span>
                       <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np2</span><span class="p">)])</span>
<span class="n">Pcp</span> <span class="o">=</span> <span class="n">zveccp_ohe</span> <span class="o">@</span> <span class="n">Bcp</span> <span class="o">@</span> <span class="n">zveccp_ohe</span><span class="o">.</span><span class="n">T</span>

<span class="n">P_aff_and_cp</span> <span class="o">=</span> <span class="p">(</span><span class="n">Pcp</span> <span class="o">+</span> <span class="n">Paff</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="n">A_aff_and_cp</span> <span class="o">=</span>  <span class="n">gp</span><span class="o">.</span><span class="n">simulations</span><span class="o">.</span><span class="n">sample_edges</span><span class="p">(</span><span class="n">P_aff_and_cp</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The probability matrix and the adjacency matrix look like this:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">cmaps</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>

<span class="n">gp</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">P_aff_and_cp</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">zveccp</span><span class="p">,</span> <span class="n">outer_hier_labels</span><span class="o">=</span><span class="n">zvecaff</span><span class="p">,</span>
                <span class="n">title</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmaps</span><span class="p">[</span><span class="s2">&quot;sequential&quot;</span><span class="p">]);</span>
<span class="n">gp</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">A_aff_and_cp</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">zveccp</span><span class="p">,</span> <span class="n">outer_hier_labels</span><span class="o">=</span><span class="n">zvecaff</span><span class="p">,</span>
                <span class="n">title</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmaps</span><span class="p">[</span><span class="s2">&quot;sequential&quot;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
</div>
<p>You embed it into <span class="math notranslate nohighlight">\(4\)</span> dimensions using <code class="docutils literal notranslate"><span class="pre">node2vec</span></code> like this, with true affinity community labels first:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.embed</span> <span class="kn">import</span> <span class="n">node2vec_embed</span> <span class="k">as</span> <span class="n">node2vec</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>

<span class="n">p</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">;</span> <span class="n">q</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span> <span class="n">w</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span> <span class="n">T</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">d</span> <span class="o">=</span> <span class="mi">4</span>  <span class="c1"># number of embedding dimensions to use</span>
<span class="n">Xhat</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">node2vec</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">from_numpy_matrix</span><span class="p">(</span><span class="n">A_aff_and_cp</span><span class="p">),</span> <span class="n">return_hyperparameter</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">p</span><span class="p">),</span>
                     <span class="n">inout_hyperparameter</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">q</span><span class="p">),</span> <span class="n">dimensions</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">num_walks</span><span class="o">=</span><span class="n">w</span><span class="p">,</span> <span class="n">walk_length</span><span class="o">=</span><span class="n">T</span><span class="p">,</span>
                     <span class="n">iterations</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.plot</span> <span class="kn">import</span> <span class="n">pairplot</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">pairplot</span><span class="p">(</span><span class="n">Xhat</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">zvecaff</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Node2Vec Embedding of 2-Truths example&quot;</span><span class="p">,</span> <span class="n">legend_name</span><span class="o">=</span><span class="s2">&quot;Affinity&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Seems like we’ve got two relatively separate blobs, so let’s see if we can identify them using <code class="docutils literal notranslate"><span class="pre">KMeans</span></code> with <span class="math notranslate nohighlight">\(2\)</span> clusters like we did previously. Nothing too challenging here, just review of what we’ve already done:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kmeans_n2v_aff</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">preds_aff</span> <span class="o">=</span> <span class="n">kmeans_n2v_aff</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">Xhat</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We visualize the predictions as a confusion matrix (the <code class="docutils literal notranslate"><span class="pre">confusion_matrix()</span></code> function can only handle the cases where both the truths and the predictions are integers or strings, not mixed types, so we have to convert the predicted labels first), and calculate the ARI and error rate:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># arbitrary call C1 0 and C2 1</span>
<span class="n">map_truth_to_binary</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;C1&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;C2&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>

<span class="c1"># and convert zvecaff to the binary map we specified above</span>
<span class="n">zvecaff_binary</span> <span class="o">=</span> <span class="p">[</span><span class="n">map_truth_to_binary</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">zvecaff</span><span class="p">]</span>
<span class="c1"># confusion matrix and normalized confusion matrix</span>
<span class="n">cf_mtx_n2v_aff</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">zvecaff_binary</span><span class="p">,</span> <span class="n">preds_aff</span><span class="p">)</span>
<span class="n">cf_norm_n2v_aff</span> <span class="o">=</span> <span class="n">cf_mtx_n2v_aff</span><span class="o">/</span><span class="n">cf_mtx_n2v_aff</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span><span class="kc">None</span><span class="p">]</span>
<span class="n">ari</span> <span class="o">=</span> <span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">zvecaff</span><span class="p">,</span> <span class="n">preds_aff</span><span class="p">)</span>

<span class="c1"># remap the predicted labels to the binarized affinity labels</span>
<span class="n">preds_aff_remapped</span> <span class="o">=</span> <span class="n">remap_labels</span><span class="p">(</span><span class="n">zvecaff_binary</span><span class="p">,</span> <span class="n">preds_aff</span><span class="p">)</span>
<span class="n">er_rt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">preds_aff_remapped</span> <span class="o">!=</span> <span class="n">zvecaff_binary</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cf_norm_n2v_aff</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmaps</span><span class="p">[</span><span class="s2">&quot;sequential&quot;</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Normalized confusion matrix, ARI=</span><span class="si">{:.3f}</span><span class="s2">, Error = </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ari</span><span class="p">,</span> <span class="n">er_rt</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;True Label&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>So we have a pretty decent ARI of <span class="math notranslate nohighlight">\(0.514\)</span>, and our error rate is only <span class="math notranslate nohighlight">\(0.14\)</span>.</p>
<div class="section" id="sometimes-you-have-to-modify-your-data-to-learn-from-it">
<h4><span class="section-number">8.1.3.1.1. </span>Sometimes, you have to modify your data to learn from it<a class="headerlink" href="#sometimes-you-have-to-modify-your-data-to-learn-from-it" title="Permalink to this headline">¶</a></h4>
<p>Now, what to do about the core-periphery nodes? If we peek at the pairs plot with the core-periphery nodes highlighted, we see:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">pairplot</span><span class="p">(</span><span class="n">Xhat</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">zveccp</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Node2Vec Embedding&quot;</span><span class="p">,</span> <span class="n">legend_name</span><span class="o">=</span><span class="s2">&quot;Core-Periphery&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>For some of these dimensions, for instance, dimension <span class="math notranslate nohighlight">\(1\)</span> against dimension <span class="math notranslate nohighlight">\(2\)</span>, we can see a sort of “disc” forming which separates the points pretty well into the core versus the peripheral nodes. To make these points more separable based on this fact is pretty easy. Let’s start by taking a look at the points we have, and we’ll show where the center of these points is with a black star:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute the center of each dimension</span>
<span class="n">center</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Xhat</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_n2v</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;Dimension 2&quot;</span> <span class="p">:</span> <span class="n">Xhat</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;Dimension 3&quot;</span> <span class="p">:</span> <span class="n">Xhat</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span> <span class="s2">&quot;Core-Periphery&quot;</span><span class="p">:</span> <span class="n">zveccp</span><span class="p">})</span>
<span class="n">palette</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Core&quot;</span><span class="p">:</span> <span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="s2">&quot;Per.&quot;</span><span class="p">:</span> <span class="s2">&quot;red&quot;</span><span class="p">}</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data_n2v</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;Dimension 2&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Dimension 3&quot;</span><span class="p">,</span> 
                <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;Core-Periphery&quot;</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">palette</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Node2Vec Embedding of 2-Truths Example&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">center</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">center</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;*&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>The nodes close to the star tend to be core nodes, and the nodes farther away from the star tend to be peripheral nodes. So, what happens if we just measure how far each point is away from this center, and then use that as our coordinate system instead? Let’s give that a try:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Xhat_xfm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">Xhat</span> <span class="o">-</span> <span class="n">center</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_n2v_xfm</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;Distance from center in dimension 2&quot;</span> <span class="p">:</span> <span class="n">Xhat_xfm</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span>
                          <span class="s2">&quot;Distance from center in dimension 3&quot;</span> <span class="p">:</span> <span class="n">Xhat_xfm</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span>
                          <span class="s2">&quot;Core-Periphery&quot;</span><span class="p">:</span> <span class="n">zveccp</span><span class="p">})</span>
<span class="n">palette</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Core&quot;</span><span class="p">:</span> <span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="s2">&quot;Per.&quot;</span><span class="p">:</span> <span class="s2">&quot;red&quot;</span><span class="p">}</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data_n2v_xfm</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;Distance from center in dimension 2&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Distance from center in dimension 3&quot;</span><span class="p">,</span> 
                <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;Core-Periphery&quot;</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">palette</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Node2Vec Embedding of 2-Truths Example&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Now, we’re starting to get somewhere! Let’s look at the pairs plot now:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">pairplot</span><span class="p">(</span><span class="n">Xhat_xfm</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">zveccp</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Embedding after transforming for distance to center&quot;</span><span class="p">,</span> <span class="n">legend_name</span><span class="o">=</span><span class="s2">&quot;Core-Periphery&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Things are starting to look a lot more obvious! Now, we have all of the core nodes pretty well-separated from the peripheral nodes. We’ll classify these points using Gaussian Mixture Model, which is similar to <code class="docutils literal notranslate"><span class="pre">KMeans</span></code>, but allows us to capture the fact that the points from the Peripheral community are more spread out than the points from the core community:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.mixture</span> <span class="kn">import</span> <span class="n">GaussianMixture</span>

<span class="n">preds_cp</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">Xhat_xfm</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We repeat our analysis that we did previously to obtain the confusion matrix, the ARI, and the error rate:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># arbitrary call Core 0 and Per. 1</span>
<span class="n">map_truth_to_binary</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Core&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Per.&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
<span class="n">map_binary_to_truth</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s2">&quot;Core&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s2">&quot;Per.&quot;</span><span class="p">}</span>

<span class="c1"># and convert zveccp to the binary map we specified above</span>
<span class="n">zveccp_binary</span> <span class="o">=</span> <span class="p">[</span><span class="n">map_truth_to_binary</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">zveccp</span><span class="p">]</span>
<span class="c1"># confusion matrix and normalized confusion matrix</span>
<span class="n">cf_mtx_n2v_cp</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">zveccp_binary</span><span class="p">,</span> <span class="n">preds_cp</span><span class="p">)</span>
<span class="n">cf_norm_n2v_cp</span> <span class="o">=</span> <span class="n">cf_mtx_n2v_cp</span><span class="o">/</span><span class="n">cf_mtx_n2v_cp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span><span class="kc">None</span><span class="p">]</span>
<span class="n">ari</span> <span class="o">=</span> <span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">zveccp</span><span class="p">,</span> <span class="n">preds_cp</span><span class="p">)</span>

<span class="c1"># remap the predicted labels to the binarized core-periphery labels</span>
<span class="n">preds_cp_remapped</span> <span class="o">=</span> <span class="n">remap_labels</span><span class="p">(</span><span class="n">zveccp_binary</span><span class="p">,</span> <span class="n">preds_cp</span><span class="p">)</span>
<span class="n">er_rt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">preds_cp_remapped</span> <span class="o">!=</span> <span class="n">zveccp_binary</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cf_norm_n2v_aff</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmaps</span><span class="p">[</span><span class="s2">&quot;sequential&quot;</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Normalized confusion matrix, ARI=</span><span class="si">{:.3f}</span><span class="s2">, Error = </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ari</span><span class="p">,</span> <span class="n">er_rt</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;True Label&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Wow! We were only wrong <span class="math notranslate nohighlight">\(7\%\)</span> percent of the time! This is incredible! To emphasize just how crazy this is, let’s look back at the points, before we did any of this tranformation business, and look at the predictions we were able to produce. We’ll use <code class="docutils literal notranslate"><span class="pre">remap_labels</span></code> on our predictions so we can make more sense of them:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">preds_cp_remapped</span> <span class="o">=</span> <span class="p">[</span><span class="n">map_binary_to_truth</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">remap_labels</span><span class="p">(</span><span class="n">zveccp_binary</span><span class="p">,</span> <span class="n">preds_cp</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">pairplot</span><span class="p">(</span><span class="n">Xhat</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">preds_cp_remapped</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Node2Vec Embedding&quot;</span><span class="p">,</span> <span class="n">legend_name</span><span class="o">=</span><span class="s2">&quot;Prediction&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Which looks like our classifier was able to successfully capture the idea that the core nodes tend to be in the middle, and the peripheral nodes around the edge!</p>
<p>This example is a great exercise in why you should always look carefully and think about your data before you go ahead and analyze it. If you hadn’t looked at this pair plot, the fact that the core nodes tended to be closer to the center would have been completely unobvious to you. Further, if you hadn’t <em>thought</em> about this fact, you wouldn’t have known how you could <em>exploit</em> this trend in your data by just taking the distance to the center in each dimension. Notice that other than this simple transformation, you used basically the same strategies from before; you didn’t need to do anything fancy with your clustering algorithm, and you were able to make predictions for an otherwise quite complicated embedding by just changing the dimensions of our embedding around slightly.</p>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./applications/ch8"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="ch8.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">8. </span>Applications When You Have One Network</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="testing-differences.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">8.2. </span>Testing for Differences between Groups of Edges</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Joshua Vogelstein, Eric Bridgeford, and Alex Loftus<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>