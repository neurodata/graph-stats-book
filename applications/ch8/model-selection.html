
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>8.3. Model Selection &#8212; Hands-on Network Machine Learning with Scikit-Learn and Graspologic</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="8.4. Single-Network Vertex Nomination" href="single-vertex-nomination.html" />
    <link rel="prev" title="8.2. Testing for Differences between Groups of Edges" href="testing-differences.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Hands-on Network Machine Learning with Scikit-Learn and Graspologic</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../coverpage.html">
   Hands-on Network Machine Learning with Scikit-Learn and Graspologic
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/terminology.html">
   Terminology and Math Refresher
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch1/ch1.html">
   1. The Network Machine Learning Landscape
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/what-is-a-network.html">
     1.1. What Is A Network?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/why-study-networks.html">
     1.2. Why Study Networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/examples-of-applications.html">
     1.3. Examples of applications
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/types-of-networks.html">
     1.4. Types of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/types-of-learning-probs.html">
     1.5. Types of Network Learning Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/main-challenges.html">
     1.6. Main Challenges of Network Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/exercises.html">
     1.7. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch2/ch2.html">
   2. End-to-end Biology Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/big-picture.html">
     2.1. Look at the big picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/get-the-data.html">
     2.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/prepare-the-data.html">
     2.3. Prepare the Data for Network Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/transformation-techniques.html">
     2.4. Transformation Techniques
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/select-and-train.html">
     2.5. Select and Train a Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/fine-tune.html">
     2.6. Fine-Tune your Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch3/ch3.html">
   3. End-to-end Business Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/big-picture.html">
     3.1. Look at the Big Picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/get-the-data.html">
     3.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/discover-and-visualize.html">
     3.3. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/prepare-the-data.html">
     3.4. Prepare the Data for Network Algorithms
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Representations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch4/ch4.html">
   4. Properties of Networks as a Statistical Object
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/matrix-representations.html">
     4.1. Matrix Representations Of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/network-representations.html">
     4.2. Representations of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/properties-of-networks.html">
     4.3. Properties of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/regularization.html">
     4.4. Regularization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch5/ch5.html">
   5. Why Use Statistical Models?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/why-use-models.html">
     5.1. Why Use Statistical Models?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_ER.html">
     5.2. Erdös-Rényi (ER) Random Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_SBM.html">
     5.3. Stochastic Block Models (SBM)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_RDPG.html">
     5.4. Random Dot Product Graphs (RDPG)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/multi-network-models.html">
     5.5. Multiple Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_theory.html">
     5.6. Single network model theory
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch6/ch6.html">
   6. Learning Network Representations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/estimating-parameters_mle.html">
     6.1. Estimating Parameters in Network Models via MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/why-embed-networks.html">
     6.2. Why embed networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/spectral-embedding.html">
     6.3. Spectral Embedding Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/estimating-parameters_spectral.html">
     6.4. Estimating Parameters with Spectaal Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/random-walk-diffusion-methods.html">
     6.5. Random-Walk and Diffusion-based Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/graph-neural-networks.html">
     6.6. Graph Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/multigraph-representation-learning.html">
     6.7. Multiple-Network Representation Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/joint-representation-learning.html">
     6.8. Joint Representation Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/estimating-parameters_theory.html">
     6.9. Model Estimation Theory
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch7/ch7.html">
   7. Theoretical Results
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch7/theory-single-network.html">
     7.1. Theory for Single Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch7/theory-multigraph.html">
     7.2. Theory for Multiple-Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch7/theory-matching.html">
     7.3. Theory for Graph Matching
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="ch8.html">
   8. Applications When You Have One Network
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="community-detection.html">
     8.1. Community Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="testing-differences.html">
     8.2. Testing for Differences between Groups of Edges
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     8.3. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="single-vertex-nomination.html">
     8.4. Single-Network Vertex Nomination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="out-of-sample.html">
     8.5. Out-of-sample Embedding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch9/ch9.html">
   9. Applications for Two Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch9/two-sample-hypothesis.html">
     9.1. Two-Sample Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch9/graph-matching-vertex.html">
     9.2. Graph Matching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch9/multiple-vertex-nomination.html">
     9.3. Vertex Nomination For Multiple Networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch10/ch10.html">
   10. Applications for Many Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch10/anomaly-detection.html">
     10.1. Anomaly Detection For Timeseries of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch10/significant-edges.html">
     10.2. Testing for Significant Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch10/significant-vertices.html">
     10.3. Testing for Significant Vertices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch10/significant-communities.html">
     10.4. Testing for Significant Communities
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://graspologic.readthedocs.io/en/latest/">
   Graspologic Documentation
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/applications/ch8/model-selection.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/neurodata/graph-stats-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/neurodata/graph-stats-book/issues/new?title=Issue%20on%20page%20%2Fapplications/ch8/model-selection.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/neurodata/graph-stats-book/edit/master/network_machine_learning_in_python/applications/ch8/model-selection.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/neurodata/graph-stats-book/master?urlpath=tree/network_machine_learning_in_python/applications/ch8/model-selection.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sequentially-nested-hypotheses-allow-us-to-choose-the-best-hypothesis-from-the-candidates">
   8.3.1. Sequentially nested hypotheses allow us to choose the best hypothesis from the candidates
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#developing-sequentially-nested-hypotheses-for-network-data">
   8.3.2. Developing sequentially nested hypotheses for network data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multiple-hypothesis-correction-ensures-the-p-value-we-obtain-is-accurate">
   8.3.3. Multiple Hypothesis Correction ensures the
   <span class="math notranslate nohighlight">
    \(p\)
   </span>
   -value we obtain is accurate
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-selection-for-unweighted-networks">
     8.3.3.1. Model Selection for unweighted networks
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Model Selection</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sequentially-nested-hypotheses-allow-us-to-choose-the-best-hypothesis-from-the-candidates">
   8.3.1. Sequentially nested hypotheses allow us to choose the best hypothesis from the candidates
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#developing-sequentially-nested-hypotheses-for-network-data">
   8.3.2. Developing sequentially nested hypotheses for network data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multiple-hypothesis-correction-ensures-the-p-value-we-obtain-is-accurate">
   8.3.3. Multiple Hypothesis Correction ensures the
   <span class="math notranslate nohighlight">
    \(p\)
   </span>
   -value we obtain is accurate
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-selection-for-unweighted-networks">
     8.3.3.1. Model Selection for unweighted networks
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="model-selection">
<h1><span class="section-number">8.3. </span>Model Selection<a class="headerlink" href="#model-selection" title="Permalink to this headline">¶</a></h1>
<p>In the past two sections, we’ve covered quite a bit of ground in our understanding of Stochastic Block Models. We introduced the Structured Independent Edge Model, a generalization of the Stochastic Block Model that allows us to compare probabilities of various edge clusters in the network. Next, we introduced the community detection problem, and showed how the adjacency spectal embedding coupled with various adjustments of unsupervised clustering techniques allowed us to learn estimated community assignments <span class="math notranslate nohighlight">\(\vec z\)</span> fo the nodes of the network. We then learned how we can use these community assignments to produce estimates of the block matrix, <span class="math notranslate nohighlight">\(\hat B\)</span>, so that we have a useful model of the network.</p>
<p>As we have learned over the course of the book so far, one of our core aims in machine learning is to identify the <em>simplest</em> model that maintains a <em>faithful</em> representation of the underlying data with which we are presented. Imagine we toss two identical fair coins <span class="math notranslate nohighlight">\(20\)</span> times and <span class="math notranslate nohighlight">\(10\)</span> times respectively, which each have <span class="math notranslate nohighlight">\(p_1 = p_2 = p = 0.5\)</span> (the probability of landing on heads, <span class="math notranslate nohighlight">\(0.5\)</span>, is identical to the probability of landing on tails). The first coin lands on heads <span class="math notranslate nohighlight">\(11\)</span> times out of <span class="math notranslate nohighlight">\(20\)</span> flips, and the second coin lands on heads <span class="math notranslate nohighlight">\(4\)</span> times. In truth, these coins are identical; we simply, by chance, produced estimates <span class="math notranslate nohighlight">\(\hat p_1 = \frac{11}{20} = 0.55\)</span> and <span class="math notranslate nohighlight">\(\hat p_2 = \frac{4}{10} = 0.4\)</span>. In reality, the best estimate of <span class="math notranslate nohighlight">\(\hat p\)</span>, the true probability, would be to <em>pool</em> across the two samples, which would give us that <span class="math notranslate nohighlight">\(\hat p = \frac{15}{30} = 0.5\)</span>. The problem here is, when we have a real sample of data, we <em>don’t know</em> that <span class="math notranslate nohighlight">\(p_1 = p_2\)</span>. As we learned in the preceding section, we can derive hypotheses tests where <span class="math notranslate nohighlight">\(H_0: p_1 = p_2\)</span> against <span class="math notranslate nohighlight">\(H_a: p_1 = p_2\)</span>, and we can simply test these hypotheses directly. Let’s say we didn’t flip two coins, however. Let’s say we flipped three coins, where in reality <span class="math notranslate nohighlight">\(p_1 = p_2 = 0.5\)</span>, and <span class="math notranslate nohighlight">\(p_3 = 0.4\)</span>. We need to build upon our two-sample hypothesis testing strategies in order to produce ideal inference about the relationships between <span class="math notranslate nohighlight">\(p_1\)</span>, <span class="math notranslate nohighlight">\(p_2\)</span>, and <span class="math notranslate nohighlight">\(p_3\)</span>. To answer these sorts of questions, we turn to <em>model selection</em>.</p>
<p><strong>Model selection</strong> is the task of presenting several possible statistical models which we think describe our sample and using quantitative strategies to determine which statistical models are best supported by the samples with which we are presented. In our coin flip example with three coins where <span class="math notranslate nohighlight">\(p_1\)</span> and <span class="math notranslate nohighlight">\(p_2\)</span> are equal but <span class="math notranslate nohighlight">\(p_3\)</span> is diffferent, this means that we use the sample to determine reasonable statistical models that could be possible. In the context of coin flipping experiments, the statistical models are delineated by the types of coins that could have reasonably been used for the experiment. For instance, we might propose a statistical model where <span class="math notranslate nohighlight">\(p_1 = p_2 = p_3\)</span>, another model where <span class="math notranslate nohighlight">\(p_1 = p_2\)</span> but <span class="math notranslate nohighlight">\(p_3\)</span> does not equal <span class="math notranslate nohighlight">\(p_1\)</span> nor <span class="math notranslate nohighlight">\(p_2\)</span>, and a third model where <span class="math notranslate nohighlight">\(p_1\)</span>, <span class="math notranslate nohighlight">\(p_2\)</span>, and <span class="math notranslate nohighlight">\(p_3\)</span> were all different. As an observer, you might say, this subset of three possible statistical model misses quite a few possibilities! There is another possible model where <span class="math notranslate nohighlight">\(p_2 = p_3\)</span> but <span class="math notranslate nohighlight">\(p_1\)</span> does not equal <span class="math notranslate nohighlight">\(p_2\)</span> nor <span class="math notranslate nohighlight">\(p_3\)</span>, and another where <span class="math notranslate nohighlight">\(p_1 = p_3\)</span> but <span class="math notranslate nohighlight">\(p_2\)</span> does not equal <span class="math notranslate nohighlight">\(p_1\)</span> nor <span class="math notranslate nohighlight">\(p_3\)</span>. Each of these models has a corresponding hypothesis under which the model is “correct”. When we actually want to select the bests model, however, we will use the fact a specific property of the hypotheses we actually chose, the fact that they are <em>sequentially nested</em>, to identify the best statistical model supported by the sample.</p>
<div class="section" id="sequentially-nested-hypotheses-allow-us-to-choose-the-best-hypothesis-from-the-candidates">
<h2><span class="section-number">8.3.1. </span>Sequentially nested hypotheses allow us to choose the best hypothesis from the candidates<a class="headerlink" href="#sequentially-nested-hypotheses-allow-us-to-choose-the-best-hypothesis-from-the-candidates" title="Permalink to this headline">¶</a></h2>
<p>Let’s formalize this situation a little bit more. We have the following three hypotheses. <span class="math notranslate nohighlight">\(H_0: p_1 = p_2 = p_3 = a\)</span>, against <span class="math notranslate nohighlight">\(H_1: p_1 = p_2 = a\)</span>, but <span class="math notranslate nohighlight">\(p_3 = c\)</span>. Finally, we have <span class="math notranslate nohighlight">\(H_2: p_1 = a\)</span>, <span class="math notranslate nohighlight">\(p_2 = b\)</span>, and <span class="math notranslate nohighlight">\(p_3 = c\)</span>. The hypothesis <span class="math notranslate nohighlight">\(H\)</span> is <strong>nested</strong> in the hypothesis <span class="math notranslate nohighlight">\(H'\)</span> if whenever <span class="math notranslate nohighlight">\(H\)</span> is true, <span class="math notranslate nohighlight">\(H'\)</span> is also true. In this sense, the hypothesis <span class="math notranslate nohighlight">\(H'\)</span> is said to contain the hypothesis <span class="math notranslate nohighlight">\(H\)</span>. Let’s consider <span class="math notranslate nohighlight">\(H_0\)</span> and <span class="math notranslate nohighlight">\(H_1\)</span>, for instance. Notice that if <span class="math notranslate nohighlight">\(H_0\)</span> is true, then <span class="math notranslate nohighlight">\(p_1 = p_2 = p_3 = a\)</span>. However, <span class="math notranslate nohighlight">\(H_1\)</span> is also true, since <span class="math notranslate nohighlight">\(p_1 = p_2 = a\)</span>, and <span class="math notranslate nohighlight">\(p_3= c\)</span> can also be set equal to <span class="math notranslate nohighlight">\(p_1\)</span> and <span class="math notranslate nohighlight">\(p_2\)</span> if <span class="math notranslate nohighlight">\(c = a\)</span>. A sequence of hypotheses <span class="math notranslate nohighlight">\(H_0, H_1, ..., H_n\)</span> is called <strong>sequentially nested</strong> if <span class="math notranslate nohighlight">\(H_0\)</span> is nested in <span class="math notranslate nohighlight">\(H_1\)</span>, which is nested in <span class="math notranslate nohighlight">\(H_2\)</span>, so on and so forth up to <span class="math notranslate nohighlight">\(H_{n-1}\)</span> is nested in <span class="math notranslate nohighlight">\(H_n\)</span>. Note that the sequence of hypotheses that we presented for our three coin example are sequentially nested. We already saw that <span class="math notranslate nohighlight">\(H_0\)</span> was nested in <span class="math notranslate nohighlight">\(H_1\)</span>. Now, let’s compare <span class="math notranslate nohighlight">\(H_2\)</span> to <span class="math notranslate nohighlight">\(H_1\)</span>. Notet that if <span class="math notranslate nohighlight">\(a = b\)</span>, that <span class="math notranslate nohighlight">\(p_1 = p_2\)</span>, and <span class="math notranslate nohighlight">\(p_3 = c\)</span>, exactly as in <span class="math notranslate nohighlight">\(H_1\)</span>, so <span class="math notranslate nohighlight">\(H_1\)</span> is nested in <span class="math notranslate nohighlight">\(H_2\)</span>. Therefore, since <span class="math notranslate nohighlight">\(H_0\)</span> is nested in <span class="math notranslate nohighlight">\(H_1\)</span> and <span class="math notranslate nohighlight">\(H_1\)</span> is nested in <span class="math notranslate nohighlight">\(H_2\)</span>, The sequence <span class="math notranslate nohighlight">\(H_0\)</span>, <span class="math notranslate nohighlight">\(H_1\)</span>, and <span class="math notranslate nohighlight">\(H_2\)</span> are sequentially nested.</p>
<p>What advantage does sequentially nesting hypotheses give us? In statistics, and in particular when dealing with sequences of hypothesis tests all of which correspond to candidate models which are based on the Bernoulli distribution, statistical tests can be used to <em>provably</em> identify the best candidate model corresponding to a hypothesis. This means that we can select one of the <span class="math notranslate nohighlight">\(n\)</span> total hypotheses amongst <span class="math notranslate nohighlight">\(H_0, ..., H_n\)</span>, and can use the results of this hypothesis to construct a statistical model which is best supported by the data. This distinction is key for numerous statistical results, and will form the foundation of our development of model selection approaches for network machine learning.</p>
</div>
<div class="section" id="developing-sequentially-nested-hypotheses-for-network-data">
<h2><span class="section-number">8.3.2. </span>Developing sequentially nested hypotheses for network data<a class="headerlink" href="#developing-sequentially-nested-hypotheses-for-network-data" title="Permalink to this headline">¶</a></h2>
<p>What does this have to do with network data? Let’s imagine that we are presented with the school network that we are accustomed to. <span class="math notranslate nohighlight">\(100\)</span> students attend one of two schools. Nodes are students, and edges represent whether a pair of students are friends. We’ll imagine we’ve already performed community detection on the network, and have sorted the nodes based on the school to which the students attend:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">sbm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">ns</span> <span class="o">=</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">]</span>  <span class="c1"># network with 100 nodes</span>
<span class="n">B</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]]</span>  <span class="c1"># block matrix</span>

<span class="c1"># sample a single simple adjacency matrix from SBM(z, B)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">sbm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">ns</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">B</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">zs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ns</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ns</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">draw_multiplot</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">draw_multiplot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">zs</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$SBM_n(</span><span class="se">\\</span><span class="s2">vec z, B)$ Simulation, nodes ordered by school&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/model-selection_2_0.png" src="../../_images/model-selection_2_0.png" />
</div>
</div>
<p>Remember in the two-block SBM, that we have the following block matrix:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    B &amp;= \begin{bmatrix}
        b_{11} &amp; b_{12} \\ b_{21} &amp; b_{22}
    \end{bmatrix}
\end{align*}\]</div>
<p>The network is undirected by construction, so by definition, <span class="math notranslate nohighlight">\(b_{21} = b_{12}\)</span>. But what about the other entries to the block matrix? It seems pretty clear that the on-diagonal blocks have a different probability than the off-diagonal blocks, so perhaps it seems reasonable to conclude that <span class="math notranslate nohighlight">\(b_{11}, b_{22} \neq b_{12}, b_{21}\)</span>. But what about the on-diagonal blocks? What can we say about the relationship between <span class="math notranslate nohighlight">\(b_{11}\)</span> and <span class="math notranslate nohighlight">\(b_{22}\)</span>? To begin to perform inference on <span class="math notranslate nohighlight">\(B\)</span>, we need a community assignment vector <span class="math notranslate nohighlight">\(\vec z\)</span>, which was the vector whose entries <span class="math notranslate nohighlight">\(z_{i}\)</span> indicate which of the <span class="math notranslate nohighlight">\(K\)</span> communities the node <span class="math notranslate nohighlight">\(i\)</span> is part of. For the purposes of this section, we will assume that we are either handed the community assignment vector <span class="math notranslate nohighlight">\(\vec z\)</span> with our sample, or we have estimated it using community detection, as we explored in the <a class="reference external" href="#link?">preceding section</a>. Next, we use the community assignment vector (or the estimated community assignment vector, <span class="math notranslate nohighlight">\(\hat{\vec z}\)</span>) to produce an estimate of the block matrix, <span class="math notranslate nohighlight">\(\hat B\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">SBMEstimator</span>

<span class="n">sbm_mod</span> <span class="o">=</span> <span class="n">SBMEstimator</span><span class="p">(</span><span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">sbm_mod</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">zs</span><span class="p">)</span>
<span class="n">Bhat</span> <span class="o">=</span> <span class="n">sbm_mod</span><span class="o">.</span><span class="n">block_p_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">plot_block</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">blockname</span><span class="o">=</span><span class="s2">&quot;School&quot;</span><span class="p">,</span> <span class="n">blocktix</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span>
               <span class="n">blocklabs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;School 1&quot;</span><span class="p">,</span> <span class="s2">&quot;School 2&quot;</span><span class="p">]):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    
    <span class="k">with</span> <span class="n">sns</span><span class="o">.</span><span class="n">plotting_context</span><span class="p">(</span><span class="s2">&quot;talk&quot;</span><span class="p">,</span> <span class="n">font_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Purples&quot;</span><span class="p">,</span>
                        <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">cbar_kws</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">shrink</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        <span class="n">cbar</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">collections</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="n">blockname</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="n">blockname</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">blocktix</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">blocklabs</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">blocktix</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">blocklabs</span><span class="p">)</span>
        <span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">set_frame_on</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span>

<span class="n">plot_block</span><span class="p">(</span><span class="n">Bhat</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Estimated Block Probability Matrix, $</span><span class="se">\\</span><span class="s2">hat B$&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/model-selection_5_0.png" src="../../_images/model-selection_5_0.png" />
</div>
</div>
<p>Next, we assemble the following statistical models:</p>
<ol class="simple">
<li><p>The network is Erdos-Renyi: the simplest possible model would be the model where all of the block probabilities are the same; that is, <span class="math notranslate nohighlight">\(b_{11} = b_{12} = b_{21} = b_{22}\)</span>. This is equivalent to an Erdos-Renyi random network with probability <span class="math notranslate nohighlight">\(a\)</span>, <span class="math notranslate nohighlight">\(ER_n(a)\)</span>. This doesn’t seem totally reasonable based on the estimated block probability matrix we see above, but it is better to ask questions to see whether something else is better supported by the data than it is to make outright assumptions. For this reason, we will let the null hypothesis <span class="math notranslate nohighlight">\(H_0 : b_{11} = b_{12} = b_{21} = b_{22} = a\)</span>. This can be encoded in graspologic using the string, <code class="docutils literal notranslate"><span class="pre">&quot;aaaa&quot;</span></code>, or that all four entries of the four-block matrix <span class="math notranslate nohighlight">\(B\)</span> are the same value, <span class="math notranslate nohighlight">\(a\)</span>. It is typically the case when testing statistical models to let the null hypothesis <span class="math notranslate nohighlight">\(H_0\)</span> be that the network is Erdos-Renyi.</p></li>
<li><p>Planted partition: As we discussed above, the planted partition model is the model where <span class="math notranslate nohighlight">\(b_{11} = b_{22} = a\)</span>, but <span class="math notranslate nohighlight">\(b_{21} = b_{12} = b\)</span>, where <span class="math notranslate nohighlight">\(a \neq b\)</span>. The within-community edges share a common probability <span class="math notranslate nohighlight">\(a\)</span>, and the between-community edges share a common probability <span class="math notranslate nohighlight">\(b\)</span> which is distinct from <span class="math notranslate nohighlight">\(a\)</span>. The corresponding hypothesis is indicated by <span class="math notranslate nohighlight">\(H_1 : b_{11} = b_{22} = a, b_{12} = b_{21} = b, a \neq b\)</span>. This hypothesis can be encoded in graspologic using the string, <code class="docutils literal notranslate"><span class="pre">&quot;abba&quot;</span></code>.</p></li>
<li><p>Symmetric Heterogeneous: as discussed above, the symmetric heterogeneous model is the moddel where <span class="math notranslate nohighlight">\(b_{12} = b_{21}\)</span>; that is, the block matrix <span class="math notranslate nohighlight">\(B\)</span> is symmetric. However, there is heterogeneity in the within-community block probabilities; that is, <span class="math notranslate nohighlight">\(b_{11} = a\)</span>, but <span class="math notranslate nohighlight">\(b_{22} = c\)</span>, where <span class="math notranslate nohighlight">\(a \neq c\)</span>. this hypothesis is encoded in graspologic using the string, <code class="docutils literal notranslate"><span class="pre">&quot;abbc&quot;</span></code>.</p></li>
</ol>
</div>
<div class="section" id="multiple-hypothesis-correction-ensures-the-p-value-we-obtain-is-accurate">
<h2><span class="section-number">8.3.3. </span>Multiple Hypothesis Correction ensures the <span class="math notranslate nohighlight">\(p\)</span>-value we obtain is accurate<a class="headerlink" href="#multiple-hypothesis-correction-ensures-the-p-value-we-obtain-is-accurate" title="Permalink to this headline">¶</a></h2>
<p>When performing multiple statistical tests, we run into the multiple hypothesis correction problem. We have <span class="math notranslate nohighlight">\(5000\)</span> networks, which are samples from corresponding <span class="math notranslate nohighlight">\(ER_n(0.5)\)</span> networks. For each network <span class="math notranslate nohighlight">\(i\)</span>, we use the one-sample test to investigate whether <span class="math notranslate nohighlight">\(p_i = 0.5\)</span>. The null hypothesis for the <span class="math notranslate nohighlight">\(i^{th}\)</span> network is <span class="math notranslate nohighlight">\(H_{0, i}: p_i = 0.5\)</span>, against <span class="math notranslate nohighlight">\(H_{A,i}: p_i \neq 0.5\)</span>. We choose to use the Binomial test as our statistical test, as we covered in the section on <a class="reference external" href="#link?">One-Sample Testing</a>.
Our below visualization shows the the <span class="math notranslate nohighlight">\(p\)</span>-values of our <span class="math notranslate nohighlight">\(5000\)</span> statistical tests as a histogram, where the bar-height indicates the number of <span class="math notranslate nohighlight">\(p\)</span>-values which fall into the indicated range:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">er_np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">binom_test</span>

<span class="n">nnetworks</span> <span class="o">=</span> <span class="mi">5000</span> <span class="c1"># the number of networks</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># the true probability</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>  <span class="c1"># the number of nodes</span>
<span class="n">nedge_possible</span> <span class="o">=</span> <span class="n">n</span><span class="o">*</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>  <span class="c1"># the number of potential edges</span>
<span class="c1"># sample 100 er_n(0.5) networks</span>
<span class="n">As</span> <span class="o">=</span> <span class="p">[</span><span class="n">er_np</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">nnetworks</span><span class="p">)]</span>

<span class="c1"># get the indices of the upper triangle of Asrt</span>
<span class="n">upper_tri_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">triu_indices</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># create a boolean array that is nxn</span>
<span class="n">upper_tri_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
<span class="c1"># set indices which correspond to the upper triangle to True</span>
<span class="n">upper_tri_mask</span><span class="p">[</span><span class="n">upper_tri_idx</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># perform binomial test to see if number of edges which exist in the network</span>
<span class="c1"># relative the number of edges which are possible supports a p-value of 0.5</span>
<span class="c1"># this is analogous to flipping a coin nedge_possible times, and observing </span>
<span class="c1"># the number of heads we see in the upper-right triangle of the adjacency matrix,</span>
<span class="c1"># and asking whether this supports a probability of heads of 0.5</span>
<span class="n">pvals</span> <span class="o">=</span> <span class="p">[</span><span class="n">binom_test</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">upper_tri_mask</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="n">nedge_possible</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">A</span> <span class="ow">in</span> <span class="n">As</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">real_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">pvals</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pval&quot;</span><span class="p">])</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">real_df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;pval&quot;</span><span class="p">,</span> <span class="n">stat</span><span class="o">=</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span>
            <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">common_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">binwidth</span><span class="o">=</span><span class="mf">.05</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Fraction of $p$-values&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;$p$-value&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;$p$-values if the null hypothesis is true&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">.08</span><span class="p">,</span> <span class="mf">.08</span><span class="p">,</span> <span class="s2">&quot;Decision threshold, $</span><span class="se">\\</span><span class="s2">alpha = 0.05$&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/model-selection_8_0.png" src="../../_images/model-selection_8_0.png" />
</div>
</div>
<p>In general, we will correctly reject the alternative hypothesis, and accept the null hypothesis. This is great, since <span class="math notranslate nohighlight">\(p_i\)</span> is, in fact, <span class="math notranslate nohighlight">\(0.5\)</span> as specified by the null hypothesis <span class="math notranslate nohighlight">\(H_{0,i}\)</span>. However, we notice something particularly strange: For a portion of the tests, we are, in-fact, <em>wrong</em>. We obtain many <span class="math notranslate nohighlight">\(p\)</span>-values which are under our decision threshold of <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>, and would incorrectly report that thhe alternative hypothesis is correct, and <span class="math notranslate nohighlight">\(p_i\)</span> is <em>not</em> <span class="math notranslate nohighlight">\(0.5\)</span>. This is wrong, and extremely problematic! Remember that the <span class="math notranslate nohighlight">\(p\)</span>-value was defined as the probability that the null hypothesis (here, that <span class="math notranslate nohighlight">\(p_i = 0.5\)</span>) would be incorrectly rejected in favor of the alternative hypothesis (here, that <span class="math notranslate nohighlight">\(p_i \neq 0.5\)</span>). In fact, if the null hypothesis were true, we would expect to see <span class="math notranslate nohighlight">\(p\)</span>-values of at most <span class="math notranslate nohighlight">\(\alpha\)</span> being reported about <span class="math notranslate nohighlight">\(\alpha\)</span> of the time (this assumes all of the networks are independent, but even when they are not all independent, we still obtain a similarly shocking conclusion). This means that with <span class="math notranslate nohighlight">\(n=5000\)</span> tests and <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>, we would expect to be wrong about <span class="math notranslate nohighlight">\(n\cdot \alpha = 50\)</span> times.</p>
<p>As scientists, it is our responsibility that when we report statistical decisions, that we are not reporting things where we know that a fraction of our results are wrong. For this reason, a focus of statistics in recent decades has been the development of methods which, in effect, <em>inflate</em> the <span class="math notranslate nohighlight">\(p\)</span>-values based on the number of tests that we perform, so that we run into this issue at much lower rate than <span class="math notranslate nohighlight">\(\alpha\)</span> of the time. These strategies are collectively known as <strong>multiple comparisons adjustments</strong>. We won’t go into too many details with how multiple comparisons adjustments are performed, but in general given a list of <span class="math notranslate nohighlight">\(p\)</span>-values <code class="docutils literal notranslate"><span class="pre">pvals</span></code>, you can adjust the <span class="math notranslate nohighlight">\(p\)</span>-values using the <code class="docutils literal notranslate"><span class="pre">multipletests()</span></code> method from <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code>. Let’s see what happens when we adjust our <span class="math notranslate nohighlight">\(p\)</span>-values here:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">statsmodels.stats.multitest</span> <span class="kn">import</span> <span class="n">multipletests</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>  <span class="c1"># the desired alpha of the test</span>
<span class="n">_</span><span class="p">,</span> <span class="n">adj_pvals</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">multipletests</span><span class="p">(</span><span class="n">pvals</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;holm&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">real_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">adj_pvals</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pval&quot;</span><span class="p">])</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">real_df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;pval&quot;</span><span class="p">,</span> <span class="n">stat</span><span class="o">=</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span>
            <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">common_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">binwidth</span><span class="o">=</span><span class="mf">.05</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Fraction of adjusted $p$-values&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Adjusted $p$-value&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;$p$-values if the null hypothesis is true&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">.08</span><span class="p">,</span> <span class="mf">.08</span><span class="p">,</span> <span class="s2">&quot;Decision threshold, $</span><span class="se">\\</span><span class="s2">alpha = 0.05$&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/model-selection_11_0.png" src="../../_images/model-selection_11_0.png" />
</div>
</div>
<p>After adjusting for multiple comparisons, we end up with all of the <span class="math notranslate nohighlight">\(p\)</span>-values being <span class="math notranslate nohighlight">\(1\)</span>. Therefore, we <em>never</em> incorrectly reject the null hypothesis anymore.</p>
<p>In general, for multiple hypothesis correction, we recommend using Holm-Bonferroni correction, which is encoded with the parameter <code class="docutils literal notranslate"><span class="pre">multitest_method=&quot;holm&quot;</span></code>. We recommend the use of the Holm-Bonferroni approach because it ensures that our <span class="math notranslate nohighlight">\(p\)</span>-value produced by using multiple statistical tests controls the <a class="reference external" href="https://en.wikipedia.org/wiki/Family-wise_error_rate">Family-Wise Error Rate (FWER)</a> with no requirements as to the problem we glossed over previously, the <em>dependence</em> of the hypotheses being tested. This may give us adjusted <span class="math notranslate nohighlight">\(p\)</span>-values that are a little higher than several other methods (such as the popular Benjamini-Hochberg procedure), but in general we prefer to err on the side of caution when reporting scientific discoveries and do <em>not</em> want to spend effort investigating hypothetical dependencies amongst our hypothesis tests.</p>
<div class="section" id="model-selection-for-unweighted-networks">
<h3><span class="section-number">8.3.3.1. </span>Model Selection for unweighted networks<a class="headerlink" href="#model-selection-for-unweighted-networks" title="Permalink to this headline">¶</a></h3>
<p>Finally, to implement the actual hypothesis test, the procedure will be to estimate a test statistic and <span class="math notranslate nohighlight">\(p\)</span>-value using our procedure of choice, for each of the possible alternative hypotheses (the hypotheses <span class="math notranslate nohighlight">\(H_1, H_2, ..., H_n\)</span>, depending on how many hypotheses we have). If any of the adjusted <span class="math notranslate nohighlight">\(p\)</span>-values which we produce are smaller than our decision threshold of <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>, we accept the hypothesis with the smallest <span class="math notranslate nohighlight">\(p\)</span>-value. If none of the adjusted <span class="math notranslate nohighlight">\(p\)</span>-values we produce our smaller than our decision threshold, we accept the null hypothesis <span class="math notranslate nohighlight">\(H_0\)</span>. <code class="docutils literal notranslate"><span class="pre">graspologic</span></code> makes this implementation easy for us:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alt_hypotheses</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;abba&#39;</span><span class="p">,</span> <span class="s1">&#39;abbd&#39;</span><span class="p">]</span>
<span class="n">pval</span><span class="p">,</span> <span class="n">opt_structure</span> <span class="o">=</span> <span class="n">sbm_mod</span><span class="o">.</span><span class="n">estimate_block_structure</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">zs</span><span class="p">),</span> <span class="n">candidates</span> <span class="o">=</span> <span class="n">alt_hypotheses</span><span class="p">,</span>
                                 <span class="n">test_method</span> <span class="o">=</span> <span class="s2">&quot;fisher_exact&quot;</span><span class="p">,</span> <span class="n">multitest_method</span> <span class="o">=</span> <span class="s2">&quot;holm&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.05</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;p-value: </span><span class="si">{:.3f}</span><span class="s2">, optimal-structure: </span><span class="si">{:s}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pval</span><span class="p">,</span> <span class="n">opt_structure</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:root:All simulated values are lower than table statistic : pval technically of 0.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:root:All simulated values are lower than table statistic : pval technically of 0.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>p-value: 0.002, optimal-structure: abba
</pre></div>
</div>
</div>
</div>
<p>So, the model correctly reports that <span class="math notranslate nohighlight">\(H_1\)</span> is true with <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>, and the optimal block structure is reported as <span class="math notranslate nohighlight">\(H_1: b_{11} = b_{22} = b, b_{12} = b_{21} = a, a \neq b\)</span>. The adjusted <span class="math notranslate nohighlight">\(p\)</span>-value is approximately <span class="math notranslate nohighlight">\(.002\)</span>.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./applications/ch8"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="testing-differences.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">8.2. </span>Testing for Differences between Groups of Edges</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="single-vertex-nomination.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">8.4. </span>Single-Network Vertex Nomination</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Joshua Vogelstein, Alex Loftus, and Eric Bridgeford<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>