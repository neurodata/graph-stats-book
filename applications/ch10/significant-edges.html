
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>10.2. Testing for Significant Edges &#8212; Hands-on Network Machine Learning with Scikit-Learn and Graspologic</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="10.3. Testing for Significant Vertices" href="significant-vertices.html" />
    <link rel="prev" title="10.1. Anomaly Detection For Timeseries of Networks" href="anomaly-detection.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Hands-on Network Machine Learning with Scikit-Learn and Graspologic</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../coverpage.html">
   Hands-on Network Machine Learning with Scikit-Learn and Graspologic
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/terminology.html">
   Terminology and Math Refresher
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch1/ch1.html">
   1. The Network Machine Learning Landscape
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/what-is-a-network.html">
     1.1. What Is A Network?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/why-study-networks.html">
     1.2. Why Study Networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/examples-of-applications.html">
     1.3. Examples of applications
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/types-of-networks.html">
     1.4. Types of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/types-of-learning-probs.html">
     1.5. Types of Network Learning Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/main-challenges.html">
     1.6. Main Challenges of Network Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/exercises.html">
     1.7. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch2/ch2.html">
   2. End-to-end Biology Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/big-picture.html">
     2.1. Look at the big picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/get-the-data.html">
     2.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/prepare-the-data.html">
     2.3. Prepare the Data for Network Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/transformation-techniques.html">
     2.4. Transformation Techniques
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/select-and-train.html">
     2.5. Select and Train a Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/fine-tune.html">
     2.6. Fine-Tune your Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch3/ch3.html">
   3. End-to-end Business Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/big-picture.html">
     3.1. Look at the Big Picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/get-the-data.html">
     3.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/discover-and-visualize.html">
     3.3. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/prepare-the-data.html">
     3.4. Prepare the Data for Network Algorithms
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Representations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch4/ch4.html">
   4. Properties of Networks as a Statistical Object
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/matrix-representations.html">
     4.1. Matrix Representations Of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/network-representations.html">
     4.2. Representations of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/properties-of-networks.html">
     4.3. Properties of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/regularization.html">
     4.4. Regularization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch5/ch5.html">
   5. Why Use Statistical Models?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/why-use-models.html">
     5.1. Why Use Statistical Models?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_ER.html">
     5.2. Erdös-Rényi (ER) Random Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_SBM.html">
     5.3. Stochastic Block Models (SBM)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_RDPG.html">
     5.4. Random Dot Product Graphs (RDPG)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/multi-network-models.html">
     5.5. Multiple Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/models-with-covariates.html">
     5.6. Network Models with Covariates
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_theory.html">
     5.7. Single network model theory
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch6/ch6.html">
   6. Learning Network Representations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/estimating-parameters_mle.html">
     6.1. Estimating Parameters in Network Models via MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/why-embed-networks.html">
     6.2. Why embed networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/spectral-embedding.html">
     6.3. Spectral Embedding Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/estimating-parameters_spectral.html">
     6.4. Estimating Parameters with Spectaal Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/random-walk-diffusion-methods.html">
     6.5. Random-Walk and Diffusion-based Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/graph-neural-networks.html">
     6.6. Graph Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/multigraph-representation-learning.html">
     6.7. Multiple-Network Representation Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/joint-representation-learning.html">
     6.8. Joint Representation Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/estimating-parameters_theory.html">
     6.9. Model Estimation Theory
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch7/ch7.html">
   7. Theoretical Results
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch7/theory-single-network.html">
     7.1. Theory for Single Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch7/theory-multigraph.html">
     7.2. Theory for Multiple-Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch7/theory-matching.html">
     7.3. Theory for Graph Matching
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch8/ch8.html">
   8. Applications When You Have One Network
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch8/community-detection.html">
     8.1. Community Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch8/testing-differences.html">
     8.2. Testing for Differences between Groups of Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch8/model-selection.html">
     8.3. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch8/single-vertex-nomination.html">
     8.4. Single-Network Vertex Nomination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch8/out-of-sample.html">
     8.5. Out-of-sample Embedding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch9/ch9.html">
   9. Applications for Two Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch9/two-sample-hypothesis.html">
     9.1. Two-Sample Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch9/graph-matching-vertex.html">
     9.2. Graph Matching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch9/multiple-vertex-nomination.html">
     9.3. Vertex Nomination For Multiple Networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="ch10.html">
   10. Applications for Many Networks
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="anomaly-detection.html">
     10.1. Anomaly Detection For Timeseries of Networks
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     10.2. Testing for Significant Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="significant-vertices.html">
     10.3. Testing for Significant Vertices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="significant-communities.html">
     10.4. Testing for Significant Communities
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://graspologic.readthedocs.io/en/latest/">
   Graspologic Documentation
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/applications/ch10/significant-edges.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/neurodata/graph-stats-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/neurodata/graph-stats-book/issues/new?title=Issue%20on%20page%20%2Fapplications/ch10/significant-edges.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/neurodata/graph-stats-book/edit/master/network_machine_learning_in_python/applications/ch10/significant-edges.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/neurodata/graph-stats-book/master?urlpath=tree/network_machine_learning_in_python/applications/ch10/significant-edges.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fisher-s-exact-test-for-edge-importance">
   10.2.1. Fisher’s Exact Test for Edge Importance
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#using-edge-importances-to-estimate-the-signal-subnetwork">
   10.2.2. Using edge importances to estimate the signal subnetwork
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#building-a-classifier-using-the-estimated-signal-subnetwork">
   10.2.3. Building a classifier using the estimated signal subnetwork
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayes-plugin-classifier-statistical-intuition">
     10.2.3.1. Bayes Plugin Classifier (Statistical Intuition)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-with-bayes-plugin-classifier">
     10.2.3.2. Classification with Bayes Plugin Classifier
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Testing for Significant Edges</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fisher-s-exact-test-for-edge-importance">
   10.2.1. Fisher’s Exact Test for Edge Importance
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#using-edge-importances-to-estimate-the-signal-subnetwork">
   10.2.2. Using edge importances to estimate the signal subnetwork
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#building-a-classifier-using-the-estimated-signal-subnetwork">
   10.2.3. Building a classifier using the estimated signal subnetwork
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayes-plugin-classifier-statistical-intuition">
     10.2.3.1. Bayes Plugin Classifier (Statistical Intuition)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-with-bayes-plugin-classifier">
     10.2.3.2. Classification with Bayes Plugin Classifier
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="testing-for-significant-edges">
<h1><span class="section-number">10.2. </span>Testing for Significant Edges<a class="headerlink" href="#testing-for-significant-edges" title="Permalink to this headline">¶</a></h1>
<p>For the next two sections, we will turn back to an example we came across back when we discussed the <a class="reference external" href="#link?">Signal Subnetwork model</a>. If you recall, we had <span class="math notranslate nohighlight">\(100\)</span> networks, which were either earthlings or astronauts. The networks each had <span class="math notranslate nohighlight">\(5\)</span> nodes, which represented different lobes of the brain. The occipital lobe is responsible for sight, the temporal lobe with emotions and language, the parietal with hearing, the frontal with thinking and movement, and the insula with basic survivability skills. The astronauts were forced to live for several hundred thousand years on a planet in which their eyesight was challenged, and over time, evolution selected the astronauts who had a higher probability of connections between the occipital lobe and other areas of the brain. Our question of interest was as follows: if we are shown a network, how do we decide whether that network is from an earthling or an astronaut? Can we come up with a signal subnetwork classifier?</p>
<p>To begin to address this question, we came up with the signal subnetwork model. What we established wit hthe signal subnetwork model was that all of the edges in each network could be broken up into one of two groups: either the signal edges or the non-signal edges. We collected these signal edges into a set called the “signal subnetwork”, which was a parameter for the signal subnetwork model. For these signal edges, the probability of an edge existing (or not) was different for two (or more) classes in our problem. What this means is that, in our problem above, the edges which had a node in the occipital lobe had a different connection probability for the astronauts than the humans. On the other hand, the non-signal edges did not have a different connection probability for the astronauts than the humans.</p>
<p>To start this section off, let’s first sample some example networks from the signal subnetwork model. Let’s assume that we have a total of <span class="math notranslate nohighlight">\(100\)</span> people, each of whom are either astronauts (with probability <span class="math notranslate nohighlight">\(\pi_{ast} = 0.4\)</span>) or humans (with probability <span class="math notranslate nohighlight">\(\pi_{earth} = 0.6\)</span>). First, we’ll roll our 2-sided die <span class="math notranslate nohighlight">\(100\)</span> times, where side 1 (class 1) corresponds to astronauts, and side 2 (class 2) corresponds to humans. We will then create the class assignment vector <span class="math notranslate nohighlight">\(\vec y\)</span> using the number of times the die lands on each class:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">pi_ast</span> <span class="o">=</span> <span class="mf">0.4</span>
<span class="n">pi_hum</span> <span class="o">=</span> <span class="mf">0.6</span>
<span class="n">M</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># roll a 2-sided die 100 times, with probability 0.4 of landing on side 1 (astronaut) </span>
<span class="c1"># and 0.6 of landing on side 2 (earthling)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="n">classnames</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Astronaut&quot;</span><span class="p">,</span> <span class="s2">&quot;Earthling&quot;</span><span class="p">]</span>
<span class="n">class_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">pvals</span><span class="o">=</span><span class="p">[</span><span class="n">pi_ast</span><span class="p">,</span> <span class="n">pi_hum</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of individuals who are astronauts: </span><span class="si">{:d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">class_counts</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of individuals who are humans: </span><span class="si">{:d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">class_counts</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

<span class="c1"># create class assignment vector, and randomly reshuffle class labels for each individual</span>
<span class="n">yvec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">class_counts</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">class_counts</span><span class="p">[</span><span class="mi">1</span><span class="p">])])</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">yvec</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of individuals who are astronauts: 39
Number of individuals who are humans: 61
</pre></div>
</div>
</div>
</div>
<p>Next, we construct the probability matrices for each class. The probabilities for edges in which a node is in the occipital lobe are higher for the astronauts than the humans:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># the number of nodes</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">5</span>
<span class="c1"># edge probabilities for humans are random</span>
<span class="n">P_hum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="o">*</span><span class="n">n</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="c1"># networks are undirected, so make the probability matrix symmetric</span>
<span class="n">P_hum</span> <span class="o">=</span> <span class="p">(</span><span class="n">P_hum</span> <span class="o">+</span> <span class="n">P_hum</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
<span class="c1"># networks are loopless, so remove the diagonal</span>
<span class="n">P_hum</span> <span class="o">=</span> <span class="n">P_hum</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">P_hum</span><span class="p">))</span>

<span class="c1"># the names of each of the five nodes</span>
<span class="n">nodenames</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Occipital&quot;</span><span class="p">,</span> <span class="s2">&quot;Frontal&quot;</span><span class="p">,</span> <span class="s2">&quot;Temporal&quot;</span><span class="p">,</span> <span class="s2">&quot;Frontal&quot;</span><span class="p">,</span> <span class="s2">&quot;Insula&quot;</span><span class="p">]</span>
<span class="c1"># the signal edges</span>
<span class="n">E</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
<span class="n">P_ast</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">P_hum</span><span class="p">)</span>

<span class="c1"># probabilities for signal edges are higher in astronauts than humans</span>
<span class="c1"># square root function biases them towards 1, which is higher than</span>
<span class="c1"># whatever they are right now since they are between 0 and 1</span>
<span class="n">P_ast</span><span class="p">[</span><span class="n">E</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">P_ast</span><span class="p">[</span><span class="n">E</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="k">def</span> <span class="nf">plot_prob</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">nodename</span><span class="o">=</span><span class="s2">&quot;Brain Area&quot;</span><span class="p">,</span> <span class="n">nodetix</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">],</span>
             <span class="n">nodelabs</span><span class="o">=</span><span class="n">nodenames</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    
    <span class="k">with</span> <span class="n">sns</span><span class="o">.</span><span class="n">plotting_context</span><span class="p">(</span><span class="s2">&quot;talk&quot;</span><span class="p">,</span> <span class="n">font_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Purples&quot;</span><span class="p">,</span>
                        <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">cbar_kws</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">shrink</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">yticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">xticklabels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        <span class="n">cbar</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">collections</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="n">nodename</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="n">nodename</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">nodetix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">nodelabs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">nodetix</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">nodelabs</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">nodetix</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">nodelabs</span><span class="p">)</span>
        <span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">set_frame_on</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="n">plot_prob</span><span class="p">(</span><span class="n">P_hum</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Earthling Probability Matrix&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plot_prob</span><span class="p">(</span><span class="n">P_ast</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Astronaut Probability Matrix&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plot_prob</span><span class="p">(</span><span class="n">E</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Signal Edges&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plot_prob</span><span class="p">(</span><span class="n">P_ast</span> <span class="o">-</span> <span class="n">P_hum</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$P_</span><span class="si">{ast}</span><span class="s2"> - P_</span><span class="si">{earth}</span><span class="s2">$&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/significant-edges_4_0.png" src="../../_images/significant-edges_4_0.png" />
</div>
</div>
<p>Finally, we use the class assignment vector <span class="math notranslate nohighlight">\(\vec y\)</span> to sample individual networks for each of the individuals. We plot an adjacency matrix for the first individual:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">ier</span>

<span class="c1"># arrange the probability matrices in a list</span>
<span class="n">prob_mtxs</span> <span class="o">=</span> <span class="p">[</span><span class="n">P_ast</span><span class="p">,</span> <span class="n">P_hum</span><span class="p">]</span>
<span class="c1"># initialize empty list for adjacency matrices</span>
<span class="n">As</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">yvec</span><span class="p">:</span>
    <span class="c1"># sample adjacency matrix for an individual of class y using the probability</span>
    <span class="c1"># matrix for that class</span>
    <span class="n">As</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ier</span><span class="p">(</span><span class="n">prob_mtxs</span><span class="p">[</span><span class="n">y</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="c1"># stack the adjacency matrices for each individual such that node i is first dimension,</span>
<span class="c1"># node j is second dimension, and the individual index m is the third dimension</span>
<span class="n">As</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">As</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_2017</span><span class="o">/</span><span class="mf">808418603.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">ier</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> 
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="c1"># arrange the probability matrices in a list</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">prob_mtxs</span> <span class="o">=</span> <span class="p">[</span><span class="n">P_ast</span><span class="p">,</span> <span class="n">P_hum</span><span class="p">]</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="c1"># initialize empty list for adjacency matrices</span>

<span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">hostedtoolcache</span><span class="o">/</span><span class="n">Python</span><span class="o">/</span><span class="mf">3.8.12</span><span class="o">/</span><span class="n">x64</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.8</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">graphbook_code</span><span class="o">/</span><span class="fm">__init__</span><span class="o">.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">     </span><span class="mi">25</span> 
<span class="g g-Whitespace">     </span><span class="mi">26</span> <span class="c1"># star imports work only because we have __all__ defined</span>
<span class="ne">---&gt; </span><span class="mi">27</span> <span class="kn">from</span> <span class="nn">.plotting</span> <span class="kn">import</span> <span class="o">*</span>
<span class="g g-Whitespace">     </span><span class="mi">28</span> <span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="o">*</span>
<span class="g g-Whitespace">     </span><span class="mi">29</span> <span class="kn">from</span> <span class="nn">.siem</span> <span class="kn">import</span> <span class="o">*</span>

<span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">hostedtoolcache</span><span class="o">/</span><span class="n">Python</span><span class="o">/</span><span class="mf">3.8.12</span><span class="o">/</span><span class="n">x64</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.8</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">graphbook_code</span><span class="o">/</span><span class="n">plotting</span><span class="o">.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> 
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="c1"># from graspologic.plot.plot import _check_common_inputs, _process_graphs, _plot_groups</span>
<span class="ne">----&gt; </span><span class="mi">8</span> <span class="kn">from</span> <span class="nn">graspologic.plot.plot</span> <span class="kn">import</span> <span class="p">(</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span>     <span class="n">_check_common_inputs</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span>     <span class="n">_process_graphs</span><span class="p">,</span>

<span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">hostedtoolcache</span><span class="o">/</span><span class="n">Python</span><span class="o">/</span><span class="mf">3.8.12</span><span class="o">/</span><span class="n">x64</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.8</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">graspologic</span><span class="o">/</span><span class="fm">__init__</span><span class="o">.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> 
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="kn">import</span> <span class="nn">graspologic.align</span>
<span class="ne">----&gt; </span><span class="mi">5</span> <span class="kn">import</span> <span class="nn">graspologic.cluster</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="kn">import</span> <span class="nn">graspologic.datasets</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="kn">import</span> <span class="nn">graspologic.embed</span>

<span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">hostedtoolcache</span><span class="o">/</span><span class="n">Python</span><span class="o">/</span><span class="mf">3.8.12</span><span class="o">/</span><span class="n">x64</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.8</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">graspologic</span><span class="o">/</span><span class="n">cluster</span><span class="o">/</span><span class="fm">__init__</span><span class="o">.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="c1"># Licensed under the MIT License.</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> 
<span class="ne">----&gt; </span><span class="mi">4</span> <span class="kn">from</span> <span class="nn">.autogmm</span> <span class="kn">import</span> <span class="n">AutoGMMCluster</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="kn">from</span> <span class="nn">.divisive_cluster</span> <span class="kn">import</span> <span class="n">DivisiveCluster</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="kn">from</span> <span class="nn">.gclust</span> <span class="kn">import</span> <span class="n">GaussianCluster</span>

<span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">hostedtoolcache</span><span class="o">/</span><span class="n">Python</span><span class="o">/</span><span class="mf">3.8.12</span><span class="o">/</span><span class="n">x64</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.8</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">graspologic</span><span class="o">/</span><span class="n">cluster</span><span class="o">/</span><span class="n">autogmm</span><span class="o">.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">     </span><span class="mi">18</span> <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">ParameterGrid</span>
<span class="g g-Whitespace">     </span><span class="mi">19</span> <span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">check_scalar</span>
<span class="ne">---&gt; </span><span class="mi">20</span> <span class="kn">from</span> <span class="nn">typing_extensions</span> <span class="kn">import</span> <span class="n">Literal</span>
<span class="g g-Whitespace">     </span><span class="mi">21</span> 
<span class="g g-Whitespace">     </span><span class="mi">22</span> <span class="kn">from</span> <span class="nn">.base</span> <span class="kn">import</span> <span class="n">BaseCluster</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;typing_extensions&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.plot</span> <span class="kn">import</span> <span class="n">heatmap</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">));</span>
<span class="n">plot_prob</span><span class="p">(</span><span class="n">As</span><span class="p">[:,:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;First individual, an </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">classnames</span><span class="p">[</span><span class="n">yvec</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/significant-edges_7_0.png" src="../../_images/significant-edges_7_0.png" />
</div>
</div>
<p>The key ideas we want to capture in our classifier are as follows:</p>
<ol class="simple">
<li><p>We want to <em>only</em> look at the edges which have a differing connection probability amongst our classes. This means that we only want to look at <em>signal edges</em> which are in the <em>signal subnetwork</em>, and we want to ignore edges which are not in the signal subnetwork. Edges which are not in the signal subnetwork are simply noise, since they have the same connection probability between the classes, and therefore are not useful for differentiating between the different classes.</p></li>
<li><p>We want to incorporate the structure of the network into the classifier. This means we want to use the fact that nodes are nodes, and that edges are connections between nodes, to determine how to classify networks as earthling or astronaut.</p></li>
</ol>
<p>To begin, we will start by addressing aim 1. We need to find which edges are in the signal subnetework. Stated another way, we need to <em>estimate</em> the signal subnetwork. What this requires is a way to identify which edges will best capture the difference between the classes in our network. Do we know anything which can do this? As it turns out, we can use Fisher’s exact test, something we learned about in the section on <a class="reference external" href="http://docs.neurodata.io/graph-stats-book/applications/ch8/testing-differences.html#two-sample-hypothesis-testing-with-coins">testing for differences between groups of edges</a>, to identify the signal subnetwork. In the next section on <a class="reference external" href="#link?">identifying significant vertices</a>, we will address the second point on using the structure of the network to further refine these potential signal edges.</p>
<div class="section" id="fisher-s-exact-test-for-edge-importance">
<h2><span class="section-number">10.2.1. </span>Fisher’s Exact Test for Edge Importance<a class="headerlink" href="#fisher-s-exact-test-for-edge-importance" title="Permalink to this headline">¶</a></h2>
<p>If you remember back to the coin flip example, our setting was as follows. We had two coins, coin <span class="math notranslate nohighlight">\(1\)</span> and coin <span class="math notranslate nohighlight">\(2\)</span>, and we wanted to test whether their probabilities of landing on heads were different. Our hypotheses were <span class="math notranslate nohighlight">\(H_A: p_1 \neq p_2\)</span>, against the null hypothesis that <span class="math notranslate nohighlight">\(H_0: p_1 = p_2\)</span>. We therefore had two random samples, the outcomes of ten coin flips from coin one and the outcomes of ten coin flips from coin two, meaning that our test of <span class="math notranslate nohighlight">\(H_A\)</span> against <span class="math notranslate nohighlight">\(H_0\)</span> fell into the <em>two-sample testing</em> regime. To address this, what we used was Fisher’s exact test, where we counted the number of times each coin landed on heads and tails, which we aggregated in a table:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>First coin</p></th>
<th class="head"><p>Second coin</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Landed on heads</p></td>
<td><p>7</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p>Landed on tails</p></td>
<td><p>3</p></td>
<td><p>9</p></td>
</tr>
</tbody>
</table>
<p>As it turns out, we can adapt this test for our situation here too! For a single edge, what we want to do is test whether <span class="math notranslate nohighlight">\(H_A: p_{ij}^{(ast)} \neq p_{ij}^{(earth)}\)</span>, against the null hypothesis that <span class="math notranslate nohighlight">\(H_0: p_{ij}^{(ast)} = p_{ij}^{(earth)}\)</span>. The key property of Fisher’s exact test that makes this desirable for us is that, when <span class="math notranslate nohighlight">\(H_0\)</span> is true (and the probabilities are equal), the Fisher’s exact test statistic is smaller, whereas when <span class="math notranslate nohighlight">\(H_A\)</span> is true (and the probabilities are not equal), the Fisher’s exact test statistic is bigger. We will exploit this feature in our design of a classifier for astronauts versus earthlings. Note that we are using the Fisher’s exact test statistic, and <em>not</em> the <span class="math notranslate nohighlight">\(p\)</span>-value of the test, for this step like we did previously when testing for differences between groups of edges. For each edge <span class="math notranslate nohighlight">\((i, j)\)</span>, we will construct the following table:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>Astronauts</p></th>
<th class="head"><p>Earthlings</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Edge <span class="math notranslate nohighlight">\((i,j)\)</span> exists</p></td>
<td><p>Number of astronauts with <span class="math notranslate nohighlight">\((i,j)\)</span></p></td>
<td><p>Number of earthlings with edge <span class="math notranslate nohighlight">\((i,j)\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Edge <span class="math notranslate nohighlight">\((i,j)\)</span> does not exist</p></td>
<td><p>Number of astronauts with edge <span class="math notranslate nohighlight">\((i,j)\)</span></p></td>
<td><p>Number of earthlings without edge <span class="math notranslate nohighlight">\((i,j)\)</span></p></td>
</tr>
</tbody>
</table>
<p>Which we can do in python as follows, for the edge from the occipital lobe to the temporal lobe:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># (1,2) corresponds to the edge from occipital to temporal lobe</span>

<span class="n">ast_edge</span> <span class="o">=</span> <span class="n">As</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">yvec</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>  <span class="c1"># count the number of astronauts with edge i,j</span>
<span class="n">hum_edge</span> <span class="o">=</span> <span class="n">As</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">yvec</span> <span class="o">==</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>  <span class="c1"># count the number of earthlings with edge i,j</span>
<span class="n">ast_noedge</span> <span class="o">=</span> <span class="n">class_counts</span><span class="p">[</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">ast_edge</span>  <span class="c1"># count the number of astronauts without edge i,j</span>
<span class="n">hum_noedge</span> <span class="o">=</span> <span class="n">class_counts</span><span class="p">[</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">hum_edge</span>  <span class="c1"># count the number of earthlings without edge i,j</span>

<span class="n">edge_tab</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">ast_edge</span><span class="p">,</span> <span class="n">hum_edge</span><span class="p">],</span> <span class="p">[</span><span class="n">ast_noedge</span><span class="p">,</span> <span class="n">hum_noedge</span><span class="p">]])</span>  <span class="c1"># arrange as in table shown above</span>

<span class="nb">print</span><span class="p">(</span><span class="n">edge_tab</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[18. 12.]
 [21. 49.]]
</pre></div>
</div>
</div>
</div>
<p>Next, we compute the Fisher’s exact test statistic on the data, using scipy:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">fisher_exact</span>

<span class="n">test_statistic</span><span class="p">,</span> <span class="n">pval</span> <span class="o">=</span> <span class="n">fisher_exact</span><span class="p">(</span><span class="n">edge_tab</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;p-value: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pval</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>p-value: 0.0071
</pre></div>
</div>
</div>
</div>
<p>Note that since the edge <span class="math notranslate nohighlight">\((i,j)\)</span> that we chose above corresponded to the edge between the occipital and temporal lobe, we expect this edge to indicate a disparity between the astronauts and the earthlings. Why is this? Well, quite simply, by construction, this edge is a <em>signal</em> edge, which means that it carries real <em>signal</em> in differentiating a network from a human from a network of an alien. Why is this a big deal?</p>
<p>Well, let’s see what happens if we were to compute this for a non-signal edge. Let’s arbitrarily choose the edge between the temporal and frontal lobes, which corresponds to <span class="math notranslate nohighlight">\(i=3\)</span> (the temporal lobe) and <span class="math notranslate nohighlight">\(j = 2\)</span> (the frontal lobe):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># (3,2) corresponds to the edge from temporal to frontal lobe</span>

<span class="n">ast_edge</span> <span class="o">=</span> <span class="n">As</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">yvec</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>  <span class="c1"># count the number of astronauts with edge i,j</span>
<span class="n">hum_edge</span> <span class="o">=</span> <span class="n">As</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">yvec</span> <span class="o">==</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>  <span class="c1"># count the number of earthlings with edge i,j</span>
<span class="n">ast_noedge</span> <span class="o">=</span> <span class="n">class_counts</span><span class="p">[</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">ast_edge</span>  <span class="c1"># count the number of astronauts without edge i,j</span>
<span class="n">hum_noedge</span> <span class="o">=</span> <span class="n">class_counts</span><span class="p">[</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">hum_edge</span>  <span class="c1"># count the number of earthlings without edge i,j</span>

<span class="n">edge_tab</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">ast_edge</span><span class="p">,</span> <span class="n">hum_edge</span><span class="p">],</span> <span class="p">[</span><span class="n">ast_noedge</span><span class="p">,</span> <span class="n">hum_noedge</span><span class="p">]])</span>  <span class="c1"># arrange as in table shown above</span>

<span class="n">test_statistic</span><span class="p">,</span> <span class="n">pval</span> <span class="o">=</span> <span class="n">fisher_exact</span><span class="p">(</span><span class="n">edge_tab</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;p-value: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pval</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>p-value: 0.8000
</pre></div>
</div>
</div>
</div>
<p>Well, now this test statistic happens to be a <em>lot</em> smaller than the previous one we saw, now doesn’t it? Is this just by chance? The answer is: no! For signal edges, the test statistic will, by construction, <em>generally</em> be smaller than the test statistic in a non-signal edge. By <em>generally</em>, we mean that it will <em>tend</em> to be smaller (but not always!). We could certainly get samples of data where this is not the case, analogous to the idea that we could flip a fair coin (with equal probability of seeing heads and tails) 10 times and obtain all 10 flips being heads. For this reason, we will use the Fisher’s exact test statistic to quantify how “important” an edge is for differentiating the two classes, or as an edge importance statistic. We will exploit this edge importance statistic as we build up our classifier further.</p>
</div>
<div class="section" id="using-edge-importances-to-estimate-the-signal-subnetwork">
<h2><span class="section-number">10.2.2. </span>Using edge importances to estimate the signal subnetwork<a class="headerlink" href="#using-edge-importances-to-estimate-the-signal-subnetwork" title="Permalink to this headline">¶</a></h2>
<p>We will use the Fisher’s exact test statistic to develop an approach which allows us to properly estimate a signal subnetwork model. The key idea is this: if we were to use any one edge of the network, we would not really be able to predict whether someone is an earthling or an alien. The reason for this is that edges either exist, or not, so unless one of the class edge probabilities for a particular edge happens to be really low (near zero) and the other happens to be really high (near one), the only informative decision boundary we could construct would be to assign one class to the networks where that particular edge exists, or the other class to the networks where that particular edge does not exist. Even less interestingly, we could abitrarily say that every network is in a particular class, which is also not going to be a particularly interesting classifier.</p>
<p>Another thing we could do would be to use <em>every</em> edge in the network to develop a classifier, which also isn’t the best we could do. This is because if we use every edge in the classifier, w would have a lot of <em>noise</em> from the non-signal edges. This means that even though we might learn <em>something</em> from the signal edges, anything we learn is going to end up being diluted down by noise because we are including a lot of uninformative information in our classifier (the non-signal edges).</p>
<p>Rather, what we want to do is investigate to find the edges which are carrying all of the signal, and then isolate our downstream learning from information captured by those edges. This is because the signal edges carry all of the informative information about differentiating networks from one class to the other. This begs the question, how do we find the signal edges, and isolate them from the non-signal edges?</p>
<p>As we mentioned in the preceding subsection, as it happens, the Fisher’s exact test statistic is going to tend to be larger for edges in which there is actual signal (the edge probability is different for astronauts and humans), and smaller when there is no signal (the edge probability is the same for astronauts and humans). That is, if an edge is in the signal subnetwork, the Fisher’s exact test statistic is big, and if it is not in the signal subnetwork, the Fisher’s exact test statistic is small. For this reason, what we end up doing is <em>rank transforming</em> the Fisher’s exact test statistics, and then pick an arbitrary number of the highest ranking test statistics to retain for classification.</p>
<p>We start by constructing a <strong>significance matrix</strong>, which is a collection of all of the Fisher’s exact test statistics for each edge:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sig_mtx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">))</span>
<span class="n">ast_idxs</span> <span class="o">=</span> <span class="n">yvec</span> <span class="o">==</span> <span class="mi">1</span>  <span class="c1"># the individuals who are astronauts</span>
<span class="n">hum_idxs</span> <span class="o">=</span> <span class="n">yvec</span> <span class="o">==</span> <span class="mi">2</span>  <span class="c1"># the individuals who are earthlings</span>
<span class="c1"># since the networks are undirected, only need to compute for upper triangle</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="n">ast_edgeij</span> <span class="o">=</span> <span class="n">As</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">ast_idxs</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">hum_edgeij</span> <span class="o">=</span> <span class="n">As</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">hum_idxs</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">table</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">ast_edgeij</span><span class="p">,</span> <span class="n">hum_edgeij</span><span class="p">],</span>
                          <span class="p">[</span><span class="n">class_counts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">ast_edgeij</span><span class="p">,</span> <span class="n">class_counts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">hum_edgeij</span><span class="p">]])</span>
        <span class="n">sig_mtx</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">fisher_exact</span><span class="p">(</span><span class="n">table</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">sig_mtx</span> <span class="o">=</span> <span class="n">sig_mtx</span> <span class="o">+</span> <span class="n">sig_mtx</span><span class="o">.</span><span class="n">T</span>  <span class="c1"># symmetrize</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">));</span>
<span class="n">plot_prob</span><span class="p">(</span><span class="n">sig_mtx</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Significance matrix&quot;</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">sig_mtx</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/significant-edges_17_0.png" src="../../_images/significant-edges_17_0.png" />
</div>
</div>
<p>Notice that the edges with the highest Fisher’s exact test statistics in the significance matrix tend to be the edges with a node in the occipital lobe, which are our signal edges. This is great news! Next, we rank the test statistics in the significance matrix, from smallest to largest:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">rankdata</span>

<span class="n">rank_sig_mtx</span> <span class="o">=</span> <span class="n">rankdata</span><span class="p">(</span><span class="n">sig_mtx</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">));</span>
<span class="n">plot_prob</span><span class="p">(</span><span class="n">rank_sig_mtx</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Ranked significance matrix&quot;</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">rank_sig_mtx</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/significant-edges_20_0.png" src="../../_images/significant-edges_20_0.png" />
</div>
</div>
<p>And the ranks are biggest for the Fisher’s exact test statistics with a node in the occipital lobe. Then, we select a number of edges (the size of the signal subnetwork) <span class="math notranslate nohighlight">\(K\)</span>, and retain the top <span class="math notranslate nohighlight">\(K\)</span> edges, by their test statistic significances. The top <span class="math notranslate nohighlight">\(K\)</span> edges by significance are an estimate of the signal subnetwork, <span class="math notranslate nohighlight">\(\hat{\mathcal S}\)</span>.</p>
<p>We can implement everything we’ve learned so far in graspologic relatively easily, using the <code class="docutils literal notranslate"><span class="pre">SignalSubgraph</span></code> class:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.subgraph</span> <span class="kn">import</span> <span class="n">SignalSubgraph</span>

<span class="n">K</span> <span class="o">=</span> <span class="mi">8</span>  <span class="c1"># the number of edges in the subgraph</span>
<span class="n">sgest</span> <span class="o">=</span> <span class="n">SignalSubgraph</span><span class="p">()</span>
<span class="n">sgest</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">As</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">yvec</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">constraints</span><span class="o">=</span><span class="n">K</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Next, we arrange this into a matrix so that we can look at the signal subnetwork we identified, and compare it to the true signal subnetwork:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sigsub</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">))</span>  <span class="c1"># initialize empty matrix</span>
<span class="n">sigsub</span><span class="p">[</span><span class="n">sgest</span><span class="o">.</span><span class="n">sigsub_</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">));</span>
<span class="n">plot_prob</span><span class="p">(</span><span class="n">E</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;True Signal Subnetwork&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plot_prob</span><span class="p">(</span><span class="n">sigsub</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Estimated Signal Subnetwork&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/significant-edges_25_0.png" src="../../_images/significant-edges_25_0.png" />
</div>
</div>
<p>So our estimated signal subnetwork looks pretty close to the true signal subnetwork.</p>
<p>A question you might be wondering concerns how exactly we chose the number of signal edges to include in our estimate of the signal subnetwork, <span class="math notranslate nohighlight">\(\hat{\mathcal S}\)</span>. If we knew the number of edges in the signal subnetwork ahead of time, the choice would be easy: just choose <span class="math notranslate nohighlight">\(K\)</span> to be the number of edges in the signal subnetwork! In real data, however, this isn’t really going to be the case. For this reason, we will have to estimate <span class="math notranslate nohighlight">\(K\)</span> using <span class="math notranslate nohighlight">\(\hat K\)</span>. To learn how to estimate <span class="math notranslate nohighlight">\(K\)</span>, we first need to learn how to put what we’ve covered so far into a classifier, so read on!</p>
</div>
<div class="section" id="building-a-classifier-using-the-estimated-signal-subnetwork">
<h2><span class="section-number">10.2.3. </span>Building a classifier using the estimated signal subnetwork<a class="headerlink" href="#building-a-classifier-using-the-estimated-signal-subnetwork" title="Permalink to this headline">¶</a></h2>
<p>Finally, we can use the estimated signal subnetwork that we have constructed to devise a classifier. The objective of a classifier is to take new pieces of data (in this case, new networks), and assign them to the class which they are most likely from. How do we determine which class a network is most likely from?</p>
<p>At the moment, we have our estimate of the signal subnetwork, <span class="math notranslate nohighlight">\(\hat{\mathcal S}\)</span>, and have a bunch of networks from one of two classes: astronaut (class 1) or alien (class 2). The edges of the network are binary, and we want to use the edges which are in the signal subnetwork to classify points as either astronaut or alien. A natural classifier choice for this situation is known as the Naive Bayes classifier. We have all the ingredients we need to construct the Naive Bayes classifier, so we’ll try to put this together. Feel free to skip past this next section if you want to jump right into the implementation of the classifier. In this next section, we will explain some of the intuition of the Naive Bayes classifer, which might require a bit of a probability and statistics background.</p>
<div class="section" id="bayes-plugin-classifier-statistical-intuition">
<h3><span class="section-number">10.2.3.1. </span>Bayes Plugin Classifier (Statistical Intuition)<a class="headerlink" href="#bayes-plugin-classifier-statistical-intuition" title="Permalink to this headline">¶</a></h3>
<p>The core idea of the Naive Bayes classifier is, if our data have features which are zeros and ones, we can use the <em>class-conditional probabilities</em> to determine whether a point is from class <span class="math notranslate nohighlight">\(1\)</span> or class <span class="math notranslate nohighlight">\(2\)</span>. The idea is as follows. First, we assume that all of the individual features of our data (the features, in our case, are the edges of the network that are in the signal subnetwork) are independent, then the likelihood of observing a particular sequence of edges in the signal subnetwork of the <span class="math notranslate nohighlight">\(m^{th}\)</span> network if that network is in class <span class="math notranslate nohighlight">\(y\)</span> is as follows. First, we will just write down some simpler notation for the quantity we want:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \mathbb P(\text{observing }A^{(m)}\text{ given we assume }\text{$m$ is in class $y$} \text{ where the signal subnetwork is $\mathcal S$}) = \mathbb P(A^{(m)} | y_m = y; \mathcal S)
\end{align*}\]</div>
<p>Nothing happened in this step just yet; we just made a smaller notation for the quantity on the left that we will use later on. In this next step, we use the fact that, if edges existing and not existing are independent, then the probability of observing a sequence of edges is the product of the probabilities of observing each individual edge. This is called an <em>independent edge assumption</em>. We proceed as follows:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \mathbb P(A^{(m)}| y_m = y; \mathcal S) &amp;= \prod_{(i,j) \in \mathcal S} \mathbb P(a_{ij}^{(m)} | y_m = y; \mathcal S)
\end{align*}\]</div>
<p>Note that we are taking the product of each pair of edges, <span class="math notranslate nohighlight">\((i,j)\)</span>, which are in the signal sub-network. Next, if we remember back to the Independent-Edge Random Network (IER), we assumed that if <span class="math notranslate nohighlight">\(\mathbf A^{(m)}\)</span> was an <span class="math notranslate nohighlight">\(IER_n(P^y)\)</span> network, that every edge <span class="math notranslate nohighlight">\(\mathbf a_{ij}^{(m)}\)</span> had a probability of <span class="math notranslate nohighlight">\(p^y_{ij}\)</span> of taking a value of <span class="math notranslate nohighlight">\(1\)</span> (the edge exists), and a probability of <span class="math notranslate nohighlight">\(1 - p_{ij}^y\)</span> of taking a value of <span class="math notranslate nohighlight">\(0\)</span> (the edge does not exist). What this means is that <span class="math notranslate nohighlight">\(\mathbf a_{ij}^{(m)}\)</span> is something called a <strong>Bernoulli distributed random variable</strong>. The probability of seeing a particular realization <span class="math notranslate nohighlight">\(a_{ij}^{(m)}\)</span> of a Bernoulli distributed random variable is relatively straightforward to see. We want the quantity <span class="math notranslate nohighlight">\(\mathbb P(A^{(m)} | y_m = y; \mathcal S)\)</span> to reflect the following two facts we’ve already discussed:</p>
<ol class="simple">
<li><p>If <span class="math notranslate nohighlight">\(a_{ij}^{(m)}\)</span> is <span class="math notranslate nohighlight">\(1\)</span>, then <span class="math notranslate nohighlight">\(\mathbb P(A^{(m)} | \mathbf y_m = y; \mathcal S)\)</span> is <span class="math notranslate nohighlight">\(p_{ij}^y\)</span>.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(a_{ij}^{(m)}\)</span> is <span class="math notranslate nohighlight">\(0\)</span>, then <span class="math notranslate nohighlight">\(\mathbb P(A^{(m)} | \mathbf y_m = y; \mathcal S)\)</span> is <span class="math notranslate nohighlight">\(1 - p_{ij}^y\)</span>.
Is there a succinct expression that we can express this with? Yes! Try the following equation:</p></li>
</ol>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \mathbb P(A^{(m)} | \mathbf y_m = y; \mathcal S) &amp;= (p_{ij}^y)^{a_{ij}^{(m)}} (1 - p_{ij}^y)^{1 - a_{ij}^{(m)}}
\end{align*}\]</div>
<p>Notice that if <span class="math notranslate nohighlight">\(a_{ij}^{(m)}\)</span> is <span class="math notranslate nohighlight">\(1\)</span>, then <span class="math notranslate nohighlight">\(1 - a_{ij}^{(m)}\)</span> is <span class="math notranslate nohighlight">\(0\)</span>. Therefore, <span class="math notranslate nohighlight">\((1 - p_{ij}^y)^{1 - a_{ij}^{(m)}}\)</span> is just <span class="math notranslate nohighlight">\(1\)</span>, since any number raised to the <span class="math notranslate nohighlight">\(0\)</span> power is <span class="math notranslate nohighlight">\(1\)</span>. On the other hand, <span class="math notranslate nohighlight">\((p_{ij}^y)^{a_{ij}^{(m)}}\)</span> is <span class="math notranslate nohighlight">\(p_{ij}^y\)</span>, since any number raised to the <span class="math notranslate nohighlight">\(1\)</span> power is itself. Therefore, this expression fits the bill for us. So, we can simplify our expression as:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\mathbb P(A^{(m)} | y_m = y; \mathcal S) &amp;= \prod_{(i,j) \in \mathcal S} (p_{ij}^y)^{a_{ij}^{(m)}} (1 - p_{ij}^y)^{1 - a_{ij}^{(m)}}
\end{align*}\]</div>
<p>And we’re almost there! The next thing we’re going to do is a little tricky, but fortunately we can turn to Bayes’ Theorem for help. What we want to do is compute the probability of observing <em>both</em> <span class="math notranslate nohighlight">\(A^{(m)}\)</span> <em>and</em> <span class="math notranslate nohighlight">\(y_m\)</span> having the value <span class="math notranslate nohighlight">\(y\)</span>, not the probability of observing <span class="math notranslate nohighlight">\(A^{(m)}\)</span> given that we assume that <span class="math notranslate nohighlight">\(y_m\)</span> is <span class="math notranslate nohighlight">\(y\)</span>. In statistical notation, what this amounts to is:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \mathbb P(\text{observing }A^{(m)}\text{ and }\text{$m$ is in class $y$} \text{ where the signal subnetwork is $\mathcal S$}) = \mathbb P(A^{(m)}, y_m = y; \mathcal S)
\end{align*}\]</div>
<p>This expression is a little confusing, but its interpretation is relatively straightforward: it is the probability that we see both things happening at the same time (the random network <span class="math notranslate nohighlight">\(\mathbf A^{(m)}\)</span> takes the value <span class="math notranslate nohighlight">\(A^{(m)}\)</span> and the random class <span class="math notranslate nohighlight">\(\mathbf y_m\)</span> has the value <span class="math notranslate nohighlight">\(y\)</span>) rather than just assume that the random class <span class="math notranslate nohighlight">\(\mathbf y_m\)</span> already is <span class="math notranslate nohighlight">\(y\)</span>. We can compute this quantity by remembering <a class="reference external" href="#link?">Bayes’ Theorem</a>:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
     \mathbb P(A^{(m)} |  \mathbb y_m = y; \mathcal S) &amp;= \frac{\mathbb P(A^{(m)}, \mathbb y_m = y; \mathcal S)}{\mathbb P(\mathbb y_m = y)}
\end{align*}\]</div>
<p>Note that this implies the following:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\mathbb P(A^{(m)}, \mathbb y_m = y; \mathcal S) &amp;= \mathbb P(A^{(m)} | \mathbb y_m = y; \mathcal S)\mathbb P(\mathbb y_m = y)
\end{align*}\]</div>
<p>Plugging in the value we obtained above:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\mathbb P(A^{(m)}, \mathbb y_m = y; \mathcal S) &amp;= \mathbb P(\mathbb y_m = y)\prod_{(i, j) \in \mathcal S} (p_{ij}^y)^{a_{ij}^{(m)}} (1 - p_{ij}^y)^{1 - a_{ij}^{(m)}}
\end{align*}\]</div>
<p>Remember that the parameter of the signal subnetwork model, <span class="math notranslate nohighlight">\(\pi_y\)</span>, represented the probability of our <span class="math notranslate nohighlight">\(Y\)</span>-sided die landing on class <span class="math notranslate nohighlight">\(y\)</span>, and therefore was the probability that the random class <span class="math notranslate nohighlight">\(\mathbf y_m\)</span> took the value <span class="math notranslate nohighlight">\(y\)</span>. Therefore, <span class="math notranslate nohighlight">\(\mathbb P(\mathbb y_m = y) = \pi_y\)</span>, since these two quantites represent the same thing! So:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\mathbb P(A^{(m)}, \mathbb y_m = y; \mathcal S) &amp;= \pi_y \prod_{(i, j) \in \mathcal S} (p_{ij}^y)^{a_{ij}^{(m)}} (1 - p_{ij}^y)^{1 - a_{ij}^{(m)}}
\end{align*}\]</div>
<p>Finally, we introduce a new quantity. This quantity is very similar to the above quantity we came across, but with some terms reversed:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \mathbb P(\text{$m$ is in class $y$}\text{ given we observe }$A^{(m)}$ \text{ where the signal subnetwork is $\mathcal S$}) = \mathbb P(\mathbb y_m = y | A^{(m)}; \mathcal S)
\end{align*}\]</div>
<p>Remember that we saw that using Bayes Theorem, we can just rewrite this expression as:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\mathbb P(\mathbb y_m = y | A^{(m)}; \mathcal S) &amp;= \frac{\mathbb P(A^{(m)}, \mathbb y_m = y; \mathcal S)}{\mathbb P(A^{(m)}; \mathcal S)}
\end{align*}\]</div>
<p>But using the expression we just obtained for <span class="math notranslate nohighlight">\(\mathbb P(A^{(m)}, \mathbb y_m = y; \mathcal S)\)</span>, we can write this down as:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\mathbb P(\mathbb y_m = y | A^{(m)}; \mathcal S) &amp;= \frac{\pi_y \prod_{(i, j) \in \mathcal S} (p_{ij}^y)^{a_{ij}^{(m)}} (1 - p_{ij}^y)^{1 - a_{ij}^{(m)}}}{\mathbb P(A^{(m)}; \mathcal S)}
\end{align*}\]</div>
<p>So, what this quantity tells us is the probability that item <span class="math notranslate nohighlight">\(m\)</span> is in class <span class="math notranslate nohighlight">\(y\)</span>, given that we observe that item <span class="math notranslate nohighlight">\(m\)</span> has the network <span class="math notranslate nohighlight">\(A^{(m)}\)</span> with signal subnetwork <span class="math notranslate nohighlight">\(\mathcal S\)</span>! When we have a new piece of data, this is an excellent quantity to compute! The reason for this is that, if we see a new network and want to assign it to a class, we want to choose the class that we think is most reasonable, or most probable. Therefore, given a new network to classify, it is reasonable to just estimate the class of this new network to be the class which is most probable, which is:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \hat y_m &amp;= \text{argmax}_{y \in \left\{1, ..., Y\right\}}\mathbb P(\mathbb y_m = y | A^{(m)}; \mathcal S) \\
    &amp;= \text{argmax}_{y \in \left\{1,..., Y\right\}}\frac{\pi_y \prod_{(i, j) \in \mathcal S} (p_{ij}^y)^{a_{ij}^{(m)}} (1 - p_{ij}^y)^{1 - a_{ij}^{(m)}}}{\mathbb P(A^{(m)}; \mathcal S)}
\end{align*}\]</div>
<p>What this states in words is, we check all possible values that <span class="math notranslate nohighlight">\(y\)</span> could take (1, 2, 3, … all the way to <span class="math notranslate nohighlight">\(Y\)</span>), and compute the probability that the class is <span class="math notranslate nohighlight">\(y\)</span> given the network we observed. Then, we just choose which of the values was most plausible, and return it for our prediction <span class="math notranslate nohighlight">\(\hat y_m\)</span>. But wait! We can simplify this expression even further. Note that the quantity <span class="math notranslate nohighlight">\(\mathbb P(A^{(m)}; \mathcal S)\)</span> has <em>no</em> dependence on the particular class we are checking for a given value of <span class="math notranslate nohighlight">\(y\)</span>. This means that the denominator will be the same for all of the possible values of <span class="math notranslate nohighlight">\(y\)</span>, and therefore won’t impact which of the <span class="math notranslate nohighlight">\(y\)</span>s is the actual maximum. Therefore, we can just drop this term entirely, giving us the quantity that will become the objective function for our classification task:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\hat y_m &amp;= \text{argmax}_{y \in \left\{1,..., Y\right\}}\pi_y \prod_{(i, j) \in \mathcal S} (p_{ij}^y)^{a_{ij}^{(m)}} (1 - p_{ij}^y)^{1 - a_{ij}^{(m)}}
\end{align*}\]</div>
<p>Now what you might be wondering is, we don’t know <span class="math notranslate nohighlight">\(\mathcal S\)</span>, the vector <span class="math notranslate nohighlight">\(\vec \pi\)</span>, nor the probability matrices <span class="math notranslate nohighlight">\(P_1,..., P_Y\)</span>. This is why this is called a “Bayes Plugin” classifier. What we do is we estimate the signal subnetwork <span class="math notranslate nohighlight">\(\mathcal S\)</span> using the approach we outlined above to produce <span class="math notranslate nohighlight">\(\hat{\mathcal S}\)</span>, and then we use the class vector <span class="math notranslate nohighlight">\(\vec y\)</span> that we observed to produce estimates of <span class="math notranslate nohighlight">\(\vec \pi\)</span>, where:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \hat{\pi_y} &amp;= \frac{M_y}{M}
\end{align*}\]</div>
<p>where <span class="math notranslate nohighlight">\(M\)</span> is the total number of networks, and <span class="math notranslate nohighlight">\(M_y\)</span> is the number of networks where <span class="math notranslate nohighlight">\(y_m = y\)</span>. Finally, we compute the estimated probability entries, using:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \hat p_{ij}^y &amp;= \frac{1}{M_y} \sum_{m : y_m = y} a_{ij}^{(m)}
\end{align*}\]</div>
<p>What this means is that, for each edge <span class="math notranslate nohighlight">\((i,j)\)</span> which is in the estimated signal subnetwork <span class="math notranslate nohighlight">\(\hat{\mathcal S}\)</span>, we look at the <span class="math notranslate nohighlight">\(m\)</span>s where the class <span class="math notranslate nohighlight">\(y_m\)</span> is <span class="math notranslate nohighlight">\(y\)</span>, and then we just compute the fraction of the edges which exist across all of the <span class="math notranslate nohighlight">\(M_y\)</span> networks where <span class="math notranslate nohighlight">\(y_m = y\)</span>. Finally, we estimate the class for our new network <span class="math notranslate nohighlight">\(A^{(m)}\)</span> by just “plugging in” these values to the objective function:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \hat y_m &amp;= \text{argmax}_{y \in \left\{1,..., Y\right\}}\hat \pi_y \prod_{(i, j) \in \hat{\mathcal S}} (\hat p_{ij}^y)^{a_{ij}^{(m)}} (1 - \hat p_{ij}^y)^{1 - a_{ij}^{(m)}}
\end{align*}\]</div>
<p>which is the objective function for the Bayes Plugin classifier.</p>
</div>
<div class="section" id="classification-with-bayes-plugin-classifier">
<h3><span class="section-number">10.2.3.2. </span>Classification with Bayes Plugin Classifier<a class="headerlink" href="#classification-with-bayes-plugin-classifier" title="Permalink to this headline">¶</a></h3>
<p>So, how do we actually use the estimated signal subnetwork <span class="math notranslate nohighlight">\(\hat{\mathcal S}\)</span> to classify new points? Quite simply, we can just use sklearn’s <code class="docutils literal notranslate"><span class="pre">BernoulliNB</span></code> from <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>, which is the Naive Bayes classifier for data where the features take values of <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span> (such as our network). We need to reorganize our data a little bit to get it into the format we want. Our estimated signal subnetwork <span class="math notranslate nohighlight">\(\hat{\mathcal S}\)</span> is returned to us by <code class="docutils literal notranslate"><span class="pre">graspologic</span></code> in the format of a <code class="docutils literal notranslate"><span class="pre">[2</span> <span class="pre">x</span> <span class="pre">K]</span></code> matrix, where <span class="math notranslate nohighlight">\(K\)</span> is the number of edges in the signal subnetwork. The first row is the row index of the entry of the signal subnetwork, and the second row is the column index of the entry in the signal subnetwork. We need to coerce this into an <code class="docutils literal notranslate"><span class="pre">[M</span> <span class="pre">x</span> <span class="pre">K]</span></code> matrix which we will call <span class="math notranslate nohighlight">\(D\)</span>, where <span class="math notranslate nohighlight">\(M\)</span> is the total number of networks, and <span class="math notranslate nohighlight">\(K\)</span> is the number of edges in the signal subnetwork. Each entry of this matrix <span class="math notranslate nohighlight">\(d_{mk}\)</span> represents the adjacency value of the <span class="math notranslate nohighlight">\(m^{th}\)</span> individual for the <span class="math notranslate nohighlight">\(k^{th}\)</span> element of the signal subnetwork:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">As</span><span class="p">[</span><span class="n">sgest</span><span class="o">.</span><span class="n">sigsub_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">sgest</span><span class="o">.</span><span class="n">sigsub_</span><span class="p">[</span><span class="mi">1</span><span class="p">],:]</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
</div>
<p>Next, we create a Naive Bayes classifier, and fit the classifier using the class vector <span class="math notranslate nohighlight">\(\vec y\)</span> for all of our samples:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">BernoulliNB</span>

<span class="n">classifier</span> <span class="o">=</span> <span class="n">BernoulliNB</span><span class="p">()</span>
<span class="c1"># fit the classifier using the vector of classes for each sample</span>
<span class="n">classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">yvec</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>BernoulliNB()
</pre></div>
</div>
</div>
</div>
<p>Let’s see how it does! We create <span class="math notranslate nohighlight">\(50\)</span> new networks, which are astronauts or earthlings, and assess the performance using the classification accuracy:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Mtest</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># roll a 2-sided die 100 times, with probability 0.4 of landing on side 1 (astronaut) </span>
<span class="c1"># and 0.6 of landing on side 2 (earthling)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345678</span><span class="p">)</span>
<span class="n">class_countstest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">Mtest</span><span class="p">,</span> <span class="n">pvals</span><span class="o">=</span><span class="p">[</span><span class="n">pi_ast</span><span class="p">,</span> <span class="n">pi_hum</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of individuals who are astronauts: </span><span class="si">{:d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">class_counts</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of individuals who are humans: </span><span class="si">{:d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">class_counts</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

<span class="c1"># create class assignment vector, and randomly reshuffle class labels for each individual</span>
<span class="n">yvectest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">class_countstest</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">class_countstest</span><span class="p">[</span><span class="mi">1</span><span class="p">])])</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345678</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">yvectest</span><span class="p">)</span>

<span class="n">Astest</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">yvectest</span><span class="p">:</span>
    <span class="c1"># sample adjacency matrix for an individual of class y using the probability</span>
    <span class="c1"># matrix for that class</span>
    <span class="n">Astest</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ier</span><span class="p">(</span><span class="n">prob_mtxs</span><span class="p">[</span><span class="n">y</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="c1"># stack the adjacency matrices for each individual such that node i is first dimension,</span>
<span class="c1"># node j is second dimension, and the individual index m is the third dimension</span>
<span class="n">Astest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">Astest</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">datatest</span> <span class="o">=</span> <span class="n">Astest</span><span class="p">[</span><span class="n">sgest</span><span class="o">.</span><span class="n">sigsub_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">sgest</span><span class="o">.</span><span class="n">sigsub_</span><span class="p">[</span><span class="mi">1</span><span class="p">],:]</span><span class="o">.</span><span class="n">T</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">datatest</span><span class="p">)</span>

<span class="c1"># classifier accuracy is the fraction of predictions that are correct</span>
<span class="n">acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">yvectest</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Classifier Accuracy: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of individuals who are astronauts: 40
Number of individuals who are humans: 60
Classifier Accuracy: 0.770
</pre></div>
</div>
</div>
</div>
<p>Which means our classifier is right about <span class="math notranslate nohighlight">\(77\%\)</span> of the time. Not bad!</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./applications/ch10"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="anomaly-detection.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">10.1. </span>Anomaly Detection For Timeseries of Networks</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="significant-vertices.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">10.3. </span>Testing for Significant Vertices</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Joshua Vogelstein, Alex Loftus, and Eric Bridgeford<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>