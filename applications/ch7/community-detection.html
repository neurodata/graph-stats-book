
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>6.1. Community Detection &#8212; Hands-on Network Machine Learning with Scikit-Learn and Graspologic</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="6.2. Testing for Differences between Groups of Edges" href="testing-differences.html" />
    <link rel="prev" title="6. Applications When You Have One Network" href="ch7.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Hands-on Network Machine Learning with Scikit-Learn and Graspologic</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../coverpage.html">
                    Hands-on Network Machine Learning with Scikit-Learn and Graspologic
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/terminology.html">
   Terminology
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch1/ch1.html">
   1. The Network Machine Learning Landscape
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/what-is-a-network.html">
     1.1. What is network machine learning?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/why-study-networks.html">
     1.2. Why do we study networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/types-nml-problems.html">
     1.3. Types of Network Machine Learning Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/examples-of-applications.html">
     1.4. Examples of applications
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/challenges-of-nml.html">
     1.5. Challenges of Network Machine Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch2/ch2.html">
   2. End-to-end Biology Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/big-picture.html">
     2.1. Look at the big picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/get-the-data.html">
     2.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/prepare-the-data.html">
     2.3. Prepare the Data for Network Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/select-and-train.html">
     2.4. Select and Train a Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/fine-tune.html">
     2.5. Fine-Tune your Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/discover-and-visualize.html">
     2.6. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Representations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch4/ch4.html">
   3. Properties of Networks as a Statistical Object
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/matrix-representations.html">
     3.1. Matrix Representations Of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/properties-of-networks.html">
     3.2. Properties of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/network-representations.html">
     3.3. Representations of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/regularization.html">
     3.4. Regularization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch5/ch5.html">
   4. Why Use Statistical Models?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_ER.html">
     4.1. Erdös-Rényi (ER) Random Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_SBM.html">
     4.2. Stochastic Block Models (SBM)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_RDPG.html">
     4.3. Random Dot Product Graphs (RDPG)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_IER.html">
     4.4. Inhomogeneous Erdos Renyi (IER) Random Network Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_SIEM.html">
     4.5. Structured Independent Edge Model (SIEM)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/multi-network-models.html">
     4.6. Multiple Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/models-with-covariates.html">
     4.7. Network Models with Network Covariates
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch6/ch6.html">
   5. Learning Network Representations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/estimating-parameters_mle.html">
     5.1. Estimating Parameters in Network Models via MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/why-embed-networks.html">
     5.2. Why embed networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/spectral-embedding.html">
     5.3. Spectral embedding methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/multigraph-representation-learning.html">
     5.4. Multiple-Network Representation Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/joint-representation-learning.html">
     5.5. Joint Representation Learning
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="ch7.html">
   6. Applications When You Have One Network
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     6.1. Community Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="testing-differences.html">
     6.2. Testing for Differences between Groups of Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="model-selection.html">
     6.3. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="vertex-nomination.html">
     6.4. Single-Network Vertex Nomination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="out-of-sample.html">
     6.5. Out-of-sample Embedding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch8/ch8.html">
   7. Applications for Two Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch8/two-sample-hypothesis.html">
     7.1. Latent Two-Sample Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch8/significant-communities.html">
     7.2. Two-sample hypothesis testing in SBMs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch8/graph-matching-vertex.html">
     7.3. Graph Matching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch8/multiple-vertex-nomination.html">
     7.4. Vertex Nomination For Two Networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch9/ch9.html">
   8. Applications for Many Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch9/anomaly-detection.html">
     8.1. Anomaly Detection For Timeseries of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch9/significant-edges.html">
     8.2. Testing for Significant Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch9/significant-vertices.html">
     8.3. Testing for Significant Vertices
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Next Steps
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../next/ch10/ch10.html">
   9. Where do we go from here?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../next/ch10/random-walk-diffusion-methods.html">
     9.1. Random walk and diffusion-based methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../next/ch10/gnn.html">
     9.2. Graph Neural Networks
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Appendix
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../appendix/ch11/ch11.html">
   10. Representations (Extended)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch11/alt-reps.html">
     10.1. Alternative Network Representations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../appendix/ch12/ch12.html">
   11. Network Model Theory
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch12/background.html">
     11.1. Background
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch12/foundation.html">
     11.2. Foundation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch12/ers.html">
     11.3. Erdös-Rényi (ER) Random Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch12/sbms.html">
     11.4. Stochastic Block Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch12/rdpgs.html">
     11.5. RDPGs and more general network models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../appendix/ch13/ch13.html">
   12. Learning Representations Theory
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch13/mle-theory.html">
     12.1. Maximum Likelihood Estimate Theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch13/spectral-theory.html">
     12.2. Spectral Method Theory
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../appendix/ch14/ch14.html">
   13. Applications (Extended)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch14/hypothesis.html">
     13.1. Hypothesis Testing with coin flips
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch14/unsupervised.html">
     13.2. Unsupervised learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendix/ch14/bayes.html">
     13.3. Bayes Plugin Classifier
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://graspologic.readthedocs.io/en/latest/">
   Graspologic Documentation
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/neurodata/graph-stats-book/master?urlpath=tree/network_machine_learning_in_python/applications/ch7/community-detection.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/neurodata/graph-stats-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/neurodata/graph-stats-book/issues/new?title=Issue%20on%20page%20%2Fapplications/ch7/community-detection.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/neurodata/graph-stats-book/edit/master/network_machine_learning_in_python/applications/ch7/community-detection.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/applications/ch7/community-detection.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stochastic-block-model-with-unknown-communities-when-you-know-the-number-of-communities-k">
   6.1.1. Stochastic Block Model with unknown communities when you know the number of communities
   <span class="math notranslate nohighlight">
    \(K\)
   </span>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#estimating-community-assignments-via-k-means">
     6.1.1.1. Estimating community assignments via
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -means
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluating-your-clustering">
     6.1.1.2. Evaluating your clustering
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#by-remapping-the-labels-you-can-evaluate-the-error-rate">
       6.1.1.2.1. By remapping the labels, you can evaluate the error rate
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#number-of-communities-k-is-not-known">
   6.1.2. Number of communities
   <span class="math notranslate nohighlight">
    \(K\)
   </span>
   is not known
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-the-silhouette-score-to-deduce-an-appropriate-number-of-communities">
     6.1.2.1. Using the silhouette score to deduce an appropriate number of communities
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#community-detection-with-other-types-of-embeddings">
   6.1.3. Community detection with other types of embeddings
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#community-detection-with-other-types-of-clustering-algorithms">
   6.1.4. Community detection with other types of clustering algorithms
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#choosing-number-of-clusters-with-gmm">
     6.1.4.1. Choosing number of clusters with GMM
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   6.1.5. References
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Community Detection</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stochastic-block-model-with-unknown-communities-when-you-know-the-number-of-communities-k">
   6.1.1. Stochastic Block Model with unknown communities when you know the number of communities
   <span class="math notranslate nohighlight">
    \(K\)
   </span>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#estimating-community-assignments-via-k-means">
     6.1.1.1. Estimating community assignments via
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -means
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluating-your-clustering">
     6.1.1.2. Evaluating your clustering
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#by-remapping-the-labels-you-can-evaluate-the-error-rate">
       6.1.1.2.1. By remapping the labels, you can evaluate the error rate
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#number-of-communities-k-is-not-known">
   6.1.2. Number of communities
   <span class="math notranslate nohighlight">
    \(K\)
   </span>
   is not known
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-the-silhouette-score-to-deduce-an-appropriate-number-of-communities">
     6.1.2.1. Using the silhouette score to deduce an appropriate number of communities
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#community-detection-with-other-types-of-embeddings">
   6.1.3. Community detection with other types of embeddings
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#community-detection-with-other-types-of-clustering-algorithms">
   6.1.4. Community detection with other types of clustering algorithms
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#choosing-number-of-clusters-with-gmm">
     6.1.4.1. Choosing number of clusters with GMM
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   6.1.5. References
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="community-detection">
<span id="ch7-comm-detect"></span><h1><span class="section-number">6.1. </span>Community Detection<a class="headerlink" href="#community-detection" title="Permalink to this headline">#</a></h1>
<p>In <a class="reference internal" href="../../representations/ch6/estimating-parameters_mle.html#ch6-mle"><span class="std std-numref">Section 5.1</span></a> you learned how to estimate the parameters for an SBM via Maximum Likelihood Estimation (MLE). Unfortunately, we have skipped a relatively fundamental problem with SBM parameter estimation. You will notice that everything we have covered about the SBM to date assumes that you the assignments to one of <span class="math notranslate nohighlight">\(K\)</span> possible communities for each node, which is given by the node assignment variable <span class="math notranslate nohighlight">\(z_i\)</span> for each node in the network. Why is this problematic? Well, quite simply, when you are learning about <em>many</em> different networks you might come across, you might not actually <em>observe</em> the communities of each node.</p>
<p>Consider, for instance, the school example you have worked extensively with. In the context of the SBM, it makes sense to guess that two individuals will have a higher chaance of being friends if they attend the same school than if they did not go to the same school. Remember, when you knew what school each student was from and could <em>order</em> the students by school ahead of time, the network looked like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">sbm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">ns</span> <span class="o">=</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">]</span>  <span class="c1"># network with 100 nodes</span>
<span class="n">B</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]]</span>  <span class="c1"># block matrix</span>

<span class="c1"># sample a single simple adjacency matrix from SBM(z, B)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">sbm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">ns</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">B</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">zs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">draw_multiplot</span><span class="p">,</span> <span class="n">cmaps</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">draw_multiplot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">zs</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$SBM_n(z, B)$ Simulation, nodes ordered by school&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/community-detection_3_0.png" src="../../_images/community-detection_3_0.png" />
</div>
</div>
<p>The block structure is <em>completely obvious</em>, and it seems like you could almost just guess which nodes are from which communities by looking at the adjacency matrix (with the proper ordering). Ant therein lies the issue: if you did not know which school each student was from, you would have <em>no way</em> of actually using the technique you described in the preceding chapter to estimate parameters for your SBM. If your nodes were just randomly ordered, you might see something instead like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># generate a reordering of the n nodes</span>
<span class="n">vtx_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ns</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ns</span><span class="p">),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">Aperm</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="nb">tuple</span><span class="p">([</span><span class="n">vtx_perm</span><span class="p">])]</span> <span class="p">[:,</span><span class="n">vtx_perm</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">draw_multiplot</span><span class="p">(</span><span class="n">Aperm</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$SBM_n(z, B)$ Simulation, random node order&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/community-detection_6_0.png" src="../../_images/community-detection_6_0.png" />
</div>
</div>
<p>It is extremely unclear which nodes are in which community, because there is no immediate block structure to the network. So, what <em>can</em> you do?</p>
<p>What you will do is use a clever technique we discussed in <a class="reference internal" href="../../representations/ch6/spectral-embedding.html#ch6-spectral"><span class="std std-numref">Section 5.3</span></a>, called a <em>spectral embedding</em>, to learn not only about each edge, but to <em>learn about each node in relation to all of the other nodes</em>. What do we mean by this? What we mean is that, while looking at a single edge in your network, you only have two possible choices: the edge exists or it does not exist. However, if you instead consider nodes in <em>relation</em> to one another, you can start to deduce patterns about how your nodes might be organized in the community sense. While seeing that two students Bill and Stephanie were friends will not tell us whether Bill and Stephanie were in the same school, if you knew that Bill and Stephanie also shared many other friends (such as Denise, Albert, and Kwan), and those friends also tended to be friends, that piece of information might tell us that they all might happen to be school mates.</p>
<p>The embedding technique you will tend to employ, the <em>spectral embedding</em>, allows you to pick up on these <em>community</em> sorts of tendencies. When we call a set of nodes a <strong>community</strong> in the context of a network, what we mean is that these nodes are <em>stochastically equivalent</em>. What this means is that this particular group of nodes will tend to have similar <em>other</em> nodes that they are connected to. The spectral embeddings will help us to identify these communities of nodes, and hopefully, when you review the communities of nodes you learn, you will be able to derive some sort of insight as to what, exactly, these communities are. For instance, in your school example, ideally, you might pick up on two communities of nodes, one for each school. The process of learning community assignments for nodes in a network is known as <strong>community detection</strong>. This problem has been well-established in the network science literature, such as <code class="docutils literal notranslate"><span class="pre">Amini2012Jul</span></code>, <span id="id1">[<a class="reference internal" href="../../representations/ch6/spectral-embedding.html#id27" title="Avanti Athreya, Donniell E. Fishkind, Minh Tang, Carey E. Priebe, Youngser Park, Joshua T. Vogelstein, Keith Levin, Vince Lyzinski, and Yichen Qin. Statistical inference on random dot product graphs: a survey. J. Mach. Learn. Res., 18(1):8393–8484, January 2017. doi:10.5555/3122009.3242083.">2</a>]</span>, <span id="id2">[<a class="reference internal" href="../../representations/ch4/network-representations.html#id39" title="M. E. J. Newman. Modularity and community structure in networks. Proc. Natl. Acad. Sci. U.S.A., 103(23):8577–8582, June 2006. doi:10.1073/pnas.0601602103.">1</a>]</span>, and <span id="id3">[]</span>, to name a few.</p>
<section id="stochastic-block-model-with-unknown-communities-when-you-know-the-number-of-communities-k">
<span id="ch7-comm-detect-known"></span><h2><span class="section-number">6.1.1. </span>Stochastic Block Model with unknown communities when you know the number of communities <span class="math notranslate nohighlight">\(K\)</span><a class="headerlink" href="#stochastic-block-model-with-unknown-communities-when-you-know-the-number-of-communities-k" title="Permalink to this headline">#</a></h2>
<p>When you know the number of communities (even if you don’t know which community each node is in), the procedure for fitting a Stochastic Block Model to a network is relatively straightforward. Let’s consider a similar example to the scenario we evaluated in the lead-in to this section, but with <span class="math notranslate nohighlight">\(3\)</span> communities instead of <span class="math notranslate nohighlight">\(2\)</span>. You will have a block matrix given by:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    B &amp;= \begin{bmatrix}
        0.6 &amp; 0.2 &amp; 0.2 \\
        0.2 &amp; 0.6 &amp; 0.2 \\
        0.2 &amp; 0.2 &amp; 0.6
    \end{bmatrix}
\end{align*}\]</div>
<p>Which is a Stochastic block model in which the within-community edge probability is <span class="math notranslate nohighlight">\(0.6\)</span>, and exceeds the between-community edge probability of <span class="math notranslate nohighlight">\(0.2\)</span>. You will produce a matrix with <span class="math notranslate nohighlight">\(120\)</span> nodes in total.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">sbm</span>

<span class="n">ns</span> <span class="o">=</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">30</span><span class="p">]</span>
<span class="n">B</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]]</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">sbm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">ns</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">B</span><span class="p">)</span>

<span class="c1"># the true community labels</span>
<span class="n">z</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">ns</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ns</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ns</span><span class="p">[</span><span class="mi">2</span><span class="p">])]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">draw_multiplot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">z</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;A, Simulated $SBM_</span><span class="si">{100}</span><span class="s2">( </span><span class="se">\\</span><span class="s2">vec z, B)$&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/community-detection_9_0.png" src="../../_images/community-detection_9_0.png" />
</div>
</div>
<p>Remember, however, that you do not <em>actually</em> know the community labels of each node in <span class="math notranslate nohighlight">\(A\)</span>, so this problem is a little more difficult than it might seem. If you reordered the nodes, the community each node is assigned to would not be as visually obvious as it is here in this example, as you saw in the  lead-in to this section.</p>
<p>Your goal here, then, is to determine this hidden, or <em>latent</em>, community assignment vector, so that you can learn things about the SBM that you are studying.</p>
<p>You begin by first embedding <span class="math notranslate nohighlight">\(A\)</span> to estimate a latent position matrix. Remember that to deduce whether there is any latent structure, you take a look at the latent position matrix using a pairplot, like we learned about in <span class="xref myst">Chapter 6</span>. When you know that the number of communities that you are looking for is <span class="math notranslate nohighlight">\(K\)</span>, you will embed into that many dimensions. For instance, here we assume that we know that there are <span class="math notranslate nohighlight">\(3\)</span> communities, so we set <code class="docutils literal notranslate"><span class="pre">n_components=3</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.embed</span> <span class="kn">import</span> <span class="n">AdjacencySpectralEmbed</span>

<span class="c1"># adjacency spectral embedding when we look for 3 communities</span>
<span class="n">ase</span> <span class="o">=</span> <span class="n">AdjacencySpectralEmbed</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">Xhat</span> <span class="o">=</span> <span class="n">ase</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.plot</span> <span class="kn">import</span> <span class="n">pairplot</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">pairplot</span><span class="p">(</span><span class="n">Xhat</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Pairplot of embedding of $A$&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/community-detection_12_0.png" src="../../_images/community-detection_12_0.png" />
</div>
</div>
<p>You have some <em>really</em> prominent latent structure here, which is evident from the tightly clustered blobs you have in your pairplot. To see just how well-separated these blobs are, let’s cheat for a second and look at the true labels of each of the points:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">pairplot</span><span class="p">(</span><span class="n">Xhat</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">z</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Pairplot of embedding of $A$&quot;</span><span class="p">,</span> <span class="n">legend_name</span><span class="o">=</span><span class="s2">&quot;Community (Unknown)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/community-detection_14_0.png" src="../../_images/community-detection_14_0.png" />
</div>
</div>
<p>So from what we can see, it’s pretty clear that these extremely tight “blobs” in your dataset correspond <em>exactly</em> to the true community labels of the nodes in your network. So, what you need is a technique which can take a latent position matrix, not know <em>anything</em> about these blobs, and and provide us with a way to learn which points correspond to which blob. For this, we turn to unsupervised learning; particularly the <span class="math notranslate nohighlight">\(k\)</span>-means algorithm.</p>
<p>In this next section, we will assume that you are familiar with several concepts from <em>unsupervised learning</em>, including the <span class="math notranslate nohighlight">\(k\)</span>-means algorithm, the Adjusted Rand Index (ARI), confusion matrices, and the silhouette score. If you aren’t already familiar or want a quick refresher, check out the unsupervised learning basics section of the appendix in <a class="reference internal" href="../../appendix/ch14/unsupervised.html#ch14-unsup"><span class="std std-numref">Section 13.2</span></a>, which covers the required background knowledge for these concepts. Briefly, we will use <span class="math notranslate nohighlight">\(k\)</span>-means to <em>estimate</em> the latent community assignment vector, the ARI and confusion matrices to study the homogeneity of the resulting latent community estimates, and the silhouette score to evaluate the latent community estimates.</p>
<section id="estimating-community-assignments-via-k-means">
<h3><span class="section-number">6.1.1.1. </span>Estimating community assignments via <span class="math notranslate nohighlight">\(k\)</span>-means<a class="headerlink" href="#estimating-community-assignments-via-k-means" title="Permalink to this headline">#</a></h3>
<p>First, we use <span class="math notranslate nohighlight">\(k\)</span>-means to estimate the latent community assignment vector, which we will denote with <span class="math notranslate nohighlight">\(\hat{\vec z}\)</span>. The reason that we have the <span class="math notranslate nohighlight">\(\vec\cdot\)</span> symbol is because this is a vector (it has <span class="math notranslate nohighlight">\(n\)</span> elements), and the result we put the <span class="math notranslate nohighlight">\(\hat \cdot\)</span> symbol on top of that is it is <em>also</em> an estimate of the true community assignment vector, <span class="math notranslate nohighlight">\(\vec z\)</span>, for the SBM. We can produce the estimate of the community assignment vector using <code class="docutils literal notranslate"><span class="pre">KMeans()</span></code> from <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="n">labels_kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">Xhat</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="evaluating-your-clustering">
<span id="ch7-comm-detect-eval"></span><h3><span class="section-number">6.1.1.2. </span>Evaluating your clustering<a class="headerlink" href="#evaluating-your-clustering" title="Permalink to this headline">#</a></h3>
<p>In this instance, you have your true community labels already known, because this is just a simulation. When you know your true node labels ahead of time, you can do some special evaluations that take advantage of the fact that you have the true labels. The first of these is to study the confusion matrix, which you can produce with <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>’s <code class="docutils literal notranslate"><span class="pre">confusion_matrix()</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="c1"># compute the confusion matrix between the true labels z</span>
<span class="c1"># and the predicted labels labels_kmeans</span>
<span class="n">cf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">labels_kmeans</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cf_matrix</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmaps</span><span class="p">[</span><span class="s2">&quot;sequential&quot;</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Confusion matrix&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;True Label (School)&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/community-detection_20_0.png" src="../../_images/community-detection_20_0.png" />
</div>
</div>
<p>When you have a good clustering that aligns well with your true labels, you will see that the predictions will tend to be <em>homogeneous</em>: a particular true label will correspond to a particular predicted label, and vice-versa. You can evaluate this <em>homogeneity</em> (how well, in general, one true label corresponds to one predicted label, and vice-versa) using the Adjusted Rand Index (ARI), where a score of closer to <span class="math notranslate nohighlight">\(1\)</span> indicates that the true and predicted labels are perfectly homogeneous (one true label corresponds to exactly one predicted label):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">adjusted_rand_score</span>

<span class="n">ari_kmeans</span> <span class="o">=</span> <span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">labels_kmeans</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ari_kmeans</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0
</pre></div>
</div>
</div>
</div>
<section id="by-remapping-the-labels-you-can-evaluate-the-error-rate">
<h4><span class="section-number">6.1.1.2.1. </span>By remapping the labels, you can evaluate the error rate<a class="headerlink" href="#by-remapping-the-labels-you-can-evaluate-the-error-rate" title="Permalink to this headline">#</a></h4>
<p>Looking back at the confusion matrix:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cf_matrix</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmaps</span><span class="p">[</span><span class="s2">&quot;sequential&quot;</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Confusion matrix&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;True Label&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/community-detection_24_0.png" src="../../_images/community-detection_24_0.png" />
</div>
</div>
<p>It seems pretty clear that the label correspondance between the true labels and predicted labels is as follows:</p>
<ol class="simple">
<li><p>Nodes which have a true label of <span class="math notranslate nohighlight">\(0\)</span> correspond to a predicted label of <span class="math notranslate nohighlight">\(0\)</span>,</p></li>
<li><p>Nodes which have a true label of <span class="math notranslate nohighlight">\(1\)</span> correspond to a predicted label of <span class="math notranslate nohighlight">\(2\)</span>,</p></li>
<li><p>Nodes which have a true label of <span class="math notranslate nohighlight">\(2\)</span> correspond to a predicted label of <span class="math notranslate nohighlight">\(1\)</span>.</p></li>
</ol>
<p>This is because all of the nodes which have a true label of <span class="math notranslate nohighlight">\(0\)</span> are assigned a predicted label of <span class="math notranslate nohighlight">\(0\)</span>, all of the nodes with a true label of <span class="math notranslate nohighlight">\(1\)</span> are assigned a predicted label of <span class="math notranslate nohighlight">\(2\)</span>, and all of the nodes with a true label of <span class="math notranslate nohighlight">\(2\)</span> have a predicted label of <span class="math notranslate nohighlight">\(1\)</span>. But when the results aren’t perfect, this is a little bit harder to do, and involves a bit of background in optimization theory, which is outside of the scope of this book. Fortunately, <code class="docutils literal notranslate"><span class="pre">graspologic</span></code> makes this easy for us, with the <code class="docutils literal notranslate"><span class="pre">remap_labels()</span></code> function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.utils</span> <span class="kn">import</span> <span class="n">remap_labels</span>

<span class="n">labels_kmeans_remap</span> <span class="o">=</span> <span class="n">remap_labels</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">labels_kmeans</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You can use these remapped labels to understand when <code class="docutils literal notranslate"><span class="pre">KMeans</span></code> is, or is not, producing reasonable labels for your investigation. You begin by first looking at a pairs plot, which now will color the points by their assigned community:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">pairplot</span><span class="p">(</span><span class="n">Xhat</span><span class="p">,</span>
         <span class="n">labels</span><span class="o">=</span><span class="n">labels_kmeans_remap</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;KMeans on embedding, ARI: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">ari_kmeans</span><span class="p">)[:</span><span class="mi">5</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
         <span class="n">legend_name</span><span class="o">=</span><span class="s1">&#39;Predicted label (remapped)&#39;</span><span class="p">,</span>
         <span class="n">height</span><span class="o">=</span><span class="mf">3.5</span><span class="p">,</span>
         <span class="n">palette</span><span class="o">=</span><span class="s1">&#39;muted&#39;</span><span class="p">,);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/community-detection_28_0.png" src="../../_images/community-detection_28_0.png" />
</div>
</div>
<p>The final utility of the pairs plot is that you can investigate which points, if any, the clustering technique is getting wrong. You can do this by looking at the classification error of the nodes to each community:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">error</span> <span class="o">=</span> <span class="n">z</span> <span class="o">-</span> <span class="n">labels_kmeans_remap</span>  <span class="c1"># compute which assigned labels from labels_kmeans_remap differ from the true labels z</span>
<span class="n">error</span> <span class="o">=</span> <span class="n">error</span> <span class="o">!=</span> <span class="mi">0</span>  <span class="c1"># if the difference between the community labels is non-zero, an error has occurred</span>
<span class="n">er_rt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>  <span class="c1"># error rate is the frequency of making an error</span>

<span class="n">palette</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Correct Pred.&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.7</span><span class="p">,</span><span class="mf">0.2</span><span class="p">),</span>
           <span class="s1">&#39;Wrong Pred.&#39;</span><span class="p">:(</span><span class="mf">0.8</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)}</span>

<span class="n">error_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">*</span><span class="p">[</span><span class="s1">&#39;Correct Pred.&#39;</span><span class="p">])</span>  <span class="c1"># initialize numpy array for each node</span>
<span class="n">error_label</span><span class="p">[</span><span class="n">error</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;Wrong Pred.&#39;</span>  <span class="c1"># add label &#39;Wrong&#39; for each error that is made</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pairplot</span><span class="p">(</span><span class="n">Xhat</span><span class="p">,</span>
         <span class="n">labels</span><span class="o">=</span><span class="n">error_label</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Error from KMeans, Error rate: </span><span class="si">{:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">er_rt</span><span class="p">),</span>
         <span class="n">legend_name</span><span class="o">=</span><span class="s1">&#39;Error label&#39;</span><span class="p">,</span>
         <span class="n">height</span><span class="o">=</span><span class="mf">3.5</span><span class="p">,</span>
         <span class="n">palette</span><span class="o">=</span><span class="n">palette</span><span class="p">,);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/community-detection_31_0.png" src="../../_images/community-detection_31_0.png" />
</div>
</div>
<p>Great! Our classification has not made any errors.</p>
<p>To learn about the block matrix <span class="math notranslate nohighlight">\(B\)</span>, you can now use the <code class="docutils literal notranslate"><span class="pre">SBMEstimator</span></code> class, with your predicted labels:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.models</span> <span class="kn">import</span> <span class="n">SBMEstimator</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SBMEstimator</span><span class="p">(</span><span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">labels_kmeans_remap</span><span class="p">)</span>
<span class="n">Bhat</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">block_p_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">heatmap</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">mtxs</span> <span class="o">=</span> <span class="p">[</span><span class="n">Bhat</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">B</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">Bhat</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">B</span><span class="p">))]</span>
<span class="n">titles</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;True $B_</span><span class="si">{SBM}</span><span class="s2">$&quot;</span><span class="p">,</span> <span class="s2">&quot; Prediction $\hat B_</span><span class="si">{SBM}</span><span class="s2">$&quot;</span><span class="p">,</span> <span class="s2">&quot;$|\hat B_</span><span class="si">{SBM}</span><span class="s2"> - B_</span><span class="si">{SBM}</span><span class="s2">|$&quot;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axs</span><span class="o">.</span><span class="n">flat</span><span class="p">):</span>
    <span class="n">heatmap</span><span class="p">(</span><span class="n">mtxs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">font_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
            <span class="n">title</span><span class="o">=</span><span class="n">titles</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/community-detection_35_0.png" src="../../_images/community-detection_35_0.png" />
</div>
</div>
<p>Which appears to be relatively close to the true block matrix.</p>
<div class="admonition-recap-of-inference-for-stochastic-block-model-with-known-number-of-communities admonition">
<p class="admonition-title">Recap of inference for Stochastic Block Model with known number of communities</p>
<ol class="simple">
<li><p>You learned that the adjacency spectral embedding is a key algorithm for making sense of networks which are realizations of SBM random networks. The estimates of latent positions produced by ASE are critical for learning community assignments.</p></li>
<li><p>You learned that unsuperised learning (such as K-means) allows us to ues the estimated latent positions to learn community assignments for each node in your network.</p></li>
<li><p>You can use <code class="docutils literal notranslate"><span class="pre">remap_labels</span></code> to align predicted labels with true labels, if true labels are known. This is useful for benchmarking techniques on networks with known community labels.</p></li>
<li><p>You evaluate the quality of unsupervised learning by plotting the predicted node labels and (if you know the true labels) the errorfully classified nodes. The ARI and the error rate summarize how effective your unsupervised learning techniques performed.</p></li>
</ol>
</div>
</section>
</section>
</section>
<section id="number-of-communities-k-is-not-known">
<span id="ch7-comm-detect-unknown"></span><h2><span class="section-number">6.1.2. </span>Number of communities <span class="math notranslate nohighlight">\(K\)</span> is not known<a class="headerlink" href="#number-of-communities-k-is-not-known" title="Permalink to this headline">#</a></h2>
<p>In real data, you almost never have the beautiful canonical modular structure obvious to yourom a Stochastic Block Model. This means that it is <em>extremely infrequently</em> going to be the case that you know exactly how you should set the number of communities, <span class="math notranslate nohighlight">\(K\)</span>, ahead of time.</p>
<p>Let’s first remember back to the single network models section, when you took a Stochastic block model with obvious community structure, and let’s see what happens when you just move the nodes of the adjacency matrix around. You begin with a similar adjacency matrix to <span class="math notranslate nohighlight">\(A\)</span> given above, for the <span class="math notranslate nohighlight">\(3\)</span>-community SBM example, but with the within and between-community edge probabilities a bit closer together so that you can see what happens when you experience errors. The communities are still quite apparent from the adjaceny matrix:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">B</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]]</span>
<span class="n">ns</span> <span class="o">=</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">30</span><span class="p">]</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">sbm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">ns</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">B</span><span class="p">)</span>

<span class="c1"># the true community labels</span>
<span class="n">z</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">ns</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ns</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ns</span><span class="p">[</span><span class="mi">2</span><span class="p">])]</span>
<span class="n">draw_multiplot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">z</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Simulated SBM($\pi$, B)&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/community-detection_37_0.png" src="../../_images/community-detection_37_0.png" />
</div>
</div>
<p>Next, you permute the nodes around to reorder the realized adjacency matrix:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># generate a reordering of the n nodes</span>
<span class="n">vtx_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">A_permuted</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="nb">tuple</span><span class="p">([</span><span class="n">vtx_perm</span><span class="p">])]</span> <span class="p">[:,</span><span class="n">vtx_perm</span><span class="p">]</span>
<span class="n">z_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">z</span><span class="p">)[</span><span class="n">vtx_perm</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">heatmap</span> <span class="k">as</span> <span class="n">hm_code</span> 
<span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">draw_layout_plot</span> <span class="k">as</span> <span class="n">lp_code</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># heatmap</span>
<span class="n">hm</span> <span class="o">=</span> <span class="n">hm_code</span><span class="p">(</span>
    <span class="n">A_permuted</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;sequential&quot;</span><span class="p">,</span>
    <span class="n">xticklabels</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">yticklabels</span><span class="o">=</span><span class="mi">10</span>
<span class="p">)</span>

<span class="c1"># layout plot</span>
<span class="n">lp_code</span><span class="p">(</span><span class="n">A_permuted</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">pos</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">z_perm</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;qualitative&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Simulated $SBM(</span><span class="se">\\</span><span class="s2">vec z, B)$, reordered vertices&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.1</span><span class="p">)</span>

<span class="n">fig</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/community-detection_40_0.png" src="../../_images/community-detection_40_0.png" />
</div>
</div>
<p>You only get to see the adjacency matrix in the <em>left</em> panel; the panel in the <em>right</em> is constructed by using the true labels (which you do <em>not</em> have!). This means that you proceed for statistical inference about the random network underlying your realized network using <em>only</em> the heatmap you have at left. It is not immediately obvious that this is the realization of a random network which is an SBM with <span class="math notranslate nohighlight">\(3\)</span> communities.</p>
<p>Our procedure is <em>very</em> similar to what you did previously <a class="reference internal" href="#ch7-comm-detect-known"><span class="std std-ref">when the number of communities was known</span></a>. You again embed, but this time since you don’t know the number of communities you are looking for, you using the “elbow picking” technique to select the dimensionality:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ase_perm</span> <span class="o">=</span> <span class="n">AdjacencySpectralEmbed</span><span class="p">()</span>  <span class="c1"># adjacency spectral embedding, with optimal number of latent dimensions selected using elbow picking</span>
<span class="n">Xhat_permuted</span> <span class="o">=</span> <span class="n">ase_perm</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">A_permuted</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You examine the pairs plot, <em>just</em> like in the section on <a class="reference external" href="#link?">pairs plots</a>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">pairplot</span><span class="p">(</span><span class="n">Xhat_permuted</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;SBM adjacency spectral embedding&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/community-detection_44_0.png" src="../../_images/community-detection_44_0.png" />
</div>
</div>
<p>You can still see that there is some level of latent community structure apparent in the pairs plot, as you can see some “blob” separation.</p>
<p>Next, you have the biggest difference with the approach you took previously. Since you do <em>not</em> know the optimal number of clusters <span class="math notranslate nohighlight">\(K\)</span> <em>nor</em> the true community assignments, you must choose an unsupervised clustering technique which allows us to <em>compare</em> clusterings with different choices of cluster counts. Fortunately, this is pretty easy for us to do, too, using a simple statistic known as the <a class="reference internal" href="../../appendix/ch14/unsupervised.html#ch14-unsup-eval-silhouette"><span class="std std-ref">silhouette score</span></a>. If you don’t know what the silhouette score is, you can read about it in the appendix.</p>
<section id="using-the-silhouette-score-to-deduce-an-appropriate-number-of-communities">
<h3><span class="section-number">6.1.2.1. </span>Using the silhouette score to deduce an appropriate number of communities<a class="headerlink" href="#using-the-silhouette-score-to-deduce-an-appropriate-number-of-communities" title="Permalink to this headline">#</a></h3>
<p>Now that you have the Silhouette score, deducing an appropriate number of communities is pretty easy. You choose a range of clusters that you think might be appropriate for your network. Let’s say, for instance, you think there might be as many as <span class="math notranslate nohighlight">\(10\)</span> clusters in your dataset. You perform a clustering using unsupervised learning for all possible numbers of clusters, from <span class="math notranslate nohighlight">\(2\)</span> all the way up to the maximum number of clusters you think could be reasonable. Then, you compute the silhouette score for this number of clusters. Finally, you choose the number of clusters which has the highest Silhouette score. Let’s see how to do this, using <code class="docutils literal notranslate"><span class="pre">graspologic</span></code>’s <code class="docutils literal notranslate"><span class="pre">KMeansCluster()</span></code> function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.cluster</span> <span class="kn">import</span> <span class="n">KMeansCluster</span>

<span class="n">km_clust</span> <span class="o">=</span> <span class="n">KMeansCluster</span><span class="p">(</span><span class="n">max_clusters</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span>
<span class="n">km_clust</span> <span class="o">=</span> <span class="n">km_clust</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xhat_permuted</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Next, you visualize the Silhouette Score as a function of the number of clusters:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">DataFrame</span> <span class="k">as</span> <span class="n">df</span>

<span class="n">nclusters</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>  <span class="c1"># graspologic nclusters goes from 2 to max_clusters</span>
<span class="n">silhouette</span> <span class="o">=</span> <span class="n">km_clust</span><span class="o">.</span><span class="n">silhouette_</span> <span class="c1"># obtain the respective silhouette</span>

<span class="n">ss_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">({</span><span class="s2">&quot;Number of Clusters&quot;</span><span class="p">:</span> <span class="n">nclusters</span><span class="p">,</span> <span class="s2">&quot;Silhouette Score&quot;</span><span class="p">:</span> <span class="n">silhouette</span><span class="p">})</span>  <span class="c1"># place into pandas dataframe</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">ss_df</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;Number of Clusters&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Silhouette Score&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Silhouette Analysis of KMeans Clusterings&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/community-detection_49_0.png" src="../../_images/community-detection_49_0.png" />
</div>
</div>
<p>As you can see, Silhouette analysis has indicated the best number of clusters as <span class="math notranslate nohighlight">\(3\)</span> (which, is indeed, <em>correct</em> since we are performing a simulation where we know the right answer). We can get the labels produced by <span class="math notranslate nohighlight">\(k\)</span>-means using automatic number of clusters selection as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">labels_autokmeans</span> <span class="o">=</span> <span class="n">km_clust</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">Xhat_permuted</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As an exercise, you should go through the <a class="reference internal" href="#ch7-comm-detect-eval"><span class="std std-ref">preceding section on evaluation</span></a>, and recompute all the diagnostics we did last time for determining whether our predictions were reasonable. You will do this by comparing the true permuted labels <code class="docutils literal notranslate"><span class="pre">z</span></code> to the predicted labels on the permuted nodes, <code class="docutils literal notranslate"><span class="pre">labels_autokmeans</span></code>.</p>
</section>
</section>
<section id="community-detection-with-other-types-of-embeddings">
<h2><span class="section-number">6.1.3. </span>Community detection with other types of embeddings<a class="headerlink" href="#community-detection-with-other-types-of-embeddings" title="Permalink to this headline">#</a></h2>
<p>There are a number of ways to take a network and produce an embedding for a network. We have covered ASE and LSE so far in this book, but in the conclusion of this text, you will learn about a few new ones briefly, including GNNs and <code class="docutils literal notranslate"><span class="pre">node2vec()</span></code>. These techniques (and many others) can be used, often interchangeably, with <code class="docutils literal notranslate"><span class="pre">ASE</span></code> as we discussed above to produce similar predicted community assignments for your network, or different depending on the parameters chosen for the embedding technique and the topology of the network.</p>
</section>
<section id="community-detection-with-other-types-of-clustering-algorithms">
<h2><span class="section-number">6.1.4. </span>Community detection with other types of clustering algorithms<a class="headerlink" href="#community-detection-with-other-types-of-clustering-algorithms" title="Permalink to this headline">#</a></h2>
<p>Similarly, there is no restriction to community detection with using <span class="math notranslate nohighlight">\(k\)</span>-means specifically. In fact, for a lot of reasons, the <span class="math notranslate nohighlight">\(k\)</span>-means algorithm might not even be the most sensible approach to go with.</p>
<p>In this next section, we’ll cover a slight augmentation of the SBM, called the Degree-Corrected SBM (DCSBM), wherein nodes are still grouped into communities, but each node can have an augmented node degree. While the block matrix stays similar overall, the individual edge probabilities are:</p>
<div class="math notranslate nohighlight">
\[    p_{ij} = \theta_i \theta_j b_{z_i z_i}\]</div>
<p>Where <span class="math notranslate nohighlight">\(\theta_i\)</span> is a scaling factor for the probabilities of student <span class="math notranslate nohighlight">\(i\)</span>, and increases (or decreases) the probability that student <span class="math notranslate nohighlight">\(i\)</span> is friends with other students (in general). This can be conceptualized intuitively as the student being more popular, and therefore more likely to be friends with people on accord of their popularity in general.</p>
<p>Let’s take a look at a simulated example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">rdpg</span>

<span class="k">def</span> <span class="nf">ohe</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
    <span class="n">K</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">T</span><span class="p">))</span>
    <span class="n">ohe_dat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">K</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
        <span class="n">ohe_dat</span><span class="p">[:,</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">T</span> <span class="o">==</span> <span class="n">t</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ohe_dat</span>

<span class="n">ns</span> <span class="o">=</span> <span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">60</span><span class="p">]</span>
<span class="c1"># strategy for sampling a DCSBM</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">ns</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">ns</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">ns</span><span class="p">[</span><span class="mi">2</span><span class="p">])))</span>
<span class="n">B</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]]</span>
<span class="n">z</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ns</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ns</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ns</span><span class="p">[</span><span class="mi">2</span><span class="p">])]</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">ohe</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
<span class="n">U</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">Vt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="n">Bsqrt</span> <span class="o">=</span> <span class="n">U</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span> <span class="o">@</span> <span class="n">Z</span> <span class="o">@</span> <span class="n">Bsqrt</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">rdpg</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">P_dcsbm</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">X</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">rdpg</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">z</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend_</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Community (Unknown)&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;True Latent Positions&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Latent dimension 1&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Latent dimension 2&quot;</span><span class="p">)</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">P_dcsbm</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">z</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Probability matrix, DCSBM&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">z</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Sample of DCSBM&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/community-detection_55_0.png" src="../../_images/community-detection_55_0.png" />
</div>
</div>
<p>As you can see, the probability matrix is no longer perfectly modular like it would be for an SBM, and in fact, the nodes have an extremely “erratic” looking structure in the probability matrix. However, there is still some fairly clear modularity, which we would hope that our community detection approach might pick up. Let’s see what a spectral embedding looks like for our network sample:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Xhat</span> <span class="o">=</span> <span class="n">AdjacencySpectralEmbed</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">pairplot</span><span class="p">(</span><span class="n">Xhat</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">z</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Estimate of latent positions&quot;</span><span class="p">,</span> <span class="n">legend_name</span><span class="o">=</span><span class="s2">&quot;Community (Unknown)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/community-detection_58_0.png" src="../../_images/community-detection_58_0.png" />
</div>
</div>
<p>The nodes still look pretty well-separated within-community in the estimates of the latent positions, which is good news since this means our clustering technique should be able to pick this up, right?</p>
<p>The answer is: it <em>depends</em>. Unfortunately, <span class="math notranslate nohighlight">\(k\)</span>-means tends to perform unideal in these situations; that is, when the cluster “shapes” are not totally spherical. You’ll notice, in particular, in the figure above that the clusters look a bit more <em>elliptical</em> in shape than they do like round balls. Let’s take a look at how <span class="math notranslate nohighlight">\(k\)</span>-means does, by performing a <span class="math notranslate nohighlight">\(k\)</span>-means clustering, remapping the labels produced by the clustering, and then looking at the error rate and resulting error pairplot for <span class="math notranslate nohighlight">\(k\)</span>-means:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># predict with k-means</span>
<span class="n">labels_kmeans_erratic</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">Xhat</span><span class="p">)</span>
<span class="c1"># remap the labels</span>
<span class="n">labels_kmeans_erratic_remap</span> <span class="o">=</span> <span class="n">remap_labels</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">labels_kmeans_erratic</span><span class="p">)</span>
<span class="c1"># compute error rate</span>
<span class="n">error</span> <span class="o">=</span> <span class="n">z</span> <span class="o">-</span> <span class="n">labels_kmeans_erratic_remap</span>  <span class="c1"># compute which assigned labels from labels_kmeans_remap differ from the true labels z</span>
<span class="n">error</span> <span class="o">=</span> <span class="n">error</span> <span class="o">!=</span> <span class="mi">0</span>  <span class="c1"># if the difference between the community labels is non-zero, an error has occurred</span>
<span class="n">er_rt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>  <span class="c1"># error rate is the frequency of making an error</span>

<span class="n">palette</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Correct Pred.&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.7</span><span class="p">,</span><span class="mf">0.2</span><span class="p">),</span>
           <span class="s1">&#39;Wrong Pred.&#39;</span><span class="p">:(</span><span class="mf">0.8</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)}</span>

<span class="n">error_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">*</span><span class="p">[</span><span class="s1">&#39;Correct Pred.&#39;</span><span class="p">])</span>  <span class="c1"># initialize numpy array for each node</span>
<span class="n">error_label</span><span class="p">[</span><span class="n">error</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;Wrong Pred.&#39;</span>  <span class="c1"># add label &#39;Wrong&#39; for each error that is made</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">pairplot</span><span class="p">(</span><span class="n">Xhat</span><span class="p">,</span>
         <span class="n">labels</span><span class="o">=</span><span class="n">error_label</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Error from KMeans, Error rate: </span><span class="si">{:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">er_rt</span><span class="p">),</span>
         <span class="n">legend_name</span><span class="o">=</span><span class="s1">&#39;Error label&#39;</span><span class="p">,</span>
         <span class="n">height</span><span class="o">=</span><span class="mf">3.5</span><span class="p">,</span>
         <span class="n">palette</span><span class="o">=</span><span class="n">palette</span><span class="p">,);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/community-detection_61_0.png" src="../../_images/community-detection_61_0.png" />
</div>
</div>
<p>So, <span class="math notranslate nohighlight">\(k\)</span>-means is getting the <em>wrong</em> answer almost <span class="math notranslate nohighlight">\(20\%\)</span> of the time, which might be decent, but let’s see if we can do better.</p>
<p>Next, we’re going to use a slight augmentation of <span class="math notranslate nohighlight">\(k\)</span>-means, called a Gaussian Mixture Model (GMM). Basically, a Gaussian Mixture Model allows you to account for the fact that, in the pairs plot with the true (unknown) community labels, the latent positions for each community tend to be somewhat erratically shaped (they aren’t perfect bloby circles anymore); in this case, they allow for <em>elliptical</em> patterns in the latent positions. When we use <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>’s <code class="docutils literal notranslate"><span class="pre">GaussianMixture()</span></code> for clustering, we instead get something like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.mixture</span> <span class="kn">import</span> <span class="n">GaussianMixture</span>
<span class="c1"># predict with gmm</span>
<span class="n">labels_gmm_erratic</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span><span class="n">n_components</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">Xhat</span><span class="p">)</span>
<span class="c1"># remap the labels</span>
<span class="n">labels_gmm_erratic_remap</span> <span class="o">=</span> <span class="n">remap_labels</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">labels_gmm_erratic</span><span class="p">)</span>
<span class="c1"># compute error rate</span>
<span class="n">error</span> <span class="o">=</span> <span class="n">z</span> <span class="o">-</span> <span class="n">labels_gmm_erratic_remap</span>  <span class="c1"># compute which assigned labels from labels_gmm_erratic_remap differ from the true labels z</span>
<span class="n">error</span> <span class="o">=</span> <span class="n">error</span> <span class="o">!=</span> <span class="mi">0</span>  <span class="c1"># if the difference between the community labels is non-zero, an error has occurred</span>
<span class="n">er_rt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>  <span class="c1"># error rate is the frequency of making an error</span>

<span class="n">palette</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Correct Pred.&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.7</span><span class="p">,</span><span class="mf">0.2</span><span class="p">),</span>
           <span class="s1">&#39;Wrong Pred.&#39;</span><span class="p">:(</span><span class="mf">0.8</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)}</span>

<span class="n">error_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">*</span><span class="p">[</span><span class="s1">&#39;Correct Pred.&#39;</span><span class="p">])</span>  <span class="c1"># initialize numpy array for each node</span>
<span class="n">error_label</span><span class="p">[</span><span class="n">error</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;Wrong Pred.&#39;</span>  <span class="c1"># add label &#39;Wrong&#39; for each error that is made</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">pairplot</span><span class="p">(</span><span class="n">Xhat</span><span class="p">,</span>
         <span class="n">labels</span><span class="o">=</span><span class="n">error_label</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Error from GMM, Error rate: </span><span class="si">{:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">er_rt</span><span class="p">),</span>
         <span class="n">legend_name</span><span class="o">=</span><span class="s1">&#39;Error label&#39;</span><span class="p">,</span>
         <span class="n">height</span><span class="o">=</span><span class="mf">3.5</span><span class="p">,</span>
         <span class="n">palette</span><span class="o">=</span><span class="n">palette</span><span class="p">,);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/community-detection_64_0.png" src="../../_images/community-detection_64_0.png" />
</div>
</div>
<p>GMM here does a bit better, making a lot fewer errors. For the reason that the GMM tends to work well in the situation where <span class="math notranslate nohighlight">\(k\)</span>-means works great (the nodes within a community are stochastically equivalent), and <em>much</em> better in the situation where <span class="math notranslate nohighlight">\(k\)</span>-means struggles (the nodes within a community are <em>not</em> stochastically equivalent, such as in the DCSBM example), we tend to recommend GMM in practice. For more details on the inner workings of the GMM, check out the appendix section on <code class="xref std std-numref docutils literal notranslate"><span class="pre">app:ch14:gmm</span></code>.</p>
<section id="choosing-number-of-clusters-with-gmm">
<h3><span class="section-number">6.1.4.1. </span>Choosing number of clusters with GMM<a class="headerlink" href="#choosing-number-of-clusters-with-gmm" title="Permalink to this headline">#</a></h3>
<p>When you don’t know the number of clusters to use, you can still use the silhouette score; however, with GMM in particular, there is a better approach known as the Bayesian Information Criterion (BIC). If you remember back from your probability or statistics course, the likelihood is the probability of observing the data that you see (in this case, estimated latent positions), given a particular set of parameters (which, in the case of the of the GMM, are the estimated community assignments <span class="math notranslate nohighlight">\(\hat{\vec z}\)</span>, the estimated means of the communities <span class="math notranslate nohighlight">\(\hat {\vec \mu}\)</span>, and the estimated covariances <span class="math notranslate nohighlight">\(\hat \Sigma_k\)</span> of the communities). The parameters are typically abbreviated with the notation <span class="math notranslate nohighlight">\(\theta\)</span>, which is used as a subscript for notational reasons in the statistics community (if you want to know why, check out the appendix section on the probabilistic foundations of network models in Appendix <a class="reference internal" href="../../appendix/ch12/foundation.html#app-ch12-foundation"><span class="std std-numref">Section 11.2</span></a>). This quantity is written <span class="math notranslate nohighlight">\(Pr_\theta\left(\hat{\vec x}_1,..., \hat{\vec x}_n\right)\)</span>. The log likelihood is simply the log of this, and the negative log likelihood is simply the opposite of that. So, if the probability is high, the negative log likelihood will be low.</p>
<p>The BIC is simply a penalized version of the negative log likelihood, where you penalize the negative log likelihood (make it bigger) when the number of clusters is larger. The BIC is, where <span class="math notranslate nohighlight">\(K\)</span> is the number of communities, <span class="math notranslate nohighlight">\(\hat X\)</span> are the estimated latent positions for the <span class="math notranslate nohighlight">\(n\)</span> nodes, and <span class="math notranslate nohighlight">\(\hat {\vec z}\)</span> are the estimated community assignments for each of the <span class="math notranslate nohighlight">\(n\)</span> nodes:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    BIC_\theta\left(\hat{\vec x}_1,..., \hat{\vec x}_n\right) &amp;= K \log(n) - 2 \log\left(Pr_\theta\left(\hat{\vec x}_1,..., \hat{\vec x}_n\right) \right)
\end{align*}\]</div>
<p>The BIC penalizes more complicated models (it is higher when the number of clusters is high), so in essence, the BIC is simultaneously balancing having a parsimonious number of clusters (they are enough to give a reasonably high probability and a relatively low negative log likelihood, but not so many that we end up with a really complicated and large model). For more information, check out the appendix section for <span class="xref myst">BIC</span>.</p>
<p>To choose the optimal number of clusters with GMM using the BIC, we can use the <code class="docutils literal notranslate"><span class="pre">AutoGMMCluster()</span></code>. Again, we set <code class="docutils literal notranslate"><span class="pre">max_components</span></code> to the maximum number of clusters that we think would be reasonable; in this case, <span class="math notranslate nohighlight">\(10\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.cluster.autogmm</span> <span class="kn">import</span> <span class="n">AutoGMMCluster</span>

<span class="n">autogmm_clust</span> <span class="o">=</span> <span class="n">AutoGMMCluster</span><span class="p">(</span><span class="n">max_components</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span>

<span class="n">labels_autogmm_erratic</span> <span class="o">=</span> <span class="n">autogmm_clust</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">Xhat</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To compute the “best” clustering, <code class="docutils literal notranslate"><span class="pre">AugoGMMCluster()</span></code> will automatically estimate GMMs with various numbers of components, parameter choices, and other attributes. The best clusterings are the ones with the lowest BIC, so to compare the BIC across each number of clusters, we should find the minimum BIC for a given number of components:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">autogmm_clust</span><span class="o">.</span><span class="n">results_</span> <span class="c1"># obtain the respective results</span>
<span class="c1"># summarize by taking the minimum for each number of clusters</span>
<span class="n">results_summarized</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;n_components&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s2">&quot;bic/aic&quot;</span><span class="p">:</span> <span class="s2">&quot;min&quot;</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nclusters</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>  <span class="c1"># graspologic nclusters goes from 2 to max_clusters</span>

<span class="n">bic_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">({</span><span class="s2">&quot;Number of Clusters&quot;</span><span class="p">:</span> <span class="n">nclusters</span><span class="p">,</span> <span class="s2">&quot;BIC&quot;</span><span class="p">:</span> <span class="n">results_summarized</span><span class="p">[</span><span class="s2">&quot;bic/aic&quot;</span><span class="p">]})</span>  <span class="c1"># place into pandas dataframe</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">bic_df</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;Number of Clusters&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;BIC&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;BIC Analysis of GMM Clusterings&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/community-detection_69_0.png" src="../../_images/community-detection_69_0.png" />
</div>
</div>
<p>The optimal number of clusters is identified as <span class="math notranslate nohighlight">\(3\)</span>, which is correct. Next, let’s take a look at the confusion matrix. We’ll normalize the confusion matrix column-wise, to indicate the portion of points with a given predicted label which correspond to a particular true label:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute the confusion matrix between the true labels z</span>
<span class="c1"># and the predicted labels labels_kmeans</span>
<span class="n">cf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">zs</span><span class="p">,</span> <span class="n">labels_autogmm_erratic</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">,:]</span>
<span class="n">cfm_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">cf_matrix</span><span class="p">,</span> <span class="n">cf_matrix</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ValueError</span><span class="g g-Whitespace">                                </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">41</span><span class="p">],</span> <span class="n">line</span> <span class="mi">3</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># compute the confusion matrix between the true labels z</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="c1"># and the predicted labels labels_kmeans</span>
<span class="ne">----&gt; </span><span class="mi">3</span> <span class="n">cf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">zs</span><span class="p">,</span> <span class="n">labels_autogmm_erratic</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">,:]</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">cfm_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">cf_matrix</span><span class="p">,</span> <span class="n">cf_matrix</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.8.16/x64/lib/python3.8/site-packages/sklearn/metrics/_classification.py:317,</span> in <span class="ni">confusion_matrix</span><span class="nt">(y_true, y_pred, labels, sample_weight, normalize)</span>
<span class="g g-Whitespace">    </span><span class="mi">232</span> <span class="k">def</span> <span class="nf">confusion_matrix</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">233</span>     <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">None</span>
<span class="g g-Whitespace">    </span><span class="mi">234</span> <span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">235</span><span class="w">     </span><span class="sd">&quot;&quot;&quot;Compute confusion matrix to evaluate the accuracy of a classification.</span>
<span class="g g-Whitespace">    </span><span class="mi">236</span><span class="sd"> </span>
<span class="g g-Whitespace">    </span><span class="mi">237</span><span class="sd">     By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`</span>
<span class="sd">   (...)</span>
<span class="g g-Whitespace">    </span><span class="mi">315</span><span class="sd">     (0, 2, 1, 1)</span>
<span class="g g-Whitespace">    </span><span class="mi">316</span><span class="sd">     &quot;&quot;&quot;</span>
<span class="ne">--&gt; </span><span class="mi">317</span>     <span class="n">y_type</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">_check_targets</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">318</span>     <span class="k">if</span> <span class="n">y_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">319</span>         <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> is not supported&quot;</span> <span class="o">%</span> <span class="n">y_type</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.8.16/x64/lib/python3.8/site-packages/sklearn/metrics/_classification.py:86,</span> in <span class="ni">_check_targets</span><span class="nt">(y_true, y_pred)</span>
<span class="g g-Whitespace">     </span><span class="mi">59</span> <span class="k">def</span> <span class="nf">_check_targets</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
<span class="g g-Whitespace">     </span><span class="mi">60</span><span class="w">     </span><span class="sd">&quot;&quot;&quot;Check that y_true and y_pred belong to the same classification task.</span>
<span class="g g-Whitespace">     </span><span class="mi">61</span><span class="sd"> </span>
<span class="g g-Whitespace">     </span><span class="mi">62</span><span class="sd">     This converts multiclass or binary types to a common shape, and raises a</span>
<span class="sd">   (...)</span>
<span class="g g-Whitespace">     </span><span class="mi">84</span><span class="sd">     y_pred : array or indicator matrix</span>
<span class="g g-Whitespace">     </span><span class="mi">85</span><span class="sd">     &quot;&quot;&quot;</span>
<span class="ne">---&gt; </span><span class="mi">86</span>     <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">87</span>     <span class="n">type_true</span> <span class="o">=</span> <span class="n">type_of_target</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;y_true&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">88</span>     <span class="n">type_pred</span> <span class="o">=</span> <span class="n">type_of_target</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;y_pred&quot;</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.8.16/x64/lib/python3.8/site-packages/sklearn/utils/validation.py:397,</span> in <span class="ni">check_consistent_length</span><span class="nt">(*arrays)</span>
<span class="g g-Whitespace">    </span><span class="mi">395</span> <span class="n">uniques</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">396</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">uniques</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">397</span>     <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">398</span>         <span class="s2">&quot;Found input variables with inconsistent numbers of samples: </span><span class="si">%r</span><span class="s2">&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">399</span>         <span class="o">%</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">lengths</span><span class="p">]</span>
<span class="g g-Whitespace">    </span><span class="mi">400</span>     <span class="p">)</span>

<span class="ne">ValueError</span>: Found input variables with inconsistent numbers of samples: [100, 190]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cfm_norm</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmaps</span><span class="p">[</span><span class="s2">&quot;sequential&quot;</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Normalized confusion matrix&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;True Label (School)&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>As we can see, for a particular predicted label, almost all of the points correspond to a single unique true label. Stated another way, our clusters are non-overlapping (with respect to the true labels), in that a single predicted label tends to correspond to a single true label.</p>
</section>
</section>
<section id="references">
<h2><span class="section-number">6.1.5. </span>References<a class="headerlink" href="#references" title="Permalink to this headline">#</a></h2>
<div class="docutils container" id="id4">
<dl class="citation">
<dt class="label" id="id40"><span class="brackets"><a class="fn-backref" href="#id2">1</a></span></dt>
<dd><p>M. E. J. Newman. Modularity and community structure in networks. <em>Proc. Natl. Acad. Sci. U.S.A.</em>, 103(23):8577–8582, June 2006. <a class="reference external" href="https://doi.org/10.1073/pnas.0601602103">doi:10.1073/pnas.0601602103</a>.</p>
</dd>
<dt class="label" id="id20"><span class="brackets"><a class="fn-backref" href="#id1">2</a></span></dt>
<dd><p>Avanti Athreya, Donniell E. Fishkind, Minh Tang, Carey E. Priebe, Youngser Park, Joshua T. Vogelstein, Keith Levin, Vince Lyzinski, and Yichen Qin. Statistical inference on random dot product graphs: a survey. <em>J. Mach. Learn. Res.</em>, 18(1):8393–8484, January 2017. <a class="reference external" href="https://doi.org/10.5555/3122009.3242083">doi:10.5555/3122009.3242083</a>.</p>
</dd>
</dl>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./applications/ch7"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="ch7.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">6. </span>Applications When You Have One Network</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="testing-differences.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">6.2. </span>Testing for Differences between Groups of Edges</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Eric Bridgeford, Alex Loftus, and Joshua Vogelstein<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>