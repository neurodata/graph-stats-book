Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.8.13/x64/lib/python3.8/site-packages/jupyter_cache/executors/utils.py", line 51, in single_nb_execution
    executenb(
  File "/opt/hostedtoolcache/Python/3.8.13/x64/lib/python3.8/site-packages/nbclient/client.py", line 1204, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/opt/hostedtoolcache/Python/3.8.13/x64/lib/python3.8/site-packages/nbclient/util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/opt/hostedtoolcache/Python/3.8.13/x64/lib/python3.8/site-packages/nbclient/util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "/opt/hostedtoolcache/Python/3.8.13/x64/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/hostedtoolcache/Python/3.8.13/x64/lib/python3.8/site-packages/nbclient/client.py", line 663, in async_execute
    await self.async_execute_cell(
  File "/opt/hostedtoolcache/Python/3.8.13/x64/lib/python3.8/site-packages/nbclient/client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/opt/hostedtoolcache/Python/3.8.13/x64/lib/python3.8/site-packages/nbclient/client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
from torch.nn import Linear
import torch.nn.functional as F
from torch_geometric.nn import GCNConv
from torch_geometric.nn import global_mean_pool


class GCN(torch.nn.Module):
    def __init__(self, hidden_channels):
        super(GCN, self).__init__()
        torch.manual_seed(12345)
        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, hidden_channels)
        self.conv3 = GCNConv(hidden_channels, hidden_channels)
        self.lin = Linear(hidden_channels, dataset.num_classes, bias=False)

    def forward(self, x, edge_index, batch):

        # 1. Obtain node embeddings via convolutional layers 
        x = self.conv1(x, edge_index)
        x = x.relu()
        x = self.conv2(x, edge_index)
        x = x.relu()
        x = self.conv3(x, edge_index)

        # 2. Readout layer to produce network embedding
        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]

        # 3. Apply a prediction classifier to the network embedding
#         x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin(x)
        
        return x
device = 'mps'
model = GCN(hidden_channels=64).to(device)
print(model)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mRuntimeError[0m                              Traceback (most recent call last)
Input [0;32mIn [10][0m, in [0;36m<cell line: 34>[0;34m()[0m
[1;32m     32[0m         [38;5;28;01mreturn[39;00m x
[1;32m     33[0m device [38;5;241m=[39m [38;5;124m'[39m[38;5;124mmps[39m[38;5;124m'[39m
[0;32m---> 34[0m model [38;5;241m=[39m [43mGCN[49m[43m([49m[43mhidden_channels[49m[38;5;241;43m=[39;49m[38;5;241;43m64[39;49m[43m)[49m[38;5;241;43m.[39;49m[43mto[49m[43m([49m[43mdevice[49m[43m)[49m
[1;32m     35[0m [38;5;28mprint[39m(model)

File [0;32m/opt/hostedtoolcache/Python/3.8.13/x64/lib/python3.8/site-packages/torch/nn/modules/module.py:927[0m, in [0;36mModule.to[0;34m(self, *args, **kwargs)[0m
[1;32m    923[0m         [38;5;28;01mreturn[39;00m t[38;5;241m.[39mto(device, dtype [38;5;28;01mif[39;00m t[38;5;241m.[39mis_floating_point() [38;5;129;01mor[39;00m t[38;5;241m.[39mis_complex() [38;5;28;01melse[39;00m [38;5;28;01mNone[39;00m,
[1;32m    924[0m                     non_blocking, memory_format[38;5;241m=[39mconvert_to_format)
[1;32m    925[0m     [38;5;28;01mreturn[39;00m t[38;5;241m.[39mto(device, dtype [38;5;28;01mif[39;00m t[38;5;241m.[39mis_floating_point() [38;5;129;01mor[39;00m t[38;5;241m.[39mis_complex() [38;5;28;01melse[39;00m [38;5;28;01mNone[39;00m, non_blocking)
[0;32m--> 927[0m [38;5;28;01mreturn[39;00m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_apply[49m[43m([49m[43mconvert[49m[43m)[49m

File [0;32m/opt/hostedtoolcache/Python/3.8.13/x64/lib/python3.8/site-packages/torch/nn/modules/module.py:579[0m, in [0;36mModule._apply[0;34m(self, fn)[0m
[1;32m    577[0m [38;5;28;01mdef[39;00m [38;5;21m_apply[39m([38;5;28mself[39m, fn):
[1;32m    578[0m     [38;5;28;01mfor[39;00m module [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39mchildren():
[0;32m--> 579[0m         [43mmodule[49m[38;5;241;43m.[39;49m[43m_apply[49m[43m([49m[43mfn[49m[43m)[49m
[1;32m    581[0m     [38;5;28;01mdef[39;00m [38;5;21mcompute_should_use_set_data[39m(tensor, tensor_applied):
[1;32m    582[0m         [38;5;28;01mif[39;00m torch[38;5;241m.[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):
[1;32m    583[0m             [38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,[39;00m
[1;32m    584[0m             [38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,[39;00m
[0;32m   (...)[0m
[1;32m    589[0m             [38;5;66;03m# global flag to let the user control whether they want the future[39;00m
[1;32m    590[0m             [38;5;66;03m# behavior of overwriting the existing tensor or not.[39;00m

File [0;32m/opt/hostedtoolcache/Python/3.8.13/x64/lib/python3.8/site-packages/torch/nn/modules/module.py:579[0m, in [0;36mModule._apply[0;34m(self, fn)[0m
[1;32m    577[0m [38;5;28;01mdef[39;00m [38;5;21m_apply[39m([38;5;28mself[39m, fn):
[1;32m    578[0m     [38;5;28;01mfor[39;00m module [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39mchildren():
[0;32m--> 579[0m         [43mmodule[49m[38;5;241;43m.[39;49m[43m_apply[49m[43m([49m[43mfn[49m[43m)[49m
[1;32m    581[0m     [38;5;28;01mdef[39;00m [38;5;21mcompute_should_use_set_data[39m(tensor, tensor_applied):
[1;32m    582[0m         [38;5;28;01mif[39;00m torch[38;5;241m.[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):
[1;32m    583[0m             [38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,[39;00m
[1;32m    584[0m             [38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,[39;00m
[0;32m   (...)[0m
[1;32m    589[0m             [38;5;66;03m# global flag to let the user control whether they want the future[39;00m
[1;32m    590[0m             [38;5;66;03m# behavior of overwriting the existing tensor or not.[39;00m

File [0;32m/opt/hostedtoolcache/Python/3.8.13/x64/lib/python3.8/site-packages/torch/nn/modules/module.py:602[0m, in [0;36mModule._apply[0;34m(self, fn)[0m
[1;32m    598[0m [38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to[39;00m
[1;32m    599[0m [38;5;66;03m# track autograd history of `param_applied`, so we have to use[39;00m
[1;32m    600[0m [38;5;66;03m# `with torch.no_grad():`[39;00m
[1;32m    601[0m [38;5;28;01mwith[39;00m torch[38;5;241m.[39mno_grad():
[0;32m--> 602[0m     param_applied [38;5;241m=[39m [43mfn[49m[43m([49m[43mparam[49m[43m)[49m
[1;32m    603[0m should_use_set_data [38;5;241m=[39m compute_should_use_set_data(param, param_applied)
[1;32m    604[0m [38;5;28;01mif[39;00m should_use_set_data:

File [0;32m/opt/hostedtoolcache/Python/3.8.13/x64/lib/python3.8/site-packages/torch/nn/modules/module.py:925[0m, in [0;36mModule.to.<locals>.convert[0;34m(t)[0m
[1;32m    922[0m [38;5;28;01mif[39;00m convert_to_format [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mNone[39;00m [38;5;129;01mand[39;00m t[38;5;241m.[39mdim() [38;5;129;01min[39;00m ([38;5;241m4[39m, [38;5;241m5[39m):
[1;32m    923[0m     [38;5;28;01mreturn[39;00m t[38;5;241m.[39mto(device, dtype [38;5;28;01mif[39;00m t[38;5;241m.[39mis_floating_point() [38;5;129;01mor[39;00m t[38;5;241m.[39mis_complex() [38;5;28;01melse[39;00m [38;5;28;01mNone[39;00m,
[1;32m    924[0m                 non_blocking, memory_format[38;5;241m=[39mconvert_to_format)
[0;32m--> 925[0m [38;5;28;01mreturn[39;00m [43mt[49m[38;5;241;43m.[39;49m[43mto[49m[43m([49m[43mdevice[49m[43m,[49m[43m [49m[43mdtype[49m[43m [49m[38;5;28;43;01mif[39;49;00m[43m [49m[43mt[49m[38;5;241;43m.[39;49m[43mis_floating_point[49m[43m([49m[43m)[49m[43m [49m[38;5;129;43;01mor[39;49;00m[43m [49m[43mt[49m[38;5;241;43m.[39;49m[43mis_complex[49m[43m([49m[43m)[49m[43m [49m[38;5;28;43;01melse[39;49;00m[43m [49m[38;5;28;43;01mNone[39;49;00m[43m,[49m[43m [49m[43mnon_blocking[49m[43m)[49m

[0;31mRuntimeError[0m: PyTorch is not linked with support for mps devices
RuntimeError: PyTorch is not linked with support for mps devices

