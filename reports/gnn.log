Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/jupyter_cache/executors/utils.py", line 51, in single_nb_execution
    executenb(
  File "/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/nbclient/client.py", line 1204, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/nbclient/util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/nbclient/util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/nbclient/client.py", line 663, in async_execute
    await self.async_execute_cell(
  File "/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/nbclient/client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/nbclient/client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
# from IPython.display import Javascript
# display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))

model = GCN(hidden_channels=64)
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)
criterion = torch.nn.CrossEntropyLoss()

def train():
    model.train()

    for data in train_loader:  # Iterate in batches over the training dataset.
        
        out = model(data.x.float(), data.edge_index, data.batch)  # Perform a single forward pass.
        loss = criterion(out, data.y[:, 0].long())  # Compute the loss.
        
        loss.backward()  # Derive gradients.
        optimizer.step()  # Update parameters based on gradients.
        optimizer.zero_grad()  # Clear gradients.

def test(loader):
        model.eval()

        correct = 0
        for data in loader:  # Iterate in batches over the training/test dataset.
            out = model(data.x.float(), data.edge_index, data.batch)  
            pred = out.argmax(dim=1)  # Use the class with highest probability.
            correct += int((pred == data.y[:, 0]).sum())  # Check against ground-truth labels.
        return correct / len(loader.dataset)  # Derive ratio of correct predictions.

R = 10  # number of epochs
for epoch in range(0, R):
    train()
    train_acc = test(train_loader)
    test_acc = test(test_loader)
    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mRuntimeError[0m                              Traceback (most recent call last)
Cell [0;32mIn [11], line 33[0m
[1;32m     31[0m [38;5;28;01mfor[39;00m epoch [38;5;129;01min[39;00m [38;5;28mrange[39m([38;5;241m0[39m, R):
[1;32m     32[0m     train()
[0;32m---> 33[0m     train_acc [38;5;241m=[39m [43mtest[49m[43m([49m[43mtrain_loader[49m[43m)[49m
[1;32m     34[0m     test_acc [38;5;241m=[39m test(test_loader)
[1;32m     35[0m     [38;5;28mprint[39m([38;5;124mf[39m[38;5;124m'[39m[38;5;124mEpoch: [39m[38;5;132;01m{[39;00mepoch[38;5;132;01m:[39;00m[38;5;124m03d[39m[38;5;132;01m}[39;00m[38;5;124m, Train Acc: [39m[38;5;132;01m{[39;00mtrain_acc[38;5;132;01m:[39;00m[38;5;124m.4f[39m[38;5;132;01m}[39;00m[38;5;124m, Test Acc: [39m[38;5;132;01m{[39;00mtest_acc[38;5;132;01m:[39;00m[38;5;124m.4f[39m[38;5;132;01m}[39;00m[38;5;124m'[39m)

Cell [0;32mIn [11], line 27[0m, in [0;36mtest[0;34m(loader)[0m
[1;32m     25[0m     out [38;5;241m=[39m model(data[38;5;241m.[39mx[38;5;241m.[39mfloat(), data[38;5;241m.[39medge_index, data[38;5;241m.[39mbatch)  
[1;32m     26[0m     pred [38;5;241m=[39m out[38;5;241m.[39margmax(dim[38;5;241m=[39m[38;5;241m1[39m)  [38;5;66;03m# Use the class with highest probability.[39;00m
[0;32m---> 27[0m     correct [38;5;241m+[39m[38;5;241m=[39m [38;5;28mint[39m(([43mpred[49m[43m [49m[38;5;241;43m==[39;49m[43m [49m[43mdata[49m[38;5;241;43m.[39;49m[43my[49m[43m[[49m[43m:[49m[43m,[49m[43m [49m[38;5;241;43m0[39;49m[43m][49m)[38;5;241m.[39msum())  [38;5;66;03m# Check against ground-truth labels.[39;00m
[1;32m     28[0m [38;5;28;01mreturn[39;00m correct [38;5;241m/[39m [38;5;28mlen[39m(loader[38;5;241m.[39mdataset)

[0;31mRuntimeError[0m: The size of tensor a (63) must match the size of tensor b (64) at non-singleton dimension 0
RuntimeError: The size of tensor a (63) must match the size of tensor b (64) at non-singleton dimension 0

