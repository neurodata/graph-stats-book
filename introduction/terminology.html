
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Terminology and Math Refresher &#8212; Hands-on Network Machine Learning with Scikit-Learn and Graspologic</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >let toggleHintShow = 'Click to show';</script>
    <script >let toggleHintHide = 'Click to hide';</script>
    <script >let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="1. The Network Machine Learning Landscape" href="../foundations/ch1/ch1.html" />
    <link rel="prev" title="Preface" href="preface.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Hands-on Network Machine Learning with Scikit-Learn and Graspologic</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../coverpage.html">
   Hands-on Network Machine Learning with Scikit-Learn and Graspologic
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Terminology and Math Refresher
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../foundations/ch1/ch1.html">
   1. The Network Machine Learning Landscape
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../foundations/ch1/what-is-a-network.html">
     1.1. What Is A Network?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../foundations/ch1/why-study-networks.html">
     1.2. Why Study Networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../foundations/ch1/examples-of-applications.html">
     1.3. Examples of applications
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../foundations/ch1/types-of-learning-probs.html">
     1.4. Types of Network Learning Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../foundations/ch1/main-challenges.html">
     1.5. Main Challenges of Network Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../foundations/ch1/exercises.html">
     1.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../foundations/ch2/ch2.html">
   2. End-to-end Biology Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../foundations/ch2/big-picture.html">
     2.1. Look at the big picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../foundations/ch2/get-the-data.html">
     2.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../foundations/ch2/prepare-the-data.html">
     2.3. Prepare the Data for Network Algorithms
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../foundations/ch3/ch3.html">
   3. End-to-end Business Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../foundations/ch3/big-picture.html">
     3.1. Look at the Big Picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../foundations/ch3/get-the-data.html">
     3.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../foundations/ch3/discover-and-visualize.html">
     3.3. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../foundations/ch3/prepare-the-data.html">
     3.4. Prepare the Data for Network Algorithms
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Representations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../representations/ch4/ch4.html">
   4. Properties of Networks as a Statistical Object
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch4/matrix-representations.html">
     4.1. Matrix Representations Of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch4/network-representations.html">
     4.2. Representations of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch4/properties-of-networks.html">
     4.3. Properties of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch4/regularization.html">
     4.4. Regularization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../representations/ch5/ch5.html">
   5. Why Use Statistical Models?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch5/why-use-models.html">
     5.1. Why Use Statistical Models?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch5/single-network-models_ER.html">
     5.2. Erdös-Rényi (ER) Random Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch5/single-network-models_SBM.html">
     5.3. Stochastic Block Models (SBM)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch5/single-network-models_RDPG.html">
     5.4. Random Dot Product Graphs (RDPG)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch5/multi-network-models.html">
     5.5. Multiple Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch5/models-with-covariates.html">
     5.6. Network Models with Covariates
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch5/single-network-models_theory.html">
     5.7. Single network model theory
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../representations/ch6/ch6.html">
   6. Learning Network Representations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch6/estimating-parameters_mle.html">
     6.1. Estimating Parameters in Network Models via MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch6/why-embed-networks.html">
     6.2. Why embed networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch6/spectral-embedding.html">
     6.3. Spectral Embedding Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch6/estimating-parameters_spectral.html">
     6.4. Estimating Parameters with Spectral Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch6/random-walk-diffusion-methods.html">
     6.5. Random-Walk and Diffusion-based Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch6/graph-neural-networks.html">
     6.6. Graph Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch6/multigraph-representation-learning.html">
     6.7. Multiple-Network Representation Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch6/joint-representation-learning.html">
     6.8. Joint Representation Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch6/estimating-parameters_theory.html">
     6.9. Model Estimation Theory
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../representations/ch7/ch7.html">
   7. Theoretical Results
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch7/theory-single-network.html">
     7.1. Theory for Single Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch7/theory-multigraph.html">
     7.2. Theory for Multiple-Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representations/ch7/theory-matching.html">
     7.3. Theory for Graph Matching
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../applications/ch8/ch8.html">
   8. Applications When You Have One Network
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../applications/ch8/community-detection.html">
     8.1. Community Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../applications/ch8/testing-differences.html">
     8.2. Testing for Differences between Groups of Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../applications/ch8/model-selection.html">
     8.3. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../applications/ch8/single-vertex-nomination.html">
     8.4. Single-Network Vertex Nomination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../applications/ch8/out-of-sample.html">
     8.5. Out-of-sample Embedding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../applications/ch9/ch9.html">
   9. Applications for Two Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../applications/ch9/two-sample-hypothesis.html">
     9.1. Two-Sample Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../applications/ch9/significant-communities.html">
     9.2. Differences in Block Matrices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../applications/ch9/graph-matching-vertex.html">
     9.3. Graph Matching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../applications/ch9/multiple-vertex-nomination.html">
     9.4. Vertex Nomination For Multiple Networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../applications/ch10/ch10.html">
   10. Applications for Many Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../applications/ch10/anomaly-detection.html">
     10.1. Anomaly Detection For Timeseries of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../applications/ch10/significant-edges.html">
     10.2. Testing for Significant Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../applications/ch10/significant-vertices.html">
     10.3. Testing for Significant Vertices
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://graspologic.readthedocs.io/en/latest/">
   Graspologic Documentation
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/introduction/terminology.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/neurodata/graph-stats-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/neurodata/graph-stats-book/issues/new?title=Issue%20on%20page%20%2Fintroduction/terminology.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/neurodata/graph-stats-book/edit/master/network_machine_learning_in_python/introduction/terminology.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/neurodata/graph-stats-book/master?urlpath=tree/network_machine_learning_in_python/introduction/terminology.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vectors-matrices-and-numerical-spaces">
   Vectors, Matrices, and Numerical Spaces
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#numerical-spaces">
     Numerical Spaces
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-dimensional-quantities">
     One-Dimensional Quantities
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vectors">
     Vectors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matrices">
     Matrices
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#useful-functions">
   Useful Functions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probability">
   Probability
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#advanced-probability">
   Advanced Probability*
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Terminology and Math Refresher</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vectors-matrices-and-numerical-spaces">
   Vectors, Matrices, and Numerical Spaces
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#numerical-spaces">
     Numerical Spaces
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-dimensional-quantities">
     One-Dimensional Quantities
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vectors">
     Vectors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matrices">
     Matrices
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#useful-functions">
   Useful Functions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probability">
   Probability
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#advanced-probability">
   Advanced Probability*
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="terminology-and-math-refresher">
<h1>Terminology and Math Refresher<a class="headerlink" href="#terminology-and-math-refresher" title="Permalink to this headline">¶</a></h1>
<p>In this section, we outline some background terminology which will come up repeatedly throughout the book. This section attempts to standardize some background material that we think is useful going in. It is important to realize that many of the concepts discussed below are only crucial for understanding the advanced, starred sections. If you aren’t familiar with some (or any!) of the below concepts, we don’t think this would detract from your understanding of the broader content.</p>
<div class="section" id="vectors-matrices-and-numerical-spaces">
<h2>Vectors, Matrices, and Numerical Spaces<a class="headerlink" href="#vectors-matrices-and-numerical-spaces" title="Permalink to this headline">¶</a></h2>
<p>Throughout this book, we will need some level of familiarity with numerical spaces, and the grammar that we use to describe them. Taking the time to understand this notation will better help you understand many of the concepts in the rest of the book.</p>
<div class="section" id="numerical-spaces">
<h3>Numerical Spaces<a class="headerlink" href="#numerical-spaces" title="Permalink to this headline">¶</a></h3>
<p>Numerical spaces are everywhere. If you have taken any calculus or algebra courses, you are likely familiar with the natural numbers - these are just your basic one, two, three, and so on. This constitutes the most basic numerical space and is denoted by the symbol <span class="math notranslate nohighlight">\(\mathbb N\)</span>. Formally, the natural numbers describes the set:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \mathbb N &amp;= \{1, 2, 3, ...\}
\end{align*}\]</div>
<p>and continues infinitely (notice that neither negative numbers nor numbers with decimal points appear in <span class="math notranslate nohighlight">\(\mathbb N\)</span>). On a similar note, we will frequently resort to short hand to describe subsets of the natural numbers. We will use the symbol <span class="math notranslate nohighlight">\(\in\)</span> (read, “in”) to denote that one quantity is found within a particular set. For example, since <span class="math notranslate nohighlight">\(5\)</span> is a natural number, we would say that <span class="math notranslate nohighlight">\(5 \in \mathbb N\)</span>, which can be thought of as “<span class="math notranslate nohighlight">\(5\)</span> is in the set of natural numbers”. To describe a subset of the first <span class="math notranslate nohighlight">\(5\)</span> natural numbers, we would use the notation <span class="math notranslate nohighlight">\([5]\)</span>, which denotes the set:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    [5] &amp;= \{1,2,3,4,5\}
\end{align*}\]</div>
<p>In the more general case where we have some variable <span class="math notranslate nohighlight">\(n\)</span> where <span class="math notranslate nohighlight">\(n \in \mathbb N\)</span> (again, <span class="math notranslate nohighlight">\(n\)</span> is some arbitrary natural number), then:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    [n] &amp;= \{1,2,...,n\}
\end{align*}\]</div>
<p>The next most basic numerical space is known as the integers, which is just the natural numbers combined with the negative numbers and zero. Specifically:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \mathbb Z &amp;= \{..., -2, -1, 0, 1, 2, ...\}
\end{align*}\]</div>
<p>From <span class="math notranslate nohighlight">\(-\infty\)</span> up to <span class="math notranslate nohighlight">\(+\infty\)</span>.</p>
<p>There are many more numerical spaces, but in this book we’ll focus on one in particular: real numbers, denoted <span class="math notranslate nohighlight">\(\mathbb R\)</span>. The real numbers can be thought of as all the numbers that can be represented by a finite or infinite number of decimal places in between (and including) the integers. We won’t go into too many details; if you want more details on the real numbers, a good place to start would be coursework in <strong>real analysis</strong>. Particularly, the real numbers include any natural number, and integer, any decimal, or any irrational number (such as <span class="math notranslate nohighlight">\(\pi\)</span> or <span class="math notranslate nohighlight">\(\sqrt{2}\)</span>). The main thing that is interesting about the real numbers that we will <em>indirectly</em> use throughout the book is that if we have any two real numbers <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> (remember, this would be written <span class="math notranslate nohighlight">\(x, y \in \mathbb R\)</span>), then the products, ratios, or sums of them are also real numbers:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    x \cdot y, \frac{x}{y}, x + y \in \mathbb R
\end{align*}\]</div>
<p>Throughout the book, we will build upon some of these numerical spaces and introduce several new ones along the way that are interesing for network machine learning. We will do this by attempting to relate them back to the basic numerical spaces we have introduced here.</p>
</div>
<div class="section" id="one-dimensional-quantities">
<h3>One-Dimensional Quantities<a class="headerlink" href="#one-dimensional-quantities" title="Permalink to this headline">¶</a></h3>
<p>We will frequently see the term “dimensional” come up in this book, and we will attempt to give some insight into what this means here. If we were to say that <span class="math notranslate nohighlight">\(x \in \mathbb R\)</span>, we know from the above description that this means that <span class="math notranslate nohighlight">\(x\)</span> is a real number, and is therefore “in” the set of real numbers. A one-dimensional quantity is a quantity which is described by a single element from one numerical space. In this instance, <span class="math notranslate nohighlight">\(x\)</span> is described by one real number, and is therefore one-dimensional. We will use a lowercase letter (for instance, <span class="math notranslate nohighlight">\(x, a, b, \alpha, \beta\)</span>; the letters may be Roman or Greek) to denote that a quantity is one-dimensional.</p>
</div>
<div class="section" id="vectors">
<h3>Vectors<a class="headerlink" href="#vectors" title="Permalink to this headline">¶</a></h3>
<p>Building off the concept of one-dimensional variables, what if we had some variable that existed in two dimensions? For instance, consider the following:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \vec x = \begin{bmatrix}1.5 \\ 2\end{bmatrix}
\end{align*}\]</div>
<p>As we can see here, <span class="math notranslate nohighlight">\(\vec x\)</span> is now described by two real numbers (namely, <span class="math notranslate nohighlight">\(1.5\)</span> and <span class="math notranslate nohighlight">\(2\)</span>). This means that <span class="math notranslate nohighlight">\(\vec x\)</span> is now a two-dimensional quantity, since we have two separate values needed to describe <span class="math notranslate nohighlight">\(\vec x\)</span>. In this case, <span class="math notranslate nohighlight">\(\vec x\)</span> no longer is “in” the real numbers, it is instead in the two-dimensional real vectors, or <span class="math notranslate nohighlight">\(\mathbb R^2\)</span>. Here, <span class="math notranslate nohighlight">\(\vec x\)</span> is called a <strong>vector</strong>, and each of its dimensions are defined using the notation <span class="math notranslate nohighlight">\(x_1 = 1.5\)</span> and <span class="math notranslate nohighlight">\(x_2 = 2\)</span>. The subscript <span class="math notranslate nohighlight">\(x_j\)</span> just means the <span class="math notranslate nohighlight">\(j^{th}\)</span> element of <span class="math notranslate nohighlight">\(\vec x\)</span>, which is numbered by counting downwards from the first row (<span class="math notranslate nohighlight">\(j = 1\)</span>) to however many rows <span class="math notranslate nohighlight">\(\vec x\)</span> has in total. Since <span class="math notranslate nohighlight">\(\vec x\)</span> is two-dimensional, we would say that <span class="math notranslate nohighlight">\(j \in [2]\)</span>, which means <span class="math notranslate nohighlight">\(j\)</span> can be either <span class="math notranslate nohighlight">\(1\)</span> or <span class="math notranslate nohighlight">\(2\)</span>. In general, we will assume that all vectors are <strong>column vectors</strong> unless otherwise stated, which means that <span class="math notranslate nohighlight">\(\vec x\)</span> will be assumed to be vertically aligned. This will not make much of a conceptual difference, but it will play a role when we define operations between vectors and matrices later on. On the other hand, a <strong>row vector</strong> will typically be denoted by using the <strong>transpose</strong> symbol, which we will learn about later on in the section on operators. Unlike a column vector, a row vector is aligned horizontally. For example, a row vector with entries identical to <span class="math notranslate nohighlight">\(\vec x\)</span> will be denoted:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \vec x^\top = \begin{bmatrix}1.5 &amp; 2\end{bmatrix}
\end{align*}\]</div>
<p>In the general case, for any set <span class="math notranslate nohighlight">\(\mathcal S\)</span>, we would say that <span class="math notranslate nohighlight">\(\vec s \in \mathcal S^d\)</span> if (think through this notation!) for any <span class="math notranslate nohighlight">\(j \in [d]\)</span>, <span class="math notranslate nohighlight">\(s_j \in \mathcal S\)</span>. The key aspects are that the symbol for the vector will be a lower case letter (in this example, <span class="math notranslate nohighlight">\(s\)</span>) like the one-dimensional quantity, but will add the <span class="math notranslate nohighlight">\(\vec{}\)</span> symbol to denote that it is a vector with more than one dimension. The quantity <span class="math notranslate nohighlight">\(d\)</span> that you see in the superscript is referred to as the dimensionality. In this example, we would say that <span class="math notranslate nohighlight">\(\vec s\)</span> is a <span class="math notranslate nohighlight">\(d\)</span>-dimensional <span class="math notranslate nohighlight">\(\mathcal S\)</span>-vector.</p>
</div>
<div class="section" id="matrices">
<h3>Matrices<a class="headerlink" href="#matrices" title="Permalink to this headline">¶</a></h3>
<p>Matrices come up a lot in network science because we often represent networks as matrices: the adjacency matrix, for instance, is a way to represent a network in terms of its edge connections. Because networks can be represented as matrices, we’ll sometimes just talk about matrices directly.</p>
<p>We will see a variety of different types of matrices throughout this book, so let’s start with a simple example. Consider the following marix:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    X = \begin{bmatrix}
    1.5 &amp; 1.7 \\
    2 &amp; 1.8
    \end{bmatrix}
\end{align*}\]</div>
<p>Here, we can see that <span class="math notranslate nohighlight">\(X\)</span> is described by four real numbers, with a particular arrangement. This time, we say that <span class="math notranslate nohighlight">\(X\)</span> is an element of the set of all possible <span class="math notranslate nohighlight">\(2 \times 2\)</span> (2 rows, and 2 columns) matrices with real entries. In symbols, we would describe this as <span class="math notranslate nohighlight">\(\mathbb R^{2 \times 2}\)</span>, where <span class="math notranslate nohighlight">\(\mathbb R\)</span> says that the elements of the matrix are real numbers, and <span class="math notranslate nohighlight">\(2 \times 2\)</span> means that the matrix has two rows and two columns. We can describe the entries of a matrix using indexing, very similar to what we did for vectors. In matrices, the rows and columns matter. In this case, the rows go from left to right horizontally, and the columns go from top to bottom vertically. The rows will be numbered from the top of the matrix to the bottom, and the columns will be numbered from the left-most column to the right-most column. For instance, the first row of the matrix <span class="math notranslate nohighlight">\(X\)</span> is the row-vector <span class="math notranslate nohighlight">\(\begin{bmatrix}1.5 &amp; 1.7\end{bmatrix}\)</span>, and the second column of the matrix <span class="math notranslate nohighlight">\(X\)</span> is the column-vector <span class="math notranslate nohighlight">\(\begin{bmatrix}1.7 \\ 1.8\end{bmatrix}\)</span>. This subscripts <span class="math notranslate nohighlight">\(x_{ij}\)</span> means the entry of the matrix <span class="math notranslate nohighlight">\(X\)</span> in the <span class="math notranslate nohighlight">\(i^{th}\)</span> row aand the <span class="math notranslate nohighlight">\(j^{th}\)</span> column. In this instance, we would describe that <span class="math notranslate nohighlight">\(x_{11} = 1.5\)</span>, <span class="math notranslate nohighlight">\(x_{12} = 1.7\)</span>, <span class="math notranslate nohighlight">\(x_{21}=2\)</span>, and <span class="math notranslate nohighlight">\(x_{22} = 1.8\)</span>.</p>
<p>In the general case, for a set <span class="math notranslate nohighlight">\(\mathcal S\)</span>, we would say that <span class="math notranslate nohighlight">\(S \in \mathcal S^{r \times c}\)</span> if (think this through!) for any <span class="math notranslate nohighlight">\(i \in [r]\)</span> and any <span class="math notranslate nohighlight">\(j \in [c]\)</span>, <span class="math notranslate nohighlight">\(s_{ij} \in \mathcal S\)</span>. Like before, the key aspects are that the symbol for a matrix will be a capital letter (in this example, <span class="math notranslate nohighlight">\(S\)</span>) to denote that it is a matrix, and its entries <span class="math notranslate nohighlight">\(s_{ij}\)</span> will be denoted using a lowercase letter. The quantity <span class="math notranslate nohighlight">\(r\)</span> is known as the row count and the quantity <span class="math notranslate nohighlight">\(c\)</span> is known as the column count of the matrix <span class="math notranslate nohighlight">\(S\)</span>. In this example, we would say that <span class="math notranslate nohighlight">\(S\)</span> is a <span class="math notranslate nohighlight">\(\mathcal S\)</span>-matrix with <span class="math notranslate nohighlight">\(r\)</span> rows and <span class="math notranslate nohighlight">\(c\)</span> columns.</p>
<p>Another thing we will see arise periodically is that vectors can be denoted as matrices with a single column. For example, in our example above in the vector section, we might equivalently write that <span class="math notranslate nohighlight">\(\vec s \in \mathcal S^{d \times 1}\)</span>. The “1” for the columns just denotes that <span class="math notranslate nohighlight">\(\vec s\)</span> is a column vector with <span class="math notranslate nohighlight">\(d\)</span> rows in total. This will be useful when we define functions for matrices, and use the same notation for functions on vectors.</p>
</div>
</div>
<div class="section" id="useful-functions">
<h2>Useful Functions<a class="headerlink" href="#useful-functions" title="Permalink to this headline">¶</a></h2>
<p>Throughout the book, we will deal with many types of functions which take mathematical objects (potentially multiple) that exist in one numerical space and produce a mathematical object (potentially in a different) numerical space. You are probably familiar with several of these, such as the addition or multiplication operators on one-dimensional quantities. We will touch on some of the more fancy ones that we will see arise throughout the book.</p>
<p>The <strong>sum</strong>, denoted by a fancy capital epsilon <span class="math notranslate nohighlight">\(\sum\)</span>, denotes that we are summing a bunch of items which can be easily indexed. For instance, consider if we have a vector <span class="math notranslate nohighlight">\(\vec x \in \mathbb R^d\)</span>, so <span class="math notranslate nohighlight">\(\vec x\)</span> is a <span class="math notranslate nohighlight">\(d\)</span>-dimensional vector. If we wanted to take the sum of all of the elements of <span class="math notranslate nohighlight">\(\vec x\)</span>, we would write:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \sum_{i = 1}^d x_i = x_1 + x_2 + ... + x_d
\end{align*}\]</div>
<p>The <em>summand</em> of the sum, the <span class="math notranslate nohighlight">\(x_i\)</span>s next to the <span class="math notranslate nohighlight">\(\sum\)</span> symbol, are the terms that will be summed up. Further, note that the <span class="math notranslate nohighlight">\(\sum\)</span> symbol also indicates the indices of <span class="math notranslate nohighlight">\(\vec x\)</span> that will be summed. Note that on the bottom, we see that the sum says from <span class="math notranslate nohighlight">\(i = 1\)</span> and above it says <span class="math notranslate nohighlight">\(d\)</span>. This means that we sum all the elements of <span class="math notranslate nohighlight">\(x_i\)</span> starting from below at <span class="math notranslate nohighlight">\(1\)</span> and going up until <span class="math notranslate nohighlight">\(d\)</span>. We could say the exact same thing using our shorthand for this set, which we described in the section on natural numbers, <span class="math notranslate nohighlight">\([d]\)</span>:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\sum_{i \in [d]} x_i = \sum_{i = 1}^d x_i = x_1 + x_2 + ... + x_d
\end{align*}\]</div>
<p>We could similarly define <strong>any</strong> indexing set, such as <span class="math notranslate nohighlight">\(\mathcal I = \{1,3\}\)</span>, and write:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \sum_{i \in \mathcal I} x_i = x_1 + x_3
\end{align*}\]</div>
<p>The key is that the notation above or below the summand just tells us which elements we are applying the sum over. For instance, if <span class="math notranslate nohighlight">\(\vec x\)</span> was a <span class="math notranslate nohighlight">\(3\)</span>-dimensional vector:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
   \vec x = \begin{bmatrix}
      1.7 \\ 1.8 \\ 2
   \end{bmatrix}
\end{align*}\]</div>
<p>We would have that:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
   \sum_{i = 1}^3 x_i = 5.5
\end{align*}\]</div>
<p>if we were to use <span class="math notranslate nohighlight">\(\mathcal I = \{1,3\}\)</span>, then:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \sum_{i \in \mathcal I}x_i = 3.7
\end{align*}\]</div>
<p>the <strong>product</strong>, denoted by a capital pi <span class="math notranslate nohighlight">\(\prod\)</span>, behaves extremely similarly to the sum, except insted of applying sums, it applies multiplication. For instance, if we instead wanted to multiply all the elements of <span class="math notranslate nohighlight">\(\vec x\)</span>, we would write:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \prod_{i = 1}^d x_i = x_1 \times x_2 \times ... \times x_d
\end{align*}\]</div>
<p>Where <span class="math notranslate nohighlight">\(\times\)</span> is just multiplication like you are probably used to. Again, we have the exact same indexing conventions, where:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \prod_{i \in [d]} x_i=
    \prod_{i = 1}^d x_i = x_1 \times x_2 \times ... \times x_d
\end{align*}\]</div>
<p>We can again just use indexing sets, too:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \prod_{i \in \mathcal I}x_i = x_1 \times x_3
\end{align*}\]</div>
<p>With <span class="math notranslate nohighlight">\(\vec x\)</span> defined as above in the sum example, we would have that:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
   \prod_{i = 1}^3 x_i = 6.12
\end{align*}\]</div>
<p>if we were to use <span class="math notranslate nohighlight">\(\mathcal I = \{1,3\}\)</span>, then:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \prod_{i \in \mathcal I}x_i = 3.4
\end{align*}\]</div>
<p>The <strong>Euclidean inner product</strong>, or the <em>inner product</em> we will refer to in our book, is obtained by multiplying two vectors element-wise, and summing the result. Suppose we have two vectors <span class="math notranslate nohighlight">\(\vec x\)</span> and <span class="math notranslate nohighlight">\(\vec y\)</span>, which are each <span class="math notranslate nohighlight">\(d\)</span>-dimensional real vectors (both <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> must have the same number of elements). The inner product is the quantity:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \langle \vec x, \vec y\rangle &amp;= \sum_{i = 1}^d x_i y_i
\end{align*}\]</div>
<p>as we will see in a second, in matrix notation, this is exactly equivalent to writing:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \langle \vec x, \vec y\rangle &amp;= \vec x^T \vec y
\end{align*}\]</div>
<p><strong>Matrix multiplication</strong>, denoted by a circle <span class="math notranslate nohighlight">\(\cdot\)</span> (or in most cases, just two matrices side by side, with no separation), is an operation which takes a matrix which has <span class="math notranslate nohighlight">\(r\)</span> rows and <span class="math notranslate nohighlight">\(c\)</span> columns and another matrix which has <span class="math notranslate nohighlight">\(c\)</span> rows and <span class="math notranslate nohighlight">\(l\)</span> columns, and produces a matrix with <span class="math notranslate nohighlight">\(r\)</span> rows and <span class="math notranslate nohighlight">\(l\)</span> columns. Suppose we have a matrix <span class="math notranslate nohighlight">\(A \in \mathbb R^{r \times c}\)</span>, and <span class="math notranslate nohighlight">\(B \in \mathbb R^{c \times l}\)</span>. Here, <span class="math notranslate nohighlight">\(r\)</span>, <span class="math notranslate nohighlight">\(c\)</span>, and <span class="math notranslate nohighlight">\(l\)</span> could be <em>any</em> natural numbers. A matrix multiplication produces a matrix <span class="math notranslate nohighlight">\(D \in \mathbb R^{r \times l}\)</span>, where:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    d_{ij} = \sum_{k = 1}^c a_{ik}b_{kj}
\end{align*}\]</div>
<p>What does this mean intuitively? Well, let’s think about it. Let’s imagine that the <em>rows</em> of <span class="math notranslate nohighlight">\(A\)</span> are indexed from <span class="math notranslate nohighlight">\(1\)</span> to <span class="math notranslate nohighlight">\(r\)</span>, like this:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    A &amp;= \begin{bmatrix}
        \vec a_1^T \\
        \vec a_2^T \\
        \vdots \\
        \vec a_r^T
    \end{bmatrix}
\end{align*}\]</div>
<p>Note that the vectors <span class="math notranslate nohighlight">\(\vec a_i\)</span> are transposed when oriented in the matrix <span class="math notranslate nohighlight">\(A\)</span>, because they are each <span class="math notranslate nohighlight">\(c\)</span>-dimensional vectors (and by convention in our book, all vectors will be <em>column</em> vecors. So to comprise the rows of <span class="math notranslate nohighlight">\(A\)</span>, they must be “flipped”). Similarly, let’s imagine that the columns of <span class="math notranslate nohighlight">\(B\)</span> are indexed from <span class="math notranslate nohighlight">\(1\)</span> to <span class="math notranslate nohighlight">\(l\)</span>, like this:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    B &amp;= \begin{bmatrix}
        \vec b_1 &amp; \vec b_2 &amp; ... &amp; \vec b_l
    \end{bmatrix}
\end{align*}\]</div>
<p>So what is the marix <span class="math notranslate nohighlight">\(D\)</span>? Note that each entry, <span class="math notranslate nohighlight">\(d_{ij} = \langle \vec a_i, \vec b_j\rangle = \vec a_i^T \vec b_j\)</span>. So the matrix <span class="math notranslate nohighlight">\(D\)</span> is the matrix whose entries are the <em>inner products of the rows of <span class="math notranslate nohighlight">\(A\)</span> with the columns of <span class="math notranslate nohighlight">\(B\)</span></em>. In a diagram, <span class="math notranslate nohighlight">\(D\)</span> is like this:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    D &amp;= \begin{bmatrix}
        \vec a_1^T\vec b_1 &amp; ... &amp; \vec a_1^T \vec b_l \\
        \vdots &amp; \ddots &amp; \vdots \\
        \vec a_r^T \vec b_1 &amp; ... &amp; \vec a_r^T \vec b_l
    \end{bmatrix}
\end{align*}\]</div>
<p>As a matter of notation, we might often have the case where we want to discuss or interpret a single element which is a product of two matrices. For instance, suppose we care about the entry <span class="math notranslate nohighlight">\((i, j)\)</span> of <span class="math notranslate nohighlight">\(AB\)</span>. We might also describe the resulting quantity <span class="math notranslate nohighlight">\(d_{ij}\)</span> using the notation <span class="math notranslate nohighlight">\((AB)_{ij}\)</span>. The reason we adopt this notation is that we want to emphasize that the matrix multiplication operation is performed first (it is in <em>parentheses</em>), and then we look at the <span class="math notranslate nohighlight">\((i,j)\)</span> entry of the resulting matrix.</p>
<p>The <strong>Euclidean distance</strong> is the most common distance between vectors we will see in this book. The Euclidean distance effectively tells us how far apart two points in <span class="math notranslate nohighlight">\(d\)</span>-dimensional space are. Given <span class="math notranslate nohighlight">\(\vec x, \vec y \in \mathbb R^d\)</span> (<span class="math notranslate nohighlight">\(\vec x\)</span> and <span class="math notranslate nohighlight">\(\vec y\)</span> are <span class="math notranslate nohighlight">\(d\)</span>-dimensional real vectors), the Euclidean distance is the quantity:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \delta(\vec x, \vec y) &amp;= \langle \vec x - \vec y, \vec x - \vec y\rangle = \sum_{i = 1}^d (x_i - y_i)^2
\end{align*}\]</div>
<p>In particular, if we check the distance between a vector and the origin (the <strong>zero-vector</strong>, denoted <span class="math notranslate nohighlight">\(0_d\)</span>, which is a <span class="math notranslate nohighlight">\(d\)</span>-dimensional vector where all entries are <span class="math notranslate nohighlight">\(0\)</span>), we end up with a very useful quantity, called the squared Euclidean norm. We will use a special notation for the Euclidean norm, which is:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    ||\vec x||_2^2 &amp;= \delta(\vec x, 0_d) = \sum_{i = 1}^dx_i^2
\end{align*}\]</div>
<p>The subscript <span class="math notranslate nohighlight">\(_2\)</span> just means that this is the “2”-norm, which is a concept outside of the scope of this book. The superscript <span class="math notranslate nohighlight">\(^2\)</span> means that this is the squared Euclidean norm. Therefore, the Euclidean norm itself is:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
||\vec x||_2 &amp;= \sqrt{\delta(\vec x, 0_d)} = \sqrt{\sum_{i = 1}^d x_i^2}
\end{align*}\]</div>
<p>What does this mean interpretation wise? The “square” operation basically means, if there are dimensions of <span class="math notranslate nohighlight">\(\vec x\)</span> that are big, the norm will end up being big. If the dimensions of <span class="math notranslate nohighlight">\(\vec x\)</span> are small, they will not contribute very much to the norm.</p>
<p>Based on the equation we saw above for the Euclidean distance, we could also understand the Euclidean distance to be the squared Euclidean norm of the vector which is the difference between <span class="math notranslate nohighlight">\(\vec x\)</span> and <span class="math notranslate nohighlight">\(\vec y\)</span>. Using this convention:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \delta(\vec x, \vec y) &amp;= ||\vec x - \vec y||_2^2
\end{align*}\]</div>
<p>In this sense, we can see that the Euclidean distance and the Euclidean norms are attributing a concept of “length” and “how far” a vector is from another (whether that is the origin or an arbitrary real vector). Next, we will see a related concept for matrices. The <strong>squared Frobenius norm</strong> is the quantity, given a matrix <span class="math notranslate nohighlight">\(A \in \mathbb R^{r \times c}\)</span>:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    ||A||_F^2&amp;= \sum_{i = 1}^r \sum_{i = 1}^c a_{ij}^2
\end{align*}\]</div>
<p>Note that this is very similar to the squared Euclidean norm of a vector, except it is applied to both the rows <em>and</em> the columns of <span class="math notranslate nohighlight">\(A\)</span>. Again, we have a similar interpretation to the Euclidean norm. If an entry of <span class="math notranslate nohighlight">\(A\)</span> is big, it will contribute much to the Frobenius norm due to the squared <span class="math notranslate nohighlight">\(a_{ij}\)</span> term. If an entry is smaller, it will not contribute as much. The Frobenius norm itself is just the square root of this:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    ||A||_F &amp;= \sqrt{\sum_{i = 1}^r \sum_{i = 1}^c a_{ij}^2}
\end{align*}\]</div>
</div>
<div class="section" id="probability">
<h2>Probability<a class="headerlink" href="#probability" title="Permalink to this headline">¶</a></h2>
<p>Throughout this book, we will be very concerned with probabilities and probability distributions. For this reason, we will introduce some basic notation that we will be concerned with. In probability analyses, we are concerned with describing things that occur in the real world with some level of uncertainty. We capture this uncertainty using probability, which in essence, describes how likely (or unlikely) a particular outcome is compared to all of the possible outcomes that could be realized. In general, we will call the most basic objects which occur with some uncertainty <strong>random variables</strong>, which is a variable whose values that we get to see in the real world (the <em>realizations</em> of the random variable) depend on some random phenomenon. We will denote a random variable using a similar notation to a one-dimensional variable, with the exception that we will <em>bold face</em> the variable to make clear that it is random. For instance, for a one-dimensional random variable, we will use notation like <span class="math notranslate nohighlight">\(\mathbf x\)</span>.</p>
<p>Like before, we can also have random vectors and random matrices. Like for the random variable, we will denote these with bold faces too. A random vector will be denoted using a bold faced variable with the vector symbol; for example, <span class="math notranslate nohighlight">\(\vec{\mathbf x}\)</span>. Likewise, a random matrix will be denoted using a bold faced upper case letter; for example, <span class="math notranslate nohighlight">\(\mathbf X\)</span>. Similar to how we indexed vectors and matrices, the index positions of random vectors and random matrices are random variables, too. That is, <span class="math notranslate nohighlight">\(\vec{\mathbf x}\)</span> is a <span class="math notranslate nohighlight">\(d\)</span>-dimensional random vector whose entries are the random variables <span class="math notranslate nohighlight">\(\mathbf x_i\)</span> for all <span class="math notranslate nohighlight">\(i\)</span> from <span class="math notranslate nohighlight">\(1\)</span> to <span class="math notranslate nohighlight">\(d\)</span>:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \vec{\mathbf x} &amp;= \begin{bmatrix}
        \mathbf x_1 \\
        \vdots \\
        \mathbf x_d
    \end{bmatrix}
\end{align*}\]</div>
<p>And <span class="math notranslate nohighlight">\(\mathbf X\)</span> is a <span class="math notranslate nohighlight">\((r \times c)\)</span> random matrix whose entries are the random varaiables <span class="math notranslate nohighlight">\(\mathbf x_{ij}\)</span> for all <span class="math notranslate nohighlight">\(i\)</span> from <span class="math notranslate nohighlight">\(1\)</span> to <span class="math notranslate nohighlight">\(r\)</span> and <span class="math notranslate nohighlight">\(j\)</span> from <span class="math notranslate nohighlight">\(1\)</span> to <span class="math notranslate nohighlight">\(c\)</span>:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \mathbf X &amp;= \begin{bmatrix}
        \mathbf x_{11} &amp; ... &amp; \mathbf x_{1c} \\
        \vdots &amp; \ddots &amp; \vdots \\
        \mathbf x_{r1} &amp; ... &amp; \mathbf x_{rc}
    \end{bmatrix}
\end{align*}\]</div>
<p>A probability distribution, denoted by <span class="math notranslate nohighlight">\(\mathbb P\)</span>, is a function which gives the probability of a particular value being attained by a random quantity. To state this another way, the probability distribution is concerned with fixing probabilities to realizations of random quantities. to make this a little more concrete, we will give an example with the simplest possible probability distribution, the Bernoulli distribution, denoted <span class="math notranslate nohighlight">\(Bernoulli(p)\)</span>. For the sake of this example, we will say that <span class="math notranslate nohighlight">\(\mathbf x\)</span> is a random variable which is <span class="math notranslate nohighlight">\(Bernoulli(p)\)</span> distributed, which we denote by <span class="math notranslate nohighlight">\(\mathbf x \sim Bernoulli(p)\)</span>. The Bernoulli distribution describes that the probability of the random variable <span class="math notranslate nohighlight">\(\mathbf x\)</span> taking a realization of <span class="math notranslate nohighlight">\(1\)</span> is <span class="math notranslate nohighlight">\(p\)</span>, whereas the probability of the random variable <span class="math notranslate nohighlight">\(\mathbf x\)</span> taking a realization of <span class="math notranslate nohighlight">\(0\)</span> is <span class="math notranslate nohighlight">\(1 - p\)</span>. Using the probability distribution, we would say that:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \mathbb P(\mathbf x = 0) &amp;= 1 - p \\
    \mathbb P(\mathbf x = 1) &amp;= p
\end{align*}\]</div>
</div>
<div class="section" id="advanced-probability">
<h2>Advanced Probability*<a class="headerlink" href="#advanced-probability" title="Permalink to this headline">¶</a></h2>
<p>the probability distribution for a random vector or a random matrix is described very similarly. The caveat is that with a random vector/matrix, we affix a probability of <em>every element</em> of the random vector/matrix equaling the realized vector/matrix. For instance, if <span class="math notranslate nohighlight">\(\vec{\mathbf x}\)</span> is a random vector taking realizations which are <span class="math notranslate nohighlight">\(d\)</span>-dimensional vectors, and <span class="math notranslate nohighlight">\(\vec x\)</span> is one such <span class="math notranslate nohighlight">\(d\)</span>-dimensional vector, then:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \mathbb P(\vec{\mathbf x} = \vec x) = \mathbb P(\mathbf x_1 = x_1, ..., \mathbf x_d = x_d)
\end{align*}\]</div>
<p>and likewise, if <span class="math notranslate nohighlight">\(\mathbf X\)</span> is a random matrix taking realizations which are <span class="math notranslate nohighlight">\(r \times c\)</span> matrices, and <span class="math notranslate nohighlight">\(X\)</span> is one such <span class="math notranslate nohighlight">\(r \times c\)</span> matrix, then:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \mathbb P(\mathbf X = X) &amp;= \mathbb P(\mathbf x_{11} = x_{11}, ..., \mathbf x_{rc} = x_{rc}) \\
    &amp;= \mathbb P(\mathbf x_{ij} = x_{ij} \text{ for any }i\text{ and }j)
\end{align*}\]</div>
<p>A probability concept we will see arise frequently in the advanced sections of the book is one called independence. A pair of random variables are independent if for any <span class="math notranslate nohighlight">\(x\)</span> which is a possible realization of <span class="math notranslate nohighlight">\(\mathbf x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> is a possible realization of <span class="math notranslate nohighlight">\(\mathbf y\)</span>, then:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \mathbb P(\mathbf x = x, \mathbf y = y) = \mathbb P(\mathbf x = x) \mathbb P(\mathbf y = y)
\end{align*}\]</div>
<p>A related concept that will be very important in our study of random matrices is the idea of mutual independence. If we have a set of <span class="math notranslate nohighlight">\(n\)</span> random variables <span class="math notranslate nohighlight">\(\mathbf x_i\)</span> for all <span class="math notranslate nohighlight">\(i = 1,..., n\)</span>, this set of random variables is said to be mutually independent if for any <span class="math notranslate nohighlight">\(x_1\)</span> which is a possible realization of <span class="math notranslate nohighlight">\(\mathbf x_1\)</span>, any <span class="math notranslate nohighlight">\(x_2\)</span> which is a possible realization of <span class="math notranslate nohighlight">\(\mathbf x_2\)</span>, and so on up to <span class="math notranslate nohighlight">\(\mathbf x_n\)</span>, then:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \mathbb P(\mathbf x_1 = x_1, ..., \mathbf x_n = x_n) = \prod_{i = 1}^n \mathbb P(\mathbf x_i = x_i)
\end{align*}\]</div>
<p>The ways in which this is useful will become more obvious through some of the advanced material of later chapters.</p>
<p>Another important concept we will see arise in some of the advanced material is the idea of conditional distributions. Given <span class="math notranslate nohighlight">\(x\)</span> which is a possible realization of <span class="math notranslate nohighlight">\(\mathbf x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> is a possible realization of <span class="math notranslate nohighlight">\(\mathbf y\)</span>, then the conditional distribution of <span class="math notranslate nohighlight">\(\mathbf x\)</span> on <span class="math notranslate nohighlight">\(\mathbf y\)</span> is the quantity:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\mathbb P(\mathbf x = x | \mathbf y = y) &amp;= \frac{\mathbb P(\mathbf x = x, \mathbf y = y)}{\mathbb P(\mathbf y = y)}
\end{align*}\]</div>
<p>While outside the scope of this book, it can be shown that this is a proper probability distribution function, but we mainly are concerned with the fact that this is simply a useful notation for an intuitive idea. What this allows us to capture is the idea of attributing a probability for a random variable <span class="math notranslate nohighlight">\(\mathbf x\)</span> obtaining the value <span class="math notranslate nohighlight">\(x\)</span>, given that we already know that <span class="math notranslate nohighlight">\(\mathbf y\)</span> obtains the value <span class="math notranslate nohighlight">\(y\)</span>. A related concept, Baye’s Rule, uses a simple consequence of this theorem. Note that we could flip the probability statement above, and would obtain that:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\mathbb P(\mathbf y = y | \mathbf x = x) &amp;= \frac{\mathbb P(\mathbf x = x, \mathbf y = y)}{\mathbb P(\mathbf x = x)}
\end{align*}\]</div>
<p>a simple rearrangement of terms by multiplying both sides by <span class="math notranslate nohighlight">\(\mathbb P(\mathbf x = x)\)</span> gives us that:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\mathbb P(\mathbf x, \mathbf y)&amp;= 
\mathbb P(\mathbf y = y | \mathbf x = x)\mathbb P(\mathbf x = x)
\end{align*}\]</div>
<p>Substituting this in to our first definition for a conditional distribution of <span class="math notranslate nohighlight">\(\mathbf x\)</span> on <span class="math notranslate nohighlight">\(\mathbf y\)</span> gives:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\mathbb P(\mathbf x = x | \mathbf y = y) &amp;= \frac{\mathbb P(\mathbf y = y | \mathbf x = x)\mathbb P(\mathbf x = x)}{\mathbb P(\mathbf y = y)}
\end{align*}\]</div>
<p>which is Baye’s Rule.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./introduction"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="preface.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Preface</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../foundations/ch1/ch1.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">1. </span>The Network Machine Learning Landscape</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Joshua Vogelstein, Alex Loftus, and Eric Bridgeford<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>