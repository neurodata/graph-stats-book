
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>11.1. Background &#8212; Hands-on Network Machine Learning with Scikit-Learn and Graspologic</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="11.2. Foundation" href="foundation.html" />
    <link rel="prev" title="11. Network Model Theory" href="ch12.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Hands-on Network Machine Learning with Scikit-Learn and Graspologic</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../coverpage.html">
                    Hands-on Network Machine Learning with Scikit-Learn and Graspologic
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/terminology.html">
   Terminology
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch1/ch1.html">
   1. The Network Machine Learning Landscape
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/what-is-a-network.html">
     1.1. What is network machine learning?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/why-study-networks.html">
     1.2. Why do we study networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/types-nml-problems.html">
     1.3. Types of Network Machine Learning Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/examples-of-applications.html">
     1.4. Examples of applications
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch2/ch2.html">
   2. End-to-end Biology Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/big-picture.html">
     2.1. Look at the big picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/get-the-data.html">
     2.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/prepare-the-data.html">
     2.3. Prepare the Data for Network Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/select-and-train.html">
     2.4. Select and Train a Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/fine-tune.html">
     2.5. Fine-Tune your Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/discover-and-visualize.html">
     2.6. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Representations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch4/ch4.html">
   3. Properties of Networks as a Statistical Object
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/matrix-representations.html">
     3.1. Matrix Representations Of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/properties-of-networks.html">
     3.2. Properties of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/network-representations.html">
     3.3. Representations of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/regularization.html">
     3.4. Regularization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch5/ch5.html">
   4. Why Use Statistical Models?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_ER.html">
     4.1. Erdös-Rényi (ER) Random Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_SBM.html">
     4.2. Stochastic Block Models (SBM)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_RDPG.html">
     4.3. Random Dot Product Graphs (RDPG)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_IER.html">
     4.4. Inhomogeneous Erdos Renyi (IER) Random Network Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/multi-network-models.html">
     4.5. Multiple Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/models-with-covariates.html">
     4.6. Network Models with Network Covariates
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch6/ch6.html">
   5. Learning Network Representations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/estimating-parameters_mle.html">
     5.1. Estimating Parameters in Network Models via MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/why-embed-networks.html">
     5.2. Why embed networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/spectral-embedding.html">
     5.3. Spectral embedding methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/multigraph-representation-learning.html">
     5.4. Multiple-Network Representation Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/joint-representation-learning.html">
     5.5. Joint Representation Learning
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch7/ch7.html">
   6. Applications When You Have One Network
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch7/community-detection.html">
     6.1. Community Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch7/testing-differences.html">
     6.2. Testing for Differences between Groups of Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch7/model-selection.html">
     6.3. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch7/out-of-sample.html">
     6.4. Out-of-sample Embedding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch8/ch8.html">
   7. Applications for Two Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/two-sample-hypothesis.html">
     7.1. Latent Two-Sample Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/significant-communities.html">
     7.2. Two-sample hypothesis testing in SBMs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/graph-matching-vertex.html">
     7.3. Graph Matching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/multiple-vertex-nomination.html">
     7.4. Vertex Nomination For Two Networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch9/ch9.html">
   8. Applications for Many Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/anomaly-detection.html">
     8.1. Anomaly Detection For Timeseries of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/significant-edges.html">
     8.2. Testing for Significant Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/significant-vertices.html">
     8.3. Testing for Significant Vertices
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Next Steps
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../next/ch10/ch10.html">
   9. Where do we go from here?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Appendix
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch11/ch11.html">
   10. Representations (Extended)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch11/alt-reps.html">
     10.1. Alternative Network Representations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="ch12.html">
   11. Network Model Theory
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     11.1. Background
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="foundation.html">
     11.2. Foundation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ers.html">
     11.3. Erdös-Rényi (ER) Random Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sbms.html">
     11.4. Stochastic Block Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="rdpgs.html">
     11.5. RDPGs and more general network models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch13/ch13.html">
   12. Learning Representations Theory
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch13/mle-theory.html">
     12.1. Maximum Likelihood Estimate Theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch13/lse.html">
     12.2. Finding singular vectors With singular value decomposition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch13/spectral-theory.html">
     12.7. Spectral Method Theory
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch14/ch14.html">
   13. Applications (Extended)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch14/hypothesis.html">
     13.1. Hypothesis Testing with coin flips
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch14/unsupervised.html">
     13.2. Unsupervised learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch14/bayes.html">
     13.3. Bayes Plugin Classifier
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://graspologic.readthedocs.io/en/latest/">
   Graspologic Documentation
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/neurodata/graph-stats-book/master?urlpath=tree/network_machine_learning_in_python/appendix/ch12/background.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/neurodata/graph-stats-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/neurodata/graph-stats-book/issues/new?title=Issue%20on%20page%20%2Fappendix/ch12/background.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/neurodata/graph-stats-book/edit/master/network_machine_learning_in_python/appendix/ch12/background.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/appendix/ch12/background.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#notational-tendencies">
   11.1.1. Notational Tendencies
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#background-in-probability-distributions-and-distribution-functions">
   11.1.2. Background in probability distributions and distribution functions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#abuses-of-notation">
   11.1.3. Abuses of notation
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Background</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#notational-tendencies">
   11.1.1. Notational Tendencies
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#background-in-probability-distributions-and-distribution-functions">
   11.1.2. Background in probability distributions and distribution functions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#abuses-of-notation">
   11.1.3. Abuses of notation
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="background">
<span id="app-ch12-background"></span><h1><span class="section-number">11.1. </span>Background<a class="headerlink" href="#background" title="Permalink to this headline">#</a></h1>
<p>To understand this section, there are some important background points you should be get some familiarity with. First, you should be readily familiar with all of the mathematical operations and concepts from probability and statistics which are explained directly in the Terminology. We will introduce some of these background points, and the specific notations we will use for this section here. It is often the case that when you read probability or statistics books, that different instructors or professors will use different notations that will differ. We find these differences to be cumbersome, so we’re going to hopefully outline most of the common ones that people have multiple notations for here. They are:</p>
<section id="notational-tendencies">
<h2><span class="section-number">11.1.1. </span>Notational Tendencies<a class="headerlink" href="#notational-tendencies" title="Permalink to this headline">#</a></h2>
<ol class="simple">
<li><p>Extrapolatory ellipses: We might often summarize a sequence of natural numbers with ellipses; e.g., <span class="math notranslate nohighlight">\(\{1, ..., n\}\)</span>. All the ellipses mean is to just continue indexing in the meantime, until you reach the last index in the sequence. For instance, in the above sequence, the ellipses stand for <span class="math notranslate nohighlight">\(4\)</span>, <span class="math notranslate nohighlight">\(5\)</span>, <span class="math notranslate nohighlight">\(6\)</span>, … all the way up to <span class="math notranslate nohighlight">\(n-1\)</span>. These ellipses have the same interpretation in either vectors or matrices; just continue the numbering pattern upwards basically.</p></li>
<li><p>Shorthand for sequences of natural numbers: We will denote a sequence of natural numbers that goes from <span class="math notranslate nohighlight">\(1\)</span> up to <span class="math notranslate nohighlight">\(n\)</span> using the notation <span class="math notranslate nohighlight">\([n]\)</span>. Stated another way, <span class="math notranslate nohighlight">\([n] = \{1, ..., n\}\)</span>.</p></li>
<li><p>Useful numerical spaces: We will often use a number of numerical spaces in this book. The common ones will tend to be accented with a double bold-faced print. They are the natural numbers (denoted <span class="math notranslate nohighlight">\(\mathbb N\)</span>), the integers (denoted <span class="math notranslate nohighlight">\(\mathbb Z\)</span>), the non-negative integers (denoted <span class="math notranslate nohighlight">\(\mathbb Z_{\geq 0}\)</span>), the positive integers (denoted <span class="math notranslate nohighlight">\(\mathbb Z_+\)</span>), and the real numbers (denoted <span class="math notranslate nohighlight">\(\mathbb R\)</span>).</p></li>
<li><p>Shorthand for objects which can be (arbitrary) values from a particular numerical space: it will often be the case that in describing a network model, our description applies regardless of what the value is for a particular number in that description. For this reason, we tend to use notation to denote the arbitrariness of this choice. We will use the notation <span class="math notranslate nohighlight">\(x \in \mathcal S\)</span> to denote that the value <span class="math notranslate nohighlight">\(x\)</span> (which could be a scalar, a vector, or a matrix) has values which can be described by the numerical space captured by <span class="math notranslate nohighlight">\(\mathcal S\)</span>. For instance, <span class="math notranslate nohighlight">\(x \in \mathbb R\)</span> means that <span class="math notranslate nohighlight">\(x\)</span> is an arbitrary real number. <span class="math notranslate nohighlight">\(\vec x \in \mathbb R^d\)</span> means that <span class="math notranslate nohighlight">\(\vec x\)</span> is an arbitrary vector with <span class="math notranslate nohighlight">\(d\)</span> elements, where each element is an arbitrary real number; e.g., <span class="math notranslate nohighlight">\(x_i \in \mathbb R\)</span>. Another common vector representation we will see is <span class="math notranslate nohighlight">\(\vec x \in [K]^d\)</span> or <span class="math notranslate nohighlight">\(\vec x \in \{1,..., K\}^d\)</span>, which in both cases, means that each element <span class="math notranslate nohighlight">\(x_i\)</span> is an arbitrary natural number that is at most <span class="math notranslate nohighlight">\(K\)</span>. <span class="math notranslate nohighlight">\(X \in \mathbb R^{r \times c}\)</span> means that <span class="math notranslate nohighlight">\(X\)</span> is an arbitrary vector with <span class="math notranslate nohighlight">\(r\)</span> rows and <span class="math notranslate nohighlight">\(c\)</span> columns, where each element is an arbitrary real number; e.g., <span class="math notranslate nohighlight">\(x_{ij} \in \mathbb R\)</span>.</p></li>
<li><p>Vector in-line notation: with <span class="math notranslate nohighlight">\(\vec x\)</span> as a vector, we might sometimes resort to describing <span class="math notranslate nohighlight">\(\vec x\)</span> using an in-line notation which directly captures its dimensionality. We might say something like, <span class="math notranslate nohighlight">\(\vec x = (x_i)_{i = 1}^d\)</span>, which just means that <span class="math notranslate nohighlight">\(\vec x\)</span> looks like this:</p></li>
</ol>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \vec x = \begin{bmatrix}
        x_1 \\
        x_2 \\
        \vdots \\
        x_d
    \end{bmatrix}
\end{align*}\]</div>
<ol class="simple">
<li><p>Matrix in-line notation: with <span class="math notranslate nohighlight">\(X\)</span> as a matrix, we might similarly describe <span class="math notranslate nohighlight">\(X\)</span> using in-line notation which captures its number of rows and columns, with something like <span class="math notranslate nohighlight">\(X = (x_{ij})_{i \in [r], j \in [c]}\)</span> or <span class="math notranslate nohighlight">\(\left((x_{ij})_{j = 1}^c\right)_{i = 1}^r\)</span>. What this means is that we first “unroll” <span class="math notranslate nohighlight">\(X\)</span> <em>across</em> the dimension being indexed by <span class="math notranslate nohighlight">\(j\)</span> from <span class="math notranslate nohighlight">\(1\)</span> to <span class="math notranslate nohighlight">\(c\)</span>, and then <em>down</em> the dimension being indexed by <span class="math notranslate nohighlight">\(i\)</span> from <span class="math notranslate nohighlight">\(1\)</span> to <span class="math notranslate nohighlight">\(r\)</span>. In this sense, <span class="math notranslate nohighlight">\(X\)</span> would be a matrix with <span class="math notranslate nohighlight">\(r\)</span> rows and <span class="math notranslate nohighlight">\(c\)</span> columns. It would look like this:</p></li>
</ol>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    X &amp;= \begin{bmatrix}
        x_{11} &amp; ... &amp; x_{1c} \\
        \vdots &amp; \ddots &amp; \vdots \\
        x_{r1} &amp; ... &amp; x_{rc}
    \end{bmatrix}
\end{align*}\]</div>
</section>
<section id="background-in-probability-distributions-and-distribution-functions">
<h2><span class="section-number">11.1.2. </span>Background in probability distributions and distribution functions<a class="headerlink" href="#background-in-probability-distributions-and-distribution-functions" title="Permalink to this headline">#</a></h2>
<ol class="simple">
<li><p>Distribution functions for random variables: <span class="math notranslate nohighlight">\(\mathbf x \sim F\)</span>, which basically can be read as, the random variable (which is denoted with a bold-faced <span class="math notranslate nohighlight">\(\mathbf x\)</span>) has a distribution which is delineated by the distribution function <span class="math notranslate nohighlight">\(F\)</span>.” For instance, if <span class="math notranslate nohighlight">\(\mathbf x \sim Bern(p)\)</span>, this means that the random variable <span class="math notranslate nohighlight">\(\mathbf x\)</span> has a distribution which can be described by a Bernoulli random variable with probability <span class="math notranslate nohighlight">\(p\)</span>. Stated mathematically:$<span class="math notranslate nohighlight">\(Pr(\mathbf x = x) = \begin{cases}p &amp; x = 1 \\1 - p &amp; x = 0\end{cases}\)</span><span class="math notranslate nohighlight">\(In this case, what this means is that realizations of \)</span>\mathbf x<span class="math notranslate nohighlight">\(, denoted by \)</span>x<span class="math notranslate nohighlight">\( (no bold-face), are like a coin flip which lands on heads with probability \)</span>p<span class="math notranslate nohighlight">\( and tails with probability \)</span>1 - p<span class="math notranslate nohighlight">\(, where &quot;heads&quot; is akin to \)</span>x<span class="math notranslate nohighlight">\( having a value of \)</span>1<span class="math notranslate nohighlight">\(, and &quot;tails&quot; is akin to \)</span>x<span class="math notranslate nohighlight">\( having a value of \)</span>0$.</p>
<ul class="simple">
<li><p>We believe that familiarity with the Bernoulli distribution with probability parameter <span class="math notranslate nohighlight">\(p\)</span> denoted <span class="math notranslate nohighlight">\(Bern(p)\)</span>, the Categorical (Multinoulli) distribution with probability vector <span class="math notranslate nohighlight">\(\vec p\)</span>, the Normal distribution <span class="math notranslate nohighlight">\(\mathcal N(\mu, \sigma^2)\)</span>, and the Uniform distribution <span class="math notranslate nohighlight">\(Unif(a, b)\)</span> with a minimum at <span class="math notranslate nohighlight">\(a\)</span> and a maximum at <span class="math notranslate nohighlight">\(b\)</span> would be valuable to look at. If you are already familiar with these words but forget exactly what they mean, we will describe them in-line as necessary, as well.</p></li>
</ul>
</li>
<li><p>Distribution functions for random vectors: <span class="math notranslate nohighlight">\(\mathbf {\vec x} \sim F\)</span>, which can be read as, “the random vector <span class="math notranslate nohighlight">\(\mathbf x\)</span> has a distribution function which is delineated by the distribution function <span class="math notranslate nohighlight">\(F\)</span>”. In most cases, we will assume some level of statistical independence for random vectors, which basically means that instead of describing <span class="math notranslate nohighlight">\(\mathbf{\vec x}\)</span> itself directly as having a distribution, we can for our purposes describe each individual element of <span class="math notranslate nohighlight">\(\mathbf {\vec x}\)</span>, written <span class="math notranslate nohighlight">\(\mathbf x_i\)</span>, as having a distribution. This will reduce cumbersome descriptions of distribution functions for random vectors to simpler distributions functions for random variables.</p>
<ul class="simple">
<li><p>This brings us to an important aside. When we are working with vectors (either random or fixed), you might see us use the fancy word “dimensions” to describe individual elements of these vectors. The <span class="math notranslate nohighlight">\(i^{th}\)</span> dimension of a scalar vector <span class="math notranslate nohighlight">\(\vec x\)</span> is just the <span class="math notranslate nohighlight">\(i^{th}\)</span> element of that vector; e.g., <span class="math notranslate nohighlight">\(x_i\)</span>, which is a scalar. The <span class="math notranslate nohighlight">\(i^{th}\)</span> dimension of a random vector <span class="math notranslate nohighlight">\(\mathbf {\vec x}\)</span> is similar, where <span class="math notranslate nohighlight">\(\mathbf x_i\)</span> is a random variable.</p></li>
</ul>
</li>
<li><p>Distribution functions for random matrices: <span class="math notranslate nohighlight">\(\mathbf X \sim F\)</span>, which can be read as, “the random matrix <span class="math notranslate nohighlight">\(\mathbf x\)</span> has a distribution function which is delineated by the distribution function <span class="math notranslate nohighlight">\(F\)</span>”. Here, we will also tend to assume statistical independence for random matrices, which again means that instead of describing <span class="math notranslate nohighlight">\(\mathbf X\)</span>, we can just look at the individual elements of <span class="math notranslate nohighlight">\(\mathbf X\)</span>, denoted <span class="math notranslate nohighlight">\(\mathbf x_{ij}\)</span>, as having distributions.</p>
<ul class="simple">
<li><p>There is one important exception to this, which will arise for the <em>a posteriori</em> Random Dot Product Graph, which will use something called <strong>inner-product distributions</strong>. In this case, instead of describing <span class="math notranslate nohighlight">\(\mathbf X\)</span> itself, we will describe a family of distributions for random vectors, which comprise the rows of <span class="math notranslate nohighlight">\(\mathbf X\)</span>. We will try our best to explain these in an intuitive way without going outside of the scope of a graduate understanding of statistics.</p></li>
</ul>
</li>
<li><p>Parametrized functions: In statistics, there is a concept called a <strong>parameter</strong>. A parameter is a number, or a set of numbers, which uniquely defines the behavior of something. In our case, we will often be concerned with parametrized random variables, such as <span class="math notranslate nohighlight">\(\mathbf x \sim Bern(p)\)</span>, which states that <span class="math notranslate nohighlight">\(\mathbf x\)</span> is a random variable which is described by the Bernoulli distribution with <em>parameter</em> <span class="math notranslate nohighlight">\(p\)</span>. In this case, in a sense, the “<span class="math notranslate nohighlight">\(p\)</span>” is static, in that for our particular random variable <span class="math notranslate nohighlight">\(\mathbf x\)</span> that we are talking about, <span class="math notranslate nohighlight">\(p\)</span> itself isn’t going to change. However, when we talk about realizations of <span class="math notranslate nohighlight">\(\mathbf x\)</span> (which are <span class="math notranslate nohighlight">\(0\)</span>s and <span class="math notranslate nohighlight">\(1\)</span>s) these realizations can, and will, change. In this sense, when we take probability statements about <span class="math notranslate nohighlight">\(\mathbf x\)</span>, such as <span class="math notranslate nohighlight">\(Pr(\mathbf x = 1, p) = p\)</span> or <span class="math notranslate nohighlight">\(Pr(\mathbf x = 0, p) = 1 - p\)</span>, the probability is a function of <em>both</em> the parameter <span class="math notranslate nohighlight">\(p\)</span> <em>and</em> the value <span class="math notranslate nohighlight">\(x\)</span> which <span class="math notranslate nohighlight">\(\mathbf x\)</span> takes. Simultaneously, however, when we study <span class="math notranslate nohighlight">\(\mathbf x\)</span>, the <span class="math notranslate nohighlight">\(p\)</span> isn’t going to change for a given <span class="math notranslate nohighlight">\(\mathbf x\)</span>. For this reason, we explicitly delineate this difference by instead dropping the <span class="math notranslate nohighlight">\(p\)</span> down as  a subscript; e.g., <span class="math notranslate nohighlight">\(Pr(\mathbf x = x, p)\)</span> will instead be denoted as <span class="math notranslate nohighlight">\(Pr_p(\mathbf x = x)\)</span>. This makes explicit that <span class="math notranslate nohighlight">\(p\)</span> is a parameter of the distribution of <span class="math notranslate nohighlight">\(\mathbf x\)</span>, and not something that is realized (or changing) for different realizations of <span class="math notranslate nohighlight">\(\mathbf x\)</span>.</p></li>
<li><p>Arbitrary sets of parameters: When we describe random variables very generally, it is often the case that we want to be as unrestrictive as possible. For instance, if we are describing a generic random variable <span class="math notranslate nohighlight">\(\mathbf x\)</span> which could have a Bernoulli distribution with a parameter <span class="math notranslate nohighlight">\(p\)</span> <em>or</em> a Normal distribution with mean <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>, we have different sets of parameters depending on which distribution <span class="math notranslate nohighlight">\(\mathbf x\)</span> has. When a random variable could have different parameters, we will often describe the parameters using the notation <span class="math notranslate nohighlight">\(\theta\)</span>, which is just an arbitrary parameter set. For instance, in the example we gave, <span class="math notranslate nohighlight">\(\theta\)</span> could be the set <span class="math notranslate nohighlight">\(\{p\}\)</span> or the set <span class="math notranslate nohighlight">\(\{\mu, \sigma^2\}\)</span>, so we will just describe <span class="math notranslate nohighlight">\(\mathbf x\)</span> in terms of the generic parameter <span class="math notranslate nohighlight">\(\theta\)</span> instead of cumbersomely writing that the parameter set can be different every time. In this sense, <span class="math notranslate nohighlight">\(\theta\)</span> will denote an arbitrary set of parameters for a random variable <span class="math notranslate nohighlight">\(\mathbf x\)</span>, a random vector <span class="math notranslate nohighlight">\(\mathbf{\vec x}\)</span>, or a random matrix <span class="math notranslate nohighlight">\(\mathbf X\)</span>.</p></li>
</ol>
</section>
<section id="abuses-of-notation">
<h2><span class="section-number">11.1.3. </span>Abuses of notation<a class="headerlink" href="#abuses-of-notation" title="Permalink to this headline">#</a></h2>
<p>In statistical work, there is a common problem experienced called an “abuse” of notation. What this means is a particular notation choice which takes on multiple meanings. These can really complicate things for your understanding, if you see a notation defined and used as one particular thing, and then redefined and reused as another particular thing. We will use one particular abuse of notation fairly regularly. As it turns out, if we have a random variable, random vector, or random matrix, a unique distribution can be delineated <em>entirely</em> by its cumulative distribution. This is an important aside, since cumulative distribution functions aren’t distributions <em>themselves</em>, but they each equivalently delineate unique distributions. To make this description explicit, let’s say that <span class="math notranslate nohighlight">\(\mathbf x \sim \mathcal N(\mu, \sigma^2)\)</span>, which means that <span class="math notranslate nohighlight">\(\mathbf x\)</span> has the Normal distribution with mean <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>. This statement is explicit, and will not stop being true. But, equivalently, we might use an <em>abuse</em> of notation, by defining the cumulative distribution function:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    F_{\mu, \sigma^2}(x) &amp;= \int_{-\infty}^x f_{\mu, \sigma^2}(x) \text{d}x
\end{align*}\]</div>
<p>where <span class="math notranslate nohighlight">\(f_{\mu, \sigma^2}(x)\)</span> is the probability density for the normal distribution at the value <span class="math notranslate nohighlight">\(x\)</span> with mean <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma^2\)</span>. For a given choice of <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma^2\)</span>, <span class="math notranslate nohighlight">\(F_{\mu, \sigma^2}(x)\)</span> has a unique value over the range of values which <span class="math notranslate nohighlight">\(x\)</span> could take. In this sense, if we were to say that <span class="math notranslate nohighlight">\(\mathbf x \sim F_{\mu, \sigma^2}\)</span>, we have kind of “abused” the notation of the cumulative distribution function, in that the cumulative distribution function is not <em>itself</em> a description for a random variable. However, since <span class="math notranslate nohighlight">\(F_{\mu,\sigma^2}\)</span> is unique for a <span class="math notranslate nohighlight">\(\mathcal N(\mu, \sigma^2)\)</span> random variable, it “does the job” for us, and is “clear enough” for our purposes. The reason that we do this is, sometimes we might want to leave it <em>totally generic</em> as to the type of distribution that our random variable is described as. For instance, we could say <span class="math notranslate nohighlight">\(\mathbf x \sim F\)</span>, which just means that <span class="math notranslate nohighlight">\(\mathbf x\)</span> is a random variable with an arbitrary cumulative distribution function <span class="math notranslate nohighlight">\(F\)</span>. This leaves it generic to us the specifics of <span class="math notranslate nohighlight">\(F\)</span>, including the parameter choices that could be chosen, or the behavior of the specific family of random variables that it would define. This will come up when we study <em>inner product distributions</em> below.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./appendix/ch12"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="ch12.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">11. </span>Network Model Theory</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="foundation.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">11.2. </span>Foundation</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Eric Bridgeford, Alex Loftus, and Joshua Vogelstein<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>