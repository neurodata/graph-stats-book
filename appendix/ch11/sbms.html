
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>11.4. Stochastic Block Models &#8212; Hands-on Network Machine Learning with Scikit-Learn and Graspologic</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="11.5. RDPGs and more general network models" href="rdpgs.html" />
    <link rel="prev" title="11.3. Erdös-Rényi (ER) Random Networks" href="ers.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Hands-on Network Machine Learning with Scikit-Learn and Graspologic</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../coverpage.html">
                    Hands-on Network Machine Learning with Scikit-Learn and Graspologic
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/terminology.html">
   Terminology
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch1/ch1.html">
   1. The Network Machine Learning Landscape
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/what-is-a-network.html">
     1.1. What is network machine learning?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/why-study-networks.html">
     1.2. Why do we study networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/types-nml-problems.html">
     1.3. Types of Network Machine Learning Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/examples-of-applications.html">
     1.4. Examples of applications
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch2/ch2.html">
   2. End-to-end Biology Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/big-picture.html">
     2.1. Look at the big picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/get-the-data.html">
     2.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/prepare-the-data.html">
     2.3. Prepare the Data for Network Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/discover-and-visualize.html">
     2.4. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch3/ch3.html">
   3. End-to-end Business Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/big-picture.html">
     3.1. Look at the Big Picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/get-the-data.html">
     3.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/discover-and-visualize.html">
     3.3. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/prepare-the-data.html">
     3.4. Prepare the Data for Network Algorithms
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Representations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch4/ch4.html">
   4. Properties of Networks as a Statistical Object
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/matrix-representations.html">
     4.1. Matrix Representations Of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/properties-of-networks.html">
     4.2. Properties of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/network-representations.html">
     4.3. Representations of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/regularization.html">
     4.4. Regularization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch5/ch5.html">
   5. Why Use Statistical Models?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_ER.html">
     5.1. Erdös-Rényi (ER) Random Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_SBM.html">
     5.2. Stochastic Block Models (SBM)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_RDPG.html">
     5.3. Random Dot Product Graphs (RDPG)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_IER.html">
     5.4. Inhomogeneous Erdos Renyi (IER) Random Network Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/multi-network-models.html">
     5.5. Multiple Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/models-with-covariates.html">
     5.6. Network Models with Covariates
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch6/ch6.html">
   6. Learning Network Representations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/estimating-parameters_mle.html">
     6.1. Estimating Parameters in Network Models via MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/spectral-embedding.html">
     6.2. Spectral Embedding Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/estimating-parameters_spectral.html">
     6.3. Estimating Parameters for the RDPG
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/random-walk-diffusion-methods.html">
     6.4. Random walk and diffusion-based methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/graph-neural-networks.html">
     6.5. Graph Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/multigraph-representation-learning.html">
     6.6. Multiple-Network Representation Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/joint-representation-learning.html">
     6.7. Joint Representation Learning
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch7/ch7.html">
   7. Applications When You Have One Network
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch7/community-detection.html">
     7.1. Community Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch7/testing-differences.html">
     7.2. Testing for Differences between Groups of Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch7/model-selection.html">
     7.3. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch7/single-vertex-nomination.html">
     7.4. Single-Network Vertex Nomination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch7/out-of-sample.html">
     7.5. Out-of-sample Embedding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch8/ch8.html">
   8. Applications for Two Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/two-sample-hypothesis.html">
     8.1. Latent Two-Sample Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/significant-communities.html">
     8.2. Two-sample hypothesis testing in SBMs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/graph-matching-vertex.html">
     8.3. Graph Matching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/multiple-vertex-nomination.html">
     8.4. Vertex Nomination For Two Networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch9/ch9.html">
   9. Applications for Many Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/anomaly-detection.html">
     9.1. Anomaly Detection For Timeseries of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/significant-edges.html">
     9.2. Testing for Significant Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/significant-vertices.html">
     9.3. Testing for Significant Vertices
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Appendix
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch10/ch10.html">
   10. Representations (Extended)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch10/alt-reps.html">
     10.1. Alternative Network Representations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="ch11.html">
   11. Network Model Theory
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="background.html">
     11.1. Background
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="foundation.html">
     11.2. Foundation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ers.html">
     11.3. Erdös-Rényi (ER) Random Networks
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     11.4. Stochastic Block Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="rdpgs.html">
     11.5. RDPGs and more general network models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch12/ch12.html">
   12. Learning Representations Theory
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch12/mle-theory.html">
     12.1. Maximum Likelihood Estimate Theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch12/spectral-theory.html">
     12.2. Spectral Method Theory
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://graspologic.readthedocs.io/en/latest/">
   Graspologic Documentation
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/neurodata/graph-stats-book/master?urlpath=tree/network_machine_learning_in_python/appendix/ch11/sbms.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/neurodata/graph-stats-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/neurodata/graph-stats-book/issues/new?title=Issue%20on%20page%20%2Fappendix/ch11/sbms.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/neurodata/graph-stats-book/edit/master/network_machine_learning_in_python/appendix/ch11/sbms.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/appendix/ch11/sbms.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-priori-stochastic-block-model">
   11.4.1.
   <em>
    A Priori
   </em>
   Stochastic Block Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#probability">
     11.4.1.1. Probability
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-posteriori-stochastic-block-model">
   11.4.2.
   <em>
    A Posteriori
   </em>
   Stochastic Block Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     11.4.2.1. Probability
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#degree-corrected-stochastic-block-model-dcsbm">
   11.4.3. Degree-Corrected Stochastic Block Model (DCSBM)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-priori-dcsbm">
     11.4.3.1.
     <em>
      A Priori
     </em>
     DCSBM
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       11.4.3.1.1. Probability
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-posteriori-dcsbm">
     11.4.3.2.
     <em>
      A Posteriori
     </em>
     DCSBM
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Stochastic Block Models</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-priori-stochastic-block-model">
   11.4.1.
   <em>
    A Priori
   </em>
   Stochastic Block Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#probability">
     11.4.1.1. Probability
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-posteriori-stochastic-block-model">
   11.4.2.
   <em>
    A Posteriori
   </em>
   Stochastic Block Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     11.4.2.1. Probability
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#degree-corrected-stochastic-block-model-dcsbm">
   11.4.3. Degree-Corrected Stochastic Block Model (DCSBM)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-priori-dcsbm">
     11.4.3.1.
     <em>
      A Priori
     </em>
     DCSBM
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       11.4.3.1.1. Probability
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-posteriori-dcsbm">
     11.4.3.2.
     <em>
      A Posteriori
     </em>
     DCSBM
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="stochastic-block-models">
<span id="app-ch11-sbms"></span><h1><span class="section-number">11.4. </span>Stochastic Block Models<a class="headerlink" href="#stochastic-block-models" title="Permalink to this headline">#</a></h1>
<section id="a-priori-stochastic-block-model">
<h2><span class="section-number">11.4.1. </span><em>A Priori</em> Stochastic Block Model<a class="headerlink" href="#a-priori-stochastic-block-model" title="Permalink to this headline">#</a></h2>
<p>The <em>a priori</em> SBM is an SBM in which we know ahead of time (<em>a priori</em>) which nodes are in which communities. Here, we will use the variable <span class="math notranslate nohighlight">\(K\)</span> to denote the maximum number of different communities. The ordering of the communities does not matter; the community we call <span class="math notranslate nohighlight">\(1\)</span> versus <span class="math notranslate nohighlight">\(2\)</span> versus <span class="math notranslate nohighlight">\(K\)</span> is largely a symbolic distinction (the only thing that matters is that they are <em>different</em>). The <em>a priori</em> SBM has the following parameter:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Space</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(B\)</span></p></td>
<td><p>[0,1]<span class="math notranslate nohighlight">\(^{K \times K}\)</span></p></td>
<td><p>The block matrix, which assigns edge probabilities for pairs of communities</p></td>
</tr>
</tbody>
</table>
<p>To describe the <em>A Priori</em> SBM, we will designate the community each node is a part of using a vector, which has a single community assignment for each node in the network. We will call this <strong>node assignment vector</strong> <span class="math notranslate nohighlight">\(\vec{\tau}\)</span>, and it is a <span class="math notranslate nohighlight">\(n\)</span>-length vector (one element for each node) with elements which can take values from <span class="math notranslate nohighlight">\(1\)</span> to <span class="math notranslate nohighlight">\(K\)</span>. In symbols, we would say that <span class="math notranslate nohighlight">\(\vec\tau \in \{1, ..., K\}^n\)</span>. What this means is that for a given element of <span class="math notranslate nohighlight">\(\vec \tau\)</span>, <span class="math notranslate nohighlight">\(\tau_i\)</span>, that <span class="math notranslate nohighlight">\(\tau_i\)</span> is the community assignment (either <span class="math notranslate nohighlight">\(1\)</span>, <span class="math notranslate nohighlight">\(2\)</span>, so on and so forth up to <span class="math notranslate nohighlight">\(K\)</span>) for the <span class="math notranslate nohighlight">\(i^{th}\)</span> node. If there we hahd an example where there were <span class="math notranslate nohighlight">\(2\)</span> communities (<span class="math notranslate nohighlight">\(K = 2\)</span>) for instance, and the first two nodes are in community <span class="math notranslate nohighlight">\(1\)</span> and the second two in community <span class="math notranslate nohighlight">\(2\)</span>, then <span class="math notranslate nohighlight">\(\vec\tau\)</span> would be a vector which looks like:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \vec\tau &amp;= \begin{bmatrix}1 &amp; 1 &amp; 2 &amp; 2\end{bmatrix}^\top
\end{align*}\]</div>
<p>Next, let’s discuss the matrix <span class="math notranslate nohighlight">\(B\)</span>, which is known as the <strong>block matrix</strong> of the SBM. We write down that <span class="math notranslate nohighlight">\(B \in [0, 1]^{K \times K}\)</span>, which means that the block matrix is a matrix with <span class="math notranslate nohighlight">\(K\)</span> rows and <span class="math notranslate nohighlight">\(K\)</span> columns. If we have a pair of nodes and know which of the <span class="math notranslate nohighlight">\(K\)</span> communities each node is from, the block matrix tells us the probability that those two nodes are connected. If our networks are simple, the matrix <span class="math notranslate nohighlight">\(B\)</span> is also symmetric, which means that if <span class="math notranslate nohighlight">\(b_{kk'} = p\)</span> where <span class="math notranslate nohighlight">\(p\)</span> is a probability, that <span class="math notranslate nohighlight">\(b_{k'k} = p\)</span>, too. The requirement of <span class="math notranslate nohighlight">\(B\)</span> to be symmetric exists <em>only</em> if we are dealing with undirected networks.</p>
<p>Finally, let’s think about how to write down the generative model for the <em>a priori</em> SBM. Intuitionally what we want to reflect is, if we know that node <span class="math notranslate nohighlight">\(i\)</span> is in community <span class="math notranslate nohighlight">\(k'\)</span> and node <span class="math notranslate nohighlight">\(j\)</span> is in community <span class="math notranslate nohighlight">\(k\)</span>, that the <span class="math notranslate nohighlight">\((k', k)\)</span> entry of the block matrix is the probability that <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> are connected. We say that given  <span class="math notranslate nohighlight">\(\tau_i = k'\)</span> and <span class="math notranslate nohighlight">\(\tau_j = k\)</span>, <span class="math notranslate nohighlight">\(\mathbf a_{ij}\)</span> is sampled independently from a <span class="math notranslate nohighlight">\(Bern(b_{k' k})\)</span> distribution for all <span class="math notranslate nohighlight">\(j &gt; i\)</span>. Note that the adjacencies <span class="math notranslate nohighlight">\(\mathbf a_{ij}\)</span> are not <em>necessarily</em> identically distributed, because the probability depends on the community of edge <span class="math notranslate nohighlight">\((i,j)\)</span>. If <span class="math notranslate nohighlight">\(\mathbf A\)</span> is an <em>a priori</em> SBM network with parameter <span class="math notranslate nohighlight">\(B\)</span>, and <span class="math notranslate nohighlight">\(\vec{\tau}\)</span> is a realization of the node-assignment vector, we write that <span class="math notranslate nohighlight">\(\mathbf A \sim SBM_{n,\vec \tau}(B)\)</span>.</p>
<section id="probability">
<h3><span class="section-number">11.4.1.1. </span>Probability<a class="headerlink" href="#probability" title="Permalink to this headline">#</a></h3>
<p>What does the probability for the <em>a priori</em> SBM look like? In our previous description, we admittedly simplified things to an extent to keep the wording down. In truth, we model the <em>a priori</em> SBM using a <em>latent variable</em> model, which means that the node assignment vector, <span class="math notranslate nohighlight">\(\vec{\pmb \tau}\)</span>, is treated as <em>random</em>. For the case of the <em>a priori</em> SBM, it just so happens that we <em>know</em> the specific value that this latent variable <span class="math notranslate nohighlight">\(\vec{\pmb \tau}\)</span> takes, <span class="math notranslate nohighlight">\(\vec \tau\)</span>, ahead of time.</p>
<p>Fortunately, since <span class="math notranslate nohighlight">\(\vec \tau\)</span> is a <em>parameter</em> of the <em>a priori</em> SBM, the probability is a bit simpler than for the <em>a posteriori</em> SBM. This is because the <em>a posteriori</em> SBM requires an integration over potential realizations of <span class="math notranslate nohighlight">\(\vec{\pmb \tau}\)</span>, whereas the <em>a priori</em> SBM does not, since we already know that <span class="math notranslate nohighlight">\(\vec{\pmb \tau}\)</span> was realized as <span class="math notranslate nohighlight">\(\vec\tau\)</span>.</p>
<p>Putting these steps together gives us that:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
Pr_\theta(A) &amp;= Pr_{\theta}(\mathbf A = A | \vec{\pmb \tau} = \vec\tau) \\
&amp;= \prod_{j &gt; i} Pr_\theta(\mathbf a_{ij} = a_{ij} | \vec{\pmb \tau} = \vec\tau),\;\;\;\;\textrm{Independence Assumption}
\end{align*}\]</div>
<p>Next, for the <em>a priori</em> SBM, we know that each edge <span class="math notranslate nohighlight">\(\mathbf a_{ij}\)</span> only <em>actually</em> depends on the community assignments of nodes <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>, so we know that <span class="math notranslate nohighlight">\(Pr_{\theta}(\mathbf a_{ij} = a_{ij} | \vec{\pmb \tau} = \vec\tau) = Pr(\mathbf a_{ij} = a_{ij} | \tau_i = k', \tau_j = k)\)</span>, where <span class="math notranslate nohighlight">\(k\)</span> and <span class="math notranslate nohighlight">\(k'\)</span> are any of the <span class="math notranslate nohighlight">\(K\)</span> possible communities. This is because the community assignments of nodes that are not nodes <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> do not matter for edge <span class="math notranslate nohighlight">\(ij\)</span>, due to the independence assumption.</p>
<p>Next, let’s think about the probability matrix <span class="math notranslate nohighlight">\(P = (p_{ij})\)</span> for the <em>a priori</em> SBM. We know that, given that <span class="math notranslate nohighlight">\(\tau_i = k'\)</span> and <span class="math notranslate nohighlight">\(\tau_j = k\)</span>,  each adjacency <span class="math notranslate nohighlight">\(\mathbf a_{ij}\)</span> is sampled independently and identically from a <span class="math notranslate nohighlight">\(Bern(b_{k',k})\)</span> distribution. This means that <span class="math notranslate nohighlight">\(p_{ij} = b_{k',k}\)</span>. Completing our analysis from above:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    Pr_\theta(A) &amp;= \prod_{j &gt; i} b_{k'k}^{a_{ij}}(1 - b_{k'k})^{1 - a_{ij}} \\
    &amp;= \prod_{k,k' \in [K]}b_{k'k}^{m_{k'k}}(1 - b_{k'k})^{n_{k'k} - m_{k'k}}
\end{align*}\]</div>
<p>Where <span class="math notranslate nohighlight">\(n_{k' k}\)</span> denotes the total number of edges possible between nodes assigned to community <span class="math notranslate nohighlight">\(k'\)</span> and nodes assigned to community <span class="math notranslate nohighlight">\(k\)</span>. That is, <span class="math notranslate nohighlight">\(n_{k' k} = \sum_{j &gt; i} \mathbb 1_{\tau_i = k'}\mathbb 1_{\tau_j = k}\)</span>. Further, we will use <span class="math notranslate nohighlight">\(m_{k' k}\)</span> to denote the total number of edges observed between these two communities. That is, <span class="math notranslate nohighlight">\(m_{k' k} = \sum_{j &gt; i}\mathbb 1_{\tau_i = k'}\mathbb 1_{\tau_j = k}a_{ij}\)</span>. Note that for a single <span class="math notranslate nohighlight">\((k',k)\)</span> community pair, that the probability is analogous to the probability of a realization of an ER random variable.</p>
<!--- We can formalize this a bit more explicitly. If we let $A^{\ell k}$ be defined as the subgraph *induced* by the edges incident nodes in community $\ell$ and those in community $k$, then we can say that $A^{\ell k}$ is a directed ER random network, --->
<p>Like the ER model, there are again equivalence classes of the sample space <span class="math notranslate nohighlight">\(\mathcal A_n\)</span> in terms of their probability. For a two-community setting, with <span class="math notranslate nohighlight">\(\vec \tau\)</span> and <span class="math notranslate nohighlight">\(B\)</span> given, the equivalence classes are the sets:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    E_{a,b,c}(\vec \tau, B) &amp;= \left\{A \in \mathcal A_n : m_{11} = a, m_{21}=m_{12} = b, m_{22} = c\right\}
\end{align*}\]</div>
<p>The number of equivalence classes possible scales with the number of communities, and the manner in which nodes are assigned to communities (particularly, the number of nodes in each community).</p>
</section>
</section>
<section id="a-posteriori-stochastic-block-model">
<h2><span class="section-number">11.4.2. </span><em>A Posteriori</em> Stochastic Block Model<a class="headerlink" href="#a-posteriori-stochastic-block-model" title="Permalink to this headline">#</a></h2>
<p>In the <em>a posteriori</em> Stochastic Block Model (SBM), we consider that node assignment to one of <span class="math notranslate nohighlight">\(K\)</span> communities is a random variable, that we <em>don’t</em> know already like te <em>a priori</em> SBM. We’re going to see a funky word come up, that you’re probably not familiar with, the <strong><span class="math notranslate nohighlight">\(K\)</span> probability simplex</strong>. What the heck is a probability simplex?</p>
<p>The intuition for a simplex is probably something you’re very familiar with, but just haven’t seen a word describe. Let’s say I have a vector, <span class="math notranslate nohighlight">\(\vec\pi = (\pi_k)_{k \in [K]}\)</span>, which has a total of <span class="math notranslate nohighlight">\(K\)</span> elements. <span class="math notranslate nohighlight">\(\vec\pi\)</span> will be a vector, which indicates the <em>probability</em> that a given node is assigned to each of our <span class="math notranslate nohighlight">\(K\)</span> communities, so we need to impose some additional constraints. Symbolically, we would say that, for all <span class="math notranslate nohighlight">\(i\)</span>, and for all <span class="math notranslate nohighlight">\(k\)</span>:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \pi_k = Pr(\pmb\tau_i = k)
\end{align*}\]</div>
<p>The <span class="math notranslate nohighlight">\(\vec \pi\)</span> we’re going to use has a very special property: all of its elements are non-negative: for all <span class="math notranslate nohighlight">\(\pi_k\)</span>, <span class="math notranslate nohighlight">\(\pi_k \geq 0\)</span>. This makes sense since <span class="math notranslate nohighlight">\(\pi_k\)</span> is being used to represent the probability of a node <span class="math notranslate nohighlight">\(i\)</span> being in group <span class="math notranslate nohighlight">\(k\)</span>, so it certainly can’t be negative. Further, there’s another thing that we want our <span class="math notranslate nohighlight">\(\vec\pi\)</span> to have: in order for each element <span class="math notranslate nohighlight">\(\pi_k\)</span> to indicate the probability of something to be assigned to <span class="math notranslate nohighlight">\(k\)</span>, we need all of the <span class="math notranslate nohighlight">\(\pi_k\)</span>s to sum up to one. This is because of something called the Law of Total Probability. If we have <span class="math notranslate nohighlight">\(K\)</span> total values that <span class="math notranslate nohighlight">\(\pmb \tau_i\)</span> could take, then it is the case that:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \sum_{k=1}^K Pr(\pmb \tau_i = k) = \sum_{k = 1}^K \pi_k = 1
\end{align*}\]</div>
<p>So, back to our question: how does a probability simplex fit in? Well, the <span class="math notranslate nohighlight">\(K\)</span> probability simplex describes all of the possible values that our vector <span class="math notranslate nohighlight">\(\vec\pi\)</span> could take! In symbols, the <span class="math notranslate nohighlight">\(K\)</span> probability simplex is:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\left\{\vec\pi : \text{for all $k$ }\pi_k \geq 0, \sum_{k = 1}^K \pi_k = 1 \right\}
\end{align*}\]</div>
<p>So the <span class="math notranslate nohighlight">\(K\)</span> probability simplex is just the space for all possible vectors which could indicate assignment probabilities to one of <span class="math notranslate nohighlight">\(K\)</span> communities.</p>
<p>What does the probability simplex look like? Below, we take a look at the <span class="math notranslate nohighlight">\(2\)</span>-probability simplex (2-d <span class="math notranslate nohighlight">\(\vec\pi\)</span>s) and the <span class="math notranslate nohighlight">\(3\)</span>-probability simplex (3-dimensional <span class="math notranslate nohighlight">\(\vec\pi\)</span>s):</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d.art3d</span> <span class="kn">import</span> <span class="n">Poly3DCollection</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">fig</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">figaspect</span><span class="p">(</span><span class="mf">.5</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Probability Simplexes&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">=</span><span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">.5</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">.5</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;$\pi_1$&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;$\pi_2$&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;2-probability simplex&quot;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">=</span><span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">z</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">verts</span> <span class="o">=</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">z</span><span class="p">))]</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_collection3d</span><span class="p">(</span><span class="n">Poly3DCollection</span><span class="p">(</span><span class="n">verts</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="n">elev</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">azim</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">.5</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">.5</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_zticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">.5</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;$\pi_1$&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;$\pi_2$&quot;</span><span class="p">)</span>
<span class="n">h</span><span class="o">=</span><span class="n">ax</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s2">&quot;$\pi_3$&quot;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;3-probability simplex&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/sbms_2_0.png" src="../../_images/sbms_2_0.png" />
</div>
</div>
<p>The values of <span class="math notranslate nohighlight">\(\vec\pi = (\pi)\)</span> that are in the <span class="math notranslate nohighlight">\(K\)</span>-probability simplex are indicated by the shaded region of each figure. This comprises the <span class="math notranslate nohighlight">\((\pi_1, \pi_2)\)</span> pairs that fall along a diagonal line from <span class="math notranslate nohighlight">\((0,1)\)</span> to <span class="math notranslate nohighlight">\((1,0)\)</span> for the <span class="math notranslate nohighlight">\(2\)</span>-simplex, and the <span class="math notranslate nohighlight">\((\pi_1, \pi_2, \pi_3)\)</span> tuples that fall on the surface of the triangular shape above with nodes at <span class="math notranslate nohighlight">\((1,0,0)\)</span>, <span class="math notranslate nohighlight">\((0,1,0)\)</span>, and <span class="math notranslate nohighlight">\((0,0,1)\)</span>.</p>
<p>This model has the following parameters:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Space</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(\vec \pi\)</span></p></td>
<td><p>the <span class="math notranslate nohighlight">\(K\)</span> probability simplex</p></td>
<td><p>The probability of a node being assigned to community <span class="math notranslate nohighlight">\(K\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(B\)</span></p></td>
<td><p>[0,1]<span class="math notranslate nohighlight">\(^{K \times K}\)</span></p></td>
<td><p>The block matrix, which assigns edge probabilities for pairs of communities</p></td>
</tr>
</tbody>
</table>
<p>The <em>a posteriori</em> SBM is a bit more complicated than the <em>a priori</em> SBM. We will think about the <em>a posteriori</em> SBM as a variation of the <em>a priori</em> SBM, where instead of the node-assignment vector being treated as a known fixed value (the community assignments), we will treat it as <em>unknown</em>. <span class="math notranslate nohighlight">\(\vec{\pmb \tau}\)</span> is called a <em>latent variable</em>, which means that it is a quantity that is never actually observed, but which will be useful for describing our model. In this case, <span class="math notranslate nohighlight">\(\vec{\pmb \tau}\)</span> takes values in the space <span class="math notranslate nohighlight">\(\{1,...,K\}^n\)</span>. This means that for a given realization of <span class="math notranslate nohighlight">\(\vec{\pmb \tau}\)</span>, denoted by <span class="math notranslate nohighlight">\(\vec \tau\)</span>, that for each of the <span class="math notranslate nohighlight">\(n\)</span> nodes in the network, we suppose that an integer value between <span class="math notranslate nohighlight">\(1\)</span> and <span class="math notranslate nohighlight">\(K\)</span> indicates which community a node is from. Statistically, we write that the node assignment for node <span class="math notranslate nohighlight">\(i\)</span>, denoted by <span class="math notranslate nohighlight">\(\pmb \tau_i\)</span>, is sampled independently and identically from <span class="math notranslate nohighlight">\(Categorical(\vec \pi)\)</span>. Stated another way, the vector <span class="math notranslate nohighlight">\(\vec\pi\)</span> indicates the probability <span class="math notranslate nohighlight">\(\pi_k\)</span> of assignment to each community <span class="math notranslate nohighlight">\(k\)</span> in the network.</p>
<p>The matrix <span class="math notranslate nohighlight">\(B\)</span> behaves exactly the same as it did with the <em>a posteriori</em> SBM. Finally, let’s think about how to write down the generative model in the <em>a posteriori</em> SBM. The model for the <em>a posteriori</em> SBM is, in fact, nearly the same as for the <em>a priori</em> SBM: we still say that given <span class="math notranslate nohighlight">\(\tau_i = k'\)</span> and <span class="math notranslate nohighlight">\(\tau_j = k\)</span>, that <span class="math notranslate nohighlight">\(\mathbf a_{ij}\)</span> are independent <span class="math notranslate nohighlight">\(Bern(b_{k'k})\)</span>. Here, however, we also describe that <span class="math notranslate nohighlight">\(\pmb \tau_i\)</span> are sampled independent and identically from <span class="math notranslate nohighlight">\(Categorical(\vec\pi)\)</span>, as we learned above. If <span class="math notranslate nohighlight">\(\mathbf A\)</span> is the adjacency matrix for an <em>a posteriori</em> SBM network with parameters <span class="math notranslate nohighlight">\(\vec \pi\)</span> and <span class="math notranslate nohighlight">\(B\)</span>, we write that <span class="math notranslate nohighlight">\(\mathbf A \sim SBM_n(\vec \pi, B)\)</span>.</p>
<section id="id1">
<h3><span class="section-number">11.4.2.1. </span>Probability<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<p>What does the probability for the <em>a posteriori</em> SBM look like? In this case, <span class="math notranslate nohighlight">\(\theta = (\vec \pi, B)\)</span> are the parameters for the model, so the probability for a realization <span class="math notranslate nohighlight">\(A\)</span> of <span class="math notranslate nohighlight">\(\mathbf A\)</span> is:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
Pr_\theta(A) &amp;= Pr_\theta(\mathbf A = A)
\end{align*}\]</div>
<p>Next, we use the fact that the probability that <span class="math notranslate nohighlight">\(\mathbf A = A\)</span> is, in fact, the <em>integration</em> (over realizations of <span class="math notranslate nohighlight">\(\vec{\pmb \tau}\)</span>) of the joint <span class="math notranslate nohighlight">\((\mathbf A, \vec{\pmb \tau})\)</span>. In this case, we will let <span class="math notranslate nohighlight">\(\mathcal T = \{1,...,K\}^n\)</span> be the space of all possible realizations that <span class="math notranslate nohighlight">\(\vec{\pmb \tau}\)</span> could take:</p>
<div class="amsmath math notranslate nohighlight" id="equation-b5ee6874-5b8f-4fad-a95a-2af70918e70e">
<span class="eqno">(11.1)<a class="headerlink" href="#equation-b5ee6874-5b8f-4fad-a95a-2af70918e70e" title="Permalink to this equation">#</a></span>\[\begin{align}
Pr_\theta(A)&amp;= \sum_{\vec \tau \in \mathcal T} Pr_\theta(\mathbf A = A, \vec{\pmb \tau} = \vec \tau) 
\end{align}\]</div>
<p>Next, remember that by definition of a conditional probability for a random variable <span class="math notranslate nohighlight">\(\mathbf x\)</span> taking value <span class="math notranslate nohighlight">\(x\)</span> conditioned on random variable <span class="math notranslate nohighlight">\(\mathbf y\)</span> taking the value <span class="math notranslate nohighlight">\(y\)</span>, that <span class="math notranslate nohighlight">\(Pr(\mathbf x = x | \mathbf y = y) = \frac{Pr(\mathbf x = x, \mathbf y = y)}{Pr(\mathbf y = y)}\)</span>. Note that by multiplying through by <span class="math notranslate nohighlight">\(\mathbf P(\mathbf y = y)\)</span>, we can see that <span class="math notranslate nohighlight">\(Pr(\mathbf x = x, \mathbf y = y) = Pr(\mathbf x = x| \mathbf y = y)Pr(\mathbf y = y)\)</span>. Using this logic for <span class="math notranslate nohighlight">\(\mathbf A\)</span> and <span class="math notranslate nohighlight">\(\vec{\pmb \tau}\)</span>:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
Pr_\theta(A) &amp;=\sum_{\vec \tau \in \mathcal T} Pr_\theta(\mathbf A = A| \vec{\pmb \tau} = \vec \tau)Pr(\vec{\pmb \tau} = \vec \tau)
\end{align*}\]</div>
<p>Intuitively, for each term in the sum, we are treating <span class="math notranslate nohighlight">\(\vec{\pmb \tau}\)</span> as taking a fixed value, <span class="math notranslate nohighlight">\(\vec\tau\)</span>, to evaluate this probability statement.</p>
<p>We will start by describing <span class="math notranslate nohighlight">\(Pr(\vec{\pmb \tau} = \vec\tau)\)</span>. Remember that for <span class="math notranslate nohighlight">\(\vec{\pmb \tau}\)</span>, that each entry <span class="math notranslate nohighlight">\(\pmb \tau_i\)</span> is sampled <em>independently and identically</em> from <span class="math notranslate nohighlight">\(Categorical(\vec \pi)\)</span>.The probability mass for a <span class="math notranslate nohighlight">\(Categorical(\vec \pi)\)</span>-valued random variable is <span class="math notranslate nohighlight">\(Pr(\pmb \tau_i = \tau_i; \vec \pi) = \pi_{\tau_i}\)</span>. Finally, note that if we are taking the products of <span class="math notranslate nohighlight">\(n\)</span> <span class="math notranslate nohighlight">\(\pi_{\tau_i}\)</span> terms, that many of these values will end up being the same. Consider, for instance, if the vector <span class="math notranslate nohighlight">\(\tau = [1,2,1,2,1]\)</span>. We end up with three terms of <span class="math notranslate nohighlight">\(\pi_1\)</span>, and two terms of <span class="math notranslate nohighlight">\(\pi_2\)</span>, and it does not matter which order we multiply them in. Rather, all we need to keep track of are the counts of each <span class="math notranslate nohighlight">\(\pi\)</span> term. Written another way, we can use the indicator that <span class="math notranslate nohighlight">\(\tau_i = k\)</span>, given by <span class="math notranslate nohighlight">\(\mathbb 1_{\tau_i = k}\)</span>, and a running counter over all of the community probability assignments <span class="math notranslate nohighlight">\(\pi_k\)</span> to make this expression a little more sensible. We will use the symbol <span class="math notranslate nohighlight">\(n_k = \sum_{i = 1}^n \mathbb 1_{\tau_i = k}\)</span> to denote this value, which is the number of nodes in community <span class="math notranslate nohighlight">\(k\)</span>:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
Pr_\theta(\vec{\pmb \tau} = \vec \tau) &amp;= \prod_{i = 1}^n Pr_\theta(\pmb \tau_i = \tau_i),\;\;\;\;\textrm{Independence Assumption} \\
&amp;= \prod_{i = 1}^n \pi_{\tau_i} ,\;\;\;\;\textrm{p.m.f. of a Categorical R.V.}\\
&amp;= \prod_{k = 1}^K \pi_{k}^{n_k},\;\;\;\;\textrm{Reorganizing what we are taking products of}
\end{align*}\]</div>
<p>Next, let’s think about the conditional probability term, <span class="math notranslate nohighlight">\(Pr_\theta(\mathbf A = A \big | \vec{\pmb \tau} = \vec \tau)\)</span>. Remember that the entries are all independent conditional on <span class="math notranslate nohighlight">\(\vec{\pmb \tau}\)</span> taking the value <span class="math notranslate nohighlight">\(\vec\tau\)</span>. It turns out this is exactly the same result that we obtained for the <em>a priori</em> SBM:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
Pr_\theta(\mathbf A = A \big | \vec{\pmb \tau} = \vec \tau)
&amp;= \prod_{k',k} b_{\ell k}^{m_{k' k}}(1 - b_{k' k})^{n_{k' k} - m_{k' k}}
\end{align*}\]</div>
<p>Combining these into the integrand gives:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
Pr_\theta(A) &amp;= \sum_{\vec \tau \in \mathcal T} Pr_\theta(\mathbf A = A \big | \vec{\pmb \tau} = \vec \tau) Pr_\theta(\vec{\pmb \tau} = \vec \tau) \\
&amp;= \sum_{\vec \tau \in \mathcal T} \prod_{k = 1}^K \left[\pi_k^{n_k}\cdot \prod_{k'=1}^K b_{k' k}^{m_{k' k}}(1 - b_{k' k})^{n_{k' k} - m_{k' k}}\right]
\end{align*}\]</div>
<p>Evaluating this sum explicitly proves to be relatively tedious and is a bit outside of the scope of this book, so we will omit it here.</p>
</section>
</section>
<section id="degree-corrected-stochastic-block-model-dcsbm">
<h2><span class="section-number">11.4.3. </span>Degree-Corrected Stochastic Block Model (DCSBM)<a class="headerlink" href="#degree-corrected-stochastic-block-model-dcsbm" title="Permalink to this headline">#</a></h2>
<p>Let’s think back to our school example for the Stochastic Block Model. Remember, we had 100 students, each of whom could go to one of two possible schools: school one or school two. Our network had 100 nodes, representing each of the students. We said that the school for which each student attended was represented by their node assignment <span class="math notranslate nohighlight">\(\tau_i\)</span> to one of two possible communities. The matrix <span class="math notranslate nohighlight">\(B\)</span> was the block probaability matrix, where <span class="math notranslate nohighlight">\(b_{11}\)</span> was the probability that students in school one were friends, <span class="math notranslate nohighlight">\(b_{22}\)</span> was the probability that students in school two were friends, and <span class="math notranslate nohighlight">\(b_{12} = b_{21}\)</span> was the probability that students were friends if they did not go to the same school. In this case, we said that <span class="math notranslate nohighlight">\(\mathbf A\)</span> was an <span class="math notranslate nohighlight">\(SBM_n(\tau, B)\)</span> random network.</p>
<p>When would this setup not make sense? Let’s say that Alice and Bob both go to the same school, but Alice is more popular than Bob. In general since Alice is more popular than Bob, we might want to say that for any clasasmate, Alice gets an additional “popularity benefit” to her probability of being friends with the other classmate, and Bob gets an “unpopularity penalty.” The problem here is that within a single community of an SBM, the SBM assumes that the <strong>node degree</strong> (the number of nodes each nodes is connected to) is the <em>same</em> for all nodes within a single community. This means that we would be unable to reflect this benefit/penalty system to Alice and Bob, since each student will have the same number of friends, on average. This problem is referred to as <strong>community degree homogeneity</strong> in a Stochastic Block Model Network. Community degree homogeneity just means that the node degree is <em>homogeneous</em>, or the same, for all nodes within a community.</p>
<div class="admonition-degree-homogeneity-in-a-stochastic-block-model-network admonition">
<p class="admonition-title">Degree Homogeneity in a Stochastic Block Model Network</p>
<p>Suppose that <span class="math notranslate nohighlight">\(\mathbf A \sim SBM_{n, \vec\tau}(B)\)</span>, where <span class="math notranslate nohighlight">\(\mathbf A\)</span> has <span class="math notranslate nohighlight">\(K=2\)</span> communities. What is the node degree of each node in <span class="math notranslate nohighlight">\(\mathbf A\)</span>?</p>
<p>For an arbitrary node <span class="math notranslate nohighlight">\(v_i\)</span> which is in community <span class="math notranslate nohighlight">\(k\)</span> (either one or two), we will compute the expectated value of the degree <span class="math notranslate nohighlight">\(deg(v_i)\)</span>, written <span class="math notranslate nohighlight">\(\mathbb E\left[deg(v_i); \tau_i = k\right]\)</span>. We will let <span class="math notranslate nohighlight">\(n_k\)</span> represent the number of nodes whose node assignments <span class="math notranslate nohighlight">\(\tau_i\)</span> are to community <span class="math notranslate nohighlight">\(k\)</span>. Let’s see what happens:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \mathbb E\left[deg(v_i); \tau_i = k\right] &amp;= \mathbb E\left[\sum_{j = 1}^n \mathbf a_{ij}\right] \\
    &amp;= \sum_{j = 1}^n \mathbb E[\mathbf a_{ij}]
\end{align*}\]</div>
<p>We use the <em>linearity of expectation</em> again to get from the top line to the second line. Next, instead of summing over all the nodes, we’ll break the sum up into the nodes which are in the same community as node <span class="math notranslate nohighlight">\(i\)</span>, and the ones in the <em>other</em> community <span class="math notranslate nohighlight">\(k'\)</span>. We use the notation <span class="math notranslate nohighlight">\(k'\)</span> to emphasize that <span class="math notranslate nohighlight">\(k\)</span> and <span class="math notranslate nohighlight">\(k'\)</span> are different values:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \mathbb E\left[deg(v_i); \tau_i = k\right] &amp;= \sum_{j : i \neq j, \tau_j = k} \mathbb E\left[\mathbf a_{ij}\right] + \sum_{j : \tau_j =k'} \mathbb E[\mathbf a_{ij}]
\end{align*}\]</div>
<p>In the first sum, we have <span class="math notranslate nohighlight">\(n_k-1\)</span> total edges (the number of nodes that aren’t node <span class="math notranslate nohighlight">\(i\)</span>, but are in the same community), and in the second sum, we have <span class="math notranslate nohighlight">\(n_{k'}\)</span> total edges (the number of nodes that are in the other community). Finally, we will use that the probability of an edge in the same community is <span class="math notranslate nohighlight">\(b_{kk}\)</span>, but the probability of an edge between the communities is <span class="math notranslate nohighlight">\(b_{k' k}\)</span>. Finally, we will use that the expected value of an adjacency <span class="math notranslate nohighlight">\(\mathbf a_{ij}\)</span> which is Bernoulli distributed is its probability:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \mathbb E\left[deg(v_i); \tau_i = k\right] &amp;= \sum_{j : i \neq j, \tau_j = k} b_{kk} + \sum_{j : \tau_j = \ell} b_{kk'},\;\;\;\;\mathbf a_{ij}\textrm{ are Bernoulli distributed} \\
    &amp;= (n_k - 1)b_{kk} + n_{k'} b_{kk'}
\end{align*}\]</div>
<p>This holds for any node <span class="math notranslate nohighlight">\(i\)</span> which is in community <span class="math notranslate nohighlight">\(k\)</span>. Therefore, the expected node degree is the same, or <strong>homogeneous</strong>, within a community of an SBM.</p>
</div>
<p>To address this limitation, we turn to the Degree-Corrected Stochastic Block Model, or DCSBM. As with the Stochastic Block Model, there is both a <em>a priori</em> and <em>a posteriori</em> DCSBM.</p>
<section id="a-priori-dcsbm">
<h3><span class="section-number">11.4.3.1. </span><em>A Priori</em> DCSBM<a class="headerlink" href="#a-priori-dcsbm" title="Permalink to this headline">#</a></h3>
<p>Like the <em>a priori</em> SBM, the <em>a priori</em> DCSBM is where we know which nodes are in which communities ahead of time. Here, we will use the variable <span class="math notranslate nohighlight">\(K\)</span> to denote the number of different communiies. The <em>a priori</em> DCSBM has the following two parameters:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Space</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(B\)</span></p></td>
<td><p>[0,1]<span class="math notranslate nohighlight">\(^{K \times K}\)</span></p></td>
<td><p>The block matrix, which assigns edge probabilities for pairs of communities</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(\vec\theta\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mathbb R^n_+\)</span></p></td>
<td><p>The degree correction vector, which adjusts the degree for pairs of nodes</p></td>
</tr>
</tbody>
</table>
<p>The latent community assignment vector <span class="math notranslate nohighlight">\(\vec{\pmb \tau}\)</span> with a known <em>a priori</em> realization <span class="math notranslate nohighlight">\(\vec{\tau}\)</span> and the block matrix <span class="math notranslate nohighlight">\(B\)</span> are exactly the same for the <em>a priori</em> DCSBM as they were for the <em>a priori</em> SBM.</p>
<p>The vector <span class="math notranslate nohighlight">\(\vec\theta\)</span> is the degree correction vector. Each entry <span class="math notranslate nohighlight">\(\theta_i\)</span> is a positive scalar. <span class="math notranslate nohighlight">\(\theta_i\)</span> defines how much more (or less) edges associated with node <span class="math notranslate nohighlight">\(i\)</span> are connected due to their association with node <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p>Finally, let’s think about how to write down the generative model for the <em>a priori</em> DCSBM. We say that <span class="math notranslate nohighlight">\(\tau_i = k'\)</span> and <span class="math notranslate nohighlight">\(\tau_j = k\)</span>, <span class="math notranslate nohighlight">\(\mathbf a_{ij}\)</span> is sampled independently from a <span class="math notranslate nohighlight">\(Bern(\theta_i \theta_j b_{k'k})\)</span> distribution for all <span class="math notranslate nohighlight">\(j &gt; i\)</span>. As we can see, <span class="math notranslate nohighlight">\(\theta_i\)</span> in a sense is “correcting” the probabilities of each adjacency to node <span class="math notranslate nohighlight">\(i\)</span> to be higher, or lower, depending on the value of <span class="math notranslate nohighlight">\(\theta_i\)</span> that that which is given by the block probabilities <span class="math notranslate nohighlight">\(b_{\ell k}\)</span>. If <span class="math notranslate nohighlight">\(\mathbf A\)</span> is an <em>a priori</em> DCSBM network with parameters and <span class="math notranslate nohighlight">\(B\)</span>, we write that <span class="math notranslate nohighlight">\(\mathbf A \sim DCSBM_{n,\vec\tau}(\vec \theta, B)\)</span>.</p>
<section id="id2">
<h4><span class="section-number">11.4.3.1.1. </span>Probability<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h4>
<p>The derivation for the probability is the same as for the <em>a priori</em> SBM, with the change that <span class="math notranslate nohighlight">\(p_{ij} = \theta_i \theta_j b_{k'k}\)</span> instead of just <span class="math notranslate nohighlight">\(b_{k'k}\)</span>. This gives that the probability turns out to be:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    Pr_\theta(A) &amp;= \prod_{j &gt; i} \left(\theta_i \theta_j b_{k'k}\right)^{a_{ij}}\left(1 - \theta_i \theta_j b_{k'k}\right)^{1 - a_{ij}}
\end{align*}\]</div>
<p>The expression doesn’t simplify much more due to the fact that the probabilities are dependent on the particular <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>, so we can’t just reduce the statement in terms of <span class="math notranslate nohighlight">\(n_{k'k}\)</span> and <span class="math notranslate nohighlight">\(m_{k'k}\)</span> like for the SBM.</p>
</section>
</section>
<section id="a-posteriori-dcsbm">
<h3><span class="section-number">11.4.3.2. </span><em>A Posteriori</em> DCSBM<a class="headerlink" href="#a-posteriori-dcsbm" title="Permalink to this headline">#</a></h3>
<p>The <em>a posteriori</em> DCSBM is to the <em>a posteriori</em> SBM what the <em>a priori</em> DCSBM was to the <em>a priori</em> SBM. The changes are very minimal, so we will omit explicitly writing it all down here so we can get this section wrapped up, with the idea that the preceding section on the <em>a priori</em> DCSBM should tell you what needs to change. We will leave it as an exercise to the reader to write down a model and probability statement for realizations of the DCSBM.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./appendix/ch11"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="ers.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">11.3. </span>Erdös-Rényi (ER) Random Networks</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="rdpgs.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">11.5. </span>RDPGs and more general network models</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Eric Bridgeford, Alex Loftus, and Joshua Vogelstein<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>