
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>14.3. Bayes Plugin Classifier &#8212; Hands-on Network Machine Learning with Scikit-Learn and Graspologic</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="prev" title="14.2. Unsupervised learning" href="unsupervised.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Hands-on Network Machine Learning with Scikit-Learn and Graspologic</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../coverpage.html">
                    Hands-on Network Machine Learning with Scikit-Learn and Graspologic
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/terminology.html">
   Terminology
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch1/ch1.html">
   1. The Network Machine Learning Landscape
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/what-is-a-network.html">
     1.1. What is network machine learning?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/why-study-networks.html">
     1.2. Why do we study networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/types-nml-problems.html">
     1.3. Types of Network Machine Learning Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/examples-of-applications.html">
     1.4. Examples of applications
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch2/ch2.html">
   2. End-to-end Biology Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/big-picture.html">
     2.1. Look at the big picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/get-the-data.html">
     2.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/prepare-the-data.html">
     2.3. Prepare the Data for Network Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/discover-and-visualize.html">
     2.4. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch3/ch3.html">
   3. End-to-end Business Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/big-picture.html">
     3.1. Look at the Big Picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/get-the-data.html">
     3.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/discover-and-visualize.html">
     3.3. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/prepare-the-data.html">
     3.4. Prepare the Data for Network Algorithms
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Representations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch4/ch4.html">
   4. Properties of Networks as a Statistical Object
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/matrix-representations.html">
     4.1. Matrix Representations Of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/properties-of-networks.html">
     4.2. Properties of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/network-representations.html">
     4.3. Representations of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch4/regularization.html">
     4.4. Regularization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch5/ch5.html">
   5. Why Use Statistical Models?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_ER.html">
     5.1. Erdös-Rényi (ER) Random Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_SBM.html">
     5.2. Stochastic Block Models (SBM)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_RDPG.html">
     5.3. Random Dot Product Graphs (RDPG)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/single-network-models_IER.html">
     5.4. Inhomogeneous Erdos Renyi (IER) Random Network Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/multi-network-models.html">
     5.5. Multiple Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch5/models-with-covariates.html">
     5.6. Network Models with Network Covariates
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../representations/ch6/ch6.html">
   6. Learning Network Representations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/estimating-parameters_mle.html">
     6.1. Estimating Parameters in Network Models via MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/why-embed-networks.html">
     6.2. Why embed networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/spectral-embedding.html">
     6.3. Spectral embedding methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/multigraph-representation-learning.html">
     6.4. Multiple-Network Representation Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../representations/ch6/joint-representation-learning.html">
     6.5. Joint Representation Learning
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch7/ch7.html">
   7. Applications When You Have One Network
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch7/community-detection.html">
     7.1. Community Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch7/testing-differences.html">
     7.2. Testing for Differences between Groups of Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch7/model-selection.html">
     7.3. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch7/single-vertex-nomination.html">
     7.4. Single-Network Vertex Nomination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch7/out-of-sample.html">
     7.5. Out-of-sample Embedding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch8/ch8.html">
   8. Applications for Two Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/two-sample-hypothesis.html">
     8.1. Latent Two-Sample Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/significant-communities.html">
     8.2. Two-sample hypothesis testing in SBMs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/graph-matching-vertex.html">
     8.3. Graph Matching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/multiple-vertex-nomination.html">
     8.4. Vertex Nomination For Two Networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch9/ch9.html">
   9. Applications for Many Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/anomaly-detection.html">
     9.1. Anomaly Detection For Timeseries of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/significant-edges.html">
     9.2. Testing for Significant Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/significant-vertices.html">
     9.3. Testing for Significant Vertices
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Next Steps
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../next/ch10/ch10.html">
   10. Where do we go from here?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Appendix
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch11/ch11.html">
   11. Representations (Extended)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch11/alt-reps.html">
     11.1. Alternative Network Representations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch12/ch12.html">
   12. Network Model Theory
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch12/background.html">
     12.1. Background
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch12/foundation.html">
     12.2. Foundation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch12/ers.html">
     12.3. Erdös-Rényi (ER) Random Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch12/sbms.html">
     12.4. Stochastic Block Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch12/rdpgs.html">
     12.5. RDPGs and more general network models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch13/ch13.html">
   13. Learning Representations Theory
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch13/mle-theory.html">
     13.1. Maximum Likelihood Estimate Theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch13/lse.html">
     13.2. Finding singular vectors With singular value decomposition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch13/spectral-theory.html">
     13.7. Spectral Method Theory
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="ch14.html">
   14. Applications (Extended)
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="hypothesis.html">
     14.1. Hypothesis Testing with coin flips
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="unsupervised.html">
     14.2. Unsupervised learning
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     14.3. Bayes Plugin Classifier
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://graspologic.readthedocs.io/en/latest/">
   Graspologic Documentation
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/neurodata/graph-stats-book/master?urlpath=tree/network_machine_learning_in_python/appendix/ch14/bayes.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/neurodata/graph-stats-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/neurodata/graph-stats-book/issues/new?title=Issue%20on%20page%20%2Fappendix/ch14/bayes.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/neurodata/graph-stats-book/edit/master/network_machine_learning_in_python/appendix/ch14/bayes.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/appendix/ch14/bayes.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Bayes Plugin Classifier</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="bayes-plugin-classifier">
<span id="app-ch14-bayes"></span><h1><span class="section-number">14.3. </span>Bayes Plugin Classifier<a class="headerlink" href="#bayes-plugin-classifier" title="Permalink to this headline">#</a></h1>
<p>In this next section, we will explain some of the intuition of the Naive Bayes classifer, which might require a bit of a probability and statistics background.</p>
<p>The core idea of the Naive Bayes classifier is, if our data have features which are zeros and ones, we can use the <em>class-conditional probabilities</em> to determine whether a point is from class <span class="math notranslate nohighlight">\(1\)</span> or class <span class="math notranslate nohighlight">\(2\)</span>. The idea is as follows. First, we assume that all of the individual features of our data (the features, in our case, are the edges of the network that are in the signal subnetwork) are independent, then the likelihood of observing a particular sequence of edges in the signal subnetwork of the <span class="math notranslate nohighlight">\(m^{th}\)</span> network if that network is in class <span class="math notranslate nohighlight">\(y\)</span> is as follows. First, we will just write down some simpler notation for the quantity we want:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    Pr(\text{observing }A^{(m)}\text{ given we assume $m$ is in class $y$} \text{ where the signal subnetwork is $\mathcal S$}) = Pr(A^{(m)} | y_m = y; \mathcal S)
\end{align*}\]</div>
<p>Nothing happened in this step just yet; we just made a smaller notation for the quantity on the left that we will use later on. In this next step, we use the fact that, if edges existing and not existing are independent, then the probability of observing a sequence of edges is the product of the probabilities of observing each individual edge. This is called an <em>independent edge assumption</em>. We proceed as follows:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    Pr(A^{(m)}| y_m = y; \mathcal S) &amp;= \prod_{(i,j) \in \mathcal S} Pr(a_{ij}^{(m)} | y_m = y; \mathcal S)
\end{align*}\]</div>
<p>Note that we are taking the product of each pair of edges, <span class="math notranslate nohighlight">\((i,j)\)</span>, which are in the signal sub-network. Next, if we remember back to the Independent-Edge Random Network (IER), we assumed that if <span class="math notranslate nohighlight">\(\mathbf A^{(m)}\)</span> was an <span class="math notranslate nohighlight">\(IER_n(P^y)\)</span> network, that every edge <span class="math notranslate nohighlight">\(\mathbf a_{ij}^{(m)}\)</span> had a probability of <span class="math notranslate nohighlight">\(p^y_{ij}\)</span> of taking a value of <span class="math notranslate nohighlight">\(1\)</span> (the edge exists), and a probability of <span class="math notranslate nohighlight">\(1 - p_{ij}^y\)</span> of taking a value of <span class="math notranslate nohighlight">\(0\)</span> (the edge does not exist). What this means is that <span class="math notranslate nohighlight">\(\mathbf a_{ij}^{(m)}\)</span> is something called a <strong>Bernoulli distributed random variable</strong>. The probability of seeing a particular realization <span class="math notranslate nohighlight">\(a_{ij}^{(m)}\)</span> of a Bernoulli distributed random variable is relatively straightforward to see. We want the quantity <span class="math notranslate nohighlight">\(Pr(A^{(m)} | y_m = y; \mathcal S)\)</span> to reflect the following two facts we’ve already discussed:</p>
<ol class="simple">
<li><p>If <span class="math notranslate nohighlight">\(a_{ij}^{(m)}\)</span> is <span class="math notranslate nohighlight">\(1\)</span>, then <span class="math notranslate nohighlight">\(Pr(A^{(m)} | \mathbf y_m = y; \mathcal S)\)</span> is <span class="math notranslate nohighlight">\(p_{ij}^y\)</span>.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(a_{ij}^{(m)}\)</span> is <span class="math notranslate nohighlight">\(0\)</span>, then <span class="math notranslate nohighlight">\(Pr(A^{(m)} | \mathbf y_m = y; \mathcal S)\)</span> is <span class="math notranslate nohighlight">\(1 - p_{ij}^y\)</span>.
Is there a succinct expression that we can express this with? Yes! Try the following equation:</p></li>
</ol>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    Pr(A^{(m)} | \mathbf y_m = y; \mathcal S) &amp;= (p_{ij}^y)^{a_{ij}^{(m)}} (1 - p_{ij}^y)^{1 - a_{ij}^{(m)}}
\end{align*}\]</div>
<p>Notice that if <span class="math notranslate nohighlight">\(a_{ij}^{(m)}\)</span> is <span class="math notranslate nohighlight">\(1\)</span>, then <span class="math notranslate nohighlight">\(1 - a_{ij}^{(m)}\)</span> is <span class="math notranslate nohighlight">\(0\)</span>. Therefore, <span class="math notranslate nohighlight">\((1 - p_{ij}^y)^{1 - a_{ij}^{(m)}}\)</span> is just <span class="math notranslate nohighlight">\(1\)</span>, since any number raised to the <span class="math notranslate nohighlight">\(0\)</span> power is <span class="math notranslate nohighlight">\(1\)</span>. On the other hand, <span class="math notranslate nohighlight">\((p_{ij}^y)^{a_{ij}^{(m)}}\)</span> is <span class="math notranslate nohighlight">\(p_{ij}^y\)</span>, since any number raised to the <span class="math notranslate nohighlight">\(1\)</span> power is itself. Therefore, this expression fits the bill for us. So, we can simplify our expression as:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
Pr(A^{(m)} | y_m = y; \mathcal S) &amp;= \prod_{(i,j) \in \mathcal S} (p_{ij}^y)^{a_{ij}^{(m)}} (1 - p_{ij}^y)^{1 - a_{ij}^{(m)}}
\end{align*}\]</div>
<p>And we’re almost there! The next thing we’re going to do is a little tricky, but fortunately we can turn to Bayes’ Theorem for help. What we want to do is compute the probability of observing <em>both</em> <span class="math notranslate nohighlight">\(A^{(m)}\)</span> <em>and</em> <span class="math notranslate nohighlight">\(y_m\)</span> having the value <span class="math notranslate nohighlight">\(y\)</span>, not the probability of observing <span class="math notranslate nohighlight">\(A^{(m)}\)</span> given that we assume that <span class="math notranslate nohighlight">\(y_m\)</span> is <span class="math notranslate nohighlight">\(y\)</span>. In statistical notation, what this amounts to is:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    Pr(\text{observing }A^{(m)}\text{ and }\text{$m$ is in class $y$} \text{ where the signal subnetwork is $\mathcal S$}) = Pr(A^{(m)}, y_m = y; \mathcal S)
\end{align*}\]</div>
<p>This expression is a little confusing, but its interpretation is relatively straightforward: it is the probability that we see both things happening at the same time (the random network <span class="math notranslate nohighlight">\(\mathbf A^{(m)}\)</span> takes the value <span class="math notranslate nohighlight">\(A^{(m)}\)</span> and the random class <span class="math notranslate nohighlight">\(\mathbf y_m\)</span> has the value <span class="math notranslate nohighlight">\(y\)</span>) rather than just assume that the random class <span class="math notranslate nohighlight">\(\mathbf y_m\)</span> already is <span class="math notranslate nohighlight">\(y\)</span>. We can compute this quantity by remembering <a class="reference external" href="#link?">Bayes’ Theorem</a>:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
     Pr(A^{(m)} |  \mathbb y_m = y; \mathcal S) &amp;= \frac{Pr(A^{(m)}, \mathbb y_m = y; \mathcal S)}{Pr(\mathbb y_m = y)}
\end{align*}\]</div>
<p>Note that this implies the following:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
Pr(A^{(m)}, \mathbb y_m = y; \mathcal S) &amp;= Pr(A^{(m)} | \mathbb y_m = y; \mathcal S)Pr(\mathbb y_m = y)
\end{align*}\]</div>
<p>Plugging in the value we obtained above:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
Pr(A^{(m)}, \mathbb y_m = y; \mathcal S) &amp;= Pr(\mathbb y_m = y)\prod_{(i, j) \in \mathcal S} (p_{ij}^y)^{a_{ij}^{(m)}} (1 - p_{ij}^y)^{1 - a_{ij}^{(m)}}
\end{align*}\]</div>
<p>Remember that the parameter of the signal subnetwork model, <span class="math notranslate nohighlight">\(\pi_y\)</span>, represented the probability of our <span class="math notranslate nohighlight">\(Y\)</span>-sided die landing on class <span class="math notranslate nohighlight">\(y\)</span>, and therefore was the probability that the random class <span class="math notranslate nohighlight">\(\mathbf y_m\)</span> took the value <span class="math notranslate nohighlight">\(y\)</span>. Therefore, <span class="math notranslate nohighlight">\(Pr(\mathbb y_m = y) = \pi_y\)</span>, since these two quantites represent the same thing! So:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
Pr(A^{(m)}, \mathbb y_m = y; \mathcal S) &amp;= \pi_y \prod_{(i, j) \in \mathcal S} (p_{ij}^y)^{a_{ij}^{(m)}} (1 - p_{ij}^y)^{1 - a_{ij}^{(m)}}
\end{align*}\]</div>
<p>Finally, we introduce a new quantity. This quantity is very similar to the above quantity we came across, but with some terms reversed:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    Pr(\text{$m$ is in class $y$}\text{ given we observe }A^{(m)} \text{ where the signal subnetwork is $\mathcal S$}) = Pr(\mathbb y_m = y | A^{(m)}; \mathcal S)
\end{align*}\]</div>
<p>Remember that we saw that using Bayes Theorem, we can just rewrite this expression as:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
Pr(\mathbb y_m = y | A^{(m)}; \mathcal S) &amp;= \frac{Pr(A^{(m)}, \mathbb y_m = y; \mathcal S)}{Pr(A^{(m)}; \mathcal S)}
\end{align*}\]</div>
<p>But using the expression we just obtained for <span class="math notranslate nohighlight">\(Pr(A^{(m)}, \mathbb y_m = y; \mathcal S)\)</span>, we can write this down as:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
Pr(\mathbb y_m = y | A^{(m)}; \mathcal S) &amp;= \frac{\pi_y \prod_{(i, j) \in \mathcal S} (p_{ij}^y)^{a_{ij}^{(m)}} (1 - p_{ij}^y)^{1 - a_{ij}^{(m)}}}{Pr(A^{(m)}; \mathcal S)}
\end{align*}\]</div>
<p>So, what this quantity tells us is the probability that item <span class="math notranslate nohighlight">\(m\)</span> is in class <span class="math notranslate nohighlight">\(y\)</span>, given that we observe that item <span class="math notranslate nohighlight">\(m\)</span> has the network <span class="math notranslate nohighlight">\(A^{(m)}\)</span> with signal subnetwork <span class="math notranslate nohighlight">\(\mathcal S\)</span>! When we have a new piece of data, this is an excellent quantity to compute! The reason for this is that, if we see a new network and want to assign it to a class, we want to choose the class that we think is most reasonable, or most probable. Therefore, given a new network to classify, it is reasonable to just estimate the class of this new network to be the class which is most probable, which is:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \hat y_m &amp;= \text{argmax}_{y \in \left\{1, ..., Y\right\}}Pr(\mathbb y_m = y | A^{(m)}; \mathcal S) \\
    &amp;= \text{argmax}_{y \in \left\{1,..., Y\right\}}\frac{\pi_y \prod_{(i, j) \in \mathcal S} (p_{ij}^y)^{a_{ij}^{(m)}} (1 - p_{ij}^y)^{1 - a_{ij}^{(m)}}}{Pr(A^{(m)}; \mathcal S)}
\end{align*}\]</div>
<p>What this states in words is, we check all possible values that <span class="math notranslate nohighlight">\(y\)</span> could take (1, 2, 3, … all the way to <span class="math notranslate nohighlight">\(Y\)</span>), and compute the probability that the class is <span class="math notranslate nohighlight">\(y\)</span> given the network we observed. Then, we just choose which of the values was most plausible, and return it for our prediction <span class="math notranslate nohighlight">\(\hat y_m\)</span>. But wait! We can simplify this expression even further. Note that the quantity <span class="math notranslate nohighlight">\(Pr(A^{(m)}; \mathcal S)\)</span> has <em>no</em> dependence on the particular class we are checking for a given value of <span class="math notranslate nohighlight">\(y\)</span>. This means that the denominator will be the same for all of the possible values of <span class="math notranslate nohighlight">\(y\)</span>, and therefore won’t impact which of the <span class="math notranslate nohighlight">\(y\)</span>s is the actual maximum. Therefore, we can just drop this term entirely, giving us the quantity that will become the objective function for our classification task:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\hat y_m &amp;= \text{argmax}_{y \in \left\{1,..., Y\right\}}\pi_y \prod_{(i, j) \in \mathcal S} (p_{ij}^y)^{a_{ij}^{(m)}} (1 - p_{ij}^y)^{1 - a_{ij}^{(m)}}
\end{align*}\]</div>
<p>Now what you might be wondering is, we don’t know <span class="math notranslate nohighlight">\(\mathcal S\)</span>, the vector <span class="math notranslate nohighlight">\(\vec \pi\)</span>, nor the probability matrices <span class="math notranslate nohighlight">\(P_1,..., P_Y\)</span>. This is why this is called a “Bayes Plugin” classifier. What we do is we estimate the signal subnetwork <span class="math notranslate nohighlight">\(\mathcal S\)</span> using the approach we outlined above to produce <span class="math notranslate nohighlight">\(\hat{\mathcal S}\)</span>, and then we use the class vector <span class="math notranslate nohighlight">\(\vec y\)</span> that we observed to produce estimates of <span class="math notranslate nohighlight">\(\vec \pi\)</span>, where:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \hat{\pi_y} &amp;= \frac{M_y}{M}
\end{align*}\]</div>
<p>where <span class="math notranslate nohighlight">\(M\)</span> is the total number of networks, and <span class="math notranslate nohighlight">\(M_y\)</span> is the number of networks where <span class="math notranslate nohighlight">\(y_m = y\)</span>. Finally, we compute the estimated probability entries, using:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \hat p_{ij}^y &amp;= \frac{1}{M_y} \sum_{m : y_m = y} a_{ij}^{(m)}
\end{align*}\]</div>
<p>What this means is that, for each edge <span class="math notranslate nohighlight">\((i,j)\)</span> which is in the estimated signal subnetwork <span class="math notranslate nohighlight">\(\hat{\mathcal S}\)</span>, we look at the <span class="math notranslate nohighlight">\(m\)</span>s where the class <span class="math notranslate nohighlight">\(y_m\)</span> is <span class="math notranslate nohighlight">\(y\)</span>, and then we just compute the fraction of the edges which exist across all of the <span class="math notranslate nohighlight">\(M_y\)</span> networks where <span class="math notranslate nohighlight">\(y_m = y\)</span>. Finally, we estimate the class for our new network <span class="math notranslate nohighlight">\(A^{(m)}\)</span> by just “plugging in” these values to the objective function:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \hat y_m &amp;= \text{argmax}_{y \in \left\{1,..., Y\right\}}\hat \pi_y \prod_{(i, j) \in \hat{\mathcal S}} (\hat p_{ij}^y)^{a_{ij}^{(m)}} (1 - \hat p_{ij}^y)^{1 - a_{ij}^{(m)}}
\end{align*}\]</div>
<p>which is the objective function for the Bayes Plugin classifier.</p>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./appendix/ch14"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="unsupervised.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">14.2. </span>Unsupervised learning</p>
        </div>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Eric Bridgeford, Alex Loftus, and Joshua Vogelstein<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>